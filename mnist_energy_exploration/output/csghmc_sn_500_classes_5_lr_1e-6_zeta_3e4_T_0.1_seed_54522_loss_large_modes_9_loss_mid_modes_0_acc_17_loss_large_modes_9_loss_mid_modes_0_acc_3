Namespace(N=50000, T=0.1, batch=5000, c='csghmc', classes=5, div=10, filters=16, gpu=0, hidden=10, ifprint=1.0, ifsave=1.0, lr=1e-06, part=1000000, seed=54522, sn=500, stepsize=0.01, warm=0.5, wdecay=25, zeta=30000.0)
adjust the learning rate 2.000e-06 weight decay 1.200e+01
(16, 1, 5, 5)
(16,)
(32, 16, 5, 5)
(32,)
(10, 1568)
(10,)
(5, 10)
(5,)
Current Theta
tensor([1.0000e-06, 1.0000e-06, 1.0000e-06,  ..., 1.0000e-06, 1.0000e-06,
        1.0000e-06], device='cuda:0')
Epoch 0 Iter 0 subLoss 48505.0 multi 1.00 import weight 1.00
Epoch 0 Iter 1 subLoss 47984.0 multi 1.00 import weight 1.00
Epoch 0 Iter 2 subLoss 47677.7 multi 1.00 import weight 1.00
Epoch 0 Iter 3 subLoss 47388.3 multi 1.00 import weight 1.00
Epoch 0 Iter 4 subLoss 47176.0 multi 1.00 import weight 1.00
Epoch 0 Iter 5 subLoss 46817.9 multi 1.00 import weight 1.00
Epoch 0 Iter 6 subLoss 46539.1 multi 1.00 import weight 1.00
Epoch 0 Iter 7 subLoss 46380.3 multi 1.00 import weight 1.00
Epoch 0 Iter 8 subLoss 45921.8 multi 1.00 import weight 1.00
Epoch 0 Iter 9 subLoss 45524.6 multi 1.00 import weight 1.00
Epoch 0 Iter 10 subLoss 45286.8 multi 1.00 import weight 1.00
Epoch 0 Iter 11 subLoss 45354.5 multi 1.00 import weight 1.00
Epoch 0 Acc: 42.11 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 1.00 Pidx 4535 train Loss: 45767.2 test Loss: 7347.9
Epoch 1 Iter 0 subLoss 44647.4 multi 1.00 import weight 1.00
Epoch 1 Iter 1 subLoss 44862.0 multi 1.00 import weight 1.00
Epoch 1 Iter 2 subLoss 44921.2 multi 1.00 import weight 1.00
Epoch 1 Iter 3 subLoss 45020.9 multi 1.00 import weight 1.00
Epoch 1 Iter 4 subLoss 43848.6 multi 1.00 import weight 1.00
Epoch 1 Iter 5 subLoss 42651.9 multi 1.00 import weight 1.00
Epoch 1 Iter 6 subLoss 42352.3 multi 1.00 import weight 1.00
Epoch 1 Iter 7 subLoss 43623.0 multi 1.00 import weight 1.00
Epoch 1 Iter 8 subLoss 43153.3 multi 1.00 import weight 1.00
Epoch 1 Iter 9 subLoss 41649.2 multi 1.00 import weight 1.00
Epoch 1 Iter 10 subLoss 39944.7 multi 1.00 import weight 1.00
Epoch 1 Iter 11 subLoss 39570.8 multi 1.00 import weight 1.00
Epoch 1 Acc: 59.06 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 1.00 Pidx 3957 train Loss: 41289.1 test Loss: 5869.6
Epoch 2 Iter 0 subLoss 39849.9 multi 1.00 import weight 1.00
Epoch 2 Iter 1 subLoss 43081.5 multi 1.00 import weight 1.00
Epoch 2 Iter 2 subLoss 39331.1 multi 1.00 import weight 1.00
Epoch 2 Iter 3 subLoss 37315.4 multi 1.00 import weight 1.00
Epoch 2 Iter 4 subLoss 37289.8 multi 1.00 import weight 1.00
Epoch 2 Iter 5 subLoss 35883.4 multi 1.00 import weight 1.00
Epoch 2 Iter 6 subLoss 37802.7 multi 1.00 import weight 1.00
Epoch 2 Iter 7 subLoss 39824.6 multi 1.00 import weight 1.00
Epoch 2 Iter 8 subLoss 33451.1 multi 1.00 import weight 1.00
Epoch 2 Iter 9 subLoss 33214.4 multi 1.00 import weight 1.00
Epoch 2 Iter 10 subLoss 34760.1 multi 1.00 import weight 1.00
Epoch 2 Iter 11 subLoss 37266.6 multi 1.00 import weight 1.00
Epoch 2 Acc: 40.30 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 1.00 Pidx 3726 train Loss: 45795.0 test Loss: 6762.6
Epoch 3 Iter 0 subLoss 45389.6 multi 1.00 import weight 1.00
Epoch 3 Iter 1 subLoss 39951.1 multi -1.99 import weight 1.00
Epoch 3 Iter 2 subLoss 69764.8 multi 1.00 import weight 1.00
Epoch 3 Iter 3 subLoss 45151.4 multi 1.00 import weight 1.00
Epoch 3 Iter 4 subLoss 43803.2 multi 1.00 import weight 1.00
Epoch 3 Iter 5 subLoss 42520.6 multi 1.00 import weight 1.00
Epoch 3 Iter 6 subLoss 41190.3 multi 1.00 import weight 1.00
Epoch 3 Iter 7 subLoss 40089.7 multi 1.00 import weight 1.00
Epoch 3 Iter 8 subLoss 37671.5 multi 1.00 import weight 1.00
Epoch 3 Iter 9 subLoss 35430.0 multi 1.00 import weight 1.00
Epoch 3 Iter 10 subLoss 32690.8 multi 1.00 import weight 1.00
Epoch 3 Iter 11 subLoss 31404.3 multi 1.00 import weight 1.00
Epoch 3 Acc: 75.52 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 1.00 Pidx 3140 train Loss: 31294.1 test Loss: 3916.3
Epoch 4 Iter 0 subLoss 31048.7 multi 1.00 import weight 1.00
Epoch 4 Iter 1 subLoss 31361.4 multi 1.00 import weight 1.00
Epoch 4 Iter 2 subLoss 38357.7 multi 1.00 import weight 1.00
Epoch 4 Iter 3 subLoss 55724.9 multi 1.00 import weight 1.00
Epoch 4 Iter 4 subLoss 34268.4 multi 1.00 import weight 1.00
Epoch 4 Iter 5 subLoss 31096.6 multi 1.00 import weight 1.00
Epoch 4 Iter 6 subLoss 29641.0 multi 1.00 import weight 1.00
Epoch 4 Iter 7 subLoss 28171.0 multi 1.00 import weight 1.00
Epoch 4 Iter 8 subLoss 27674.5 multi 1.00 import weight 1.00
Epoch 4 Iter 9 subLoss 26563.3 multi 1.00 import weight 1.00
Epoch 4 Iter 10 subLoss 26356.9 multi 1.00 import weight 1.00
Epoch 4 Iter 11 subLoss 25882.7 multi 1.00 import weight 1.00
Epoch 4 Acc: 81.05 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 1.00 Pidx 2588 train Loss: 27035.8 test Loss: 2915.8
Epoch 5 Iter 0 subLoss 27276.6 multi 1.00 import weight 1.00
Epoch 5 Iter 1 subLoss 35938.1 multi 1.00 import weight 1.00
Epoch 5 Iter 2 subLoss 51158.7 multi 1.00 import weight 1.00
Epoch 5 Iter 3 subLoss 40304.1 multi 1.00 import weight 1.00
Epoch 5 Iter 4 subLoss 34583.6 multi 1.00 import weight 1.00
Epoch 5 Iter 5 subLoss 29683.4 multi 1.00 import weight 1.00
Epoch 5 Iter 6 subLoss 26600.5 multi 1.00 import weight 1.00
Epoch 5 Iter 7 subLoss 24929.0 multi 1.00 import weight 1.00
Epoch 5 Iter 8 subLoss 23580.0 multi 1.00 import weight 1.00
Epoch 5 Iter 9 subLoss 22865.4 multi 1.00 import weight 1.00
Epoch 5 Iter 10 subLoss 23098.4 multi 1.00 import weight 1.00
Epoch 5 Iter 11 subLoss 23407.7 multi 1.00 import weight 1.00
Epoch 5 Acc: 72.35 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 1.00 Pidx 2340 train Loss: 33223.8 test Loss: 3639.7
Epoch 6 Iter 0 subLoss 32887.1 multi 1.00 import weight 1.00
Epoch 6 Iter 1 subLoss 66786.1 multi 1.00 import weight 1.00
Epoch 6 Iter 2 subLoss 59958.8 multi 1.00 import weight 1.00
Epoch 6 Iter 3 subLoss 41709.2 multi 1.00 import weight 1.00
Epoch 6 Iter 4 subLoss 37586.3 multi 1.00 import weight 1.00
Epoch 6 Iter 5 subLoss 35020.1 multi 1.00 import weight 1.00
Epoch 6 Iter 6 subLoss 32475.7 multi 1.00 import weight 1.00
Epoch 6 Iter 7 subLoss 30750.7 multi 1.00 import weight 1.00
Epoch 6 Iter 8 subLoss 29589.7 multi 1.00 import weight 1.00
Epoch 6 Iter 9 subLoss 27290.1 multi 1.00 import weight 1.00
Epoch 6 Iter 10 subLoss 25967.1 multi 1.00 import weight 1.00
Epoch 6 Iter 11 subLoss 25246.7 multi 1.00 import weight 1.00
Epoch 6 Acc: 84.22 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 1.00 Pidx 2524 train Loss: 24871.8 test Loss: 2591.5
Epoch 7 Iter 0 subLoss 24799.1 multi 1.00 import weight 1.00
Epoch 7 Iter 1 subLoss 23390.8 multi 1.00 import weight 1.00
Epoch 7 Iter 2 subLoss 23493.8 multi 1.00 import weight 1.00
Epoch 7 Iter 3 subLoss 22648.9 multi 1.00 import weight 1.00
Epoch 7 Iter 4 subLoss 22687.1 multi 1.00 import weight 1.00
Epoch 7 Iter 5 subLoss 25181.4 multi 1.00 import weight 1.00
Epoch 7 Iter 6 subLoss 32307.7 multi 1.00 import weight 1.00
Epoch 7 Iter 7 subLoss 29735.7 multi 1.00 import weight 1.00
Epoch 7 Iter 8 subLoss 24256.7 multi 1.00 import weight 1.00
Epoch 7 Iter 9 subLoss 20960.6 multi 1.00 import weight 1.00
Epoch 7 Iter 10 subLoss 20684.2 multi 1.00 import weight 1.00
Epoch 7 Iter 11 subLoss 20159.4 multi 1.00 import weight 1.00
Epoch 7 Acc: 87.18 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 1.00 Pidx 2015 train Loss: 19637.8 test Loss: 1948.7
Epoch 8 Iter 0 subLoss 19557.1 multi 1.00 import weight 1.00
Epoch 8 Iter 1 subLoss 19140.5 multi 1.00 import weight 1.00
Epoch 8 Iter 2 subLoss 19119.8 multi 1.00 import weight 1.00
Epoch 8 Iter 3 subLoss 20291.7 multi 1.00 import weight 1.00
Epoch 8 Iter 4 subLoss 24014.6 multi 1.00 import weight 1.00
Epoch 8 Iter 5 subLoss 21982.4 multi 1.00 import weight 1.00
Epoch 8 Iter 6 subLoss 24379.4 multi 1.00 import weight 1.00
Epoch 8 Iter 7 subLoss 17665.1 multi 1.00 import weight 1.00
Epoch 8 Iter 8 subLoss 17770.5 multi 1.00 import weight 1.00
Epoch 8 Iter 9 subLoss 16793.9 multi 1.00 import weight 1.00
Epoch 8 Iter 10 subLoss 21516.6 multi 1.00 import weight 1.00
Epoch 8 Iter 11 subLoss 31051.9 multi -1.99 import weight 1.00
Epoch 8 Acc: 19.67 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul -1.99 Pidx 3105 train Loss: 633592.6 test Loss: 111308.0
Epoch 9 Iter 0 subLoss 616804.2 multi 1.00 import weight 1.00
Epoch 9 Iter 1 subLoss 48514.6 multi -1.99 import weight 1.00
Epoch 9 Iter 2 subLoss 49062.1 multi 1.00 import weight 1.00
Epoch 9 Iter 3 subLoss 48756.8 multi 1.00 import weight 1.00
Epoch 9 Iter 4 subLoss 48017.1 multi 1.00 import weight 1.00
Epoch 9 Iter 5 subLoss 48143.1 multi 1.00 import weight 1.00
Epoch 9 Iter 6 subLoss 47818.8 multi 1.00 import weight 1.00
Epoch 9 Iter 7 subLoss 47037.1 multi 1.00 import weight 1.00
Epoch 9 Iter 8 subLoss 46125.7 multi 1.00 import weight 1.00
Epoch 9 Iter 9 subLoss 45588.0 multi 1.00 import weight 1.00
Epoch 9 Iter 10 subLoss 44615.3 multi 1.00 import weight 1.00
Epoch 9 Iter 11 subLoss 43953.4 multi 1.00 import weight 1.00
Epoch 9 Acc: 45.85 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 1.00 Pidx 4395 train Loss: 44381.5 test Loss: 7171.8
Epoch 10 Iter 0 subLoss 43463.9 multi 1.00 import weight 1.00
Epoch 10 Iter 1 subLoss 42898.9 multi 1.00 import weight 1.00
Epoch 10 Iter 2 subLoss 41796.4 multi 1.00 import weight 1.00
Epoch 10 Iter 3 subLoss 41291.1 multi 1.00 import weight 1.00
Epoch 10 Iter 4 subLoss 41114.8 multi 1.00 import weight 1.00
Epoch 10 Iter 5 subLoss 40404.9 multi 1.00 import weight 1.00
Epoch 10 Iter 6 subLoss 39956.2 multi 1.00 import weight 1.00
Epoch 10 Iter 7 subLoss 38904.4 multi 1.00 import weight 0.00
Epoch 10 Iter 8 subLoss 38640.1 multi 1.00 import weight 0.00
Epoch 10 Iter 9 subLoss 38644.0 multi 3.99 import weight 1.00
Epoch 10 Iter 10 subLoss 37463.3 multi 1.00 import weight 0.00
Epoch 10 Iter 11 subLoss 35862.4 multi 1.00 import weight 0.00
Epoch 10 Acc: 63.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 3586 train Loss: 36150.2 test Loss: 5346.3
Epoch 11 Iter 0 subLoss 35856.6 multi 1.00 import weight 0.00
Epoch 11 Iter 1 subLoss 35325.1 multi 1.00 import weight 0.00
Epoch 11 Iter 2 subLoss 34794.4 multi 1.00 import weight 0.00
Epoch 11 Iter 3 subLoss 33741.8 multi 1.00 import weight 0.00
Epoch 11 Iter 4 subLoss 33340.7 multi 1.00 import weight 0.00
Epoch 11 Iter 5 subLoss 33020.0 multi 1.00 import weight 0.00
Epoch 11 Iter 6 subLoss 32554.9 multi 1.00 import weight 0.00
Epoch 11 Iter 7 subLoss 32905.1 multi 1.00 import weight 0.00
Epoch 11 Iter 8 subLoss 32335.4 multi 1.00 import weight 0.00
Epoch 11 Iter 9 subLoss 31364.3 multi 3.99 import weight 1.00
Epoch 11 Iter 10 subLoss 30547.5 multi 1.00 import weight 0.00
Epoch 11 Iter 11 subLoss 29555.7 multi 1.00 import weight 0.00
Epoch 11 Acc: 74.08 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2955 train Loss: 29749.4 test Loss: 4151.4
Epoch 12 Iter 0 subLoss 28752.5 multi 1.00 import weight 0.00
Epoch 12 Iter 1 subLoss 28859.7 multi 1.00 import weight 0.00
Epoch 12 Iter 2 subLoss 28323.4 multi 1.00 import weight 0.00
Epoch 12 Iter 3 subLoss 27931.5 multi 1.00 import weight 0.00
Epoch 12 Iter 4 subLoss 27241.5 multi 1.00 import weight 0.00
Epoch 12 Iter 5 subLoss 27625.2 multi 1.00 import weight 0.00
Epoch 12 Iter 6 subLoss 27135.9 multi 1.00 import weight 0.00
Epoch 12 Iter 7 subLoss 27196.2 multi 1.00 import weight 0.00
Epoch 12 Iter 8 subLoss 27172.1 multi 1.00 import weight 0.00
Epoch 12 Iter 9 subLoss 26541.9 multi 1.00 import weight 0.00
Epoch 12 Iter 10 subLoss 26072.4 multi 1.00 import weight 0.00
Epoch 12 Iter 11 subLoss 27070.1 multi 1.00 import weight 0.00
Epoch 12 Acc: 70.87 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2707 train Loss: 28423.1 test Loss: 4138.5
Epoch 13 Iter 0 subLoss 27215.6 multi 1.00 import weight 0.00
Epoch 13 Iter 1 subLoss 28472.8 multi 1.00 import weight 0.00
Epoch 13 Iter 2 subLoss 27955.0 multi 1.00 import weight 0.00
Epoch 13 Iter 3 subLoss 25603.6 multi 1.00 import weight 0.00
Epoch 13 Iter 4 subLoss 25066.9 multi 1.00 import weight 0.00
Epoch 13 Iter 5 subLoss 24173.0 multi 1.00 import weight 0.00
Epoch 13 Iter 6 subLoss 23077.8 multi 1.00 import weight 0.00
Epoch 13 Iter 7 subLoss 23609.4 multi 1.00 import weight 0.00
Epoch 13 Iter 8 subLoss 25420.7 multi 1.00 import weight 0.00
Epoch 13 Iter 9 subLoss 26454.7 multi 1.00 import weight 0.00
Epoch 13 Iter 10 subLoss 30312.0 multi 1.00 import weight 0.00
Epoch 13 Iter 11 subLoss 22146.3 multi 1.00 import weight 0.00
Epoch 13 Acc: 87.02 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2214 train Loss: 21969.6 test Loss: 2748.2
Epoch 14 Iter 0 subLoss 22103.4 multi 1.00 import weight 0.00
Epoch 14 Iter 1 subLoss 20851.8 multi 1.00 import weight 0.00
Epoch 14 Iter 2 subLoss 19884.1 multi 1.00 import weight 0.00
Epoch 14 Iter 3 subLoss 20175.9 multi 1.00 import weight 0.00
Epoch 14 Iter 4 subLoss 20974.5 multi -1.99 import weight 0.00
Epoch 14 Iter 5 subLoss 134213.4 multi 1.00 import weight 0.00
Epoch 14 Iter 6 subLoss 48106.2 multi 1.00 import weight 0.00
Epoch 14 Iter 7 subLoss 41819.6 multi 1.00 import weight 0.00
Epoch 14 Iter 8 subLoss 38805.1 multi 1.00 import weight 0.00
Epoch 14 Iter 9 subLoss 36972.9 multi 1.00 import weight 0.00
Epoch 14 Iter 10 subLoss 35986.8 multi 1.00 import weight 0.00
Epoch 14 Iter 11 subLoss 35590.0 multi 1.00 import weight 0.00
Epoch 14 Acc: 70.46 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 3559 train Loss: 35414.9 test Loss: 5299.5
Epoch 15 Iter 0 subLoss 34490.2 multi 1.00 import weight 0.00
Epoch 15 Iter 1 subLoss 33610.5 multi 1.00 import weight 0.00
Epoch 15 Iter 2 subLoss 33767.6 multi 1.00 import weight 0.00
Epoch 15 Iter 3 subLoss 33161.7 multi 1.00 import weight 0.00
Epoch 15 Iter 4 subLoss 31632.3 multi 1.00 import weight 0.00
Epoch 15 Iter 5 subLoss 31146.3 multi 1.00 import weight 0.00
Epoch 15 Iter 6 subLoss 30213.8 multi 1.00 import weight 0.00
Epoch 15 Iter 7 subLoss 29303.4 multi 1.00 import weight 0.00
Epoch 15 Iter 8 subLoss 28461.5 multi 1.00 import weight 0.00
Epoch 15 Iter 9 subLoss 27568.4 multi 1.00 import weight 0.00
Epoch 15 Iter 10 subLoss 26429.8 multi 1.00 import weight 0.00
Epoch 15 Iter 11 subLoss 26487.2 multi 1.00 import weight 0.00
Epoch 15 Acc: 69.06 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2648 train Loss: 26021.4 test Loss: 3662.0
Epoch 16 Iter 0 subLoss 25832.4 multi 1.00 import weight 0.00
Epoch 16 Iter 1 subLoss 24609.6 multi 1.00 import weight 0.00
Epoch 16 Iter 2 subLoss 24066.5 multi 1.00 import weight 0.00
Epoch 16 Iter 3 subLoss 23984.1 multi 1.00 import weight 0.00
Epoch 16 Iter 4 subLoss 24385.8 multi -1.99 import weight 0.00
Epoch 16 Iter 5 subLoss 33250.1 multi 1.00 import weight 0.00
Epoch 16 Iter 6 subLoss 28431.9 multi 1.00 import weight 0.00
Epoch 16 Iter 7 subLoss 27959.8 multi 3.99 import weight 1.00
Epoch 16 Iter 8 subLoss 153241.2 multi 1.00 import weight 0.00
Epoch 16 Iter 9 subLoss 47693.1 multi 1.00 import weight 0.00
Epoch 16 Iter 10 subLoss 47178.2 multi 3.99 import weight 1.00
Epoch 16 Iter 11 subLoss 44753.4 multi 1.00 import weight 0.00
Epoch 16 Acc: 31.35 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4475 train Loss: 44994.7 test Loss: 7165.2
Epoch 17 Iter 0 subLoss 43891.0 multi 1.00 import weight 0.00
Epoch 17 Iter 1 subLoss 43434.3 multi 1.00 import weight 0.00
Epoch 17 Iter 2 subLoss 41987.8 multi 1.00 import weight 0.00
Epoch 17 Iter 3 subLoss 41147.1 multi 1.00 import weight 0.00
Epoch 17 Iter 4 subLoss 39338.1 multi 3.99 import weight 1.00
Epoch 17 Iter 5 subLoss 34935.1 multi 1.00 import weight 0.00
Epoch 17 Iter 6 subLoss 33573.3 multi 1.00 import weight 0.00
Epoch 17 Iter 7 subLoss 32356.5 multi 1.00 import weight 0.00
Epoch 17 Iter 8 subLoss 30992.1 multi 1.00 import weight 0.00
Epoch 17 Iter 9 subLoss 29276.8 multi 1.00 import weight 0.00
Epoch 17 Iter 10 subLoss 28958.5 multi 1.00 import weight 0.00
Epoch 17 Iter 11 subLoss 30319.5 multi 3.99 import weight 1.00
Epoch 17 Acc: 19.69 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 3.99 Pidx 3031 train Loss: 78312.9 test Loss: 13958.5
Epoch 18 Iter 0 subLoss 76711.1 multi 1.00 import weight 0.00
Epoch 18 Iter 1 subLoss 42632.8 multi 1.00 import weight 0.00
Epoch 18 Iter 2 subLoss 38039.7 multi 1.00 import weight 0.00
Epoch 18 Iter 3 subLoss 35347.3 multi 1.00 import weight 0.00
Epoch 18 Iter 4 subLoss 33884.9 multi 1.00 import weight 0.00
Epoch 18 Iter 5 subLoss 31927.4 multi 1.00 import weight 0.00
Epoch 18 Iter 6 subLoss 30781.6 multi 1.00 import weight 0.00
Epoch 18 Iter 7 subLoss 29899.5 multi 1.00 import weight 0.00
Epoch 18 Iter 8 subLoss 29106.6 multi 1.00 import weight 0.00
Epoch 18 Iter 9 subLoss 28689.2 multi 1.00 import weight 0.00
Epoch 18 Iter 10 subLoss 28122.0 multi 1.00 import weight 0.00
Epoch 18 Iter 11 subLoss 27561.0 multi 3.99 import weight 1.00
Epoch 18 Acc: 60.07 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 3.99 Pidx 2756 train Loss: 26965.2 test Loss: 3835.3
Epoch 19 Iter 0 subLoss 26062.6 multi 1.00 import weight 0.00
Epoch 19 Iter 1 subLoss 26225.7 multi 1.00 import weight 0.00
Epoch 19 Iter 2 subLoss 25345.4 multi 1.00 import weight 0.00
Epoch 19 Iter 3 subLoss 25141.5 multi 1.00 import weight 0.00
Epoch 19 Iter 4 subLoss 25050.2 multi 1.00 import weight 0.00
Epoch 19 Iter 5 subLoss 24654.2 multi 1.00 import weight 0.00
Epoch 19 Iter 6 subLoss 25030.5 multi 1.00 import weight 0.00
Epoch 19 Iter 7 subLoss 24902.6 multi 1.00 import weight 0.00
Epoch 19 Iter 8 subLoss 24805.2 multi -1.99 import weight 0.00
Epoch 19 Iter 9 subLoss 25280.7 multi 1.00 import weight 0.00
Epoch 19 Iter 10 subLoss 24564.7 multi 1.00 import weight 0.00
Epoch 19 Iter 11 subLoss 25148.8 multi 3.99 import weight 1.00
Epoch 19 Acc: 71.24 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 3.99 Pidx 2514 train Loss: 24125.9 test Loss: 3336.6
Epoch 20 Iter 0 subLoss 23815.6 multi 1.00 import weight 0.00
Epoch 20 Iter 1 subLoss 23392.1 multi 3.99 import weight 1.00
Epoch 20 Iter 2 subLoss 25563.5 multi 1.00 import weight 0.00
Epoch 20 Iter 3 subLoss 24429.8 multi 1.00 import weight 0.00
Epoch 20 Iter 4 subLoss 22858.2 multi 1.00 import weight 0.00
Epoch 20 Iter 5 subLoss 22628.6 multi 1.00 import weight 0.00
Epoch 20 Iter 6 subLoss 22590.4 multi 1.00 import weight 0.00
Epoch 20 Iter 7 subLoss 21796.9 multi 1.00 import weight 0.00
Epoch 20 Iter 8 subLoss 21486.3 multi 1.00 import weight 0.00
Epoch 20 Iter 9 subLoss 21436.0 multi 1.00 import weight 0.00
Epoch 20 Iter 10 subLoss 21387.6 multi 1.00 import weight 0.00
Epoch 20 Iter 11 subLoss 20540.2 multi 1.00 import weight 0.00
Epoch 20 Acc: 77.45 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2054 train Loss: 21194.1 test Loss: 2772.0
Epoch 21 Iter 0 subLoss 20992.2 multi 1.00 import weight 0.00
Epoch 21 Iter 1 subLoss 20246.3 multi 1.00 import weight 0.00
Epoch 21 Iter 2 subLoss 21056.8 multi 1.00 import weight 0.00
Epoch 21 Iter 3 subLoss 20130.9 multi 1.00 import weight 0.00
Epoch 21 Iter 4 subLoss 20126.2 multi 1.00 import weight 0.00
Epoch 21 Iter 5 subLoss 20013.0 multi 1.00 import weight 0.00
Epoch 21 Iter 6 subLoss 19845.2 multi 1.00 import weight 0.00
Epoch 21 Iter 7 subLoss 19585.3 multi 1.00 import weight 0.00
Epoch 21 Iter 8 subLoss 18737.8 multi 1.00 import weight 0.00
Epoch 21 Iter 9 subLoss 18553.5 multi 1.00 import weight 0.00
Epoch 21 Iter 10 subLoss 18525.9 multi 1.00 import weight 0.00
Epoch 21 Iter 11 subLoss 18387.9 multi 1.00 import weight 0.00
Epoch 21 Acc: 79.33 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1838 train Loss: 18630.5 test Loss: 2292.4
Epoch 22 Iter 0 subLoss 18476.8 multi 1.00 import weight 0.00
Epoch 22 Iter 1 subLoss 18303.7 multi 1.00 import weight 0.00
Epoch 22 Iter 2 subLoss 17559.6 multi 1.00 import weight 0.00
Epoch 22 Iter 3 subLoss 17182.7 multi 1.00 import weight 0.00
Epoch 22 Iter 4 subLoss 17418.8 multi 1.00 import weight 0.00
Epoch 22 Iter 5 subLoss 17726.4 multi 1.00 import weight 0.00
Epoch 22 Iter 6 subLoss 17407.8 multi 1.00 import weight 0.00
Epoch 22 Iter 7 subLoss 18354.7 multi 1.00 import weight 0.00
Epoch 22 Iter 8 subLoss 19484.9 multi 1.00 import weight 0.00
Epoch 22 Iter 9 subLoss 20736.3 multi 1.00 import weight 0.00
Epoch 22 Iter 10 subLoss 20477.1 multi 1.00 import weight 0.00
Epoch 22 Iter 11 subLoss 18785.9 multi 1.00 import weight 0.00
Epoch 22 Acc: 83.03 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1878 train Loss: 18112.6 test Loss: 2169.3
Epoch 23 Iter 0 subLoss 17448.6 multi 1.00 import weight 0.00
Epoch 23 Iter 1 subLoss 17551.7 multi 3.99 import weight 1.00
Epoch 23 Iter 2 subLoss 77054.0 multi 1.00 import weight 0.00
Epoch 23 Iter 3 subLoss 45991.2 multi 1.00 import weight 0.00
Epoch 23 Iter 4 subLoss 33151.8 multi 1.00 import weight 0.00
Epoch 23 Iter 5 subLoss 24348.6 multi 1.00 import weight 0.00
Epoch 23 Iter 6 subLoss 22096.2 multi 1.00 import weight 0.00
Epoch 23 Iter 7 subLoss 21135.0 multi 1.00 import weight 0.00
Epoch 23 Iter 8 subLoss 20833.3 multi 1.00 import weight 0.00
Epoch 23 Iter 9 subLoss 19774.5 multi 1.00 import weight 0.00
Epoch 23 Iter 10 subLoss 19294.1 multi 1.00 import weight 0.00
Epoch 23 Iter 11 subLoss 18927.2 multi 1.00 import weight 0.00
Epoch 23 Acc: 79.49 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1892 train Loss: 18701.7 test Loss: 2417.4
Epoch 24 Iter 0 subLoss 18848.5 multi 1.00 import weight 0.00
Epoch 24 Iter 1 subLoss 17843.1 multi 1.00 import weight 0.00
Epoch 24 Iter 2 subLoss 18025.2 multi 1.00 import weight 0.00
Epoch 24 Iter 3 subLoss 17277.4 multi 1.00 import weight 0.00
Epoch 24 Iter 4 subLoss 16432.9 multi 1.00 import weight 0.00
Epoch 24 Iter 5 subLoss 16447.9 multi -1.99 import weight 0.00
Epoch 24 Iter 6 subLoss 16837.6 multi 1.00 import weight 0.00
Epoch 24 Iter 7 subLoss 16743.6 multi 1.00 import weight 0.00
Epoch 24 Iter 8 subLoss 16413.2 multi 1.00 import weight 0.00
Epoch 24 Iter 9 subLoss 16333.3 multi 1.00 import weight 0.00
Epoch 24 Iter 10 subLoss 15740.8 multi 1.00 import weight 0.00
Epoch 24 Iter 11 subLoss 15603.9 multi 1.00 import weight 0.00
Epoch 24 Acc: 81.38 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1560 train Loss: 15794.9 test Loss: 1912.5
Epoch 25 Iter 0 subLoss 15267.6 multi 1.00 import weight 0.00
Epoch 25 Iter 1 subLoss 15045.8 multi 1.00 import weight 0.00
Epoch 25 Iter 2 subLoss 15622.5 multi 1.00 import weight 0.00
Epoch 25 Iter 3 subLoss 15171.9 multi 1.00 import weight 0.00
Epoch 25 Iter 4 subLoss 15018.5 multi 1.00 import weight 0.00
Epoch 25 Iter 5 subLoss 14488.3 multi 1.00 import weight 0.00
Epoch 25 Iter 6 subLoss 14380.0 multi 1.00 import weight 0.00
Epoch 25 Iter 7 subLoss 14132.1 multi 1.00 import weight 0.00
Epoch 25 Iter 8 subLoss 14223.2 multi 1.00 import weight 0.00
Epoch 25 Iter 9 subLoss 13508.5 multi 1.00 import weight 0.00
Epoch 25 Iter 10 subLoss 14333.8 multi 1.00 import weight 0.00
Epoch 25 Iter 11 subLoss 13676.7 multi 1.00 import weight 0.00
Epoch 25 Acc: 90.83 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1367 train Loss: 14186.6 test Loss: 1605.8
Epoch 26 Iter 0 subLoss 13879.9 multi 1.00 import weight 0.00
Epoch 26 Iter 1 subLoss 14392.7 multi -1.99 import weight 0.00
Epoch 26 Iter 2 subLoss 25089.9 multi 1.00 import weight 0.00
Epoch 26 Iter 3 subLoss 23120.0 multi 1.00 import weight 0.00
Epoch 26 Iter 4 subLoss 18491.6 multi 1.00 import weight 0.00
Epoch 26 Iter 5 subLoss 15527.4 multi 1.00 import weight 0.00
Epoch 26 Iter 6 subLoss 14114.2 multi 1.00 import weight 0.00
Epoch 26 Iter 7 subLoss 13554.0 multi 1.00 import weight 0.00
Epoch 26 Iter 8 subLoss 14225.7 multi 3.99 import weight 1.00
Epoch 26 Iter 9 subLoss 13205.6 multi 1.00 import weight 0.00
Epoch 26 Iter 10 subLoss 13124.3 multi 1.00 import weight 0.00
Epoch 26 Iter 11 subLoss 12946.6 multi 1.00 import weight 0.00
Epoch 26 Acc: 93.42 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1294 train Loss: 13120.7 test Loss: 1360.4
Epoch 27 Iter 0 subLoss 12950.7 multi -1.99 import weight 0.00
Epoch 27 Iter 1 subLoss 13703.1 multi 1.00 import weight 0.00
Epoch 27 Iter 2 subLoss 13589.5 multi 1.00 import weight 0.00
Epoch 27 Iter 3 subLoss 12969.4 multi -1.99 import weight 0.00
Epoch 27 Iter 4 subLoss 20373.3 multi 1.00 import weight 0.00
Epoch 27 Iter 5 subLoss 17037.8 multi 1.00 import weight 0.00
Epoch 27 Iter 6 subLoss 14656.4 multi 1.00 import weight 0.00
Epoch 27 Iter 7 subLoss 13578.6 multi 1.00 import weight 0.00
Epoch 27 Iter 8 subLoss 12668.0 multi 1.00 import weight 0.00
Epoch 27 Iter 9 subLoss 12197.9 multi 1.00 import weight 0.00
Epoch 27 Iter 10 subLoss 13038.7 multi 1.00 import weight 0.00
Epoch 27 Iter 11 subLoss 12521.4 multi 1.00 import weight 0.00
Epoch 27 Acc: 92.99 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1252 train Loss: 12638.3 test Loss: 1231.8
Epoch 28 Iter 0 subLoss 12320.5 multi 1.00 import weight 0.00
Epoch 28 Iter 1 subLoss 12354.1 multi 1.00 import weight 0.00
Epoch 28 Iter 2 subLoss 11919.5 multi 1.00 import weight 0.00
Epoch 28 Iter 3 subLoss 11563.0 multi 1.00 import weight 0.00
Epoch 28 Iter 4 subLoss 12499.7 multi 1.00 import weight 0.00
Epoch 28 Iter 5 subLoss 11697.5 multi 1.00 import weight 0.00
Epoch 28 Iter 6 subLoss 11694.1 multi 3.99 import weight 1.00
Epoch 28 Iter 7 subLoss 12868.0 multi 1.00 import weight 0.00
Epoch 28 Iter 8 subLoss 13338.8 multi 1.00 import weight 0.00
Epoch 28 Iter 9 subLoss 11835.6 multi 1.00 import weight 0.00
Epoch 28 Iter 10 subLoss 12217.9 multi 1.00 import weight 0.00
Epoch 28 Iter 11 subLoss 12804.9 multi 1.00 import weight 0.00
Epoch 28 Acc: 93.75 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1280 train Loss: 13215.2 test Loss: 1178.0
Epoch 29 Iter 0 subLoss 12615.4 multi 1.00 import weight 0.00
Epoch 29 Iter 1 subLoss 12329.2 multi 3.99 import weight 1.00
Epoch 29 Iter 2 subLoss 58278.6 multi 1.00 import weight 0.00
Epoch 29 Iter 3 subLoss 24553.4 multi 1.00 import weight 0.00
Epoch 29 Iter 4 subLoss 14333.6 multi 3.99 import weight 1.00
Epoch 29 Iter 5 subLoss 14064.3 multi 1.00 import weight 0.00
Epoch 29 Iter 6 subLoss 11349.0 multi 1.00 import weight 0.00
Epoch 29 Iter 7 subLoss 10012.0 multi 1.00 import weight 0.00
Epoch 29 Iter 8 subLoss 10798.5 multi 1.00 import weight 0.00
Epoch 29 Iter 9 subLoss 10454.8 multi 1.00 import weight 0.00
Epoch 29 Iter 10 subLoss 10207.8 multi 1.00 import weight 0.00
Epoch 29 Iter 11 subLoss 9513.5 multi 1.00 import weight 0.00
Epoch 29 Acc: 96.61 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 951 train Loss: 10002.1 test Loss: 714.5
Epoch 30 Iter 0 subLoss 9727.3 multi 1.00 import weight 0.00
Epoch 30 Iter 1 subLoss 9982.8 multi 1.00 import weight 0.00
Epoch 30 Iter 2 subLoss 9932.6 multi 1.00 import weight 0.00
Epoch 30 Iter 3 subLoss 9420.9 multi 1.00 import weight 0.00
Epoch 30 Iter 4 subLoss 9371.0 multi 1.00 import weight 0.00
Epoch 30 Iter 5 subLoss 9354.7 multi 1.00 import weight 0.00
Epoch 30 Iter 6 subLoss 8931.1 multi 1.00 import weight 0.00
Epoch 30 Iter 7 subLoss 9375.0 multi 3.99 import weight 1.00
Epoch 30 Iter 8 subLoss 14231.9 multi -4.97 import weight 0.00
Epoch 30 Iter 9 subLoss 873675.8 multi 1.00 import weight 0.00
Epoch 30 Iter 10 subLoss 58908.8 multi 1.00 import weight 0.00
Epoch 30 Iter 11 subLoss 48904.5 multi 1.00 import weight 0.00
Epoch 30 Acc: 19.34 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4890 train Loss: 49111.8 test Loss: 8338.4
Epoch 31 Iter 0 subLoss 47893.9 multi 1.00 import weight 0.00
Epoch 31 Iter 1 subLoss 47312.4 multi 1.00 import weight 0.00
Epoch 31 Iter 2 subLoss 44956.9 multi 1.00 import weight 0.00
Epoch 31 Iter 3 subLoss 42889.4 multi 1.00 import weight 0.00
Epoch 31 Iter 4 subLoss 41828.6 multi -1.99 import weight 0.00
Epoch 31 Iter 5 subLoss 45647.0 multi 1.00 import weight 0.00
Epoch 31 Iter 6 subLoss 43614.7 multi 1.00 import weight 0.00
Epoch 31 Iter 7 subLoss 42324.0 multi 1.00 import weight 0.00
Epoch 31 Iter 8 subLoss 40625.8 multi 1.00 import weight 0.00
Epoch 31 Iter 9 subLoss 39019.7 multi 1.00 import weight 0.00
Epoch 31 Iter 10 subLoss 37482.4 multi 1.00 import weight 0.00
Epoch 31 Iter 11 subLoss 35852.0 multi 3.99 import weight 1.00
Epoch 31 Acc: 59.68 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 3.99 Pidx 3585 train Loss: 34460.1 test Loss: 5105.2
Epoch 32 Iter 0 subLoss 33142.6 multi 1.00 import weight 0.00
Epoch 32 Iter 1 subLoss 37693.3 multi 1.00 import weight 0.00
Epoch 32 Iter 2 subLoss 29001.6 multi 1.00 import weight 0.00
Epoch 32 Iter 3 subLoss 27284.4 multi -1.99 import weight 0.00
Epoch 32 Iter 4 subLoss 36691.3 multi 1.00 import weight 0.00
Epoch 32 Iter 5 subLoss 28372.0 multi 1.00 import weight 0.00
Epoch 32 Iter 6 subLoss 25615.7 multi -1.99 import weight 0.00
Epoch 32 Iter 7 subLoss 28698.7 multi -1.99 import weight 0.00
Epoch 32 Iter 8 subLoss 32513.6 multi 1.00 import weight 0.00
Epoch 32 Iter 9 subLoss 29638.5 multi 1.00 import weight 0.00
Epoch 32 Iter 10 subLoss 28739.4 multi 1.00 import weight 0.00
Epoch 32 Iter 11 subLoss 27837.5 multi 1.00 import weight 0.00
Epoch 32 Acc: 79.84 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2783 train Loss: 26800.6 test Loss: 3641.4
Epoch 33 Iter 0 subLoss 25825.9 multi 1.00 import weight 0.00
Epoch 33 Iter 1 subLoss 26161.7 multi 1.00 import weight 0.00
Epoch 33 Iter 2 subLoss 24505.2 multi 1.00 import weight 0.00
Epoch 33 Iter 3 subLoss 23699.2 multi 1.00 import weight 0.00
Epoch 33 Iter 4 subLoss 23487.1 multi 1.00 import weight 0.00
Epoch 33 Iter 5 subLoss 22009.5 multi 1.00 import weight 0.00
Epoch 33 Iter 6 subLoss 22189.2 multi 1.00 import weight 0.00
Epoch 33 Iter 7 subLoss 21123.9 multi 1.00 import weight 0.00
Epoch 33 Iter 8 subLoss 20802.0 multi 1.00 import weight 0.00
Epoch 33 Iter 9 subLoss 20183.1 multi -1.99 import weight 0.00
Epoch 33 Iter 10 subLoss 21861.8 multi 1.00 import weight 0.00
Epoch 33 Iter 11 subLoss 22229.2 multi 1.00 import weight 0.00
Epoch 33 Acc: 84.14 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2222 train Loss: 21252.2 test Loss: 2703.0
Epoch 34 Iter 0 subLoss 20712.3 multi 1.00 import weight 0.00
Epoch 34 Iter 1 subLoss 20624.1 multi 1.00 import weight 0.00
Epoch 34 Iter 2 subLoss 20099.6 multi 1.00 import weight 0.00
Epoch 34 Iter 3 subLoss 20380.3 multi -1.99 import weight 0.00
Epoch 34 Iter 4 subLoss 38433.8 multi 1.00 import weight 0.00
Epoch 34 Iter 5 subLoss 26250.3 multi 1.00 import weight 0.00
Epoch 34 Iter 6 subLoss 22510.6 multi 1.00 import weight 0.00
Epoch 34 Iter 7 subLoss 20074.9 multi 1.00 import weight 0.00
Epoch 34 Iter 8 subLoss 19722.2 multi 1.00 import weight 0.00
Epoch 34 Iter 9 subLoss 19252.4 multi 1.00 import weight 0.00
Epoch 34 Iter 10 subLoss 18972.2 multi 1.00 import weight 0.00
Epoch 34 Iter 11 subLoss 18238.7 multi 1.00 import weight 0.00
Epoch 34 Acc: 88.31 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1823 train Loss: 18550.2 test Loss: 2201.6
Epoch 35 Iter 0 subLoss 17914.5 multi 1.00 import weight 0.00
Epoch 35 Iter 1 subLoss 17806.2 multi 1.00 import weight 0.00
Epoch 35 Iter 2 subLoss 17565.0 multi -4.97 import weight 0.00
Epoch 35 Iter 3 subLoss 21645.3 multi 1.00 import weight 0.00
Epoch 35 Iter 4 subLoss 18732.8 multi 3.99 import weight 1.00
Epoch 35 Iter 5 subLoss 27890.1 multi 1.00 import weight 0.00
Epoch 35 Iter 6 subLoss 27365.3 multi 1.00 import weight 0.00
Epoch 35 Iter 7 subLoss 19219.8 multi 1.00 import weight 0.00
Epoch 35 Iter 8 subLoss 17936.5 multi 1.00 import weight 0.00
Epoch 35 Iter 9 subLoss 17697.1 multi 1.00 import weight 0.00
Epoch 35 Iter 10 subLoss 17598.6 multi 1.00 import weight 0.00
Epoch 35 Iter 11 subLoss 17637.6 multi 1.00 import weight 0.00
Epoch 35 Acc: 91.46 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1763 train Loss: 17140.6 test Loss: 1982.7
Epoch 36 Iter 0 subLoss 16916.8 multi 1.00 import weight 0.00
Epoch 36 Iter 1 subLoss 16927.8 multi -1.99 import weight 0.00
Epoch 36 Iter 2 subLoss 17329.4 multi 1.00 import weight 0.00
Epoch 36 Iter 3 subLoss 16615.5 multi 1.00 import weight 0.00
Epoch 36 Iter 4 subLoss 16172.8 multi 1.00 import weight 0.00
Epoch 36 Iter 5 subLoss 16489.9 multi 1.00 import weight 0.00
Epoch 36 Iter 6 subLoss 16492.8 multi -1.99 import weight 0.00
Epoch 36 Iter 7 subLoss 16704.4 multi 1.00 import weight 0.00
Epoch 36 Iter 8 subLoss 16658.3 multi 1.00 import weight 0.00
Epoch 36 Iter 9 subLoss 16433.1 multi 3.99 import weight 1.00
Epoch 36 Iter 10 subLoss 16385.0 multi 1.00 import weight 0.00
Epoch 36 Iter 11 subLoss 15337.3 multi 1.00 import weight 0.00
Epoch 36 Acc: 93.23 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1533 train Loss: 15380.2 test Loss: 1682.2
Epoch 37 Iter 0 subLoss 15201.0 multi 1.00 import weight 0.00
Epoch 37 Iter 1 subLoss 15076.8 multi 1.00 import weight 0.00
Epoch 37 Iter 2 subLoss 14688.0 multi 1.00 import weight 0.00
Epoch 37 Iter 3 subLoss 13668.2 multi 1.00 import weight 0.00
Epoch 37 Iter 4 subLoss 15082.2 multi -1.99 import weight 0.00
Epoch 37 Iter 5 subLoss 15694.2 multi 1.00 import weight 0.00
Epoch 37 Iter 6 subLoss 14400.9 multi -1.99 import weight 0.00
Epoch 37 Iter 7 subLoss 22936.5 multi 1.00 import weight 0.00
Epoch 37 Iter 8 subLoss 18300.5 multi 3.99 import weight 1.00
Epoch 37 Iter 9 subLoss 71943.5 multi 1.00 import weight 0.00
Epoch 37 Iter 10 subLoss 40022.5 multi 1.00 import weight 0.00
Epoch 37 Iter 11 subLoss 36353.1 multi 1.00 import weight 0.00
Epoch 37 Acc: 73.81 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 3635 train Loss: 31279.9 test Loss: 4247.6
Epoch 38 Iter 0 subLoss 30366.3 multi 1.00 import weight 0.00
Epoch 38 Iter 1 subLoss 24539.8 multi 1.00 import weight 0.00
Epoch 38 Iter 2 subLoss 20540.5 multi 3.99 import weight 1.00
Epoch 38 Iter 3 subLoss 17838.1 multi 1.00 import weight 0.00
Epoch 38 Iter 4 subLoss 16757.8 multi -1.99 import weight 0.00
Epoch 38 Iter 5 subLoss 18486.8 multi -1.99 import weight 0.00
Epoch 38 Iter 6 subLoss 25842.4 multi -1.99 import weight 0.00
Epoch 38 Iter 7 subLoss 201428.9 multi 1.00 import weight 0.00
Epoch 38 Iter 8 subLoss 43389.6 multi 1.00 import weight 0.00
Epoch 38 Iter 9 subLoss 36391.8 multi 1.00 import weight 0.00
Epoch 38 Iter 10 subLoss 31199.2 multi 1.00 import weight 0.00
Epoch 38 Iter 11 subLoss 28266.5 multi 1.00 import weight 0.00
Epoch 38 Acc: 79.61 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2826 train Loss: 26057.9 test Loss: 3515.2
Epoch 39 Iter 0 subLoss 25942.7 multi 1.00 import weight 0.00
Epoch 39 Iter 1 subLoss 23805.8 multi 1.00 import weight 0.00
Epoch 39 Iter 2 subLoss 21885.5 multi 1.00 import weight 0.00
Epoch 39 Iter 3 subLoss 20304.1 multi -1.99 import weight 0.00
Epoch 39 Iter 4 subLoss 22189.6 multi 3.99 import weight 1.00
Epoch 39 Iter 5 subLoss 19016.0 multi 1.00 import weight 0.00
Epoch 39 Iter 6 subLoss 18104.7 multi 1.00 import weight 0.00
Epoch 39 Iter 7 subLoss 17273.1 multi 3.99 import weight 1.00
Epoch 39 Iter 8 subLoss 15951.8 multi 1.00 import weight 0.00
Epoch 39 Iter 9 subLoss 16591.6 multi 1.00 import weight 0.00
Epoch 39 Iter 10 subLoss 15642.9 multi 1.00 import weight 0.00
Epoch 39 Iter 11 subLoss 15347.4 multi -1.99 import weight 0.00
Epoch 39 Acc: 91.96 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 1534 train Loss: 16477.1 test Loss: 1752.9
Epoch 40 Iter 0 subLoss 16472.1 multi 1.00 import weight 0.00
Epoch 40 Iter 1 subLoss 15821.9 multi 1.00 import weight 0.00
Epoch 40 Iter 2 subLoss 16152.8 multi 1.00 import weight 0.00
Epoch 40 Iter 3 subLoss 15011.4 multi 3.99 import weight 1.00
Epoch 40 Iter 4 subLoss 15622.2 multi 3.99 import weight 1.00
Epoch 40 Iter 5 subLoss 34093.0 multi 1.00 import weight 0.00
Epoch 40 Iter 6 subLoss 22033.1 multi 1.00 import weight 0.00
Epoch 40 Iter 7 subLoss 18631.6 multi 1.00 import weight 0.00
Epoch 40 Iter 8 subLoss 17273.9 multi 6.97 import weight 1.00
Epoch 40 Iter 9 subLoss 28902.8 multi 1.00 import weight 0.00
Epoch 40 Iter 10 subLoss 15844.2 multi 1.00 import weight 0.00
Epoch 40 Iter 11 subLoss 14727.1 multi 1.00 import weight 0.00
Epoch 40 Acc: 95.41 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1472 train Loss: 14080.6 test Loss: 1388.4
Epoch 41 Iter 0 subLoss 13781.5 multi 1.00 import weight 0.00
Epoch 41 Iter 1 subLoss 13761.0 multi 1.00 import weight 0.00
Epoch 41 Iter 2 subLoss 12916.3 multi 1.00 import weight 0.00
Epoch 41 Iter 3 subLoss 12464.5 multi 1.00 import weight 0.00
Epoch 41 Iter 4 subLoss 12839.2 multi 1.00 import weight 0.00
Epoch 41 Iter 5 subLoss 12219.6 multi 3.99 import weight 0.00
Epoch 41 Iter 6 subLoss 12095.4 multi 1.00 import weight 0.00
Epoch 41 Iter 7 subLoss 11648.0 multi 1.00 import weight 0.00
Epoch 41 Iter 8 subLoss 10807.2 multi -1.99 import weight 0.00
Epoch 41 Iter 9 subLoss 12287.8 multi 1.00 import weight 0.00
Epoch 41 Iter 10 subLoss 11952.3 multi 1.00 import weight 0.00
Epoch 41 Iter 11 subLoss 11221.5 multi 1.00 import weight 0.00
Epoch 41 Acc: 96.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1122 train Loss: 11413.3 test Loss: 957.5
Epoch 42 Iter 0 subLoss 10924.4 multi 1.00 import weight 0.00
Epoch 42 Iter 1 subLoss 11194.6 multi 1.00 import weight 0.00
Epoch 42 Iter 2 subLoss 10811.1 multi -1.99 import weight 0.00
Epoch 42 Iter 3 subLoss 11316.1 multi 1.00 import weight 0.00
Epoch 42 Iter 4 subLoss 11128.4 multi 1.00 import weight 0.00
Epoch 42 Iter 5 subLoss 10626.7 multi 1.00 import weight 0.00
Epoch 42 Iter 6 subLoss 10763.9 multi 1.00 import weight 0.00
Epoch 42 Iter 7 subLoss 10362.2 multi 1.00 import weight 0.00
Epoch 42 Iter 8 subLoss 9833.4 multi 1.00 import weight 0.00
Epoch 42 Iter 9 subLoss 10708.6 multi 1.00 import weight 0.00
Epoch 42 Iter 10 subLoss 10268.8 multi 1.00 import weight 0.00
Epoch 42 Iter 11 subLoss 9736.6 multi -1.99 import weight 0.00
Epoch 42 Acc: 95.49 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 973 train Loss: 12011.5 test Loss: 1012.0
Epoch 43 Iter 0 subLoss 11393.9 multi 1.00 import weight 0.00
Epoch 43 Iter 1 subLoss 10772.5 multi -1.99 import weight 0.00
Epoch 43 Iter 2 subLoss 28414.6 multi 1.00 import weight 0.00
Epoch 43 Iter 3 subLoss 35800.8 multi 1.00 import weight 0.00
Epoch 43 Iter 4 subLoss 20034.9 multi 1.00 import weight 0.00
Epoch 43 Iter 5 subLoss 12827.9 multi 1.00 import weight 0.00
Epoch 43 Iter 6 subLoss 11710.0 multi 1.00 import weight 0.00
Epoch 43 Iter 7 subLoss 11875.7 multi 1.00 import weight 0.00
Epoch 43 Iter 8 subLoss 10855.4 multi 1.00 import weight 0.00
Epoch 43 Iter 9 subLoss 11849.5 multi -1.99 import weight 0.00
Epoch 43 Iter 10 subLoss 11788.9 multi 1.00 import weight 0.00
Epoch 43 Iter 11 subLoss 11675.5 multi 1.00 import weight 0.00
Epoch 43 Acc: 95.56 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1167 train Loss: 11439.6 test Loss: 1072.6
Epoch 44 Iter 0 subLoss 11186.8 multi 1.00 import weight 0.00
Epoch 44 Iter 1 subLoss 10811.5 multi 1.00 import weight 0.00
Epoch 44 Iter 2 subLoss 11035.8 multi 1.00 import weight 0.00
Epoch 44 Iter 3 subLoss 10548.6 multi 1.00 import weight 0.00
Epoch 44 Iter 4 subLoss 10305.7 multi 1.00 import weight 0.00
Epoch 44 Iter 5 subLoss 10756.4 multi 1.00 import weight 0.00
Epoch 44 Iter 6 subLoss 9861.9 multi 1.00 import weight 0.00
Epoch 44 Iter 7 subLoss 9731.2 multi 1.00 import weight 0.00
Epoch 44 Iter 8 subLoss 10327.2 multi 1.00 import weight 0.00
Epoch 44 Iter 9 subLoss 9212.4 multi 1.00 import weight 0.00
Epoch 44 Iter 10 subLoss 9725.8 multi 3.99 import weight 0.00
Epoch 44 Iter 11 subLoss 9563.2 multi 1.00 import weight 0.00
Epoch 44 Acc: 96.38 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 956 train Loss: 9414.4 test Loss: 756.7
Epoch 45 Iter 0 subLoss 9669.8 multi 1.00 import weight 0.00
Epoch 45 Iter 1 subLoss 8472.7 multi 1.00 import weight 0.00
Epoch 45 Iter 2 subLoss 8957.1 multi 1.00 import weight 0.00
Epoch 45 Iter 3 subLoss 8762.3 multi 1.00 import weight 0.00
Epoch 45 Iter 4 subLoss 8656.8 multi 1.00 import weight 0.00
Epoch 45 Iter 5 subLoss 8533.3 multi 1.00 import weight 0.00
Epoch 45 Iter 6 subLoss 8326.8 multi 1.00 import weight 0.00
Epoch 45 Iter 7 subLoss 8503.3 multi 1.00 import weight 0.00
Epoch 45 Iter 8 subLoss 7745.2 multi 1.00 import weight 0.00
Epoch 45 Iter 9 subLoss 7814.6 multi 1.00 import weight 0.00
Epoch 45 Iter 10 subLoss 8321.2 multi 3.99 import weight 0.00
Epoch 45 Iter 11 subLoss 20257.8 multi -1.99 import weight 0.00
Epoch 45 Acc: 20.08 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 2025 train Loss: 722361.9 test Loss: 133121.1
Epoch 46 Iter 0 subLoss 722130.5 multi 1.00 import weight 0.00
Epoch 46 Iter 1 subLoss 46922.1 multi 1.00 import weight 0.00
Epoch 46 Iter 2 subLoss 37394.7 multi 1.00 import weight 0.00
Epoch 46 Iter 3 subLoss 33346.3 multi 3.99 import weight 0.00
Epoch 46 Iter 4 subLoss 28228.9 multi 1.00 import weight 0.00
Epoch 46 Iter 5 subLoss 24873.4 multi 1.00 import weight 0.00
Epoch 46 Iter 6 subLoss 23807.5 multi 3.99 import weight 0.00
Epoch 46 Iter 7 subLoss 20793.5 multi 1.00 import weight 0.00
Epoch 46 Iter 8 subLoss 21018.0 multi 1.00 import weight 0.00
Epoch 46 Iter 9 subLoss 19554.0 multi 3.99 import weight 0.00
Epoch 46 Iter 10 subLoss 18796.3 multi -1.99 import weight 0.00
Epoch 46 Iter 11 subLoss 65365.2 multi 1.00 import weight 0.00
Epoch 46 Acc: 28.06 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 6536 train Loss: 48817.8 test Loss: 8301.5
Epoch 47 Iter 0 subLoss 46989.2 multi 1.00 import weight 0.00
Epoch 47 Iter 1 subLoss 28092.6 multi 1.00 import weight 0.00
Epoch 47 Iter 2 subLoss 21245.3 multi 1.00 import weight 0.00
Epoch 47 Iter 3 subLoss 19429.8 multi 1.00 import weight 0.00
Epoch 47 Iter 4 subLoss 18684.9 multi 1.00 import weight 0.00
Epoch 47 Iter 5 subLoss 18442.8 multi 1.00 import weight 0.00
Epoch 47 Iter 6 subLoss 17970.5 multi 1.00 import weight 0.00
Epoch 47 Iter 7 subLoss 17193.8 multi -1.99 import weight 0.00
Epoch 47 Iter 8 subLoss 18491.8 multi 1.00 import weight 0.00
Epoch 47 Iter 9 subLoss 17208.3 multi -1.99 import weight 0.00
Epoch 47 Iter 10 subLoss 19066.7 multi 1.00 import weight 0.00
Epoch 47 Iter 11 subLoss 18898.2 multi 1.00 import weight 0.00
Epoch 47 Acc: 88.87 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1889 train Loss: 17970.8 test Loss: 2105.6
Epoch 48 Iter 0 subLoss 17649.0 multi -1.99 import weight 0.00
Epoch 48 Iter 1 subLoss 19266.1 multi -1.99 import weight 0.00
Epoch 48 Iter 2 subLoss 21263.6 multi 1.00 import weight 0.00
Epoch 48 Iter 3 subLoss 18803.5 multi -1.99 import weight 0.00
Epoch 48 Iter 4 subLoss 21732.6 multi 1.00 import weight 0.00
Epoch 48 Iter 5 subLoss 19884.1 multi 3.99 import weight 0.00
Epoch 48 Iter 6 subLoss 17392.2 multi 1.00 import weight 0.00
Epoch 48 Iter 7 subLoss 17257.8 multi 1.00 import weight 0.00
Epoch 48 Iter 8 subLoss 16747.4 multi 3.99 import weight 0.00
Epoch 48 Iter 9 subLoss 15698.7 multi 3.99 import weight 0.00
Epoch 48 Iter 10 subLoss 13441.7 multi 1.00 import weight 0.00
Epoch 48 Iter 11 subLoss 13515.6 multi -1.99 import weight 0.00
Epoch 48 Acc: 88.46 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 1351 train Loss: 14862.6 test Loss: 1619.8
Epoch 49 Iter 0 subLoss 14950.6 multi 1.00 import weight 0.00
Epoch 49 Iter 1 subLoss 14087.8 multi 1.00 import weight 0.00
Epoch 49 Iter 2 subLoss 13568.7 multi -1.99 import weight 0.00
Epoch 49 Iter 3 subLoss 14438.7 multi 1.00 import weight 0.00
Epoch 49 Iter 4 subLoss 14080.1 multi 3.99 import weight 0.00
Epoch 49 Iter 5 subLoss 13856.5 multi 1.00 import weight 0.00
Epoch 49 Iter 6 subLoss 13090.7 multi 1.00 import weight 0.00
Epoch 49 Iter 7 subLoss 12577.0 multi 1.00 import weight 0.00
Epoch 49 Iter 8 subLoss 12973.0 multi -1.99 import weight 0.00
Epoch 49 Iter 9 subLoss 14006.4 multi 1.00 import weight 0.00
Epoch 49 Iter 10 subLoss 12974.2 multi 1.00 import weight 0.00
Epoch 49 Iter 11 subLoss 11876.0 multi 3.99 import weight 0.00
Epoch 49 Acc: 91.65 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 1187 train Loss: 14859.3 test Loss: 1368.5
Epoch 50 Iter 0 subLoss 14375.8 multi 1.00 import weight 0.00
Epoch 50 Iter 1 subLoss 12845.4 multi -1.99 import weight 0.00
Epoch 50 Iter 2 subLoss 38946.1 multi 1.00 import weight 0.00
Epoch 50 Iter 3 subLoss 26214.6 multi 1.00 import weight 0.00
Epoch 50 Iter 4 subLoss 15102.4 multi 1.00 import weight 0.00
Epoch 50 Iter 5 subLoss 13063.8 multi 1.00 import weight 0.00
Epoch 50 Iter 6 subLoss 13011.7 multi 1.00 import weight 0.00
Epoch 50 Iter 7 subLoss 12193.7 multi 3.99 import weight 0.00
Epoch 50 Iter 8 subLoss 11337.2 multi 1.00 import weight 0.00
Epoch 50 Iter 9 subLoss 11539.4 multi 1.00 import weight 0.00
Epoch 50 Iter 10 subLoss 10589.9 multi 1.00 import weight 0.00
Epoch 50 Iter 11 subLoss 10398.5 multi 1.00 import weight 0.00
Epoch 50 Acc: 95.04 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1039 train Loss: 10920.9 test Loss: 978.7
Epoch 51 Iter 0 subLoss 10422.6 multi 1.00 import weight 0.00
Epoch 51 Iter 1 subLoss 10499.2 multi 1.00 import weight 0.00
Epoch 51 Iter 2 subLoss 10672.9 multi 1.00 import weight 0.00
Epoch 51 Iter 3 subLoss 10792.9 multi 3.99 import weight 0.00
Epoch 51 Iter 4 subLoss 10269.5 multi 3.99 import weight 0.00
Epoch 51 Iter 5 subLoss 21583.9 multi 1.00 import weight 0.00
Epoch 51 Iter 6 subLoss 14118.4 multi 3.99 import weight 0.00
Epoch 51 Iter 7 subLoss 123567.6 multi 1.00 import weight 0.00
Epoch 51 Iter 8 subLoss 35256.3 multi 1.00 import weight 0.00
Epoch 51 Iter 9 subLoss 29874.9 multi 1.00 import weight 0.00
Epoch 51 Iter 10 subLoss 25197.1 multi -1.99 import weight 0.00
Epoch 51 Iter 11 subLoss 31986.2 multi 1.00 import weight 0.00
Epoch 51 Acc: 76.86 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 3198 train Loss: 29318.4 test Loss: 3933.2
Epoch 52 Iter 0 subLoss 28714.1 multi 1.00 import weight 0.00
Epoch 52 Iter 1 subLoss 25321.1 multi 1.00 import weight 0.00
Epoch 52 Iter 2 subLoss 22613.5 multi 1.00 import weight 0.00
Epoch 52 Iter 3 subLoss 20807.5 multi 1.00 import weight 0.00
Epoch 52 Iter 4 subLoss 17732.1 multi -1.99 import weight 0.00
Epoch 52 Iter 5 subLoss 21699.5 multi 1.00 import weight 0.00
Epoch 52 Iter 6 subLoss 20844.2 multi -1.99 import weight 0.00
Epoch 52 Iter 7 subLoss 24125.7 multi 1.00 import weight 0.00
Epoch 52 Iter 8 subLoss 22622.6 multi 1.00 import weight 0.00
Epoch 52 Iter 9 subLoss 19925.8 multi 1.00 import weight 0.00
Epoch 52 Iter 10 subLoss 18116.1 multi -1.99 import weight 0.00
Epoch 52 Iter 11 subLoss 22114.9 multi -1.99 import weight 0.00
Epoch 52 Acc: 79.80 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 2211 train Loss: 26740.0 test Loss: 3490.6
Epoch 53 Iter 0 subLoss 26118.2 multi 1.00 import weight 0.00
Epoch 53 Iter 1 subLoss 23894.5 multi 1.00 import weight 0.00
Epoch 53 Iter 2 subLoss 21942.2 multi 1.00 import weight 0.00
Epoch 53 Iter 3 subLoss 20550.6 multi -4.97 import weight 0.00
Epoch 53 Iter 4 subLoss 30331.4 multi 1.00 import weight 0.00
Epoch 53 Iter 5 subLoss 27735.8 multi 1.00 import weight 0.00
Epoch 53 Iter 6 subLoss 25966.9 multi 3.99 import weight 0.00
Epoch 53 Iter 7 subLoss 20599.7 multi 1.00 import weight 0.00
Epoch 53 Iter 8 subLoss 18438.5 multi 1.00 import weight 0.00
Epoch 53 Iter 9 subLoss 16738.9 multi 1.00 import weight 0.00
Epoch 53 Iter 10 subLoss 15228.1 multi 1.00 import weight 0.00
Epoch 53 Iter 11 subLoss 14691.0 multi -1.99 import weight 0.00
Epoch 53 Acc: 93.01 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 1469 train Loss: 17372.8 test Loss: 1776.7
Epoch 54 Iter 0 subLoss 17616.6 multi 1.00 import weight 0.00
Epoch 54 Iter 1 subLoss 15614.5 multi -1.99 import weight 0.00
Epoch 54 Iter 2 subLoss 17887.7 multi 1.00 import weight 0.00
Epoch 54 Iter 3 subLoss 16385.5 multi 3.99 import weight 0.00
Epoch 54 Iter 4 subLoss 13073.1 multi -1.99 import weight 0.00
Epoch 54 Iter 5 subLoss 14118.7 multi 6.97 import weight 1.00
Epoch 54 Iter 6 subLoss 10418.6 multi 1.00 import weight 0.00
Epoch 54 Iter 7 subLoss 10062.5 multi 1.00 import weight 0.00
Epoch 54 Iter 8 subLoss 9874.4 multi -1.99 import weight 0.00
Epoch 54 Iter 9 subLoss 11239.5 multi -1.99 import weight 0.00
Epoch 54 Iter 10 subLoss 11290.5 multi 1.00 import weight 0.00
Epoch 54 Iter 11 subLoss 10510.9 multi 1.00 import weight 0.00
Epoch 54 Acc: 95.54 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1051 train Loss: 10510.9 test Loss: 864.6
Epoch 55 Iter 0 subLoss 10004.2 multi 1.00 import weight 0.00
Epoch 55 Iter 1 subLoss 10022.4 multi -1.99 import weight 0.00
Epoch 55 Iter 2 subLoss 10692.1 multi 1.00 import weight 0.00
Epoch 55 Iter 3 subLoss 10255.4 multi 1.00 import weight 0.00
Epoch 55 Iter 4 subLoss 9655.8 multi 1.00 import weight 0.00
Epoch 55 Iter 5 subLoss 10031.3 multi -1.99 import weight 0.00
Epoch 55 Iter 6 subLoss 10290.6 multi 1.00 import weight 0.00
Epoch 55 Iter 7 subLoss 10502.9 multi -1.99 import weight 0.00
Epoch 55 Iter 8 subLoss 10727.3 multi 1.00 import weight 0.00
Epoch 55 Iter 9 subLoss 9852.1 multi 1.00 import weight 0.00
Epoch 55 Iter 10 subLoss 9926.3 multi 1.00 import weight 0.00
Epoch 55 Iter 11 subLoss 10161.8 multi 1.00 import weight 0.00
Epoch 55 Acc: 95.80 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1016 train Loss: 9721.6 test Loss: 772.0
Epoch 56 Iter 0 subLoss 9138.2 multi 1.00 import weight 0.00
Epoch 56 Iter 1 subLoss 9976.5 multi 1.00 import weight 0.00
Epoch 56 Iter 2 subLoss 9354.6 multi 3.99 import weight 0.00
Epoch 56 Iter 3 subLoss 8641.9 multi 1.00 import weight 0.00
Epoch 56 Iter 4 subLoss 7907.4 multi 1.00 import weight 0.00
Epoch 56 Iter 5 subLoss 8266.4 multi 1.00 import weight 0.00
Epoch 56 Iter 6 subLoss 7938.3 multi 1.00 import weight 0.00
Epoch 56 Iter 7 subLoss 8853.3 multi 1.00 import weight 0.00
Epoch 56 Iter 8 subLoss 7792.5 multi 1.00 import weight 0.00
Epoch 56 Iter 9 subLoss 7932.2 multi 3.99 import weight 0.00
Epoch 56 Iter 10 subLoss 9082.3 multi 1.00 import weight 0.00
Epoch 56 Iter 11 subLoss 7949.6 multi -4.97 import weight 0.00
Epoch 56 Acc: 71.16 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 794 train Loss: 31444.6 test Loss: 5682.7
Epoch 57 Iter 0 subLoss 30838.7 multi 1.00 import weight 0.00
Epoch 57 Iter 1 subLoss 15597.9 multi 1.00 import weight 0.00
Epoch 57 Iter 2 subLoss 8944.3 multi -1.99 import weight 0.00
Epoch 57 Iter 3 subLoss 10458.5 multi 3.99 import weight 0.00
Epoch 57 Iter 4 subLoss 11059.4 multi 1.00 import weight 0.00
Epoch 57 Iter 5 subLoss 8738.4 multi 1.00 import weight 0.00
Epoch 57 Iter 6 subLoss 8504.4 multi 3.99 import weight 0.00
Epoch 57 Iter 7 subLoss 8684.7 multi 1.00 import weight 0.00
Epoch 57 Iter 8 subLoss 8088.7 multi 1.00 import weight 0.00
Epoch 57 Iter 9 subLoss 7370.0 multi 1.00 import weight 0.00
Epoch 57 Iter 10 subLoss 6736.0 multi 1.00 import weight 0.00
Epoch 57 Iter 11 subLoss 7791.2 multi 3.99 import weight 0.00
Epoch 57 Acc: 96.61 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 779 train Loss: 7592.2 test Loss: 572.2
Epoch 58 Iter 0 subLoss 7237.3 multi 1.00 import weight 0.00
Epoch 58 Iter 1 subLoss 7747.0 multi 3.99 import weight 0.00
Epoch 58 Iter 2 subLoss 7399.5 multi 1.00 import weight 0.00
Epoch 58 Iter 3 subLoss 6700.8 multi 1.00 import weight 0.00
Epoch 58 Iter 4 subLoss 6877.9 multi 1.00 import weight 0.00
Epoch 58 Iter 5 subLoss 7221.8 multi 1.00 import weight 0.00
Epoch 58 Iter 6 subLoss 7398.6 multi 3.99 import weight 0.00
Epoch 58 Iter 7 subLoss 7169.1 multi 1.00 import weight 0.00
Epoch 58 Iter 8 subLoss 6535.5 multi 1.00 import weight 0.00
Epoch 58 Iter 9 subLoss 6168.0 multi 1.00 import weight 0.00
Epoch 58 Iter 10 subLoss 6514.5 multi 1.00 import weight 0.00
Epoch 58 Iter 11 subLoss 6292.2 multi 1.00 import weight 0.00
Epoch 58 Acc: 96.89 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 629 train Loss: 6758.3 test Loss: 521.8
Epoch 59 Iter 0 subLoss 6755.3 multi 1.00 import weight 0.00
Epoch 59 Iter 1 subLoss 6524.8 multi -1.99 import weight 0.00
Epoch 59 Iter 2 subLoss 6831.8 multi 1.00 import weight 0.00
Epoch 59 Iter 3 subLoss 6005.2 multi 1.00 import weight 0.00
Epoch 59 Iter 4 subLoss 6982.4 multi 1.00 import weight 0.00
Epoch 59 Iter 5 subLoss 6755.6 multi 3.99 import weight 0.00
Epoch 59 Iter 6 subLoss 7370.9 multi -1.99 import weight 0.00
Epoch 59 Iter 7 subLoss 20937.6 multi 1.00 import weight 0.00
Epoch 59 Iter 8 subLoss 12057.9 multi 1.00 import weight 0.00
Epoch 59 Iter 9 subLoss 7023.4 multi 1.00 import weight 0.00
Epoch 59 Iter 10 subLoss 6764.1 multi -4.97 import weight 0.00
Epoch 59 Iter 11 subLoss 9592.6 multi 1.00 import weight 0.00
Epoch 59 Acc: 96.65 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 959 train Loss: 7418.1 test Loss: 582.1
Epoch 60 Iter 0 subLoss 7689.0 multi 1.00 import weight 0.00
Epoch 60 Iter 1 subLoss 6442.2 multi 1.00 import weight 0.00
Epoch 60 Iter 2 subLoss 6594.5 multi 1.00 import weight 0.00
Epoch 60 Iter 3 subLoss 7535.8 multi 1.00 import weight 0.00
Epoch 60 Iter 4 subLoss 6632.1 multi 1.00 import weight 0.00
Epoch 60 Iter 5 subLoss 7011.7 multi 1.00 import weight 0.00
Epoch 60 Iter 6 subLoss 6846.5 multi -1.99 import weight 0.00
Epoch 60 Iter 7 subLoss 6929.5 multi 1.00 import weight 0.00
Epoch 60 Iter 8 subLoss 6264.6 multi 1.00 import weight 0.00
Epoch 60 Iter 9 subLoss 6058.0 multi 1.00 import weight 0.00
Epoch 60 Iter 10 subLoss 6803.5 multi 1.00 import weight 0.00
Epoch 60 Iter 11 subLoss 6259.4 multi 1.00 import weight 0.00
Epoch 60 Acc: 97.06 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 625 train Loss: 6441.8 test Loss: 512.5
Epoch 61 Iter 0 subLoss 6260.1 multi 1.00 import weight 0.00
Epoch 61 Iter 1 subLoss 6763.9 multi -1.98 import weight 0.00
Epoch 61 Iter 2 subLoss 5953.0 multi 1.00 import weight 0.00
Epoch 61 Iter 3 subLoss 6288.7 multi 1.00 import weight 0.00
Epoch 61 Iter 4 subLoss 6828.9 multi 1.00 import weight 0.00
Epoch 61 Iter 5 subLoss 6073.0 multi 1.00 import weight 0.00
Epoch 61 Iter 6 subLoss 6871.5 multi 3.99 import weight 0.00
Epoch 61 Iter 7 subLoss 6347.1 multi 1.00 import weight 0.00
Epoch 61 Iter 8 subLoss 6525.9 multi 1.00 import weight 0.00
Epoch 61 Iter 9 subLoss 6876.2 multi 6.97 import weight 1.00
Epoch 61 Iter 10 subLoss 6846.0 multi 1.00 import weight 0.00
Epoch 61 Iter 11 subLoss 6473.2 multi 1.00 import weight 0.00
Epoch 61 Acc: 96.89 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 647 train Loss: 5988.5 test Loss: 486.7
Epoch 62 Iter 0 subLoss 6396.5 multi 1.00 import weight 0.00
Epoch 62 Iter 1 subLoss 5725.7 multi 1.00 import weight 0.00
Epoch 62 Iter 2 subLoss 5971.6 multi 1.00 import weight 0.00
Epoch 62 Iter 3 subLoss 5612.7 multi 1.00 import weight 0.00
Epoch 62 Iter 4 subLoss 6679.2 multi 1.00 import weight 0.00
Epoch 62 Iter 5 subLoss 5702.5 multi 1.00 import weight 0.00
Epoch 62 Iter 6 subLoss 5783.3 multi 1.00 import weight 0.00
Epoch 62 Iter 7 subLoss 6004.3 multi 3.99 import weight 0.00
Epoch 62 Iter 8 subLoss 5746.6 multi 1.00 import weight 0.00
Epoch 62 Iter 9 subLoss 5709.3 multi 3.99 import weight 0.00
Epoch 62 Iter 10 subLoss 5242.3 multi 1.00 import weight 0.00
Epoch 62 Iter 11 subLoss 5802.5 multi 1.00 import weight 0.00
Epoch 62 Acc: 97.22 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 580 train Loss: 5822.4 test Loss: 454.2
Epoch 63 Iter 0 subLoss 5914.1 multi 1.00 import weight 0.00
Epoch 63 Iter 1 subLoss 5832.7 multi 1.00 import weight 0.00
Epoch 63 Iter 2 subLoss 5561.2 multi 1.00 import weight 0.00
Epoch 63 Iter 3 subLoss 5683.0 multi 1.00 import weight 0.00
Epoch 63 Iter 4 subLoss 5512.9 multi 1.00 import weight 0.00
Epoch 63 Iter 5 subLoss 5305.4 multi 1.00 import weight 0.00
Epoch 63 Iter 6 subLoss 5252.7 multi -1.99 import weight 0.00
Epoch 63 Iter 7 subLoss 5105.8 multi 1.00 import weight 0.00
Epoch 63 Iter 8 subLoss 5312.5 multi -1.99 import weight 0.00
Epoch 63 Iter 9 subLoss 5496.3 multi 1.00 import weight 0.00
Epoch 63 Iter 10 subLoss 5815.5 multi -1.99 import weight 0.00
Epoch 63 Iter 11 subLoss 6173.2 multi -1.99 import weight 0.00
Epoch 63 Acc: 91.92 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 617 train Loss: 9211.6 test Loss: 1069.2
Epoch 64 Iter 0 subLoss 9133.9 multi 3.99 import weight 0.00
Epoch 64 Iter 1 subLoss 50605.8 multi 1.00 import weight 0.00
Epoch 64 Iter 2 subLoss 27902.7 multi -1.99 import weight 0.00
Epoch 64 Iter 3 subLoss 290611.2 multi 1.00 import weight 0.00
Epoch 64 Iter 4 subLoss 28760.1 multi -1.99 import weight 0.00
Epoch 64 Iter 5 subLoss 37365.4 multi 1.00 import weight 0.00
Epoch 64 Iter 6 subLoss 31913.4 multi 1.00 import weight 0.00
Epoch 64 Iter 7 subLoss 28624.8 multi 1.00 import weight 0.00
Epoch 64 Iter 8 subLoss 24994.6 multi 1.00 import weight 0.00
Epoch 64 Iter 9 subLoss 22941.7 multi -1.99 import weight 0.00
Epoch 64 Iter 10 subLoss 27116.1 multi 1.00 import weight 0.00
Epoch 64 Iter 11 subLoss 24350.3 multi -1.99 import weight 0.00
Epoch 64 Acc: 81.73 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 2435 train Loss: 29318.9 test Loss: 3075.7
Epoch 65 Iter 0 subLoss 28965.2 multi -1.99 import weight 0.00
Epoch 65 Iter 1 subLoss 34195.0 multi 1.00 import weight 0.00
Epoch 65 Iter 2 subLoss 31118.2 multi 1.00 import weight 0.00
Epoch 65 Iter 3 subLoss 28479.2 multi 1.00 import weight 0.00
Epoch 65 Iter 4 subLoss 26490.5 multi -1.99 import weight 0.00
Epoch 65 Iter 5 subLoss 29175.8 multi 1.00 import weight 0.00
Epoch 65 Iter 6 subLoss 27761.6 multi 1.00 import weight 0.00
Epoch 65 Iter 7 subLoss 26456.8 multi 3.99 import weight 0.00
Epoch 65 Iter 8 subLoss 21434.1 multi 3.99 import weight 0.00
Epoch 65 Iter 9 subLoss 18544.6 multi 1.00 import weight 0.00
Epoch 65 Iter 10 subLoss 16814.2 multi 1.00 import weight 0.00
Epoch 65 Iter 11 subLoss 15932.8 multi 1.00 import weight 0.00
Epoch 65 Acc: 94.73 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1593 train Loss: 14817.8 test Loss: 1075.3
Epoch 66 Iter 0 subLoss 14850.3 multi 1.00 import weight 0.00
Epoch 66 Iter 1 subLoss 13653.5 multi 1.00 import weight 0.00
Epoch 66 Iter 2 subLoss 12222.2 multi -4.97 import weight 0.00
Epoch 66 Iter 3 subLoss 18307.8 multi 6.97 import weight 1.00
Epoch 66 Iter 4 subLoss 49232.6 multi 1.00 import weight 0.00
Epoch 66 Iter 5 subLoss 21221.8 multi 1.00 import weight 0.00
Epoch 66 Iter 6 subLoss 16753.6 multi -1.98 import weight 0.00
Epoch 66 Iter 7 subLoss 21934.6 multi 1.00 import weight 0.00
Epoch 66 Iter 8 subLoss 18000.0 multi 1.00 import weight 0.00
Epoch 66 Iter 9 subLoss 16185.3 multi -1.99 import weight 0.00
Epoch 66 Iter 10 subLoss 19224.8 multi -1.99 import weight 0.00
Epoch 66 Iter 11 subLoss 24447.1 multi 1.00 import weight 0.00
Epoch 66 Acc: 83.89 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2444 train Loss: 21207.2 test Loss: 2183.5
Epoch 67 Iter 0 subLoss 21021.3 multi -1.99 import weight 0.00
Epoch 67 Iter 1 subLoss 26596.2 multi 1.00 import weight 0.00
Epoch 67 Iter 2 subLoss 23293.6 multi 1.00 import weight 0.00
Epoch 67 Iter 3 subLoss 21156.9 multi 1.00 import weight 0.00
Epoch 67 Iter 4 subLoss 18457.8 multi -1.99 import weight 0.00
Epoch 67 Iter 5 subLoss 21732.6 multi 3.99 import weight 0.00
Epoch 67 Iter 6 subLoss 16730.9 multi 3.99 import weight 0.00
Epoch 67 Iter 7 subLoss 13330.1 multi 3.99 import weight 0.00
Epoch 67 Iter 8 subLoss 13314.1 multi 1.00 import weight 0.00
Epoch 67 Iter 9 subLoss 9111.2 multi 1.00 import weight 0.00
Epoch 67 Iter 10 subLoss 8109.4 multi 1.00 import weight 0.00
Epoch 67 Iter 11 subLoss 8126.8 multi 1.00 import weight 0.00
Epoch 67 Acc: 96.89 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 812 train Loss: 8348.8 test Loss: 634.8
Epoch 68 Iter 0 subLoss 8170.7 multi 1.00 import weight 0.00
Epoch 68 Iter 1 subLoss 7581.8 multi 1.00 import weight 0.00
Epoch 68 Iter 2 subLoss 7705.9 multi 1.00 import weight 0.00
Epoch 68 Iter 3 subLoss 7819.7 multi 3.99 import weight 0.00
Epoch 68 Iter 4 subLoss 7180.3 multi 1.00 import weight 0.00
Epoch 68 Iter 5 subLoss 6465.3 multi 1.00 import weight 0.00
Epoch 68 Iter 6 subLoss 6454.8 multi -1.99 import weight 0.00
Epoch 68 Iter 7 subLoss 7475.9 multi 1.00 import weight 0.00
Epoch 68 Iter 8 subLoss 6754.0 multi 6.97 import weight 1.00
Epoch 68 Iter 9 subLoss 6124.9 multi 1.00 import weight 0.00
Epoch 68 Iter 10 subLoss 5831.2 multi 3.99 import weight 0.00
Epoch 68 Iter 11 subLoss 6860.4 multi 1.00 import weight 0.00
Epoch 68 Acc: 96.79 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 686 train Loss: 6099.9 test Loss: 519.9
Epoch 69 Iter 0 subLoss 5465.6 multi 1.00 import weight 0.00
Epoch 69 Iter 1 subLoss 5625.5 multi -1.99 import weight 0.00
Epoch 69 Iter 2 subLoss 6390.6 multi 3.99 import weight 0.00
Epoch 69 Iter 3 subLoss 7688.0 multi 3.99 import weight 0.00
Epoch 69 Iter 4 subLoss 22929.1 multi 1.00 import weight 0.00
Epoch 69 Iter 5 subLoss 7036.4 multi -1.99 import weight 0.00
Epoch 69 Iter 6 subLoss 12894.8 multi 1.00 import weight 0.00
Epoch 69 Iter 7 subLoss 6586.5 multi 1.00 import weight 0.00
Epoch 69 Iter 8 subLoss 5806.6 multi 3.99 import weight 0.00
Epoch 69 Iter 9 subLoss 6034.0 multi 1.00 import weight 0.00
Epoch 69 Iter 10 subLoss 6090.7 multi 1.00 import weight 0.00
Epoch 69 Iter 11 subLoss 6469.4 multi 1.00 import weight 0.00
Epoch 69 Acc: 96.98 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 646 train Loss: 5971.3 test Loss: 512.6
Epoch 70 Iter 0 subLoss 5765.7 multi 1.00 import weight 0.00
Epoch 70 Iter 1 subLoss 5754.7 multi -1.99 import weight 0.00
Epoch 70 Iter 2 subLoss 5589.8 multi 1.00 import weight 0.00
Epoch 70 Iter 3 subLoss 5958.8 multi 3.99 import weight 0.00
Epoch 70 Iter 4 subLoss 6180.0 multi 1.00 import weight 0.00
Epoch 70 Iter 5 subLoss 5076.6 multi 1.00 import weight 0.00
Epoch 70 Iter 6 subLoss 5373.3 multi 1.00 import weight 0.00
Epoch 70 Iter 7 subLoss 5418.4 multi 1.00 import weight 0.00
Epoch 70 Iter 8 subLoss 5959.2 multi 6.97 import weight 1.00
Epoch 70 Iter 9 subLoss 5618.1 multi 3.99 import weight 0.00
Epoch 70 Iter 10 subLoss 6222.9 multi 1.00 import weight 0.00
Epoch 70 Iter 11 subLoss 5080.0 multi 3.99 import weight 0.00
Epoch 70 Acc: 96.24 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 507 train Loss: 5805.5 test Loss: 565.4
Epoch 71 Iter 0 subLoss 5618.4 multi 6.97 import weight 1.00
Epoch 71 Iter 1 subLoss 26959.0 multi 1.00 import weight 0.00
Epoch 71 Iter 2 subLoss 6208.1 multi 1.00 import weight 0.00
Epoch 71 Iter 3 subLoss 5232.7 multi 1.00 import weight 0.00
Epoch 71 Iter 4 subLoss 5351.5 multi 1.00 import weight 0.00
Epoch 71 Iter 5 subLoss 4847.7 multi 1.00 import weight 0.00
Epoch 71 Iter 6 subLoss 5477.9 multi -1.99 import weight 0.00
Epoch 71 Iter 7 subLoss 5099.3 multi 1.00 import weight 0.00
Epoch 71 Iter 8 subLoss 5699.0 multi -1.99 import weight 0.00
Epoch 71 Iter 9 subLoss 4850.8 multi -1.99 import weight 0.00
Epoch 71 Iter 10 subLoss 5188.2 multi 1.00 import weight 0.00
Epoch 71 Iter 11 subLoss 5227.6 multi 1.00 import weight 0.00
Epoch 71 Acc: 97.26 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 522 train Loss: 5374.8 test Loss: 468.8
Epoch 72 Iter 0 subLoss 4945.8 multi 1.00 import weight 0.00
Epoch 72 Iter 1 subLoss 5169.9 multi 1.00 import weight 0.00
Epoch 72 Iter 2 subLoss 5324.5 multi -1.99 import weight 0.00
Epoch 72 Iter 3 subLoss 5270.3 multi 1.00 import weight 0.00
Epoch 72 Iter 4 subLoss 5377.3 multi 3.99 import weight 0.00
Epoch 72 Iter 5 subLoss 5489.9 multi -1.99 import weight 0.00
Epoch 72 Iter 6 subLoss 5382.7 multi -4.97 import weight 0.00
Epoch 72 Iter 7 subLoss 12030.7 multi 1.00 import weight 0.00
Epoch 72 Iter 8 subLoss 6023.8 multi 1.00 import weight 0.00
Epoch 72 Iter 9 subLoss 4989.3 multi 1.00 import weight 0.00
Epoch 72 Iter 10 subLoss 5185.3 multi 3.99 import weight 0.00
Epoch 72 Iter 11 subLoss 5466.9 multi 3.99 import weight 0.00
Epoch 72 Acc: 95.15 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 546 train Loss: 6318.8 test Loss: 711.7
Epoch 73 Iter 0 subLoss 5730.0 multi -1.99 import weight 0.00
Epoch 73 Iter 1 subLoss 13478.1 multi 1.00 import weight 0.00
Epoch 73 Iter 2 subLoss 5823.9 multi -1.99 import weight 0.00
Epoch 73 Iter 3 subLoss 8504.1 multi 6.97 import weight 1.00
Epoch 73 Iter 4 subLoss 119110.1 multi 1.00 import weight 0.00
Epoch 73 Iter 5 subLoss 18949.4 multi 1.00 import weight 0.00
Epoch 73 Iter 6 subLoss 10486.8 multi 1.00 import weight 0.00
Epoch 73 Iter 7 subLoss 9520.3 multi -1.99 import weight 0.00
Epoch 73 Iter 8 subLoss 10977.8 multi 1.00 import weight 0.00
Epoch 73 Iter 9 subLoss 9254.4 multi 1.00 import weight 0.00
Epoch 73 Iter 10 subLoss 9072.3 multi 1.00 import weight 0.00
Epoch 73 Iter 11 subLoss 8010.4 multi 1.00 import weight 0.00
Epoch 73 Acc: 97.00 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 801 train Loss: 7882.3 test Loss: 744.5
Epoch 74 Iter 0 subLoss 7429.3 multi 1.00 import weight 0.00
Epoch 74 Iter 1 subLoss 7514.3 multi 1.00 import weight 0.00
Epoch 74 Iter 2 subLoss 7089.6 multi 1.00 import weight 0.00
Epoch 74 Iter 3 subLoss 6463.7 multi 3.98 import weight 1.00
Epoch 74 Iter 4 subLoss 5769.3 multi 1.00 import weight 0.00
Epoch 74 Iter 5 subLoss 5676.5 multi 1.00 import weight 0.00
Epoch 74 Iter 6 subLoss 5588.8 multi 3.99 import weight 0.00
Epoch 74 Iter 7 subLoss 5366.1 multi -1.99 import weight 0.00
Epoch 74 Iter 8 subLoss 6485.2 multi -1.99 import weight 0.00
Epoch 74 Iter 9 subLoss 13070.4 multi 1.00 import weight 0.00
Epoch 74 Iter 10 subLoss 5796.2 multi -1.99 import weight 0.00
Epoch 74 Iter 11 subLoss 5967.6 multi -7.96 import weight 0.00
Epoch 74 Acc: 85.33 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 596 train Loss: 19307.2 test Loss: 2157.8
Epoch 75 Iter 0 subLoss 17810.1 multi -1.99 import weight 0.00
Epoch 75 Iter 1 subLoss 80074.5 multi 1.00 import weight 0.00
Epoch 75 Iter 2 subLoss 12710.0 multi 1.00 import weight 0.00
Epoch 75 Iter 3 subLoss 10674.6 multi 3.99 import weight 0.00
Epoch 75 Iter 4 subLoss 8592.2 multi 1.00 import weight 0.00
Epoch 75 Iter 5 subLoss 7859.7 multi 1.00 import weight 0.00
Epoch 75 Iter 6 subLoss 7036.9 multi 1.00 import weight 0.00
Epoch 75 Iter 7 subLoss 6935.3 multi -1.99 import weight 0.00
Epoch 75 Iter 8 subLoss 7996.5 multi 1.00 import weight 0.00
Epoch 75 Iter 9 subLoss 7493.0 multi 1.00 import weight 0.00
Epoch 75 Iter 10 subLoss 7177.0 multi -1.99 import weight 0.00
Epoch 75 Iter 11 subLoss 7739.4 multi 1.00 import weight 0.00
Epoch 75 Acc: 96.71 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 773 train Loss: 7427.6 test Loss: 663.7
Epoch 76 Iter 0 subLoss 7344.5 multi 1.00 import weight 0.00
Epoch 76 Iter 1 subLoss 7110.2 multi 1.00 import weight 0.00
Epoch 76 Iter 2 subLoss 6513.7 multi 3.99 import weight 0.00
Epoch 76 Iter 3 subLoss 5599.7 multi -4.97 import weight 0.00
Epoch 76 Iter 4 subLoss 7336.3 multi 1.00 import weight 0.00
Epoch 76 Iter 5 subLoss 6791.2 multi 1.00 import weight 0.00
Epoch 76 Iter 6 subLoss 6428.9 multi 1.00 import weight 0.00
Epoch 76 Iter 7 subLoss 6820.5 multi 3.99 import weight 0.00
Epoch 76 Iter 8 subLoss 5720.9 multi 3.99 import weight 0.00
Epoch 76 Iter 9 subLoss 5225.2 multi 3.99 import weight 0.00
Epoch 76 Iter 10 subLoss 5897.5 multi 1.00 import weight 0.00
Epoch 76 Iter 11 subLoss 5478.7 multi -1.98 import weight 0.00
Epoch 76 Acc: 97.14 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 547 train Loss: 5456.5 test Loss: 496.3
Epoch 77 Iter 0 subLoss 5811.3 multi -1.98 import weight 0.00
Epoch 77 Iter 1 subLoss 5320.9 multi 1.00 import weight 0.00
Epoch 77 Iter 2 subLoss 5893.5 multi 3.99 import weight 0.00
Epoch 77 Iter 3 subLoss 5134.8 multi 1.00 import weight 0.00
Epoch 77 Iter 4 subLoss 5126.8 multi 1.00 import weight 0.00
Epoch 77 Iter 5 subLoss 5033.7 multi 1.00 import weight 0.00
Epoch 77 Iter 6 subLoss 4339.9 multi 1.00 import weight 0.00
Epoch 77 Iter 7 subLoss 4896.3 multi 1.00 import weight 0.00
Epoch 77 Iter 8 subLoss 4492.4 multi 1.00 import weight 0.00
Epoch 77 Iter 9 subLoss 5449.1 multi 1.00 import weight 0.00
Epoch 77 Iter 10 subLoss 4602.7 multi 1.00 import weight 0.00
Epoch 77 Iter 11 subLoss 5432.2 multi 1.00 import weight 0.00
Epoch 77 Acc: 97.30 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 543 train Loss: 4928.8 test Loss: 455.0
Epoch 78 Iter 0 subLoss 4835.4 multi 1.00 import weight 0.00
Epoch 78 Iter 1 subLoss 4488.4 multi 1.00 import weight 0.00
Epoch 78 Iter 2 subLoss 4575.1 multi 1.00 import weight 0.00
Epoch 78 Iter 3 subLoss 4918.5 multi 1.00 import weight 0.00
Epoch 78 Iter 4 subLoss 4724.6 multi 1.00 import weight 0.00
Epoch 78 Iter 5 subLoss 4888.4 multi 1.00 import weight 0.00
Epoch 78 Iter 6 subLoss 5029.8 multi 1.00 import weight 0.00
Epoch 78 Iter 7 subLoss 4595.8 multi 1.00 import weight 0.00
Epoch 78 Iter 8 subLoss 4659.0 multi 1.00 import weight 0.00
Epoch 78 Iter 9 subLoss 4667.2 multi -1.99 import weight 0.00
Epoch 78 Iter 10 subLoss 4143.8 multi 1.00 import weight 0.00
Epoch 78 Iter 11 subLoss 4917.1 multi 3.99 import weight 0.00
Epoch 78 Acc: 97.26 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 491 train Loss: 4709.6 test Loss: 450.1
Epoch 79 Iter 0 subLoss 5329.0 multi 3.98 import weight 1.00
Epoch 79 Iter 1 subLoss 4431.8 multi 1.00 import weight 0.00
Epoch 79 Iter 2 subLoss 4387.6 multi 1.00 import weight 0.00
Epoch 79 Iter 3 subLoss 4389.4 multi 3.99 import weight 0.00
Epoch 79 Iter 4 subLoss 4754.6 multi 1.00 import weight 0.00
Epoch 79 Iter 5 subLoss 4692.0 multi 1.00 import weight 0.00
Epoch 79 Iter 6 subLoss 4019.1 multi 1.00 import weight 0.00
Epoch 79 Iter 7 subLoss 4723.9 multi 3.99 import weight 0.00
Epoch 79 Iter 8 subLoss 4525.7 multi 1.00 import weight 0.00
Epoch 79 Iter 9 subLoss 4211.9 multi 1.00 import weight 0.00
Epoch 79 Iter 10 subLoss 4504.3 multi -1.99 import weight 0.00
Epoch 79 Iter 11 subLoss 4115.7 multi 1.00 import weight 0.00
Epoch 79 Acc: 97.35 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 411 train Loss: 4479.4 test Loss: 436.4
Epoch 80 Iter 0 subLoss 4084.0 multi 1.00 import weight 0.00
Epoch 80 Iter 1 subLoss 4588.1 multi -1.99 import weight 0.00
Epoch 80 Iter 2 subLoss 4280.7 multi 1.00 import weight 0.00
Epoch 80 Iter 3 subLoss 4104.7 multi 1.00 import weight 0.00
Epoch 80 Iter 4 subLoss 4520.1 multi 3.99 import weight 0.00
Epoch 80 Iter 5 subLoss 4362.5 multi 1.00 import weight 0.00
Epoch 80 Iter 6 subLoss 4738.7 multi -4.97 import weight 0.00
Epoch 80 Iter 7 subLoss 5165.6 multi 3.99 import weight 0.00
Epoch 80 Iter 8 subLoss 4945.4 multi 3.99 import weight 0.00
Epoch 80 Iter 9 subLoss 7670.5 multi 1.00 import weight 0.00
Epoch 80 Iter 10 subLoss 4337.4 multi 3.99 import weight 0.00
Epoch 80 Iter 11 subLoss 4647.9 multi 1.00 import weight 0.00
Epoch 80 Acc: 97.49 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 464 train Loss: 4443.6 test Loss: 404.6
Epoch 81 Iter 0 subLoss 4124.6 multi -1.99 import weight 0.00
Epoch 81 Iter 1 subLoss 3999.6 multi 1.00 import weight 0.00
Epoch 81 Iter 2 subLoss 3732.9 multi 1.00 import weight 0.00
Epoch 81 Iter 3 subLoss 3598.5 multi 1.00 import weight 0.00
Epoch 81 Iter 4 subLoss 4110.1 multi 1.00 import weight 0.00
Epoch 81 Iter 5 subLoss 4478.1 multi 1.00 import weight 0.00
Epoch 81 Iter 6 subLoss 4379.9 multi -1.99 import weight 0.00
Epoch 81 Iter 7 subLoss 4644.1 multi 3.99 import weight 0.00
Epoch 81 Iter 8 subLoss 4311.6 multi 1.00 import weight 0.00
Epoch 81 Iter 9 subLoss 3622.0 multi 1.00 import weight 0.00
Epoch 81 Iter 10 subLoss 4005.5 multi -1.99 import weight 0.00
Epoch 81 Iter 11 subLoss 4385.0 multi 3.98 import weight 1.00
Epoch 81 Acc: 97.24 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 3.98 Pidx 438 train Loss: 4493.3 test Loss: 444.7
Epoch 82 Iter 0 subLoss 4417.5 multi 1.00 import weight 0.00
Epoch 82 Iter 1 subLoss 4386.7 multi 6.97 import weight 1.00
Epoch 82 Iter 2 subLoss 3298.3 multi 1.00 import weight 0.00
Epoch 82 Iter 3 subLoss 3947.9 multi 1.00 import weight 0.00
Epoch 82 Iter 4 subLoss 3951.5 multi -1.99 import weight 0.00
Epoch 82 Iter 5 subLoss 4416.5 multi 3.99 import weight 0.00
Epoch 82 Iter 6 subLoss 5167.5 multi 6.97 import weight 0.00
Epoch 82 Iter 7 subLoss 6815.8 multi -1.99 import weight 0.00
Epoch 82 Iter 8 subLoss 22483.2 multi 1.00 import weight 0.00
Epoch 82 Iter 9 subLoss 4646.6 multi 6.97 import weight 0.00
Epoch 82 Iter 10 subLoss 8082.7 multi 3.99 import weight 0.00
Epoch 82 Iter 11 subLoss 29633.0 multi 3.99 import weight 0.00
Epoch 82 Acc: 38.06 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 2963 train Loss: 47019.0 test Loss: 9810.8
Epoch 83 Iter 0 subLoss 46289.6 multi 1.00 import weight 0.00
Epoch 83 Iter 1 subLoss 16384.7 multi 6.97 import weight 0.00
Epoch 83 Iter 2 subLoss 18974.3 multi 3.99 import weight 0.00
Epoch 83 Iter 3 subLoss 15723.3 multi 1.00 import weight 0.00
Epoch 83 Iter 4 subLoss 9231.4 multi 1.00 import weight 0.00
Epoch 83 Iter 5 subLoss 7864.3 multi -1.99 import weight 0.00
Epoch 83 Iter 6 subLoss 10091.8 multi 1.00 import weight 0.00
Epoch 83 Iter 7 subLoss 8137.3 multi -1.99 import weight 0.00
Epoch 83 Iter 8 subLoss 9982.5 multi 1.00 import weight 0.00
Epoch 83 Iter 9 subLoss 8422.0 multi 1.00 import weight 0.00
Epoch 83 Iter 10 subLoss 8394.2 multi 1.00 import weight 0.00
Epoch 83 Iter 11 subLoss 7456.7 multi 1.00 import weight 0.00
Epoch 83 Acc: 96.52 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 745 train Loss: 7351.9 test Loss: 791.0
Epoch 84 Iter 0 subLoss 7365.4 multi 3.99 import weight 0.00
Epoch 84 Iter 1 subLoss 6217.4 multi -1.99 import weight 0.00
Epoch 84 Iter 2 subLoss 6344.9 multi 3.99 import weight 0.00
Epoch 84 Iter 3 subLoss 5368.1 multi 1.00 import weight 0.00
Epoch 84 Iter 4 subLoss 5694.1 multi 1.00 import weight 0.00
Epoch 84 Iter 5 subLoss 5419.9 multi 3.99 import weight 0.00
Epoch 84 Iter 6 subLoss 4952.1 multi -4.97 import weight 0.00
Epoch 84 Iter 7 subLoss 6322.6 multi 1.00 import weight 0.00
Epoch 84 Iter 8 subLoss 5532.2 multi 1.00 import weight 0.00
Epoch 84 Iter 9 subLoss 5041.9 multi -1.99 import weight 0.00
Epoch 84 Iter 10 subLoss 5790.9 multi 1.00 import weight 0.00
Epoch 84 Iter 11 subLoss 5774.9 multi -4.97 import weight 0.00
Epoch 84 Acc: 95.84 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 577 train Loss: 6493.0 test Loss: 696.8
Epoch 85 Iter 0 subLoss 6448.0 multi 3.99 import weight 0.00
Epoch 85 Iter 1 subLoss 5740.5 multi 1.00 import weight 0.00
Epoch 85 Iter 2 subLoss 4996.9 multi -1.99 import weight 0.00
Epoch 85 Iter 3 subLoss 5821.4 multi -1.98 import weight 0.00
Epoch 85 Iter 4 subLoss 7394.6 multi 6.97 import weight 0.00
Epoch 85 Iter 5 subLoss 14093.5 multi -4.97 import weight 0.00
Epoch 85 Iter 6 subLoss 121808.9 multi 1.00 import weight 0.00
Epoch 85 Iter 7 subLoss 22860.7 multi 1.00 import weight 0.00
Epoch 85 Iter 8 subLoss 14661.1 multi -1.99 import weight 0.00
Epoch 85 Iter 9 subLoss 19005.2 multi 1.00 import weight 0.00
Epoch 85 Iter 10 subLoss 15536.6 multi -1.99 import weight 0.00
Epoch 85 Iter 11 subLoss 19833.2 multi 1.00 import weight 0.00
Epoch 85 Acc: 78.81 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1983 train Loss: 16287.7 test Loss: 2708.4
Epoch 86 Iter 0 subLoss 16112.5 multi 1.00 import weight 0.00
Epoch 86 Iter 1 subLoss 14584.6 multi 1.00 import weight 0.00
Epoch 86 Iter 2 subLoss 13027.7 multi -1.99 import weight 0.00
Epoch 86 Iter 3 subLoss 15494.7 multi 1.00 import weight 0.00
Epoch 86 Iter 4 subLoss 13353.5 multi 1.00 import weight 0.00
Epoch 86 Iter 5 subLoss 12914.0 multi 3.99 import weight 0.00
Epoch 86 Iter 6 subLoss 10222.0 multi 1.00 import weight 0.00
Epoch 86 Iter 7 subLoss 9714.5 multi 1.00 import weight 0.00
Epoch 86 Iter 8 subLoss 9509.0 multi 1.00 import weight 0.00
Epoch 86 Iter 9 subLoss 8604.2 multi -1.99 import weight 0.00
Epoch 86 Iter 10 subLoss 9465.6 multi 1.00 import weight 0.00
Epoch 86 Iter 11 subLoss 9176.9 multi 1.00 import weight 0.00
Epoch 86 Acc: 92.35 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 917 train Loss: 9007.1 test Loss: 1131.1
Epoch 87 Iter 0 subLoss 9259.8 multi 3.99 import weight 0.00
Epoch 87 Iter 1 subLoss 7493.7 multi 3.99 import weight 0.00
Epoch 87 Iter 2 subLoss 5771.7 multi -1.98 import weight 0.00
Epoch 87 Iter 3 subLoss 6375.9 multi 1.00 import weight 0.00
Epoch 87 Iter 4 subLoss 6470.9 multi -4.97 import weight 0.00
Epoch 87 Iter 5 subLoss 7662.8 multi 1.00 import weight 0.00
Epoch 87 Iter 6 subLoss 6968.4 multi 1.00 import weight 0.00
Epoch 87 Iter 7 subLoss 6676.5 multi 3.99 import weight 0.00
Epoch 87 Iter 8 subLoss 5782.6 multi -1.98 import weight 0.00
Epoch 87 Iter 9 subLoss 5566.5 multi 3.99 import weight 0.00
Epoch 87 Iter 10 subLoss 5222.1 multi 6.97 import weight 0.00
Epoch 87 Iter 11 subLoss 4850.0 multi 1.00 import weight 0.00
Epoch 87 Acc: 97.14 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 485 train Loss: 5053.7 test Loss: 503.9
Epoch 88 Iter 0 subLoss 5062.1 multi 1.00 import weight 0.00
Epoch 88 Iter 1 subLoss 5503.4 multi -1.99 import weight 0.00
Epoch 88 Iter 2 subLoss 4822.8 multi 1.00 import weight 0.00
Epoch 88 Iter 3 subLoss 4568.8 multi 1.00 import weight 0.00
Epoch 88 Iter 4 subLoss 4860.1 multi -4.97 import weight 0.00
Epoch 88 Iter 5 subLoss 4821.1 multi 3.99 import weight 0.00
Epoch 88 Iter 6 subLoss 4533.2 multi -4.97 import weight 0.00
Epoch 88 Iter 7 subLoss 7764.3 multi 1.00 import weight 0.00
Epoch 88 Iter 8 subLoss 6018.3 multi -4.97 import weight 0.00
Epoch 88 Iter 9 subLoss 13915.2 multi 1.00 import weight 0.00
Epoch 88 Iter 10 subLoss 8675.2 multi 1.00 import weight 0.00
Epoch 88 Iter 11 subLoss 6418.1 multi 1.00 import weight 0.00
Epoch 88 Acc: 96.75 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 641 train Loss: 5743.0 test Loss: 570.9
Epoch 89 Iter 0 subLoss 5517.0 multi 1.00 import weight 0.00
Epoch 89 Iter 1 subLoss 5293.0 multi 1.00 import weight 0.00
Epoch 89 Iter 2 subLoss 4522.4 multi 6.97 import weight 0.00
Epoch 89 Iter 3 subLoss 5036.5 multi 1.00 import weight 0.00
Epoch 89 Iter 4 subLoss 4107.7 multi 3.99 import weight 0.00
Epoch 89 Iter 5 subLoss 4363.6 multi 3.99 import weight 0.00
Epoch 89 Iter 6 subLoss 4534.1 multi -4.97 import weight 0.00
Epoch 89 Iter 7 subLoss 5185.2 multi 6.97 import weight 0.00
Epoch 89 Iter 8 subLoss 8557.7 multi 1.00 import weight 0.00
Epoch 89 Iter 9 subLoss 6173.2 multi 3.98 import weight 0.00
Epoch 89 Iter 10 subLoss 4954.5 multi -1.98 import weight 0.00
Epoch 89 Iter 11 subLoss 8074.6 multi 1.00 import weight 0.00
Epoch 89 Acc: 96.56 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 807 train Loss: 4886.5 test Loss: 505.8
Epoch 90 Iter 0 subLoss 5072.7 multi 3.98 import weight 0.00
Epoch 90 Iter 1 subLoss 4834.5 multi -1.98 import weight 0.00
Epoch 90 Iter 2 subLoss 5192.5 multi -7.96 import weight 0.00
Epoch 90 Iter 3 subLoss 22194.6 multi -4.97 import weight 0.00
Epoch 90 Iter 4 subLoss 399911.0 multi 1.00 import weight 0.00
Epoch 90 Iter 5 subLoss 30490.7 multi 1.00 import weight 0.00
Epoch 90 Iter 6 subLoss 25553.6 multi 1.00 import weight 0.00
Epoch 90 Iter 7 subLoss 22990.8 multi 1.00 import weight 0.00
Epoch 90 Iter 8 subLoss 21857.7 multi 1.00 import weight 0.00
Epoch 90 Iter 9 subLoss 20946.3 multi -1.99 import weight 0.00
Epoch 90 Iter 10 subLoss 22944.8 multi 1.00 import weight 0.00
Epoch 90 Iter 11 subLoss 21330.0 multi 1.00 import weight 0.00
Epoch 90 Acc: 74.04 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2132 train Loss: 21216.7 test Loss: 3111.6
Epoch 91 Iter 0 subLoss 20682.3 multi 3.99 import weight 0.00
Epoch 91 Iter 1 subLoss 18301.6 multi 9.96 import weight 1.00
Epoch 91 Iter 2 subLoss 15929.8 multi 1.00 import weight 0.00
Epoch 91 Iter 3 subLoss 13406.3 multi 1.00 import weight 0.00
Epoch 91 Iter 4 subLoss 13422.8 multi 1.00 import weight 0.00
Epoch 91 Iter 5 subLoss 12815.7 multi -1.99 import weight 0.00
Epoch 91 Iter 6 subLoss 13727.4 multi 1.00 import weight 0.00
Epoch 91 Iter 7 subLoss 13221.7 multi 1.00 import weight 0.00
Epoch 91 Iter 8 subLoss 12562.2 multi 1.00 import weight 0.00
Epoch 91 Iter 9 subLoss 12261.8 multi 1.00 import weight 0.00
Epoch 91 Iter 10 subLoss 11887.4 multi -4.97 import weight 0.00
Epoch 91 Iter 11 subLoss 13969.1 multi 1.00 import weight 0.00
Epoch 91 Acc: 81.30 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1396 train Loss: 14044.6 test Loss: 1852.9
Epoch 92 Iter 0 subLoss 13646.8 multi 1.00 import weight 0.00
Epoch 92 Iter 1 subLoss 13359.0 multi 3.99 import weight 0.00
Epoch 92 Iter 2 subLoss 10984.1 multi -1.99 import weight 0.00
Epoch 92 Iter 3 subLoss 12766.3 multi 1.00 import weight 0.00
Epoch 92 Iter 4 subLoss 12147.1 multi 1.00 import weight 0.00
Epoch 92 Iter 5 subLoss 11700.9 multi -4.97 import weight 0.00
Epoch 92 Iter 6 subLoss 13567.9 multi 1.00 import weight 0.00
Epoch 92 Iter 7 subLoss 13248.0 multi 1.00 import weight 0.00
Epoch 92 Iter 8 subLoss 13022.5 multi 1.00 import weight 0.00
Epoch 92 Iter 9 subLoss 12484.3 multi 1.00 import weight 0.00
Epoch 92 Iter 10 subLoss 12285.6 multi 3.99 import weight 0.00
Epoch 92 Iter 11 subLoss 10815.8 multi 3.98 import weight 0.00
Epoch 92 Acc: 93.95 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 1081 train Loss: 9492.9 test Loss: 1063.9
Epoch 93 Iter 0 subLoss 9945.8 multi -1.99 import weight 0.00
Epoch 93 Iter 1 subLoss 10133.6 multi 1.00 import weight 0.00
Epoch 93 Iter 2 subLoss 9641.5 multi 1.00 import weight 0.00
Epoch 93 Iter 3 subLoss 9415.5 multi 1.00 import weight 0.00
Epoch 93 Iter 4 subLoss 8730.7 multi 3.99 import weight 0.00
Epoch 93 Iter 5 subLoss 7846.0 multi 1.00 import weight 0.00
Epoch 93 Iter 6 subLoss 7454.2 multi 3.99 import weight 0.00
Epoch 93 Iter 7 subLoss 7418.4 multi 1.00 import weight 0.00
Epoch 93 Iter 8 subLoss 7549.9 multi -1.99 import weight 0.00
Epoch 93 Iter 9 subLoss 7052.8 multi 1.00 import weight 0.00
Epoch 93 Iter 10 subLoss 7622.9 multi 1.00 import weight 0.00
Epoch 93 Iter 11 subLoss 7195.5 multi -1.99 import weight 0.00
Epoch 93 Acc: 94.78 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 719 train Loss: 7471.3 test Loss: 843.7
Epoch 94 Iter 0 subLoss 7047.9 multi -4.97 import weight 0.00
Epoch 94 Iter 1 subLoss 9778.5 multi 1.00 import weight 0.00
Epoch 94 Iter 2 subLoss 7857.4 multi 1.00 import weight 0.00
Epoch 94 Iter 3 subLoss 7466.3 multi -4.97 import weight 0.00
Epoch 94 Iter 4 subLoss 8505.6 multi 9.96 import weight 1.00
Epoch 94 Iter 5 subLoss 9708.3 multi 1.00 import weight 0.00
Epoch 94 Iter 6 subLoss 7273.5 multi 1.00 import weight 0.00
Epoch 94 Iter 7 subLoss 7781.0 multi 1.00 import weight 0.00
Epoch 94 Iter 8 subLoss 6242.0 multi 1.00 import weight 0.00
Epoch 94 Iter 9 subLoss 6764.5 multi -1.99 import weight 0.00
Epoch 94 Iter 10 subLoss 6732.2 multi 3.99 import weight 0.00
Epoch 94 Iter 11 subLoss 6209.2 multi 3.99 import weight 0.00
Epoch 94 Acc: 95.64 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 620 train Loss: 6338.0 test Loss: 703.3
Epoch 95 Iter 0 subLoss 6090.5 multi 3.99 import weight 0.00
Epoch 95 Iter 1 subLoss 5795.6 multi 1.00 import weight 0.00
Epoch 95 Iter 2 subLoss 5504.7 multi 1.00 import weight 0.00
Epoch 95 Iter 3 subLoss 4768.6 multi -1.99 import weight 0.00
Epoch 95 Iter 4 subLoss 6169.4 multi 3.99 import weight 0.00
Epoch 95 Iter 5 subLoss 5761.8 multi 3.98 import weight 0.00
Epoch 95 Iter 6 subLoss 5267.0 multi -1.99 import weight 0.00
Epoch 95 Iter 7 subLoss 6056.9 multi 3.99 import weight 0.00
Epoch 95 Iter 8 subLoss 6872.4 multi 6.97 import weight 1.00
Epoch 95 Iter 9 subLoss 34641.9 multi 1.00 import weight 0.00
Epoch 95 Iter 10 subLoss 11030.2 multi 3.99 import weight 0.00
Epoch 95 Iter 11 subLoss 16127.2 multi -1.99 import weight 0.00
Epoch 95 Acc: 27.90 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 1612 train Loss: 123620.3 test Loss: 22575.9
Epoch 96 Iter 0 subLoss 123568.0 multi 3.99 import weight 0.00
Epoch 96 Iter 1 subLoss 84591.7 multi 1.00 import weight 0.00
Epoch 96 Iter 2 subLoss 56448.8 multi 1.00 import weight 0.00
Epoch 96 Iter 3 subLoss 52882.9 multi 1.00 import weight 0.00
Epoch 96 Iter 4 subLoss 52414.2 multi 1.00 import weight 0.00
Epoch 96 Iter 5 subLoss 52609.8 multi 1.00 import weight 0.00
Epoch 96 Iter 6 subLoss 50862.0 multi 1.00 import weight 0.00
Epoch 96 Iter 7 subLoss 49013.7 multi 1.00 import weight 0.00
Epoch 96 Iter 8 subLoss 43530.2 multi 1.00 import weight 0.00
Epoch 96 Iter 9 subLoss 40968.9 multi 1.00 import weight 0.00
Epoch 96 Iter 10 subLoss 42218.5 multi 1.00 import weight 0.00
Epoch 96 Iter 11 subLoss 37863.6 multi 1.00 import weight 0.00
Epoch 96 Acc: 43.90 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 3786 train Loss: 38820.8 test Loss: 6819.0
Epoch 97 Iter 0 subLoss 37647.4 multi 1.00 import weight 0.00
Epoch 97 Iter 1 subLoss 34332.4 multi 1.00 import weight 0.00
Epoch 97 Iter 2 subLoss 34304.6 multi 1.00 import weight 0.00
Epoch 97 Iter 3 subLoss 31916.3 multi 3.99 import weight 0.00
Epoch 97 Iter 4 subLoss 48326.6 multi 1.00 import weight 0.00
Epoch 97 Iter 5 subLoss 39840.2 multi 3.99 import weight 0.00
Epoch 97 Iter 6 subLoss 130488.7 multi 1.00 import weight 0.00
Epoch 97 Iter 7 subLoss 32675.6 multi 1.00 import weight 0.00
Epoch 97 Iter 8 subLoss 27300.2 multi -1.99 import weight 0.00
Epoch 97 Iter 9 subLoss 34544.4 multi 1.00 import weight 0.00
Epoch 97 Iter 10 subLoss 30398.2 multi 1.00 import weight 0.00
Epoch 97 Iter 11 subLoss 27206.5 multi -1.99 import weight 0.00
Epoch 97 Acc: 56.61 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 2720 train Loss: 33145.4 test Loss: 5491.3
Epoch 98 Iter 0 subLoss 32924.3 multi 1.00 import weight 0.00
Epoch 98 Iter 1 subLoss 30157.4 multi 1.00 import weight 0.00
Epoch 98 Iter 2 subLoss 27365.3 multi 3.99 import weight 0.00
Epoch 98 Iter 3 subLoss 23493.5 multi 1.00 import weight 0.00
Epoch 98 Iter 4 subLoss 22751.6 multi 1.00 import weight 0.00
Epoch 98 Iter 5 subLoss 21629.0 multi 1.00 import weight 0.00
Epoch 98 Iter 6 subLoss 21612.1 multi 1.00 import weight 0.00
Epoch 98 Iter 7 subLoss 20980.7 multi -1.99 import weight 0.00
Epoch 98 Iter 8 subLoss 21527.6 multi -1.99 import weight 0.00
Epoch 98 Iter 9 subLoss 22936.2 multi 1.00 import weight 0.00
Epoch 98 Iter 10 subLoss 22065.7 multi 1.00 import weight 0.00
Epoch 98 Iter 11 subLoss 22371.4 multi 1.00 import weight 0.00
Epoch 98 Acc: 74.29 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2237 train Loss: 21822.5 test Loss: 3482.7
Epoch 99 Iter 0 subLoss 21329.9 multi 3.99 import weight 0.00
Epoch 99 Iter 1 subLoss 20555.0 multi -1.98 import weight 0.00
Epoch 99 Iter 2 subLoss 20776.7 multi 1.00 import weight 0.00
Epoch 99 Iter 3 subLoss 20306.6 multi 1.00 import weight 0.00
Epoch 99 Iter 4 subLoss 19441.7 multi 1.00 import weight 0.00
Epoch 99 Iter 5 subLoss 20103.5 multi -1.99 import weight 0.00
Epoch 99 Iter 6 subLoss 20686.8 multi 6.97 import weight 0.00
Epoch 99 Iter 7 subLoss 18855.1 multi -1.99 import weight 0.00
Epoch 99 Iter 8 subLoss 23887.8 multi 1.00 import weight 0.00
Epoch 99 Iter 9 subLoss 18841.6 multi 3.99 import weight 0.00
Epoch 99 Iter 10 subLoss 18267.2 multi 1.00 import weight 0.00
Epoch 99 Iter 11 subLoss 17187.2 multi 3.99 import weight 0.00
Epoch 99 Acc: 76.40 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 1718 train Loss: 17636.5 test Loss: 2813.8
Epoch 100 Iter 0 subLoss 17096.2 multi 1.00 import weight 0.00
Epoch 100 Iter 1 subLoss 16944.4 multi 1.00 import weight 0.00
Epoch 100 Iter 2 subLoss 15940.1 multi -1.99 import weight 0.00
Epoch 100 Iter 3 subLoss 16435.3 multi 6.97 import weight 0.00
Epoch 100 Iter 4 subLoss 15995.8 multi 1.00 import weight 0.00
Epoch 100 Iter 5 subLoss 15727.5 multi 3.99 import weight 0.00
Epoch 100 Iter 6 subLoss 15184.2 multi -1.99 import weight 0.00
Epoch 100 Iter 7 subLoss 25609.2 multi 3.99 import weight 0.00
Epoch 100 Iter 8 subLoss 51515.0 multi 1.00 import weight 0.00
Epoch 100 Iter 9 subLoss 38790.8 multi 1.00 import weight 0.00
Epoch 100 Iter 10 subLoss 31795.9 multi 1.00 import weight 0.00
Epoch 100 Iter 11 subLoss 28491.4 multi 1.00 import weight 0.00
Epoch 100 Acc: 64.33 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2849 train Loss: 26807.5 test Loss: 3336.3
Epoch 101 Iter 0 subLoss 25782.0 multi 1.00 import weight 0.00
Epoch 101 Iter 1 subLoss 23985.0 multi 3.99 import weight 0.00
Epoch 101 Iter 2 subLoss 20372.3 multi 3.99 import weight 0.00
Epoch 101 Iter 3 subLoss 18914.3 multi 1.00 import weight 0.00
Epoch 101 Iter 4 subLoss 17199.7 multi -1.98 import weight 0.00
Epoch 101 Iter 5 subLoss 20055.8 multi 1.00 import weight 0.00
Epoch 101 Iter 6 subLoss 18272.8 multi -1.99 import weight 0.00
Epoch 101 Iter 7 subLoss 21809.7 multi -1.99 import weight 0.00
Epoch 101 Iter 8 subLoss 27782.2 multi 1.00 import weight 0.00
Epoch 101 Iter 9 subLoss 23597.3 multi 1.00 import weight 0.00
Epoch 101 Iter 10 subLoss 20800.5 multi 3.98 import weight 0.00
Epoch 101 Iter 11 subLoss 16010.1 multi 1.00 import weight 0.00
Epoch 101 Acc: 84.12 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1601 train Loss: 16127.7 test Loss: 2163.0
Epoch 102 Iter 0 subLoss 15563.5 multi 1.00 import weight 0.00
Epoch 102 Iter 1 subLoss 15157.3 multi 1.00 import weight 0.00
Epoch 102 Iter 2 subLoss 15019.8 multi 6.97 import weight 0.00
Epoch 102 Iter 3 subLoss 12834.8 multi 1.00 import weight 0.00
Epoch 102 Iter 4 subLoss 12980.9 multi -4.97 import weight 0.00
Epoch 102 Iter 5 subLoss 14059.6 multi 1.00 import weight 0.00
Epoch 102 Iter 6 subLoss 14175.8 multi 1.00 import weight 0.00
Epoch 102 Iter 7 subLoss 13609.9 multi 1.00 import weight 0.00
Epoch 102 Iter 8 subLoss 13460.4 multi 1.00 import weight 0.00
Epoch 102 Iter 9 subLoss 12342.6 multi 1.00 import weight 0.00
Epoch 102 Iter 10 subLoss 12292.7 multi -4.97 import weight 0.00
Epoch 102 Iter 11 subLoss 13632.5 multi 1.00 import weight 0.00
Epoch 102 Acc: 91.71 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1363 train Loss: 13842.5 test Loss: 1804.1
Epoch 103 Iter 0 subLoss 13253.8 multi -1.99 import weight 0.00
Epoch 103 Iter 1 subLoss 14921.7 multi 1.00 import weight 0.00
Epoch 103 Iter 2 subLoss 13695.5 multi 1.00 import weight 0.00
Epoch 103 Iter 3 subLoss 12903.7 multi -1.99 import weight 0.00
Epoch 103 Iter 4 subLoss 14015.2 multi -1.99 import weight 0.00
Epoch 103 Iter 5 subLoss 14720.5 multi 3.99 import weight 0.00
Epoch 103 Iter 6 subLoss 13224.3 multi 3.99 import weight 0.00
Epoch 103 Iter 7 subLoss 12979.9 multi 3.98 import weight 0.00
Epoch 103 Iter 8 subLoss 12358.1 multi 1.00 import weight 0.00
Epoch 103 Iter 9 subLoss 12263.1 multi 3.99 import weight 0.00
Epoch 103 Iter 10 subLoss 11556.3 multi 1.00 import weight 0.00
Epoch 103 Iter 11 subLoss 11443.3 multi 1.00 import weight 0.00
Epoch 103 Acc: 92.55 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1144 train Loss: 11538.7 test Loss: 1499.0
Epoch 104 Iter 0 subLoss 11137.2 multi -1.99 import weight 0.00
Epoch 104 Iter 1 subLoss 11344.6 multi 1.00 import weight 0.00
Epoch 104 Iter 2 subLoss 11579.6 multi -1.99 import weight 0.00
Epoch 104 Iter 3 subLoss 11532.4 multi 3.99 import weight 0.00
Epoch 104 Iter 4 subLoss 10960.1 multi 1.00 import weight 0.00
Epoch 104 Iter 5 subLoss 10639.0 multi -1.99 import weight 0.00
Epoch 104 Iter 6 subLoss 11288.9 multi 1.00 import weight 0.00
Epoch 104 Iter 7 subLoss 11147.3 multi -1.99 import weight 0.00
Epoch 104 Iter 8 subLoss 12253.0 multi 1.00 import weight 0.00
Epoch 104 Iter 9 subLoss 11802.1 multi 1.00 import weight 0.00
Epoch 104 Iter 10 subLoss 10829.1 multi -7.96 import weight 0.00
Epoch 104 Iter 11 subLoss 12766.6 multi 3.99 import weight 0.00
Epoch 104 Acc: 87.80 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 1276 train Loss: 13463.6 test Loss: 1926.6
Epoch 105 Iter 0 subLoss 13348.3 multi -4.97 import weight 0.00
Epoch 105 Iter 1 subLoss 39791.0 multi 1.00 import weight 0.00
Epoch 105 Iter 2 subLoss 14395.5 multi 1.00 import weight 0.00
Epoch 105 Iter 3 subLoss 12758.2 multi 1.00 import weight 0.00
Epoch 105 Iter 4 subLoss 12201.4 multi -4.97 import weight 0.00
Epoch 105 Iter 5 subLoss 14191.8 multi 1.00 import weight 0.00
Epoch 105 Iter 6 subLoss 14066.7 multi 1.00 import weight 0.00
Epoch 105 Iter 7 subLoss 13704.5 multi 1.00 import weight 0.00
Epoch 105 Iter 8 subLoss 12674.0 multi -1.99 import weight 0.00
Epoch 105 Iter 9 subLoss 14683.7 multi 3.99 import weight 0.00
Epoch 105 Iter 10 subLoss 12586.5 multi -1.99 import weight 0.00
Epoch 105 Iter 11 subLoss 12898.2 multi 3.99 import weight 0.00
Epoch 105 Acc: 92.68 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 1289 train Loss: 12216.1 test Loss: 1662.4
Epoch 106 Iter 0 subLoss 12115.3 multi 1.00 import weight 0.00
Epoch 106 Iter 1 subLoss 11964.2 multi -1.99 import weight 0.00
Epoch 106 Iter 2 subLoss 12371.1 multi 1.00 import weight 0.00
Epoch 106 Iter 3 subLoss 11467.9 multi 1.00 import weight 0.00
Epoch 106 Iter 4 subLoss 11747.6 multi 1.00 import weight 0.00
Epoch 106 Iter 5 subLoss 11800.7 multi 3.99 import weight 0.00
Epoch 106 Iter 6 subLoss 11012.1 multi 1.00 import weight 0.00
Epoch 106 Iter 7 subLoss 10847.9 multi 1.00 import weight 0.00
Epoch 106 Iter 8 subLoss 11213.1 multi 1.00 import weight 0.00
Epoch 106 Iter 9 subLoss 11720.5 multi -1.99 import weight 0.00
Epoch 106 Iter 10 subLoss 11093.9 multi 1.00 import weight 0.00
Epoch 106 Iter 11 subLoss 11036.8 multi 6.97 import weight 0.00
Epoch 106 Acc: 92.90 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 1103 train Loss: 10548.1 test Loss: 1417.1
Epoch 107 Iter 0 subLoss 10058.5 multi 1.00 import weight 0.00
Epoch 107 Iter 1 subLoss 9962.0 multi 1.00 import weight 0.00
Epoch 107 Iter 2 subLoss 10331.5 multi -1.99 import weight 0.00
Epoch 107 Iter 3 subLoss 10124.8 multi 1.00 import weight 0.00
Epoch 107 Iter 4 subLoss 10062.0 multi 1.00 import weight 0.00
Epoch 107 Iter 5 subLoss 9942.4 multi 1.00 import weight 0.00
Epoch 107 Iter 6 subLoss 10002.2 multi 3.99 import weight 0.00
Epoch 107 Iter 7 subLoss 9604.6 multi -1.99 import weight 0.00
Epoch 107 Iter 8 subLoss 10612.2 multi 1.00 import weight 0.00
Epoch 107 Iter 9 subLoss 10029.8 multi 1.00 import weight 0.00
Epoch 107 Iter 10 subLoss 10117.5 multi 1.00 import weight 0.00
Epoch 107 Iter 11 subLoss 9149.2 multi -4.97 import weight 0.00
Epoch 107 Acc: 93.97 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 914 train Loss: 10346.3 test Loss: 1333.8
Epoch 108 Iter 0 subLoss 10182.9 multi 1.00 import weight 0.00
Epoch 108 Iter 1 subLoss 9679.0 multi -1.99 import weight 0.00
Epoch 108 Iter 2 subLoss 9607.1 multi 1.00 import weight 0.00
Epoch 108 Iter 3 subLoss 10244.1 multi 1.00 import weight 0.00
Epoch 108 Iter 4 subLoss 10183.5 multi 3.99 import weight 0.00
Epoch 108 Iter 5 subLoss 9404.5 multi 1.00 import weight 0.00
Epoch 108 Iter 6 subLoss 9597.8 multi 3.99 import weight 0.00
Epoch 108 Iter 7 subLoss 8978.8 multi 1.00 import weight 0.00
Epoch 108 Iter 8 subLoss 9700.8 multi 3.99 import weight 0.00
Epoch 108 Iter 9 subLoss 9392.1 multi 1.00 import weight 0.00
Epoch 108 Iter 10 subLoss 9182.6 multi -1.99 import weight 0.00
Epoch 108 Iter 11 subLoss 8547.1 multi -1.99 import weight 0.00
Epoch 108 Acc: 94.71 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 854 train Loss: 9615.4 test Loss: 1141.5
Epoch 109 Iter 0 subLoss 8740.7 multi -4.97 import weight 0.00
Epoch 109 Iter 1 subLoss 14366.3 multi 1.00 import weight 0.00
Epoch 109 Iter 2 subLoss 10492.4 multi 1.00 import weight 0.00
Epoch 109 Iter 3 subLoss 9644.7 multi 3.99 import weight 0.00
Epoch 109 Iter 4 subLoss 9355.5 multi 6.97 import weight 0.00
Epoch 109 Iter 5 subLoss 15627.9 multi 3.98 import weight 0.00
Epoch 109 Iter 6 subLoss 20175.7 multi 3.99 import weight 0.00
Epoch 109 Iter 7 subLoss 24277.6 multi 1.00 import weight 0.00
Epoch 109 Iter 8 subLoss 18314.0 multi -10.94 import weight 0.00
Epoch 109 Iter 9 subLoss 52280.1 multi 1.00 import weight 0.00
Epoch 109 Iter 10 subLoss 42042.3 multi 1.00 import weight 0.00
Epoch 109 Iter 11 subLoss 35473.5 multi 1.00 import weight 0.00
Epoch 109 Acc: 72.74 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 3547 train Loss: 33151.5 test Loss: 5108.3
Epoch 110 Iter 0 subLoss 31805.3 multi -1.99 import weight 0.00
Epoch 110 Iter 1 subLoss 37066.8 multi 1.00 import weight 0.00
Epoch 110 Iter 2 subLoss 33574.1 multi 3.99 import weight 0.00
Epoch 110 Iter 3 subLoss 29950.8 multi 1.00 import weight 0.00
Epoch 110 Iter 4 subLoss 29334.6 multi 1.00 import weight 0.00
Epoch 110 Iter 5 subLoss 29253.6 multi 1.00 import weight 0.00
Epoch 110 Iter 6 subLoss 28443.0 multi -1.99 import weight 0.00
Epoch 110 Iter 7 subLoss 27912.9 multi -1.99 import weight 0.00
Epoch 110 Iter 8 subLoss 30272.7 multi 1.00 import weight 0.00
Epoch 110 Iter 9 subLoss 28300.1 multi 1.00 import weight 0.00
Epoch 110 Iter 10 subLoss 28310.8 multi -1.99 import weight 0.00
Epoch 110 Iter 11 subLoss 29379.2 multi 1.00 import weight 0.00
Epoch 110 Acc: 75.36 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2937 train Loss: 29480.2 test Loss: 4532.7
Epoch 111 Iter 0 subLoss 29307.7 multi 3.99 import weight 0.00
Epoch 111 Iter 1 subLoss 28305.8 multi 3.99 import weight 0.00
Epoch 111 Iter 2 subLoss 27219.9 multi 1.00 import weight 0.00
Epoch 111 Iter 3 subLoss 26121.9 multi -1.99 import weight 0.00
Epoch 111 Iter 4 subLoss 27068.0 multi 1.00 import weight 0.00
Epoch 111 Iter 5 subLoss 26015.2 multi 1.00 import weight 0.00
Epoch 111 Iter 6 subLoss 26788.5 multi 1.00 import weight 0.00
Epoch 111 Iter 7 subLoss 26639.4 multi 1.00 import weight 0.00
Epoch 111 Iter 8 subLoss 25818.5 multi 1.00 import weight 0.00
Epoch 111 Iter 9 subLoss 26399.0 multi 1.00 import weight 0.00
Epoch 111 Iter 10 subLoss 26587.8 multi 1.00 import weight 0.00
Epoch 111 Iter 11 subLoss 24762.8 multi 1.00 import weight 0.00
Epoch 111 Acc: 76.67 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2476 train Loss: 26110.2 test Loss: 4052.2
Epoch 112 Iter 0 subLoss 25503.6 multi 1.00 import weight 0.00
Epoch 112 Iter 1 subLoss 25408.2 multi 1.00 import weight 0.00
Epoch 112 Iter 2 subLoss 25447.3 multi 1.00 import weight 0.00
Epoch 112 Iter 3 subLoss 24822.8 multi 1.00 import weight 0.00
Epoch 112 Iter 4 subLoss 25903.2 multi 1.00 import weight 0.00
Epoch 112 Iter 5 subLoss 24177.6 multi 3.99 import weight 0.00
Epoch 112 Iter 6 subLoss 24640.0 multi 1.00 import weight 0.00
Epoch 112 Iter 7 subLoss 25116.1 multi 1.00 import weight 0.00
Epoch 112 Iter 8 subLoss 24560.1 multi 1.00 import weight 0.00
Epoch 112 Iter 9 subLoss 24218.1 multi 1.00 import weight 0.00
Epoch 112 Iter 10 subLoss 24051.7 multi 1.00 import weight 0.00
Epoch 112 Iter 11 subLoss 23552.0 multi 1.00 import weight 0.00
Epoch 112 Acc: 77.02 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2355 train Loss: 24410.9 test Loss: 3792.8
Epoch 113 Iter 0 subLoss 24334.6 multi 1.00 import weight 0.00
Epoch 113 Iter 1 subLoss 23628.0 multi 1.00 import weight 0.00
Epoch 113 Iter 2 subLoss 24410.1 multi 1.00 import weight 0.00
Epoch 113 Iter 3 subLoss 23181.7 multi 1.00 import weight 0.00
Epoch 113 Iter 4 subLoss 22886.9 multi 1.00 import weight 0.00
Epoch 113 Iter 5 subLoss 23576.3 multi 3.99 import weight 0.00
Epoch 113 Iter 6 subLoss 24345.4 multi 1.00 import weight 0.00
Epoch 113 Iter 7 subLoss 22606.2 multi -1.99 import weight 0.00
Epoch 113 Iter 8 subLoss 23006.5 multi -1.99 import weight 0.00
Epoch 113 Iter 9 subLoss 23474.2 multi 1.00 import weight 0.00
Epoch 113 Iter 10 subLoss 23422.8 multi 1.00 import weight 0.00
Epoch 113 Iter 11 subLoss 23707.2 multi -1.99 import weight 0.00
Epoch 113 Acc: 76.24 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 2370 train Loss: 23907.7 test Loss: 3756.6
Epoch 114 Iter 0 subLoss 24056.6 multi 3.99 import weight 0.00
Epoch 114 Iter 1 subLoss 23118.7 multi 1.00 import weight 0.00
Epoch 114 Iter 2 subLoss 22407.4 multi 1.00 import weight 0.00
Epoch 114 Iter 3 subLoss 22655.9 multi -1.99 import weight 0.00
Epoch 114 Iter 4 subLoss 23595.3 multi 3.99 import weight 0.00
Epoch 114 Iter 5 subLoss 22786.0 multi 1.00 import weight 0.00
Epoch 114 Iter 6 subLoss 22723.4 multi 1.00 import weight 0.00
Epoch 114 Iter 7 subLoss 22408.0 multi 3.99 import weight 0.00
Epoch 114 Iter 8 subLoss 22436.3 multi 1.00 import weight 0.00
Epoch 114 Iter 9 subLoss 22330.1 multi 1.00 import weight 0.00
Epoch 114 Iter 10 subLoss 22069.9 multi 3.99 import weight 0.00
Epoch 114 Iter 11 subLoss 22224.2 multi 3.99 import weight 0.00
Epoch 114 Acc: 77.66 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 2222 train Loss: 22141.1 test Loss: 3427.0
Epoch 115 Iter 0 subLoss 21015.3 multi 3.99 import weight 0.00
Epoch 115 Iter 1 subLoss 21053.5 multi 3.99 import weight 0.00
Epoch 115 Iter 2 subLoss 22410.5 multi -4.97 import weight 0.00
Epoch 115 Iter 3 subLoss 28263.9 multi 3.99 import weight 0.00
Epoch 115 Iter 4 subLoss 25824.2 multi 1.00 import weight 0.00
Epoch 115 Iter 5 subLoss 25492.3 multi 1.00 import weight 0.00
Epoch 115 Iter 6 subLoss 24160.0 multi 1.00 import weight 0.00
Epoch 115 Iter 7 subLoss 23452.0 multi 1.00 import weight 0.00
Epoch 115 Iter 8 subLoss 22038.9 multi 3.99 import weight 0.00
Epoch 115 Iter 9 subLoss 21943.1 multi 1.00 import weight 0.00
Epoch 115 Iter 10 subLoss 20548.4 multi 6.97 import weight 0.00
Epoch 115 Iter 11 subLoss 21186.1 multi 1.00 import weight 0.00
Epoch 115 Acc: 77.29 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2118 train Loss: 20838.4 test Loss: 3252.7
Epoch 116 Iter 0 subLoss 20049.5 multi -1.99 import weight 0.00
Epoch 116 Iter 1 subLoss 21307.6 multi 1.00 import weight 0.00
Epoch 116 Iter 2 subLoss 20298.6 multi 3.99 import weight 0.00
Epoch 116 Iter 3 subLoss 19836.3 multi 3.99 import weight 0.00
Epoch 116 Iter 4 subLoss 20321.3 multi 1.00 import weight 0.00
Epoch 116 Iter 5 subLoss 19451.5 multi -1.99 import weight 0.00
Epoch 116 Iter 6 subLoss 19896.1 multi -4.97 import weight 0.00
Epoch 116 Iter 7 subLoss 21687.3 multi 1.00 import weight 0.00
Epoch 116 Iter 8 subLoss 20628.2 multi 3.99 import weight 0.00
Epoch 116 Iter 9 subLoss 20898.7 multi 1.00 import weight 0.00
Epoch 116 Iter 10 subLoss 20645.3 multi 1.00 import weight 0.00
Epoch 116 Iter 11 subLoss 19875.5 multi 1.00 import weight 0.00
Epoch 116 Acc: 77.86 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1987 train Loss: 20201.0 test Loss: 3123.4
Epoch 117 Iter 0 subLoss 19964.4 multi 1.00 import weight 0.00
Epoch 117 Iter 1 subLoss 18923.7 multi 1.00 import weight 0.00
Epoch 117 Iter 2 subLoss 19066.1 multi 3.99 import weight 0.00
Epoch 117 Iter 3 subLoss 19524.6 multi 1.00 import weight 0.00
Epoch 117 Iter 4 subLoss 20279.5 multi 1.00 import weight 0.00
Epoch 117 Iter 5 subLoss 18905.3 multi -1.99 import weight 0.00
Epoch 117 Iter 6 subLoss 19922.5 multi 3.99 import weight 0.00
Epoch 117 Iter 7 subLoss 19520.0 multi 3.99 import weight 0.00
Epoch 117 Iter 8 subLoss 20511.2 multi 1.00 import weight 0.00
Epoch 117 Iter 9 subLoss 19756.0 multi 1.00 import weight 0.00
Epoch 117 Iter 10 subLoss 18549.1 multi 3.99 import weight 0.00
Epoch 117 Iter 11 subLoss 19972.7 multi -1.99 import weight 0.00
Epoch 117 Acc: 73.65 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 1997 train Loss: 21033.1 test Loss: 3403.2
Epoch 118 Iter 0 subLoss 20627.9 multi 6.97 import weight 0.00
Epoch 118 Iter 1 subLoss 29010.9 multi -1.99 import weight 0.00
Epoch 118 Iter 2 subLoss 45952.5 multi 1.00 import weight 0.00
Epoch 118 Iter 3 subLoss 32698.8 multi 3.99 import weight 0.00
Epoch 118 Iter 4 subLoss 35180.0 multi 1.00 import weight 0.00
Epoch 118 Iter 5 subLoss 24156.2 multi 1.00 import weight 0.00
Epoch 118 Iter 6 subLoss 23165.9 multi 1.00 import weight 0.00
Epoch 118 Iter 7 subLoss 23138.2 multi -1.99 import weight 0.00
Epoch 118 Iter 8 subLoss 23863.6 multi 1.00 import weight 0.00
Epoch 118 Iter 9 subLoss 23722.7 multi 1.00 import weight 0.00
Epoch 118 Iter 10 subLoss 23290.7 multi 3.99 import weight 0.00
Epoch 118 Iter 11 subLoss 21025.7 multi -1.98 import weight 0.00
Epoch 118 Acc: 71.55 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 2102 train Loss: 22657.3 test Loss: 3532.8
Epoch 119 Iter 0 subLoss 22186.9 multi 6.97 import weight 0.00
Epoch 119 Iter 1 subLoss 21787.1 multi 1.00 import weight 0.00
Epoch 119 Iter 2 subLoss 21824.4 multi 1.00 import weight 0.00
Epoch 119 Iter 3 subLoss 21321.2 multi 6.97 import weight 0.00
Epoch 119 Iter 4 subLoss 20471.8 multi 3.99 import weight 0.00
Epoch 119 Iter 5 subLoss 19351.6 multi 1.00 import weight 0.00
Epoch 119 Iter 6 subLoss 19657.3 multi 1.00 import weight 0.00
Epoch 119 Iter 7 subLoss 18854.7 multi -1.98 import weight 0.00
Epoch 119 Iter 8 subLoss 19282.4 multi 1.00 import weight 0.00
Epoch 119 Iter 9 subLoss 17908.2 multi 1.00 import weight 0.00
Epoch 119 Iter 10 subLoss 19257.7 multi 3.99 import weight 0.00
Epoch 119 Iter 11 subLoss 18343.0 multi 1.00 import weight 0.00
Epoch 119 Acc: 77.68 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1834 train Loss: 18686.5 test Loss: 2845.4
Epoch 120 Iter 0 subLoss 17944.3 multi -1.99 import weight 0.00
Epoch 120 Iter 1 subLoss 18638.6 multi 3.99 import weight 0.00
Epoch 120 Iter 2 subLoss 18133.4 multi 1.00 import weight 0.00
Epoch 120 Iter 3 subLoss 17407.2 multi 1.00 import weight 0.00
Epoch 120 Iter 4 subLoss 17852.4 multi -1.99 import weight 0.00
Epoch 120 Iter 5 subLoss 17727.1 multi 3.99 import weight 0.00
Epoch 120 Iter 6 subLoss 17772.1 multi 3.99 import weight 0.00
Epoch 120 Iter 7 subLoss 18484.3 multi 1.00 import weight 0.00
Epoch 120 Iter 8 subLoss 16867.7 multi 1.00 import weight 0.00
Epoch 120 Iter 9 subLoss 17981.0 multi -1.99 import weight 0.00
Epoch 120 Iter 10 subLoss 17674.9 multi -1.99 import weight 0.00
Epoch 120 Iter 11 subLoss 18619.7 multi 1.00 import weight 0.00
Epoch 120 Acc: 78.05 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1861 train Loss: 18137.6 test Loss: 2709.4
Epoch 121 Iter 0 subLoss 17963.3 multi 1.00 import weight 0.00
Epoch 121 Iter 1 subLoss 17459.5 multi -1.99 import weight 0.00
Epoch 121 Iter 2 subLoss 18209.8 multi 1.00 import weight 0.00
Epoch 121 Iter 3 subLoss 17398.9 multi 3.99 import weight 0.00
Epoch 121 Iter 4 subLoss 17461.3 multi -1.99 import weight 0.00
Epoch 121 Iter 5 subLoss 17558.6 multi 6.97 import weight 0.00
Epoch 121 Iter 6 subLoss 16687.9 multi 1.00 import weight 0.00
Epoch 121 Iter 7 subLoss 17685.0 multi -1.99 import weight 0.00
Epoch 121 Iter 8 subLoss 17456.7 multi 1.00 import weight 0.00
Epoch 121 Iter 9 subLoss 17014.7 multi 1.00 import weight 0.00
Epoch 121 Iter 10 subLoss 17042.3 multi -1.99 import weight 0.00
Epoch 121 Iter 11 subLoss 18298.3 multi 1.00 import weight 0.00
Epoch 121 Acc: 77.72 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1829 train Loss: 17598.6 test Loss: 2699.1
Epoch 122 Iter 0 subLoss 17438.4 multi 1.00 import weight 0.00
Epoch 122 Iter 1 subLoss 17823.0 multi -1.99 import weight 0.00
Epoch 122 Iter 2 subLoss 17389.5 multi 1.00 import weight 0.00
Epoch 122 Iter 3 subLoss 17112.4 multi 1.00 import weight 0.00
Epoch 122 Iter 4 subLoss 17062.0 multi 1.00 import weight 0.00
Epoch 122 Iter 5 subLoss 17398.9 multi 3.98 import weight 0.00
Epoch 122 Iter 6 subLoss 17235.5 multi 1.00 import weight 0.00
Epoch 122 Iter 7 subLoss 16500.6 multi -1.99 import weight 0.00
Epoch 122 Iter 8 subLoss 17109.9 multi -1.99 import weight 0.00
Epoch 122 Iter 9 subLoss 17387.0 multi 3.99 import weight 0.00
Epoch 122 Iter 10 subLoss 17117.1 multi 1.00 import weight 0.00
Epoch 122 Iter 11 subLoss 16558.9 multi 1.00 import weight 0.00
Epoch 122 Acc: 78.03 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1655 train Loss: 17240.6 test Loss: 2635.7
Epoch 123 Iter 0 subLoss 17204.4 multi -1.98 import weight 0.00
Epoch 123 Iter 1 subLoss 17166.9 multi 1.00 import weight 0.00
Epoch 123 Iter 2 subLoss 17346.4 multi 1.00 import weight 0.00
Epoch 123 Iter 3 subLoss 16937.6 multi -1.99 import weight 0.00
Epoch 123 Iter 4 subLoss 16585.2 multi 1.00 import weight 0.00
Epoch 123 Iter 5 subLoss 16735.7 multi 6.97 import weight 0.00
Epoch 123 Iter 6 subLoss 17317.2 multi 1.00 import weight 0.00
Epoch 123 Iter 7 subLoss 16971.4 multi 1.00 import weight 0.00
Epoch 123 Iter 8 subLoss 16098.5 multi 1.00 import weight 0.00
Epoch 123 Iter 9 subLoss 15937.2 multi 1.00 import weight 0.00
Epoch 123 Iter 10 subLoss 16832.5 multi 3.99 import weight 0.00
Epoch 123 Iter 11 subLoss 16479.6 multi 3.99 import weight 0.00
Epoch 123 Acc: 78.32 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 1647 train Loss: 16520.9 test Loss: 2558.1
Epoch 124 Iter 0 subLoss 16014.5 multi 3.99 import weight 0.00
Epoch 124 Iter 1 subLoss 15828.3 multi 3.99 import weight 0.00
Epoch 124 Iter 2 subLoss 15774.2 multi 1.00 import weight 0.00
Epoch 124 Iter 3 subLoss 15551.7 multi 1.00 import weight 0.00
Epoch 124 Iter 4 subLoss 15172.2 multi 3.99 import weight 0.00
Epoch 124 Iter 5 subLoss 14859.5 multi 3.99 import weight 0.00
Epoch 124 Iter 6 subLoss 14569.5 multi 1.00 import weight 0.00
Epoch 124 Iter 7 subLoss 13667.6 multi 1.00 import weight 0.00
Epoch 124 Iter 8 subLoss 13787.2 multi 3.99 import weight 0.00
Epoch 124 Iter 9 subLoss 12731.1 multi 1.00 import weight 0.00
Epoch 124 Iter 10 subLoss 12331.8 multi -4.97 import weight 0.00
Epoch 124 Iter 11 subLoss 13971.2 multi -1.99 import weight 0.00
Epoch 124 Acc: 92.37 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 1397 train Loss: 14560.6 test Loss: 2034.9
Epoch 125 Iter 0 subLoss 14692.0 multi -1.98 import weight 0.00
Epoch 125 Iter 1 subLoss 14958.9 multi 3.99 import weight 0.00
Epoch 125 Iter 2 subLoss 13891.0 multi 1.00 import weight 0.00
Epoch 125 Iter 3 subLoss 14036.9 multi 1.00 import weight 0.00
Epoch 125 Iter 4 subLoss 13455.0 multi -1.99 import weight 0.00
Epoch 125 Iter 5 subLoss 13887.7 multi -1.99 import weight 0.00
Epoch 125 Iter 6 subLoss 14402.8 multi -1.98 import weight 0.00
Epoch 125 Iter 7 subLoss 15242.9 multi 1.00 import weight 0.00
Epoch 125 Iter 8 subLoss 14786.6 multi 1.00 import weight 0.00
Epoch 125 Iter 9 subLoss 14632.6 multi 1.00 import weight 0.00
Epoch 125 Iter 10 subLoss 14113.6 multi 9.96 import weight 1.00
Epoch 125 Iter 11 subLoss 13665.8 multi 3.98 import weight 0.00
Epoch 125 Acc: 85.76 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 1366 train Loss: 15121.3 test Loss: 2222.0
Epoch 126 Iter 0 subLoss 14592.2 multi -1.99 import weight 0.00
Epoch 126 Iter 1 subLoss 17301.1 multi 1.00 import weight 0.00
Epoch 126 Iter 2 subLoss 15906.5 multi 1.00 import weight 0.00
Epoch 126 Iter 3 subLoss 15291.0 multi 1.00 import weight 0.00
Epoch 126 Iter 4 subLoss 14681.3 multi 6.97 import weight 0.00
Epoch 126 Iter 5 subLoss 13950.2 multi 1.00 import weight 0.00
Epoch 126 Iter 6 subLoss 11666.4 multi 1.00 import weight 0.00
Epoch 126 Iter 7 subLoss 10850.0 multi 3.99 import weight 0.00
Epoch 126 Iter 8 subLoss 10389.0 multi 1.00 import weight 0.00
Epoch 126 Iter 9 subLoss 10414.8 multi 3.99 import weight 0.00
Epoch 126 Iter 10 subLoss 10464.8 multi -4.97 import weight 0.00
Epoch 126 Iter 11 subLoss 10884.9 multi 1.00 import weight 0.00
Epoch 126 Acc: 93.81 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1088 train Loss: 10753.2 test Loss: 1400.1
Epoch 127 Iter 0 subLoss 10707.1 multi 1.00 import weight 0.00
Epoch 127 Iter 1 subLoss 10049.7 multi -1.99 import weight 0.00
Epoch 127 Iter 2 subLoss 10823.5 multi -4.97 import weight 0.00
Epoch 127 Iter 3 subLoss 12760.7 multi 3.98 import weight 0.00
Epoch 127 Iter 4 subLoss 11974.5 multi -1.99 import weight 0.00
Epoch 127 Iter 5 subLoss 14611.9 multi 1.00 import weight 0.00
Epoch 127 Iter 6 subLoss 12487.7 multi 3.99 import weight 0.00
Epoch 127 Iter 7 subLoss 10919.0 multi 1.00 import weight 0.00
Epoch 127 Iter 8 subLoss 10178.6 multi -1.99 import weight 0.00
Epoch 127 Iter 9 subLoss 11328.2 multi -1.99 import weight 0.00
Epoch 127 Iter 10 subLoss 12433.6 multi 1.00 import weight 0.00
Epoch 127 Iter 11 subLoss 11081.3 multi 1.00 import weight 0.00
Epoch 127 Acc: 92.92 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1108 train Loss: 10937.6 test Loss: 1439.0
Epoch 128 Iter 0 subLoss 10647.1 multi -1.99 import weight 0.00
Epoch 128 Iter 1 subLoss 11878.2 multi 6.97 import weight 0.00
Epoch 128 Iter 2 subLoss 12091.7 multi 3.99 import weight 0.00
Epoch 128 Iter 3 subLoss 9777.3 multi 3.99 import weight 0.00
Epoch 128 Iter 4 subLoss 9761.2 multi 1.00 import weight 0.00
Epoch 128 Iter 5 subLoss 9648.3 multi 6.97 import weight 0.00
Epoch 128 Iter 6 subLoss 9377.4 multi 6.97 import weight 0.00
Epoch 128 Iter 7 subLoss 17607.4 multi -1.99 import weight 0.00
Epoch 128 Iter 8 subLoss 90193.9 multi 1.00 import weight 0.00
Epoch 128 Iter 9 subLoss 20222.0 multi 1.00 import weight 0.00
Epoch 128 Iter 10 subLoss 18621.6 multi -1.99 import weight 0.00
Epoch 128 Iter 11 subLoss 23148.5 multi -1.99 import weight 0.00
Epoch 128 Acc: 59.82 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 2314 train Loss: 27309.2 test Loss: 4385.1
Epoch 129 Iter 0 subLoss 27280.1 multi 1.00 import weight 0.00
Epoch 129 Iter 1 subLoss 24879.0 multi 3.99 import weight 0.00
Epoch 129 Iter 2 subLoss 23068.9 multi 1.00 import weight 0.00
Epoch 129 Iter 3 subLoss 23311.7 multi 1.00 import weight 0.00
Epoch 129 Iter 4 subLoss 23132.4 multi 1.00 import weight 0.00
Epoch 129 Iter 5 subLoss 21889.1 multi 3.99 import weight 0.00
Epoch 129 Iter 6 subLoss 16774.3 multi 1.00 import weight 0.00
Epoch 129 Iter 7 subLoss 15408.6 multi 1.00 import weight 0.00
Epoch 129 Iter 8 subLoss 14219.1 multi 1.00 import weight 0.00
Epoch 129 Iter 9 subLoss 13235.8 multi -4.97 import weight 0.00
Epoch 129 Iter 10 subLoss 16477.4 multi 6.97 import weight 0.00
Epoch 129 Iter 11 subLoss 15874.4 multi 1.00 import weight 0.00
Epoch 129 Acc: 88.66 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1587 train Loss: 13106.6 test Loss: 1831.6
Epoch 130 Iter 0 subLoss 12533.6 multi -1.99 import weight 0.00
Epoch 130 Iter 1 subLoss 15519.8 multi 1.00 import weight 0.00
Epoch 130 Iter 2 subLoss 12814.3 multi 1.00 import weight 0.00
Epoch 130 Iter 3 subLoss 12537.0 multi 1.00 import weight 0.00
Epoch 130 Iter 4 subLoss 11869.1 multi 1.00 import weight 0.00
Epoch 130 Iter 5 subLoss 12220.4 multi -1.98 import weight 0.00
Epoch 130 Iter 6 subLoss 11892.9 multi -1.99 import weight 0.00
Epoch 130 Iter 7 subLoss 13775.4 multi -1.99 import weight 0.00
Epoch 130 Iter 8 subLoss 15071.3 multi 3.99 import weight 0.00
Epoch 130 Iter 9 subLoss 13013.9 multi 3.99 import weight 0.00
Epoch 130 Iter 10 subLoss 11675.5 multi 1.00 import weight 0.00
Epoch 130 Iter 11 subLoss 11284.5 multi 3.99 import weight 0.00
Epoch 130 Acc: 95.19 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 1128 train Loss: 10330.4 test Loss: 1278.6
Epoch 131 Iter 0 subLoss 10504.6 multi -1.98 import weight 0.00
Epoch 131 Iter 1 subLoss 10774.2 multi 1.00 import weight 0.00
Epoch 131 Iter 2 subLoss 9781.9 multi -4.97 import weight 0.00
Epoch 131 Iter 3 subLoss 11803.3 multi 6.97 import weight 0.00
Epoch 131 Iter 4 subLoss 15192.9 multi -1.99 import weight 0.00
Epoch 131 Iter 5 subLoss 52619.9 multi -1.99 import weight 0.00
Epoch 131 Iter 6 subLoss 1128266.5 multi 1.00 import weight 0.00
Epoch 131 Iter 7 subLoss 58233.9 multi 1.00 import weight 0.00
Epoch 131 Iter 8 subLoss 56199.2 multi 1.00 import weight 0.00
Epoch 131 Iter 9 subLoss 52301.5 multi 1.00 import weight 0.00
Epoch 131 Iter 10 subLoss 48597.6 multi 1.00 import weight 0.00
Epoch 131 Iter 11 subLoss 43897.5 multi 3.99 import weight 0.00
Epoch 131 Acc: 47.23 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 4389 train Loss: 43271.1 test Loss: 6325.5
Epoch 132 Iter 0 subLoss 42529.9 multi 3.99 import weight 0.00
Epoch 132 Iter 1 subLoss 52806.1 multi 1.00 import weight 0.00
Epoch 132 Iter 2 subLoss 50415.4 multi 1.00 import weight 0.00
Epoch 132 Iter 3 subLoss 45286.2 multi 3.99 import weight 0.00
Epoch 132 Iter 4 subLoss 33699.7 multi 1.00 import weight 0.00
Epoch 132 Iter 5 subLoss 29694.1 multi -1.99 import weight 0.00
Epoch 132 Iter 6 subLoss 35195.1 multi 1.00 import weight 0.00
Epoch 132 Iter 7 subLoss 31734.8 multi 1.00 import weight 0.00
Epoch 132 Iter 8 subLoss 29965.6 multi -1.99 import weight 0.00
Epoch 132 Iter 9 subLoss 31919.2 multi 6.97 import weight 0.00
Epoch 132 Iter 10 subLoss 26823.8 multi 1.00 import weight 0.00
Epoch 132 Iter 11 subLoss 25317.5 multi 1.00 import weight 0.00
Epoch 132 Acc: 87.53 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2531 train Loss: 23499.6 test Loss: 2455.3
Epoch 133 Iter 0 subLoss 23676.5 multi 1.00 import weight 0.00
Epoch 133 Iter 1 subLoss 22548.1 multi 1.00 import weight 0.00
Epoch 133 Iter 2 subLoss 22613.5 multi 1.00 import weight 0.00
Epoch 133 Iter 3 subLoss 20836.8 multi 3.99 import weight 0.00
Epoch 133 Iter 4 subLoss 18240.5 multi -1.99 import weight 0.00
Epoch 133 Iter 5 subLoss 19659.9 multi 3.99 import weight 0.00
Epoch 133 Iter 6 subLoss 17099.3 multi 3.99 import weight 0.00
Epoch 133 Iter 7 subLoss 16408.0 multi 1.00 import weight 0.00
Epoch 133 Iter 8 subLoss 15726.6 multi 6.97 import weight 0.00
Epoch 133 Iter 9 subLoss 16228.5 multi 1.00 import weight 0.00
Epoch 133 Iter 10 subLoss 13438.3 multi -1.99 import weight 0.00
Epoch 133 Iter 11 subLoss 13736.9 multi -1.99 import weight 0.00
Epoch 133 Acc: 83.63 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 1373 train Loss: 20048.8 test Loss: 2633.9
Epoch 134 Iter 0 subLoss 19487.6 multi 3.99 import weight 0.00
Epoch 134 Iter 1 subLoss 28338.5 multi -1.99 import weight 0.00
Epoch 134 Iter 2 subLoss 134355.2 multi 1.00 import weight 0.00
Epoch 134 Iter 3 subLoss 24563.0 multi 3.98 import weight 0.00
Epoch 134 Iter 4 subLoss 21307.4 multi 3.99 import weight 0.00
Epoch 134 Iter 5 subLoss 33191.1 multi 1.00 import weight 0.00
Epoch 134 Iter 6 subLoss 21632.8 multi -1.99 import weight 0.00
Epoch 134 Iter 7 subLoss 34039.4 multi 1.00 import weight 0.00
Epoch 134 Iter 8 subLoss 28302.3 multi 6.97 import weight 0.00
Epoch 134 Iter 9 subLoss 29504.9 multi 1.00 import weight 0.00
Epoch 134 Iter 10 subLoss 14845.5 multi 1.00 import weight 0.00
Epoch 134 Iter 11 subLoss 13354.4 multi 3.98 import weight 0.00
Epoch 134 Acc: 93.40 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 1335 train Loss: 12660.9 test Loss: 1512.2
Epoch 135 Iter 0 subLoss 12072.7 multi 1.00 import weight 0.00
Epoch 135 Iter 1 subLoss 12260.3 multi 3.98 import weight 0.00
Epoch 135 Iter 2 subLoss 11595.5 multi 1.00 import weight 0.00
Epoch 135 Iter 3 subLoss 11495.9 multi 1.00 import weight 0.00
Epoch 135 Iter 4 subLoss 10875.0 multi 1.00 import weight 0.00
Epoch 135 Iter 5 subLoss 10386.0 multi 3.99 import weight 0.00
Epoch 135 Iter 6 subLoss 10566.1 multi 1.00 import weight 0.00
Epoch 135 Iter 7 subLoss 11238.0 multi 1.00 import weight 0.00
Epoch 135 Iter 8 subLoss 10298.5 multi 3.99 import weight 0.00
Epoch 135 Iter 9 subLoss 10155.8 multi 1.00 import weight 0.00
Epoch 135 Iter 10 subLoss 10283.0 multi 1.00 import weight 0.00
Epoch 135 Iter 11 subLoss 9835.9 multi 3.99 import weight 0.00
Epoch 135 Acc: 95.50 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 983 train Loss: 9985.8 test Loss: 1191.3
Epoch 136 Iter 0 subLoss 9302.5 multi 1.00 import weight 0.00
Epoch 136 Iter 1 subLoss 9581.4 multi 1.00 import weight 0.00
Epoch 136 Iter 2 subLoss 9862.0 multi 1.00 import weight 0.00
Epoch 136 Iter 3 subLoss 9222.8 multi -1.99 import weight 0.00
Epoch 136 Iter 4 subLoss 10299.1 multi 3.98 import weight 0.00
Epoch 136 Iter 5 subLoss 9461.0 multi 3.99 import weight 0.00
Epoch 136 Iter 6 subLoss 9779.8 multi 3.98 import weight 0.00
Epoch 136 Iter 7 subLoss 8514.7 multi -10.94 import weight 0.00
Epoch 136 Iter 8 subLoss 14663.1 multi 1.00 import weight 0.00
Epoch 136 Iter 9 subLoss 12307.3 multi -1.99 import weight 0.00
Epoch 136 Iter 10 subLoss 16448.3 multi -4.97 import weight 0.00
Epoch 136 Iter 11 subLoss 62040.7 multi 1.00 import weight 0.00
Epoch 136 Acc: 52.89 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 6204 train Loss: 31589.8 test Loss: 5382.7
Epoch 137 Iter 0 subLoss 31908.7 multi 1.00 import weight 0.00
Epoch 137 Iter 1 subLoss 27668.4 multi 1.00 import weight 0.00
Epoch 137 Iter 2 subLoss 23049.5 multi 1.00 import weight 0.00
Epoch 137 Iter 3 subLoss 22718.4 multi 1.00 import weight 0.00
Epoch 137 Iter 4 subLoss 19955.8 multi 1.00 import weight 0.00
Epoch 137 Iter 5 subLoss 18496.2 multi 1.00 import weight 0.00
Epoch 137 Iter 6 subLoss 18491.0 multi 3.99 import weight 1.00
Epoch 137 Iter 7 subLoss 11541.0 multi -4.97 import weight 0.00
Epoch 137 Iter 8 subLoss 15190.3 multi 1.00 import weight 0.00
Epoch 137 Iter 9 subLoss 14337.1 multi 6.97 import weight 0.00
Epoch 137 Iter 10 subLoss 11511.9 multi 1.00 import weight 0.00
Epoch 137 Iter 11 subLoss 11271.0 multi 1.00 import weight 0.00
Epoch 137 Acc: 94.40 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1127 train Loss: 10701.3 test Loss: 1239.7
Epoch 138 Iter 0 subLoss 10535.9 multi 1.00 import weight 0.00
Epoch 138 Iter 1 subLoss 10133.3 multi 1.00 import weight 0.00
Epoch 138 Iter 2 subLoss 9981.7 multi 3.98 import weight 0.00
Epoch 138 Iter 3 subLoss 9792.1 multi -1.99 import weight 0.00
Epoch 138 Iter 4 subLoss 9821.6 multi 1.00 import weight 0.00
Epoch 138 Iter 5 subLoss 10113.6 multi 3.99 import weight 0.00
Epoch 138 Iter 6 subLoss 9096.3 multi -1.99 import weight 0.00
Epoch 138 Iter 7 subLoss 10603.6 multi 1.00 import weight 0.00
Epoch 138 Iter 8 subLoss 9328.1 multi 1.00 import weight 0.00
Epoch 138 Iter 9 subLoss 9441.3 multi 1.00 import weight 0.00
Epoch 138 Iter 10 subLoss 9560.9 multi 3.99 import weight 0.00
Epoch 138 Iter 11 subLoss 9728.3 multi 3.98 import weight 0.00
Epoch 138 Acc: 95.99 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 972 train Loss: 9279.8 test Loss: 1143.6
Epoch 139 Iter 0 subLoss 9032.8 multi 1.00 import weight 0.00
Epoch 139 Iter 1 subLoss 8984.8 multi -1.99 import weight 0.00
Epoch 139 Iter 2 subLoss 9059.8 multi 1.00 import weight 0.00
Epoch 139 Iter 3 subLoss 9149.2 multi -1.98 import weight 0.00
Epoch 139 Iter 4 subLoss 9519.6 multi 1.00 import weight 0.00
Epoch 139 Iter 5 subLoss 9458.0 multi -1.99 import weight 0.00
Epoch 139 Iter 6 subLoss 9776.3 multi 6.97 import weight 1.00
Epoch 139 Iter 7 subLoss 9132.5 multi 6.97 import weight 0.00
Epoch 139 Iter 8 subLoss 9565.5 multi 6.97 import weight 0.00
Epoch 139 Iter 9 subLoss 9954.8 multi -4.97 import weight 0.00
Epoch 139 Iter 10 subLoss 29623.3 multi 1.00 import weight 0.00
Epoch 139 Iter 11 subLoss 12496.2 multi -1.98 import weight 0.00
Epoch 139 Acc: 87.31 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 1249 train Loss: 20060.9 test Loss: 2334.7
Epoch 140 Iter 0 subLoss 19309.2 multi -1.99 import weight 0.00
Epoch 140 Iter 1 subLoss 37241.6 multi 1.00 import weight 0.00
Epoch 140 Iter 2 subLoss 27110.3 multi 3.99 import weight 0.00
Epoch 140 Iter 3 subLoss 10619.7 multi 1.00 import weight 0.00
Epoch 140 Iter 4 subLoss 10561.8 multi 3.99 import weight 0.00
Epoch 140 Iter 5 subLoss 8996.8 multi -1.99 import weight 0.00
Epoch 140 Iter 6 subLoss 8990.1 multi 1.00 import weight 0.00
Epoch 140 Iter 7 subLoss 8858.7 multi 3.99 import weight 0.00
Epoch 140 Iter 8 subLoss 8862.9 multi -4.97 import weight 0.00
Epoch 140 Iter 9 subLoss 9619.9 multi -4.97 import weight 0.00
Epoch 140 Iter 10 subLoss 12584.3 multi 1.00 import weight 0.00
Epoch 140 Iter 11 subLoss 10337.4 multi 1.00 import weight 0.00
Epoch 140 Acc: 94.94 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1033 train Loss: 10069.6 test Loss: 1247.1
Epoch 141 Iter 0 subLoss 9649.3 multi 9.96 import weight 1.00
Epoch 141 Iter 1 subLoss 9780.6 multi -7.96 import weight 0.00
Epoch 141 Iter 2 subLoss 34510.7 multi 1.00 import weight 0.00
Epoch 141 Iter 3 subLoss 16009.2 multi -1.99 import weight 0.00
Epoch 141 Iter 4 subLoss 21913.9 multi 1.00 import weight 0.00
Epoch 141 Iter 5 subLoss 18143.4 multi -1.99 import weight 0.00
Epoch 141 Iter 6 subLoss 24642.5 multi 3.99 import weight 0.00
Epoch 141 Iter 7 subLoss 15239.6 multi -1.99 import weight 0.00
Epoch 141 Iter 8 subLoss 21566.3 multi 1.00 import weight 0.00
Epoch 141 Iter 9 subLoss 17530.2 multi 1.00 import weight 0.00
Epoch 141 Iter 10 subLoss 15267.2 multi 3.99 import weight 0.00
Epoch 141 Iter 11 subLoss 10674.3 multi 6.97 import weight 0.00
Epoch 141 Acc: 94.08 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 1067 train Loss: 10359.3 test Loss: 1246.2
Epoch 142 Iter 0 subLoss 9626.7 multi -1.99 import weight 0.00
Epoch 142 Iter 1 subLoss 12089.2 multi -1.99 import weight 0.00
Epoch 142 Iter 2 subLoss 18690.3 multi -1.99 import weight 0.00
Epoch 142 Iter 3 subLoss 73523.6 multi 1.00 import weight 0.00
Epoch 142 Iter 4 subLoss 16746.2 multi -1.99 import weight 0.00
Epoch 142 Iter 5 subLoss 38714.7 multi 1.00 import weight 0.00
Epoch 142 Iter 6 subLoss 14414.2 multi -4.97 import weight 0.00
Epoch 142 Iter 7 subLoss 33388.1 multi 1.00 import weight 0.00
Epoch 142 Iter 8 subLoss 22921.2 multi 3.99 import weight 0.00
Epoch 142 Iter 9 subLoss 13059.6 multi 1.00 import weight 0.00
Epoch 142 Iter 10 subLoss 11649.4 multi 3.99 import weight 0.00
Epoch 142 Iter 11 subLoss 10186.3 multi 3.98 import weight 0.00
Epoch 142 Acc: 95.27 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 1018 train Loss: 9911.0 test Loss: 1183.5
Epoch 143 Iter 0 subLoss 9846.9 multi -4.97 import weight 0.00
Epoch 143 Iter 1 subLoss 9880.5 multi -1.99 import weight 0.00
Epoch 143 Iter 2 subLoss 11618.1 multi 1.00 import weight 0.00
Epoch 143 Iter 3 subLoss 10681.2 multi -7.96 import weight 0.00
Epoch 143 Iter 4 subLoss 13015.9 multi 6.97 import weight 0.00
Epoch 143 Iter 5 subLoss 10623.1 multi -1.98 import weight 0.00
Epoch 143 Iter 6 subLoss 11273.8 multi 3.99 import weight 0.00
Epoch 143 Iter 7 subLoss 10965.7 multi 3.99 import weight 0.00
Epoch 143 Iter 8 subLoss 9817.0 multi 1.00 import weight 0.00
Epoch 143 Iter 9 subLoss 9507.4 multi 3.99 import weight 0.00
Epoch 143 Iter 10 subLoss 9104.1 multi -1.99 import weight 0.00
Epoch 143 Iter 11 subLoss 9210.9 multi 3.99 import weight 0.00
Epoch 143 Acc: 95.31 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 921 train Loss: 9212.3 test Loss: 1125.1
Epoch 144 Iter 0 subLoss 9122.6 multi -1.99 import weight 0.00
Epoch 144 Iter 1 subLoss 9114.2 multi 1.00 import weight 0.00
Epoch 144 Iter 2 subLoss 8884.3 multi 1.00 import weight 0.00
Epoch 144 Iter 3 subLoss 8606.1 multi 1.00 import weight 0.00
Epoch 144 Iter 4 subLoss 9003.1 multi -4.97 import weight 0.00
Epoch 144 Iter 5 subLoss 9108.2 multi 1.00 import weight 0.00
Epoch 144 Iter 6 subLoss 9426.9 multi 1.00 import weight 0.00
Epoch 144 Iter 7 subLoss 9717.9 multi -1.98 import weight 0.00
Epoch 144 Iter 8 subLoss 9455.3 multi 1.00 import weight 0.00
Epoch 144 Iter 9 subLoss 9236.4 multi 1.00 import weight 0.00
Epoch 144 Iter 10 subLoss 9120.6 multi -1.98 import weight 0.00
Epoch 144 Iter 11 subLoss 9744.0 multi -4.97 import weight 0.00
Epoch 144 Acc: 94.49 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 974 train Loss: 10137.6 test Loss: 1255.4
Epoch 145 Iter 0 subLoss 9636.9 multi -1.99 import weight 0.00
Epoch 145 Iter 1 subLoss 10384.5 multi 6.97 import weight 0.00
Epoch 145 Iter 2 subLoss 9921.6 multi 3.99 import weight 0.00
Epoch 145 Iter 3 subLoss 8919.3 multi 1.00 import weight 0.00
Epoch 145 Iter 4 subLoss 9350.5 multi 9.96 import weight 1.00
Epoch 145 Iter 5 subLoss 8316.9 multi 1.00 import weight 0.00
Epoch 145 Iter 6 subLoss 8336.7 multi -4.97 import weight 0.00
Epoch 145 Iter 7 subLoss 8674.0 multi 3.99 import weight 0.00
Epoch 145 Iter 8 subLoss 8367.7 multi 1.00 import weight 0.00
Epoch 145 Iter 9 subLoss 8537.0 multi 3.99 import weight 0.00
Epoch 145 Iter 10 subLoss 8402.0 multi -1.99 import weight 0.00
Epoch 145 Iter 11 subLoss 8599.9 multi 3.99 import weight 0.00
Epoch 145 Acc: 96.13 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 859 train Loss: 8300.8 test Loss: 991.7
Epoch 146 Iter 0 subLoss 8086.7 multi 3.98 import weight 0.00
Epoch 146 Iter 1 subLoss 7509.4 multi -4.97 import weight 0.00
Epoch 146 Iter 2 subLoss 8158.3 multi 1.00 import weight 0.00
Epoch 146 Iter 3 subLoss 8318.5 multi 3.99 import weight 0.00
Epoch 146 Iter 4 subLoss 7543.9 multi 1.00 import weight 0.00
Epoch 146 Iter 5 subLoss 7749.7 multi 3.98 import weight 0.00
Epoch 146 Iter 6 subLoss 8078.8 multi 3.99 import weight 0.00
Epoch 146 Iter 7 subLoss 8051.4 multi 1.00 import weight 0.00
Epoch 146 Iter 8 subLoss 8146.7 multi -1.99 import weight 0.00
Epoch 146 Iter 9 subLoss 8101.7 multi 3.99 import weight 0.00
Epoch 146 Iter 10 subLoss 7291.2 multi 1.00 import weight 0.00
Epoch 146 Iter 11 subLoss 7296.9 multi 3.99 import weight 0.00
Epoch 146 Acc: 96.40 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 729 train Loss: 7695.5 test Loss: 915.0
Epoch 147 Iter 0 subLoss 7757.1 multi -7.96 import weight 0.00
Epoch 147 Iter 1 subLoss 8345.6 multi -1.99 import weight 0.00
Epoch 147 Iter 2 subLoss 9131.2 multi 3.99 import weight 1.00
Epoch 147 Iter 3 subLoss 7870.1 multi -1.99 import weight 0.00
Epoch 147 Iter 4 subLoss 7544.7 multi 3.98 import weight 0.00
Epoch 147 Iter 5 subLoss 6835.9 multi -1.98 import weight 0.00
Epoch 147 Iter 6 subLoss 7910.0 multi -1.99 import weight 0.00
Epoch 147 Iter 7 subLoss 7551.3 multi -7.96 import weight 0.00
Epoch 147 Iter 8 subLoss 7785.8 multi 3.99 import weight 0.00
Epoch 147 Iter 9 subLoss 7582.9 multi 3.99 import weight 0.00
Epoch 147 Iter 10 subLoss 7683.7 multi 3.98 import weight 0.00
Epoch 147 Iter 11 subLoss 7111.5 multi 3.99 import weight 0.00
Epoch 147 Acc: 96.38 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 711 train Loss: 7765.6 test Loss: 934.5
Epoch 148 Iter 0 subLoss 7801.2 multi -4.97 import weight 0.00
Epoch 148 Iter 1 subLoss 7889.7 multi -1.99 import weight 0.00
Epoch 148 Iter 2 subLoss 7973.7 multi 1.00 import weight 0.00
Epoch 148 Iter 3 subLoss 7898.9 multi -1.99 import weight 0.00
Epoch 148 Iter 4 subLoss 8006.6 multi -1.99 import weight 0.00
Epoch 148 Iter 5 subLoss 8591.6 multi 6.97 import weight 0.00
Epoch 148 Iter 6 subLoss 9320.8 multi 3.99 import weight 0.00
Epoch 148 Iter 7 subLoss 8791.1 multi 1.00 import weight 0.00
Epoch 148 Iter 8 subLoss 7627.1 multi 3.99 import weight 0.00
Epoch 148 Iter 9 subLoss 7887.2 multi 1.00 import weight 0.00
Epoch 148 Iter 10 subLoss 7363.9 multi 6.97 import weight 0.00
Epoch 148 Iter 11 subLoss 7306.6 multi -4.97 import weight 0.00
Epoch 148 Acc: 96.58 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 730 train Loss: 7594.4 test Loss: 910.3
Epoch 149 Iter 0 subLoss 7886.1 multi 3.98 import weight 0.00
Epoch 149 Iter 1 subLoss 7068.5 multi -1.99 import weight 0.00
Epoch 149 Iter 2 subLoss 7128.3 multi -4.97 import weight 0.00
Epoch 149 Iter 3 subLoss 7636.4 multi -4.97 import weight 0.00
Epoch 149 Iter 4 subLoss 9115.2 multi 1.00 import weight 0.00
Epoch 149 Iter 5 subLoss 8053.8 multi 3.99 import weight 0.00
Epoch 149 Iter 6 subLoss 7561.9 multi -1.99 import weight 0.00
Epoch 149 Iter 7 subLoss 7395.9 multi 9.96 import weight 1.00
Epoch 149 Iter 8 subLoss 7987.4 multi -1.99 import weight 0.00
Epoch 149 Iter 9 subLoss 8041.8 multi 1.00 import weight 0.00
Epoch 149 Iter 10 subLoss 7252.4 multi 1.00 import weight 0.00
Epoch 149 Iter 11 subLoss 7505.5 multi -1.98 import weight 0.00
Epoch 149 Acc: 96.87 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 750 train Loss: 7706.6 test Loss: 881.7
Epoch 150 Iter 0 subLoss 7245.9 multi -1.99 import weight 0.00
Epoch 150 Iter 1 subLoss 7741.7 multi 6.97 import weight 1.00
Epoch 150 Iter 2 subLoss 7637.8 multi -1.98 import weight 0.00
Epoch 150 Iter 3 subLoss 8582.5 multi 1.00 import weight 0.00
Epoch 150 Iter 4 subLoss 7191.0 multi 1.00 import weight 0.00
Epoch 150 Iter 5 subLoss 7268.0 multi -1.99 import weight 0.00
Epoch 150 Iter 6 subLoss 7698.0 multi -7.96 import weight 0.00
Epoch 150 Iter 7 subLoss 18832.4 multi 1.00 import weight 0.00
Epoch 150 Iter 8 subLoss 10685.0 multi -4.97 import weight 0.00
Epoch 150 Iter 9 subLoss 35180.5 multi -1.99 import weight 0.00
Epoch 150 Iter 10 subLoss 188088.4 multi 1.00 import weight 0.00
Epoch 150 Iter 11 subLoss 15398.9 multi 1.00 import weight 0.00
Epoch 150 Acc: 85.07 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1539 train Loss: 12878.1 test Loss: 1820.9
Epoch 151 Iter 0 subLoss 12536.3 multi 3.98 import weight 0.00
Epoch 151 Iter 1 subLoss 10176.6 multi 1.00 import weight 0.00
Epoch 151 Iter 2 subLoss 9773.7 multi 9.96 import weight 1.00
Epoch 151 Iter 3 subLoss 8784.5 multi 1.00 import weight 0.00
Epoch 151 Iter 4 subLoss 8530.2 multi 6.97 import weight 0.00
Epoch 151 Iter 5 subLoss 7954.7 multi -1.99 import weight 0.00
Epoch 151 Iter 6 subLoss 8739.3 multi 6.97 import weight 0.00
Epoch 151 Iter 7 subLoss 8081.6 multi 3.99 import weight 0.00
Epoch 151 Iter 8 subLoss 7845.5 multi 3.99 import weight 0.00
Epoch 151 Iter 9 subLoss 7301.9 multi -1.98 import weight 0.00
Epoch 151 Iter 10 subLoss 7707.9 multi 1.00 import weight 0.00
Epoch 151 Iter 11 subLoss 6736.3 multi 6.97 import weight 0.00
Epoch 151 Acc: 96.50 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 673 train Loss: 7209.6 test Loss: 885.9
Epoch 152 Iter 0 subLoss 7596.1 multi -4.97 import weight 0.00
Epoch 152 Iter 1 subLoss 7236.8 multi 1.00 import weight 0.00
Epoch 152 Iter 2 subLoss 7695.1 multi -4.97 import weight 0.00
Epoch 152 Iter 3 subLoss 7904.1 multi 1.00 import weight 0.00
Epoch 152 Iter 4 subLoss 7414.9 multi 3.99 import weight 0.00
Epoch 152 Iter 5 subLoss 7247.3 multi -1.98 import weight 0.00
Epoch 152 Iter 6 subLoss 7825.0 multi -4.97 import weight 0.00
Epoch 152 Iter 7 subLoss 8746.5 multi -4.97 import weight 0.00
Epoch 152 Iter 8 subLoss 20629.3 multi 9.96 import weight 0.00
Epoch 152 Iter 9 subLoss 78170.7 multi 1.00 import weight 0.00
Epoch 152 Iter 10 subLoss 30791.7 multi -1.99 import weight 0.00
Epoch 152 Iter 11 subLoss 63421.7 multi 1.00 import weight 0.00
Epoch 152 Acc: 53.01 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 6342 train Loss: 37472.8 test Loss: 6241.0
Epoch 153 Iter 0 subLoss 36598.1 multi 1.00 import weight 0.00
Epoch 153 Iter 1 subLoss 26188.2 multi 1.00 import weight 0.00
Epoch 153 Iter 2 subLoss 22559.1 multi -1.99 import weight 0.00
Epoch 153 Iter 3 subLoss 28818.7 multi 1.00 import weight 0.00
Epoch 153 Iter 4 subLoss 23603.5 multi -1.98 import weight 0.00
Epoch 153 Iter 5 subLoss 29809.5 multi 1.00 import weight 0.00
Epoch 153 Iter 6 subLoss 23396.1 multi 6.97 import weight 0.00
Epoch 153 Iter 7 subLoss 26479.0 multi 1.00 import weight 0.00
Epoch 153 Iter 8 subLoss 19258.7 multi 6.97 import weight 0.00
Epoch 153 Iter 9 subLoss 17215.2 multi -4.97 import weight 0.00
Epoch 153 Iter 10 subLoss 26811.3 multi 1.00 import weight 0.00
Epoch 153 Iter 11 subLoss 21598.4 multi -1.99 import weight 0.00
Epoch 153 Acc: 67.72 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 2159 train Loss: 29582.1 test Loss: 4403.3
Epoch 154 Iter 0 subLoss 29249.9 multi 1.00 import weight 0.00
Epoch 154 Iter 1 subLoss 22143.9 multi 3.99 import weight 0.00
Epoch 154 Iter 2 subLoss 16141.7 multi 1.00 import weight 0.00
Epoch 154 Iter 3 subLoss 15739.6 multi -7.96 import weight 0.00
Epoch 154 Iter 4 subLoss 19416.0 multi 1.00 import weight 0.00
Epoch 154 Iter 5 subLoss 18413.6 multi 1.00 import weight 0.00
Epoch 154 Iter 6 subLoss 17403.8 multi -1.99 import weight 0.00
Epoch 154 Iter 7 subLoss 18851.3 multi 1.00 import weight 0.00
Epoch 154 Iter 8 subLoss 17911.8 multi 1.00 import weight 0.00
Epoch 154 Iter 9 subLoss 17342.5 multi 3.99 import weight 0.00
Epoch 154 Iter 10 subLoss 16160.6 multi -1.99 import weight 0.00
Epoch 154 Iter 11 subLoss 17203.4 multi 1.00 import weight 0.00
Epoch 154 Acc: 79.16 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1720 train Loss: 17007.7 test Loss: 2376.9
Epoch 155 Iter 0 subLoss 16918.4 multi 3.99 import weight 0.00
Epoch 155 Iter 1 subLoss 15810.3 multi 1.00 import weight 0.00
Epoch 155 Iter 2 subLoss 15239.3 multi 1.00 import weight 0.00
Epoch 155 Iter 3 subLoss 15145.7 multi 1.00 import weight 0.00
Epoch 155 Iter 4 subLoss 15053.5 multi -1.99 import weight 0.00
Epoch 155 Iter 5 subLoss 15197.8 multi 3.98 import weight 0.00
Epoch 155 Iter 6 subLoss 15046.6 multi 3.99 import weight 0.00
Epoch 155 Iter 7 subLoss 14076.5 multi -4.97 import weight 0.00
Epoch 155 Iter 8 subLoss 15506.6 multi -1.99 import weight 0.00
Epoch 155 Iter 9 subLoss 15789.3 multi -1.99 import weight 0.00
Epoch 155 Iter 10 subLoss 16962.0 multi 1.00 import weight 0.00
Epoch 155 Iter 11 subLoss 15282.2 multi 1.00 import weight 0.00
Epoch 155 Acc: 81.55 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1528 train Loss: 15812.0 test Loss: 2171.5
Epoch 156 Iter 0 subLoss 16501.2 multi 1.00 import weight 0.00
Epoch 156 Iter 1 subLoss 15632.5 multi -7.96 import weight 0.00
Epoch 156 Iter 2 subLoss 18187.1 multi 1.00 import weight 0.00
Epoch 156 Iter 3 subLoss 17414.7 multi -4.97 import weight 0.00
Epoch 156 Iter 4 subLoss 22127.1 multi -1.99 import weight 0.00
Epoch 156 Iter 5 subLoss 36929.8 multi 1.00 import weight 0.00
Epoch 156 Iter 6 subLoss 20184.1 multi -1.98 import weight 0.00
Epoch 156 Iter 7 subLoss 25039.8 multi 3.99 import weight 0.00
Epoch 156 Iter 8 subLoss 18272.8 multi 1.00 import weight 0.00
Epoch 156 Iter 9 subLoss 17686.1 multi 1.00 import weight 0.00
Epoch 156 Iter 10 subLoss 17860.7 multi -1.99 import weight 0.00
Epoch 156 Iter 11 subLoss 17652.2 multi -1.99 import weight 0.00
Epoch 156 Acc: 78.13 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 1765 train Loss: 20120.5 test Loss: 2823.5
Epoch 157 Iter 0 subLoss 19732.0 multi -1.99 import weight 0.00
Epoch 157 Iter 1 subLoss 23382.2 multi 1.00 import weight 0.00
Epoch 157 Iter 2 subLoss 20620.6 multi 12.94 import weight 1.00
Epoch 157 Iter 3 subLoss 48278.3 multi 1.00 import weight 0.00
Epoch 157 Iter 4 subLoss 20839.5 multi 6.97 import weight 0.00
Epoch 157 Iter 5 subLoss 25676.3 multi 1.00 import weight 0.00
Epoch 157 Iter 6 subLoss 19714.8 multi 1.00 import weight 0.00
Epoch 157 Iter 7 subLoss 17669.6 multi 1.00 import weight 0.00
Epoch 157 Iter 8 subLoss 16383.1 multi 9.96 import weight 0.00
Epoch 157 Iter 9 subLoss 17694.0 multi -1.98 import weight 0.00
Epoch 157 Iter 10 subLoss 26637.5 multi 3.99 import weight 0.00
Epoch 157 Iter 11 subLoss 16067.5 multi 1.00 import weight 0.00
Epoch 157 Acc: 86.48 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1606 train Loss: 15210.5 test Loss: 2266.0
Epoch 158 Iter 0 subLoss 15284.0 multi 3.99 import weight 0.00
Epoch 158 Iter 1 subLoss 12749.3 multi -1.99 import weight 0.00
Epoch 158 Iter 2 subLoss 11625.4 multi -1.99 import weight 0.00
Epoch 158 Iter 3 subLoss 13935.8 multi 1.00 import weight 0.00
Epoch 158 Iter 4 subLoss 12881.4 multi 1.00 import weight 0.00
Epoch 158 Iter 5 subLoss 12875.9 multi -1.99 import weight 0.00
Epoch 158 Iter 6 subLoss 13126.1 multi 3.99 import weight 0.00
Epoch 158 Iter 7 subLoss 12479.7 multi -1.99 import weight 0.00
Epoch 158 Iter 8 subLoss 12655.1 multi 1.00 import weight 0.00
Epoch 158 Iter 9 subLoss 12312.3 multi -1.99 import weight 0.00
Epoch 158 Iter 10 subLoss 13467.6 multi 1.00 import weight 0.00
Epoch 158 Iter 11 subLoss 12142.6 multi 3.99 import weight 0.00
Epoch 158 Acc: 91.98 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 1214 train Loss: 12244.4 test Loss: 1578.3
Epoch 159 Iter 0 subLoss 11746.8 multi 3.99 import weight 0.00
Epoch 159 Iter 1 subLoss 11479.6 multi -1.99 import weight 0.00
Epoch 159 Iter 2 subLoss 10994.9 multi -1.99 import weight 0.00
Epoch 159 Iter 3 subLoss 11563.6 multi 1.00 import weight 0.00
Epoch 159 Iter 4 subLoss 11922.8 multi -1.99 import weight 0.00
Epoch 159 Iter 5 subLoss 13049.4 multi -1.99 import weight 0.00
Epoch 159 Iter 6 subLoss 11950.8 multi 3.99 import weight 0.00
Epoch 159 Iter 7 subLoss 11619.2 multi 3.99 import weight 0.00
Epoch 159 Iter 8 subLoss 11903.0 multi -1.99 import weight 0.00
Epoch 159 Iter 9 subLoss 10834.8 multi -4.97 import weight 0.00
Epoch 159 Iter 10 subLoss 12210.2 multi 3.98 import weight 0.00
Epoch 159 Iter 11 subLoss 12140.8 multi 6.97 import weight 0.00
Epoch 159 Acc: 93.48 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 1214 train Loss: 10983.5 test Loss: 1441.8
Epoch 160 Iter 0 subLoss 11394.6 multi 3.99 import weight 0.00
Epoch 160 Iter 1 subLoss 10729.3 multi 3.99 import weight 0.00
Epoch 160 Iter 2 subLoss 9674.1 multi 1.00 import weight 0.00
Epoch 160 Iter 3 subLoss 10372.6 multi -1.99 import weight 0.00
Epoch 160 Iter 4 subLoss 10127.9 multi -1.98 import weight 0.00
Epoch 160 Iter 5 subLoss 10658.0 multi -1.99 import weight 0.00
Epoch 160 Iter 6 subLoss 10909.8 multi 1.00 import weight 0.00
Epoch 160 Iter 7 subLoss 10863.8 multi -1.99 import weight 0.00
Epoch 160 Iter 8 subLoss 10939.6 multi -1.99 import weight 0.00
Epoch 160 Iter 9 subLoss 11496.2 multi 3.99 import weight 0.00
Epoch 160 Iter 10 subLoss 10485.2 multi 3.99 import weight 0.00
Epoch 160 Iter 11 subLoss 9683.1 multi -4.97 import weight 0.00
Epoch 160 Acc: 94.28 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 968 train Loss: 10623.3 test Loss: 1379.3
Epoch 161 Iter 0 subLoss 10691.5 multi -1.98 import weight 0.00
Epoch 161 Iter 1 subLoss 10693.8 multi 1.00 import weight 0.00
Epoch 161 Iter 2 subLoss 10876.5 multi 1.00 import weight 0.00
Epoch 161 Iter 3 subLoss 10176.5 multi 3.98 import weight 0.00
Epoch 161 Iter 4 subLoss 9765.4 multi 3.99 import weight 0.00
Epoch 161 Iter 5 subLoss 9643.3 multi 9.96 import weight 1.00
Epoch 161 Iter 6 subLoss 8802.5 multi -1.99 import weight 0.00
Epoch 161 Iter 7 subLoss 9808.2 multi -1.99 import weight 0.00
Epoch 161 Iter 8 subLoss 9978.8 multi 1.00 import weight 0.00
Epoch 161 Iter 9 subLoss 9777.8 multi 9.96 import weight 1.00
Epoch 161 Iter 10 subLoss 10020.1 multi 3.98 import weight 0.00
Epoch 161 Iter 11 subLoss 9162.6 multi 1.00 import weight 0.00
Epoch 161 Acc: 95.58 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 916 train Loss: 8698.9 test Loss: 1157.4
Epoch 162 Iter 0 subLoss 8455.5 multi 1.00 import weight 0.00
Epoch 162 Iter 1 subLoss 8383.0 multi 1.00 import weight 0.00
Epoch 162 Iter 2 subLoss 8630.7 multi 1.00 import weight 0.00
Epoch 162 Iter 3 subLoss 8499.7 multi 1.00 import weight 0.00
Epoch 162 Iter 4 subLoss 8461.8 multi -1.99 import weight 0.00
Epoch 162 Iter 5 subLoss 7921.7 multi -1.99 import weight 0.00
Epoch 162 Iter 6 subLoss 8679.1 multi 6.97 import weight 0.00
Epoch 162 Iter 7 subLoss 8246.3 multi 1.00 import weight 0.00
Epoch 162 Iter 8 subLoss 7938.7 multi 3.98 import weight 0.00
Epoch 162 Iter 9 subLoss 7339.5 multi 3.99 import weight 0.00
Epoch 162 Iter 10 subLoss 7433.1 multi -1.99 import weight 0.00
Epoch 162 Iter 11 subLoss 7904.9 multi 3.98 import weight 0.00
Epoch 162 Acc: 96.11 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 790 train Loss: 7741.1 test Loss: 1017.9
Epoch 163 Iter 0 subLoss 7567.2 multi 1.00 import weight 0.00
Epoch 163 Iter 1 subLoss 7336.0 multi 6.97 import weight 0.00
Epoch 163 Iter 2 subLoss 7265.2 multi 1.00 import weight 0.00
Epoch 163 Iter 3 subLoss 7460.1 multi -1.98 import weight 0.00
Epoch 163 Iter 4 subLoss 7846.4 multi 6.97 import weight 0.00
Epoch 163 Iter 5 subLoss 7054.5 multi 1.00 import weight 0.00
Epoch 163 Iter 6 subLoss 7001.0 multi 1.00 import weight 0.00
Epoch 163 Iter 7 subLoss 6925.8 multi 3.99 import weight 0.00
Epoch 163 Iter 8 subLoss 7103.6 multi 1.00 import weight 0.00
Epoch 163 Iter 9 subLoss 7157.4 multi 1.00 import weight 0.00
Epoch 163 Iter 10 subLoss 6923.4 multi 6.97 import weight 0.00
Epoch 163 Iter 11 subLoss 6874.7 multi 9.96 import weight 0.00
Epoch 163 Acc: 96.44 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 687 train Loss: 6752.3 test Loss: 870.7
Epoch 164 Iter 0 subLoss 6706.5 multi 3.99 import weight 0.00
Epoch 164 Iter 1 subLoss 6228.2 multi 1.00 import weight 0.00
Epoch 164 Iter 2 subLoss 6502.7 multi 1.00 import weight 0.00
Epoch 164 Iter 3 subLoss 6088.0 multi -1.99 import weight 0.00
Epoch 164 Iter 4 subLoss 6013.1 multi -1.98 import weight 0.00
Epoch 164 Iter 5 subLoss 6828.1 multi 3.98 import weight 0.00
Epoch 164 Iter 6 subLoss 6099.5 multi 3.98 import weight 0.00
Epoch 164 Iter 7 subLoss 6729.1 multi 1.00 import weight 0.00
Epoch 164 Iter 8 subLoss 6666.3 multi 1.00 import weight 0.00
Epoch 164 Iter 9 subLoss 6871.9 multi 12.94 import weight 1.00
Epoch 164 Iter 10 subLoss 6331.1 multi -1.99 import weight 0.00
Epoch 164 Iter 11 subLoss 6581.1 multi 3.99 import weight 0.00
Epoch 164 Acc: 96.79 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 658 train Loss: 6423.0 test Loss: 782.6
Epoch 165 Iter 0 subLoss 6327.6 multi 3.99 import weight 0.00
Epoch 165 Iter 1 subLoss 6281.6 multi 3.99 import weight 0.00
Epoch 165 Iter 2 subLoss 6401.0 multi -4.97 import weight 0.00
Epoch 165 Iter 3 subLoss 6211.8 multi -1.98 import weight 0.00
Epoch 165 Iter 4 subLoss 6722.2 multi 3.99 import weight 0.00
Epoch 165 Iter 5 subLoss 7051.7 multi 3.98 import weight 0.00
Epoch 165 Iter 6 subLoss 6335.4 multi -1.98 import weight 0.00
Epoch 165 Iter 7 subLoss 6532.0 multi -1.98 import weight 0.00
Epoch 165 Iter 8 subLoss 6888.8 multi -16.91 import weight 0.00
Epoch 165 Iter 9 subLoss 334630.5 multi 1.00 import weight 0.00
Epoch 165 Iter 10 subLoss 25217.4 multi 1.00 import weight 0.00
Epoch 165 Iter 11 subLoss 18186.9 multi 3.99 import weight 0.00
Epoch 165 Acc: 90.41 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 1818 train Loss: 12325.8 test Loss: 1558.2
Epoch 166 Iter 0 subLoss 10951.4 multi 1.00 import weight 0.00
Epoch 166 Iter 1 subLoss 10919.4 multi 1.00 import weight 0.00
Epoch 166 Iter 2 subLoss 11224.3 multi 1.00 import weight 0.00
Epoch 166 Iter 3 subLoss 10801.3 multi -1.98 import weight 0.00
Epoch 166 Iter 4 subLoss 11222.9 multi 3.98 import weight 0.00
Epoch 166 Iter 5 subLoss 10122.5 multi 1.00 import weight 0.00
Epoch 166 Iter 6 subLoss 10078.2 multi -4.97 import weight 0.00
Epoch 166 Iter 7 subLoss 10940.5 multi -1.99 import weight 0.00
Epoch 166 Iter 8 subLoss 11394.0 multi 6.97 import weight 0.00
Epoch 166 Iter 9 subLoss 10142.2 multi -4.97 import weight 0.00
Epoch 166 Iter 10 subLoss 11564.3 multi 3.98 import weight 0.00
Epoch 166 Iter 11 subLoss 9941.4 multi 3.98 import weight 0.00
Epoch 166 Acc: 94.92 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 994 train Loss: 9626.6 test Loss: 1183.3
Epoch 167 Iter 0 subLoss 9356.6 multi 12.94 import weight 0.00
Epoch 167 Iter 1 subLoss 8260.8 multi 3.99 import weight 0.00
Epoch 167 Iter 2 subLoss 7965.9 multi -1.99 import weight 0.00
Epoch 167 Iter 3 subLoss 8421.4 multi 3.99 import weight 0.00
Epoch 167 Iter 4 subLoss 8026.1 multi -1.99 import weight 0.00
Epoch 167 Iter 5 subLoss 7565.2 multi 3.98 import weight 0.00
Epoch 167 Iter 6 subLoss 7671.3 multi 1.00 import weight 0.00
Epoch 167 Iter 7 subLoss 7909.0 multi 6.97 import weight 0.00
Epoch 167 Iter 8 subLoss 7298.8 multi 6.97 import weight 0.00
Epoch 167 Iter 9 subLoss 7762.8 multi 1.00 import weight 0.00
Epoch 167 Iter 10 subLoss 7723.2 multi 1.00 import weight 0.00
Epoch 167 Iter 11 subLoss 7269.1 multi 3.98 import weight 0.00
Epoch 167 Acc: 96.73 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 726 train Loss: 7205.9 test Loss: 862.5
Epoch 168 Iter 0 subLoss 7104.7 multi 3.99 import weight 0.00
Epoch 168 Iter 1 subLoss 6514.5 multi 3.98 import weight 0.00
Epoch 168 Iter 2 subLoss 6693.9 multi 1.00 import weight 0.00
Epoch 168 Iter 3 subLoss 7197.2 multi 3.98 import weight 0.00
Epoch 168 Iter 4 subLoss 6702.0 multi 3.98 import weight 0.00
Epoch 168 Iter 5 subLoss 5982.5 multi -1.99 import weight 0.00
Epoch 168 Iter 6 subLoss 6737.1 multi 3.99 import weight 0.00
Epoch 168 Iter 7 subLoss 6236.4 multi -4.97 import weight 0.00
Epoch 168 Iter 8 subLoss 6675.7 multi 3.98 import weight 0.00
Epoch 168 Iter 9 subLoss 6534.9 multi 1.00 import weight 0.00
Epoch 168 Iter 10 subLoss 7084.9 multi 3.99 import weight 0.00
Epoch 168 Iter 11 subLoss 6770.9 multi -7.96 import weight 0.00
Epoch 168 Acc: 96.58 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 677 train Loss: 7003.8 test Loss: 853.9
Epoch 169 Iter 0 subLoss 6490.8 multi -1.99 import weight 0.00
Epoch 169 Iter 1 subLoss 7076.0 multi -1.99 import weight 0.00
Epoch 169 Iter 2 subLoss 7211.4 multi 1.00 import weight 0.00
Epoch 169 Iter 3 subLoss 7253.2 multi -1.98 import weight 0.00
Epoch 169 Iter 4 subLoss 7602.0 multi -1.99 import weight 0.00
Epoch 169 Iter 5 subLoss 8612.7 multi -4.97 import weight 0.00
Epoch 169 Iter 6 subLoss 25362.0 multi 1.00 import weight 0.00
Epoch 169 Iter 7 subLoss 12276.0 multi -7.96 import weight 0.00
Epoch 169 Iter 8 subLoss 50665.0 multi 1.00 import weight 0.00
Epoch 169 Iter 9 subLoss 39358.1 multi 1.00 import weight 0.00
Epoch 169 Iter 10 subLoss 31836.6 multi 1.00 import weight 0.00
Epoch 169 Iter 11 subLoss 26538.5 multi 1.00 import weight 0.00
Epoch 169 Acc: 68.20 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2653 train Loss: 25584.9 test Loss: 4176.1
Epoch 170 Iter 0 subLoss 24796.6 multi 3.99 import weight 0.00
Epoch 170 Iter 1 subLoss 20088.1 multi -1.99 import weight 0.00
Epoch 170 Iter 2 subLoss 22234.7 multi -4.97 import weight 0.00
Epoch 170 Iter 3 subLoss 30044.1 multi 1.00 import weight 0.00
Epoch 170 Iter 4 subLoss 25360.2 multi 3.99 import weight 0.00
Epoch 170 Iter 5 subLoss 20070.4 multi 3.99 import weight 0.00
Epoch 170 Iter 6 subLoss 17956.5 multi -1.99 import weight 0.00
Epoch 170 Iter 7 subLoss 20299.8 multi 6.97 import weight 0.00
Epoch 170 Iter 8 subLoss 15759.3 multi -1.99 import weight 0.00
Epoch 170 Iter 9 subLoss 19203.7 multi 1.00 import weight 0.00
Epoch 170 Iter 10 subLoss 18055.4 multi 1.00 import weight 0.00
Epoch 170 Iter 11 subLoss 17964.8 multi 1.00 import weight 0.00
Epoch 170 Acc: 79.45 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1796 train Loss: 16274.9 test Loss: 2254.4
Epoch 171 Iter 0 subLoss 16485.3 multi -4.97 import weight 0.00
Epoch 171 Iter 1 subLoss 20542.5 multi 9.96 import weight 0.00
Epoch 171 Iter 2 subLoss 16614.6 multi 3.99 import weight 0.00
Epoch 171 Iter 3 subLoss 14129.5 multi -10.94 import weight 0.00
Epoch 171 Iter 4 subLoss 45035.5 multi -1.99 import weight 0.00
Epoch 171 Iter 5 subLoss 547925.1 multi 1.00 import weight 0.00
Epoch 171 Iter 6 subLoss 38195.7 multi 1.00 import weight 0.00
Epoch 171 Iter 7 subLoss 24101.5 multi 1.00 import weight 0.00
Epoch 171 Iter 8 subLoss 22090.9 multi 3.99 import weight 0.00
Epoch 171 Iter 9 subLoss 15034.0 multi 1.00 import weight 0.00
Epoch 171 Iter 10 subLoss 14141.5 multi -1.99 import weight 0.00
Epoch 171 Iter 11 subLoss 15610.5 multi 1.00 import weight 0.00
Epoch 171 Acc: 92.06 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1561 train Loss: 15253.5 test Loss: 1765.6
Epoch 172 Iter 0 subLoss 14643.9 multi -1.99 import weight 0.00
Epoch 172 Iter 1 subLoss 16919.3 multi 6.97 import weight 0.00
Epoch 172 Iter 2 subLoss 12633.7 multi 1.00 import weight 0.00
Epoch 172 Iter 3 subLoss 11472.1 multi 1.00 import weight 0.00
Epoch 172 Iter 4 subLoss 11105.9 multi -1.99 import weight 0.00
Epoch 172 Iter 5 subLoss 12247.5 multi 1.00 import weight 0.00
Epoch 172 Iter 6 subLoss 12083.4 multi 1.00 import weight 0.00
Epoch 172 Iter 7 subLoss 11544.4 multi -1.98 import weight 0.00
Epoch 172 Iter 8 subLoss 12179.9 multi 1.00 import weight 0.00
Epoch 172 Iter 9 subLoss 12460.0 multi 1.00 import weight 0.00
Epoch 172 Iter 10 subLoss 11511.9 multi 3.99 import weight 0.00
Epoch 172 Iter 11 subLoss 10776.7 multi 3.98 import weight 0.00
Epoch 172 Acc: 94.65 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 1077 train Loss: 10970.5 test Loss: 1240.5
Epoch 173 Iter 0 subLoss 10670.0 multi 9.96 import weight 0.00
Epoch 173 Iter 1 subLoss 41238.1 multi 1.00 import weight 0.00
Epoch 173 Iter 2 subLoss 17036.7 multi 3.99 import weight 0.00
Epoch 173 Iter 3 subLoss 10249.4 multi 3.99 import weight 0.00
Epoch 173 Iter 4 subLoss 8637.5 multi 3.99 import weight 0.00
Epoch 173 Iter 5 subLoss 8841.1 multi 1.00 import weight 0.00
Epoch 173 Iter 6 subLoss 7996.3 multi 1.00 import weight 0.00
Epoch 173 Iter 7 subLoss 8250.9 multi -1.99 import weight 0.00
Epoch 173 Iter 8 subLoss 8698.0 multi -1.99 import weight 0.00
Epoch 173 Iter 9 subLoss 9188.1 multi 1.00 import weight 0.00
Epoch 173 Iter 10 subLoss 8601.2 multi -1.99 import weight 0.00
Epoch 173 Iter 11 subLoss 9232.4 multi 3.98 import weight 0.00
Epoch 173 Acc: 95.27 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 923 train Loss: 8827.2 test Loss: 1067.7
Epoch 174 Iter 0 subLoss 8341.2 multi 1.00 import weight 0.00
Epoch 174 Iter 1 subLoss 8703.3 multi -1.99 import weight 0.00
Epoch 174 Iter 2 subLoss 8576.6 multi 1.00 import weight 0.00
Epoch 174 Iter 3 subLoss 8263.9 multi 3.98 import weight 0.00
Epoch 174 Iter 4 subLoss 8288.5 multi 1.00 import weight 0.00
Epoch 174 Iter 5 subLoss 8320.6 multi 1.00 import weight 0.00
Epoch 174 Iter 6 subLoss 8425.2 multi 6.97 import weight 0.00
Epoch 174 Iter 7 subLoss 8052.1 multi 3.98 import weight 0.00
Epoch 174 Iter 8 subLoss 7579.6 multi -7.96 import weight 0.00
Epoch 174 Iter 9 subLoss 8276.4 multi -7.96 import weight 0.00
Epoch 174 Iter 10 subLoss 17707.9 multi -4.97 import weight 0.00
Epoch 174 Iter 11 subLoss 445245.2 multi 1.00 import weight 0.00
Epoch 174 Acc: 50.28 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 44524 train Loss: 170813.3 test Loss: 29950.0
Epoch 175 Iter 0 subLoss 170963.7 multi 1.00 import weight 0.00
Epoch 175 Iter 1 subLoss 45974.3 multi 1.00 import weight 0.00
Epoch 175 Iter 2 subLoss 26493.5 multi 1.00 import weight 0.00
Epoch 175 Iter 3 subLoss 24237.7 multi 1.00 import weight 0.00
Epoch 175 Iter 4 subLoss 21258.1 multi -1.99 import weight 0.00
Epoch 175 Iter 5 subLoss 23490.1 multi 3.98 import weight 0.00
Epoch 175 Iter 6 subLoss 17939.9 multi 3.99 import weight 0.00
Epoch 175 Iter 7 subLoss 15717.9 multi 1.00 import weight 0.00
Epoch 175 Iter 8 subLoss 15672.0 multi 1.00 import weight 0.00
Epoch 175 Iter 9 subLoss 14844.1 multi 3.99 import weight 0.00
Epoch 175 Iter 10 subLoss 13422.6 multi 3.99 import weight 0.00
Epoch 175 Iter 11 subLoss 12581.7 multi 3.98 import weight 0.00
Epoch 175 Acc: 93.95 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 1258 train Loss: 12485.3 test Loss: 1327.2
Epoch 176 Iter 0 subLoss 12532.2 multi 6.97 import weight 0.00
Epoch 176 Iter 1 subLoss 11926.3 multi 1.00 import weight 0.00
Epoch 176 Iter 2 subLoss 11632.2 multi -1.99 import weight 0.00
Epoch 176 Iter 3 subLoss 11289.2 multi 1.00 import weight 0.00
Epoch 176 Iter 4 subLoss 10791.1 multi 6.97 import weight 0.00
Epoch 176 Iter 5 subLoss 10046.4 multi 1.00 import weight 0.00
Epoch 176 Iter 6 subLoss 10468.5 multi -1.98 import weight 0.00
Epoch 176 Iter 7 subLoss 11259.9 multi 1.00 import weight 0.00
Epoch 176 Iter 8 subLoss 10879.6 multi 3.98 import weight 0.00
Epoch 176 Iter 9 subLoss 10585.8 multi 3.99 import weight 0.00
Epoch 176 Iter 10 subLoss 9827.7 multi 1.00 import weight 0.00
Epoch 176 Iter 11 subLoss 10316.0 multi -1.99 import weight 0.00
Epoch 176 Acc: 95.29 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 1031 train Loss: 10862.0 test Loss: 1076.5
Epoch 177 Iter 0 subLoss 10529.1 multi -1.99 import weight 0.00
Epoch 177 Iter 1 subLoss 12752.3 multi 1.00 import weight 0.00
Epoch 177 Iter 2 subLoss 10698.7 multi 3.99 import weight 0.00
Epoch 177 Iter 3 subLoss 10641.1 multi 1.00 import weight 0.00
Epoch 177 Iter 4 subLoss 9885.0 multi 1.00 import weight 0.00
Epoch 177 Iter 5 subLoss 9316.1 multi -1.99 import weight 0.00
Epoch 177 Iter 6 subLoss 9863.0 multi 3.98 import weight 0.00
Epoch 177 Iter 7 subLoss 9701.2 multi 6.97 import weight 0.00
Epoch 177 Iter 8 subLoss 9007.7 multi -1.98 import weight 0.00
Epoch 177 Iter 9 subLoss 9686.1 multi -1.98 import weight 0.00
Epoch 177 Iter 10 subLoss 11807.1 multi 9.96 import weight 0.00
Epoch 177 Iter 11 subLoss 67703.4 multi 1.00 import weight 0.00
Epoch 177 Acc: 90.72 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 6770 train Loss: 13163.2 test Loss: 1677.7
Epoch 178 Iter 0 subLoss 13097.2 multi 3.99 import weight 0.00
Epoch 178 Iter 1 subLoss 10673.6 multi 12.94 import weight 0.00
Epoch 178 Iter 2 subLoss 14661.9 multi 3.98 import weight 0.00
Epoch 178 Iter 3 subLoss 11875.9 multi 6.97 import weight 0.00
Epoch 178 Iter 4 subLoss 15224.7 multi 3.99 import weight 0.00
Epoch 178 Iter 5 subLoss 10435.4 multi -1.99 import weight 0.00
Epoch 178 Iter 6 subLoss 13684.9 multi -1.99 import weight 0.00
Epoch 178 Iter 7 subLoss 25762.4 multi 1.00 import weight 0.00
Epoch 178 Iter 8 subLoss 15572.4 multi -1.99 import weight 0.00
Epoch 178 Iter 9 subLoss 28784.6 multi 1.00 import weight 0.00
Epoch 178 Iter 10 subLoss 19648.0 multi 1.00 import weight 0.00
Epoch 178 Iter 11 subLoss 14858.5 multi 1.00 import weight 0.00
Epoch 178 Acc: 91.54 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1485 train Loss: 11212.0 test Loss: 1544.1
Epoch 179 Iter 0 subLoss 10075.5 multi -1.98 import weight 0.00
Epoch 179 Iter 1 subLoss 14367.5 multi 3.99 import weight 0.00
Epoch 179 Iter 2 subLoss 8358.9 multi -4.97 import weight 0.00
Epoch 179 Iter 3 subLoss 8735.3 multi 9.96 import weight 0.00
Epoch 179 Iter 4 subLoss 8853.0 multi 3.98 import weight 0.00
Epoch 179 Iter 5 subLoss 7925.1 multi 1.00 import weight 0.00
Epoch 179 Iter 6 subLoss 7158.4 multi 3.99 import weight 0.00
Epoch 179 Iter 7 subLoss 7491.5 multi 6.97 import weight 0.00
Epoch 179 Iter 8 subLoss 7761.9 multi 3.98 import weight 0.00
Epoch 179 Iter 9 subLoss 7489.6 multi -1.99 import weight 0.00
Epoch 179 Iter 10 subLoss 7055.9 multi 6.97 import weight 0.00
Epoch 179 Iter 11 subLoss 7433.9 multi 1.00 import weight 0.00
Epoch 179 Acc: 96.59 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 743 train Loss: 7309.1 test Loss: 812.4
Epoch 180 Iter 0 subLoss 6901.1 multi 1.00 import weight 0.00
Epoch 180 Iter 1 subLoss 6855.9 multi -4.97 import weight 0.00
Epoch 180 Iter 2 subLoss 7744.0 multi 9.96 import weight 0.00
Epoch 180 Iter 3 subLoss 7644.0 multi -4.97 import weight 0.00
Epoch 180 Iter 4 subLoss 7555.6 multi -4.97 import weight 0.00
Epoch 180 Iter 5 subLoss 14113.2 multi 12.94 import weight 0.00
Epoch 180 Iter 6 subLoss 119225.9 multi 1.00 import weight 0.00
Epoch 180 Iter 7 subLoss 11316.5 multi 3.99 import weight 0.00
Epoch 180 Iter 8 subLoss 9356.4 multi 15.93 import weight 1.00
Epoch 180 Iter 9 subLoss 11539.1 multi 6.97 import weight 0.00
Epoch 180 Iter 10 subLoss 13229.3 multi 6.97 import weight 0.00
Epoch 180 Iter 11 subLoss 13721.7 multi 3.99 import weight 0.00
Epoch 180 Acc: 94.22 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 1372 train Loss: 9918.0 test Loss: 1108.2
Epoch 181 Iter 0 subLoss 9264.1 multi -4.97 import weight 0.00
Epoch 181 Iter 1 subLoss 11659.8 multi -4.97 import weight 0.00
Epoch 181 Iter 2 subLoss 27576.7 multi -4.97 import weight 0.00
Epoch 181 Iter 3 subLoss 70741.4 multi 1.00 import weight 0.00
Epoch 181 Iter 4 subLoss 68406.8 multi 1.00 import weight 0.00
Epoch 181 Iter 5 subLoss 66154.1 multi 1.00 import weight 0.00
Epoch 181 Iter 6 subLoss 64103.2 multi 1.00 import weight 0.00
Epoch 181 Iter 7 subLoss 61629.7 multi 1.00 import weight 0.00
Epoch 181 Iter 8 subLoss 59068.1 multi 1.00 import weight 0.00
Epoch 181 Iter 9 subLoss 56777.1 multi 1.00 import weight 0.00
Epoch 181 Iter 10 subLoss 52240.4 multi 1.00 import weight 0.00
Epoch 181 Iter 11 subLoss 49707.9 multi 1.00 import weight 0.00
Epoch 181 Acc: 32.36 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4970 train Loss: 48272.4 test Loss: 8927.5
Epoch 182 Iter 0 subLoss 46858.2 multi 1.00 import weight 0.00
Epoch 182 Iter 1 subLoss 44668.1 multi 1.00 import weight 0.00
Epoch 182 Iter 2 subLoss 42159.6 multi 1.00 import weight 0.00
Epoch 182 Iter 3 subLoss 40275.6 multi 1.00 import weight 0.00
Epoch 182 Iter 4 subLoss 37883.7 multi 1.00 import weight 0.00
Epoch 182 Iter 5 subLoss 35887.4 multi 3.99 import weight 0.00
Epoch 182 Iter 6 subLoss 32119.0 multi 1.00 import weight 0.00
Epoch 182 Iter 7 subLoss 28649.0 multi 1.00 import weight 0.00
Epoch 182 Iter 8 subLoss 29434.5 multi 1.00 import weight 0.00
Epoch 182 Iter 9 subLoss 28009.1 multi 1.00 import weight 0.00
Epoch 182 Iter 10 subLoss 27328.0 multi 1.00 import weight 0.00
Epoch 182 Iter 11 subLoss 25168.7 multi 1.00 import weight 0.00
Epoch 182 Acc: 68.79 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2516 train Loss: 26048.0 test Loss: 4338.7
Epoch 183 Iter 0 subLoss 25747.9 multi 1.00 import weight 0.00
Epoch 183 Iter 1 subLoss 25748.5 multi 3.99 import weight 0.00
Epoch 183 Iter 2 subLoss 22908.2 multi 1.00 import weight 0.00
Epoch 183 Iter 3 subLoss 22137.8 multi -1.99 import weight 0.00
Epoch 183 Iter 4 subLoss 23801.9 multi 6.97 import weight 0.00
Epoch 183 Iter 5 subLoss 27700.5 multi 1.00 import weight 0.00
Epoch 183 Iter 6 subLoss 21583.1 multi 3.99 import weight 0.00
Epoch 183 Iter 7 subLoss 33465.4 multi -1.99 import weight 0.00
Epoch 183 Iter 8 subLoss 615404.9 multi 1.00 import weight 0.00
Epoch 183 Iter 9 subLoss 58442.2 multi 1.00 import weight 0.00
Epoch 183 Iter 10 subLoss 54004.5 multi 1.00 import weight 0.00
Epoch 183 Iter 11 subLoss 47394.6 multi -1.99 import weight 0.00
Epoch 183 Acc: 30.53 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 4739 train Loss: 58775.1 test Loss: 9891.0
Epoch 184 Iter 0 subLoss 56982.1 multi 1.00 import weight 0.00
Epoch 184 Iter 1 subLoss 54867.0 multi 1.00 import weight 0.00
Epoch 184 Iter 2 subLoss 50121.6 multi 1.00 import weight 0.00
Epoch 184 Iter 3 subLoss 45626.2 multi 1.00 import weight 0.00
Epoch 184 Iter 4 subLoss 42315.3 multi 1.00 import weight 0.00
Epoch 184 Iter 5 subLoss 40059.3 multi 1.00 import weight 0.00
Epoch 184 Iter 6 subLoss 38250.4 multi 1.00 import weight 0.00
Epoch 184 Iter 7 subLoss 34819.8 multi 1.00 import weight 0.00
Epoch 184 Iter 8 subLoss 33789.7 multi 1.00 import weight 0.00
Epoch 184 Iter 9 subLoss 30052.9 multi -1.99 import weight 0.00
Epoch 184 Iter 10 subLoss 35748.9 multi 1.00 import weight 0.00
Epoch 184 Iter 11 subLoss 32411.7 multi 1.00 import weight 0.00
Epoch 184 Acc: 63.71 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 3241 train Loss: 31469.5 test Loss: 4878.3
Epoch 185 Iter 0 subLoss 30707.1 multi 1.00 import weight 0.00
Epoch 185 Iter 1 subLoss 29354.7 multi 1.00 import weight 0.00
Epoch 185 Iter 2 subLoss 25986.1 multi 1.00 import weight 0.00
Epoch 185 Iter 3 subLoss 23542.1 multi 1.00 import weight 0.00
Epoch 185 Iter 4 subLoss 21708.0 multi -1.99 import weight 0.00
Epoch 185 Iter 5 subLoss 25436.4 multi -1.99 import weight 0.00
Epoch 185 Iter 6 subLoss 30450.6 multi 1.00 import weight 0.00
Epoch 185 Iter 7 subLoss 27778.2 multi -1.99 import weight 0.00
Epoch 185 Iter 8 subLoss 31835.3 multi 3.99 import weight 0.00
Epoch 185 Iter 9 subLoss 25192.0 multi 1.00 import weight 0.00
Epoch 185 Iter 10 subLoss 22842.3 multi 1.00 import weight 0.00
Epoch 185 Iter 11 subLoss 20050.1 multi 1.00 import weight 0.00
Epoch 185 Acc: 84.61 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2005 train Loss: 19600.8 test Loss: 2469.0
Epoch 186 Iter 0 subLoss 19850.4 multi -1.99 import weight 0.00
Epoch 186 Iter 1 subLoss 21826.5 multi 3.99 import weight 0.00
Epoch 186 Iter 2 subLoss 15849.8 multi 3.99 import weight 0.00
Epoch 186 Iter 3 subLoss 14246.7 multi -1.99 import weight 0.00
Epoch 186 Iter 4 subLoss 15100.4 multi 3.99 import weight 0.00
Epoch 186 Iter 5 subLoss 13803.5 multi 1.00 import weight 0.00
Epoch 186 Iter 6 subLoss 13355.7 multi 6.97 import weight 0.00
Epoch 186 Iter 7 subLoss 12489.2 multi 3.98 import weight 0.00
Epoch 186 Iter 8 subLoss 11426.9 multi 1.00 import weight 0.00
Epoch 186 Iter 9 subLoss 10965.3 multi 3.98 import weight 0.00
Epoch 186 Iter 10 subLoss 10425.7 multi -1.98 import weight 0.00
Epoch 186 Iter 11 subLoss 10634.5 multi -1.98 import weight 0.00
Epoch 186 Acc: 89.82 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 1063 train Loss: 13279.7 test Loss: 1625.0
Epoch 187 Iter 0 subLoss 13959.8 multi 3.99 import weight 0.00
Epoch 187 Iter 1 subLoss 12302.4 multi 1.00 import weight 0.00
Epoch 187 Iter 2 subLoss 10737.2 multi -4.97 import weight 0.00
Epoch 187 Iter 3 subLoss 18957.7 multi -1.99 import weight 0.00
Epoch 187 Iter 4 subLoss 34029.0 multi 1.00 import weight 0.00
Epoch 187 Iter 5 subLoss 25902.5 multi 3.99 import weight 0.00
Epoch 187 Iter 6 subLoss 12306.2 multi 3.98 import weight 0.00
Epoch 187 Iter 7 subLoss 10245.3 multi 6.97 import weight 0.00
Epoch 187 Iter 8 subLoss 9319.4 multi 1.00 import weight 0.00
Epoch 187 Iter 9 subLoss 9336.4 multi -4.97 import weight 0.00
Epoch 187 Iter 10 subLoss 10624.9 multi 1.00 import weight 0.00
Epoch 187 Iter 11 subLoss 10536.9 multi 1.00 import weight 0.00
Epoch 187 Acc: 95.12 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1053 train Loss: 10132.8 test Loss: 1044.1
Epoch 188 Iter 0 subLoss 9653.2 multi -10.94 import weight 0.00
Epoch 188 Iter 1 subLoss 12830.3 multi 3.98 import weight 0.00
Epoch 188 Iter 2 subLoss 10851.3 multi -1.98 import weight 0.00
Epoch 188 Iter 3 subLoss 11826.4 multi 1.00 import weight 0.00
Epoch 188 Iter 4 subLoss 11860.6 multi 3.99 import weight 0.00
Epoch 188 Iter 5 subLoss 10053.2 multi -1.98 import weight 0.00
Epoch 188 Iter 6 subLoss 10411.4 multi 6.97 import weight 0.00
Epoch 188 Iter 7 subLoss 9340.2 multi -1.99 import weight 0.00
Epoch 188 Iter 8 subLoss 10185.8 multi 1.00 import weight 0.00
Epoch 188 Iter 9 subLoss 9496.2 multi 1.00 import weight 0.00
Epoch 188 Iter 10 subLoss 9256.8 multi 6.97 import weight 0.00
Epoch 188 Iter 11 subLoss 8603.2 multi 1.00 import weight 0.00
Epoch 188 Acc: 95.82 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 860 train Loss: 9239.5 test Loss: 961.4
Epoch 189 Iter 0 subLoss 8754.4 multi -4.97 import weight 0.00
Epoch 189 Iter 1 subLoss 10434.6 multi -1.98 import weight 0.00
Epoch 189 Iter 2 subLoss 9901.6 multi 1.00 import weight 0.00
Epoch 189 Iter 3 subLoss 9789.6 multi -10.94 import weight 0.00
Epoch 189 Iter 4 subLoss 14127.0 multi -10.94 import weight 0.00
Epoch 189 Iter 5 subLoss 407820.6 multi 1.00 import weight 0.00
Epoch 189 Iter 6 subLoss 44531.6 multi 1.00 import weight 0.00
Epoch 189 Iter 7 subLoss 29542.0 multi 1.00 import weight 0.00
Epoch 189 Iter 8 subLoss 27701.1 multi 3.99 import weight 0.00
Epoch 189 Iter 9 subLoss 22803.2 multi 1.00 import weight 0.00
Epoch 189 Iter 10 subLoss 21122.5 multi 3.99 import weight 0.00
Epoch 189 Iter 11 subLoss 19447.2 multi 3.99 import weight 0.00
Epoch 189 Acc: 92.10 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 1944 train Loss: 17288.7 test Loss: 1648.2
Epoch 190 Iter 0 subLoss 17395.0 multi 3.99 import weight 0.00
Epoch 190 Iter 1 subLoss 15843.4 multi 6.97 import weight 0.00
Epoch 190 Iter 2 subLoss 13595.0 multi -1.99 import weight 0.00
Epoch 190 Iter 3 subLoss 14404.1 multi 1.00 import weight 0.00
Epoch 190 Iter 4 subLoss 15004.9 multi 1.00 import weight 0.00
Epoch 190 Iter 5 subLoss 14544.7 multi 1.00 import weight 0.00
Epoch 190 Iter 6 subLoss 13556.8 multi 3.99 import weight 0.00
Epoch 190 Iter 7 subLoss 13705.1 multi 3.98 import weight 0.00
Epoch 190 Iter 8 subLoss 12439.5 multi 3.99 import weight 0.00
Epoch 190 Iter 9 subLoss 12455.5 multi 3.99 import weight 0.00
Epoch 190 Iter 10 subLoss 12256.2 multi 1.00 import weight 0.00
Epoch 190 Iter 11 subLoss 12325.0 multi 3.98 import weight 0.00
Epoch 190 Acc: 93.85 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 1232 train Loss: 11907.3 test Loss: 1204.2
Epoch 191 Iter 0 subLoss 11236.8 multi -1.99 import weight 0.00
Epoch 191 Iter 1 subLoss 12143.0 multi 9.96 import weight 0.00
Epoch 191 Iter 2 subLoss 12313.6 multi -4.97 import weight 0.00
Epoch 191 Iter 3 subLoss 27860.5 multi 1.00 import weight 0.00
Epoch 191 Iter 4 subLoss 12085.4 multi 3.98 import weight 0.00
Epoch 191 Iter 5 subLoss 10663.1 multi -1.99 import weight 0.00
Epoch 191 Iter 6 subLoss 11843.7 multi 1.00 import weight 0.00
Epoch 191 Iter 7 subLoss 10753.0 multi 3.99 import weight 0.00
Epoch 191 Iter 8 subLoss 10652.4 multi -1.98 import weight 0.00
Epoch 191 Iter 9 subLoss 11157.5 multi -1.99 import weight 0.00
Epoch 191 Iter 10 subLoss 13104.7 multi -4.97 import weight 0.00
Epoch 191 Iter 11 subLoss 39364.4 multi -1.99 import weight 0.00
Epoch 191 Acc: 39.56 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 3936 train Loss: 332184.0 test Loss: 73765.4
Epoch 192 Iter 0 subLoss 322519.7 multi 1.00 import weight 0.00
Epoch 192 Iter 1 subLoss 22796.5 multi -1.99 import weight 0.00
Epoch 192 Iter 2 subLoss 36517.5 multi 1.00 import weight 0.00
Epoch 192 Iter 3 subLoss 21311.4 multi -4.97 import weight 0.00
Epoch 192 Iter 4 subLoss 33409.6 multi 1.00 import weight 0.00
Epoch 192 Iter 5 subLoss 29767.4 multi 1.00 import weight 0.00
Epoch 192 Iter 6 subLoss 26636.9 multi 6.97 import weight 0.00
Epoch 192 Iter 7 subLoss 16363.9 multi 1.00 import weight 0.00
Epoch 192 Iter 8 subLoss 15190.7 multi 6.97 import weight 0.00
Epoch 192 Iter 9 subLoss 13955.3 multi 6.97 import weight 0.00
Epoch 192 Iter 10 subLoss 12865.3 multi 3.99 import weight 0.00
Epoch 192 Iter 11 subLoss 12531.6 multi 9.96 import weight 0.00
Epoch 192 Acc: 92.24 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 1253 train Loss: 11800.0 test Loss: 1333.1
Epoch 193 Iter 0 subLoss 12213.7 multi 6.97 import weight 0.00
Epoch 193 Iter 1 subLoss 11274.7 multi 6.97 import weight 0.00
Epoch 193 Iter 2 subLoss 10699.4 multi 6.97 import weight 0.00
Epoch 193 Iter 3 subLoss 10809.8 multi -1.99 import weight 0.00
Epoch 193 Iter 4 subLoss 11253.7 multi 3.99 import weight 0.00
Epoch 193 Iter 5 subLoss 9865.5 multi 6.97 import weight 0.00
Epoch 193 Iter 6 subLoss 9687.4 multi 1.00 import weight 0.00
Epoch 193 Iter 7 subLoss 9781.2 multi -7.96 import weight 0.00
Epoch 193 Iter 8 subLoss 10280.2 multi 3.99 import weight 0.00
Epoch 193 Iter 9 subLoss 10182.9 multi 3.99 import weight 0.00
Epoch 193 Iter 10 subLoss 9557.7 multi 1.00 import weight 0.00
Epoch 193 Iter 11 subLoss 9768.1 multi 6.97 import weight 0.00
Epoch 193 Acc: 95.14 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 976 train Loss: 9699.5 test Loss: 997.1
Epoch 194 Iter 0 subLoss 9039.5 multi 3.99 import weight 0.00
Epoch 194 Iter 1 subLoss 9137.7 multi 6.97 import weight 0.00
Epoch 194 Iter 2 subLoss 9290.9 multi 1.00 import weight 0.00
Epoch 194 Iter 3 subLoss 8884.2 multi 3.99 import weight 0.00
Epoch 194 Iter 4 subLoss 8677.7 multi 9.96 import weight 0.00
Epoch 194 Iter 5 subLoss 8506.7 multi 9.96 import weight 0.00
Epoch 194 Iter 6 subLoss 8558.2 multi 1.00 import weight 0.00
Epoch 194 Iter 7 subLoss 8403.6 multi 1.00 import weight 0.00
Epoch 194 Iter 8 subLoss 7896.4 multi -4.97 import weight 0.00
Epoch 194 Iter 9 subLoss 8732.8 multi 12.94 import weight 0.00
Epoch 194 Iter 10 subLoss 11310.3 multi 6.97 import weight 0.00
Epoch 194 Iter 11 subLoss 13242.0 multi 1.00 import weight 0.00
Epoch 194 Acc: 92.96 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1324 train Loss: 9895.5 test Loss: 1180.9
Epoch 195 Iter 0 subLoss 9343.7 multi 1.00 import weight 0.00
Epoch 195 Iter 1 subLoss 9280.1 multi 1.00 import weight 0.00
Epoch 195 Iter 2 subLoss 8304.4 multi 1.00 import weight 0.00
Epoch 195 Iter 3 subLoss 7657.4 multi -1.99 import weight 0.00
Epoch 195 Iter 4 subLoss 8084.5 multi 6.97 import weight 0.00
Epoch 195 Iter 5 subLoss 7402.6 multi -10.94 import weight 0.00
Epoch 195 Iter 6 subLoss 9655.8 multi -7.96 import weight 0.00
Epoch 195 Iter 7 subLoss 34204.4 multi -1.99 import weight 0.00
Epoch 195 Iter 8 subLoss 69275.6 multi 1.00 import weight 0.00
Epoch 195 Iter 9 subLoss 50224.2 multi 1.00 import weight 0.00
Epoch 195 Iter 10 subLoss 43127.9 multi 1.00 import weight 0.00
Epoch 195 Iter 11 subLoss 35260.0 multi 3.99 import weight 0.00
Epoch 195 Acc: 95.80 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 3525 train Loss: 10233.0 test Loss: 990.2
Epoch 196 Iter 0 subLoss 9464.5 multi 1.00 import weight 0.00
Epoch 196 Iter 1 subLoss 9465.1 multi 3.99 import weight 0.00
Epoch 196 Iter 2 subLoss 8415.8 multi -4.97 import weight 0.00
Epoch 196 Iter 3 subLoss 9054.3 multi 3.99 import weight 0.00
Epoch 196 Iter 4 subLoss 8344.8 multi 3.98 import weight 0.00
Epoch 196 Iter 5 subLoss 8343.6 multi 6.97 import weight 0.00
Epoch 196 Iter 6 subLoss 7632.0 multi 1.00 import weight 0.00
Epoch 196 Iter 7 subLoss 7205.6 multi -7.96 import weight 0.00
Epoch 196 Iter 8 subLoss 7957.4 multi 1.00 import weight 0.00
Epoch 196 Iter 9 subLoss 8398.9 multi 1.00 import weight 0.00
Epoch 196 Iter 10 subLoss 8167.0 multi -1.99 import weight 0.00
Epoch 196 Iter 11 subLoss 7836.3 multi -1.99 import weight 0.00
Epoch 196 Acc: 96.01 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 783 train Loss: 8571.2 test Loss: 853.3
Epoch 197 Iter 0 subLoss 8564.4 multi -4.97 import weight 0.00
Epoch 197 Iter 1 subLoss 9351.6 multi 12.94 import weight 1.00
Epoch 197 Iter 2 subLoss 8439.7 multi -7.96 import weight 0.00
Epoch 197 Iter 3 subLoss 10774.4 multi 6.97 import weight 0.00
Epoch 197 Iter 4 subLoss 8757.6 multi -1.98 import weight 0.00
Epoch 197 Iter 5 subLoss 9396.0 multi 3.99 import weight 0.00
Epoch 197 Iter 6 subLoss 7901.0 multi 6.97 import weight 0.00
Epoch 197 Iter 7 subLoss 7659.0 multi 1.00 import weight 0.00
Epoch 197 Iter 8 subLoss 7788.2 multi 6.97 import weight 0.00
Epoch 197 Iter 9 subLoss 7738.3 multi 1.00 import weight 0.00
Epoch 197 Iter 10 subLoss 7533.9 multi 3.99 import weight 0.00
Epoch 197 Iter 11 subLoss 7047.6 multi -1.98 import weight 0.00
Epoch 197 Acc: 96.81 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 704 train Loss: 7583.6 test Loss: 742.1
Epoch 198 Iter 0 subLoss 7401.0 multi -7.96 import weight 0.00
Epoch 198 Iter 1 subLoss 7343.0 multi -4.97 import weight 0.00
Epoch 198 Iter 2 subLoss 7751.1 multi -10.94 import weight 0.00
Epoch 198 Iter 3 subLoss 9281.4 multi 3.99 import weight 0.00
Epoch 198 Iter 4 subLoss 8448.5 multi -1.99 import weight 0.00
Epoch 198 Iter 5 subLoss 8135.7 multi 1.00 import weight 0.00
Epoch 198 Iter 6 subLoss 8177.4 multi 1.00 import weight 0.00
Epoch 198 Iter 7 subLoss 8653.4 multi 1.00 import weight 0.00
Epoch 198 Iter 8 subLoss 8013.2 multi 1.00 import weight 0.00
Epoch 198 Iter 9 subLoss 7851.6 multi -1.99 import weight 0.00
Epoch 198 Iter 10 subLoss 8417.2 multi -1.98 import weight 0.00
Epoch 198 Iter 11 subLoss 8332.4 multi -4.97 import weight 0.00
Epoch 198 Acc: 96.15 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 833 train Loss: 9438.4 test Loss: 913.5
Epoch 199 Iter 0 subLoss 9606.0 multi 1.00 import weight 0.00
Epoch 199 Iter 1 subLoss 9263.5 multi -4.97 import weight 0.00
Epoch 199 Iter 2 subLoss 10278.0 multi -4.97 import weight 0.00
Epoch 199 Iter 3 subLoss 28228.0 multi 3.99 import weight 0.00
Epoch 199 Iter 4 subLoss 20138.1 multi 1.00 import weight 0.00
Epoch 199 Iter 5 subLoss 15844.8 multi 9.96 import weight 0.00
Epoch 199 Iter 6 subLoss 9250.7 multi 9.96 import weight 0.00
Epoch 199 Iter 7 subLoss 8322.9 multi 3.99 import weight 0.00
Epoch 199 Iter 8 subLoss 7952.2 multi 3.98 import weight 0.00
Epoch 199 Iter 9 subLoss 7622.0 multi 6.97 import weight 0.00
Epoch 199 Iter 10 subLoss 7430.2 multi 3.98 import weight 0.00
Epoch 199 Iter 11 subLoss 7815.5 multi 3.98 import weight 0.00
Epoch 199 Acc: 96.63 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 781 train Loss: 7313.0 test Loss: 752.5
Epoch 200 Iter 0 subLoss 7059.4 multi 6.97 import weight 0.00
Epoch 200 Iter 1 subLoss 7680.1 multi 3.99 import weight 0.00
Epoch 200 Iter 2 subLoss 7238.0 multi 3.98 import weight 0.00
Epoch 200 Iter 3 subLoss 6225.4 multi 1.00 import weight 0.00
Epoch 200 Iter 4 subLoss 6538.4 multi 3.99 import weight 0.00
Epoch 200 Iter 5 subLoss 6750.7 multi 9.96 import weight 0.00
Epoch 200 Iter 6 subLoss 6271.2 multi -4.97 import weight 0.00
Epoch 200 Iter 7 subLoss 6162.3 multi 6.97 import weight 0.00
Epoch 200 Iter 8 subLoss 7418.4 multi 1.00 import weight 0.00
Epoch 200 Iter 9 subLoss 6657.8 multi 1.00 import weight 0.00
Epoch 200 Iter 10 subLoss 6272.4 multi -1.98 import weight 0.00
Epoch 200 Iter 11 subLoss 6033.3 multi 1.00 import weight 0.00
Epoch 200 Acc: 97.00 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 603 train Loss: 6298.7 test Loss: 637.7
Epoch 201 Iter 0 subLoss 5987.7 multi 1.00 import weight 0.00
Epoch 201 Iter 1 subLoss 5876.5 multi 1.00 import weight 0.00
Epoch 201 Iter 2 subLoss 6416.9 multi 1.00 import weight 0.00
Epoch 201 Iter 3 subLoss 6691.8 multi 3.99 import weight 0.00
Epoch 201 Iter 4 subLoss 6348.6 multi 1.00 import weight 0.00
Epoch 201 Iter 5 subLoss 6759.3 multi 12.94 import weight 0.00
Epoch 201 Iter 6 subLoss 5711.4 multi -4.97 import weight 0.00
Epoch 201 Iter 7 subLoss 6197.7 multi 1.00 import weight 0.00
Epoch 201 Iter 8 subLoss 5426.0 multi -4.97 import weight 0.00
Epoch 201 Iter 9 subLoss 6262.1 multi 3.98 import weight 0.00
Epoch 201 Iter 10 subLoss 6260.8 multi 6.97 import weight 0.00
Epoch 201 Iter 11 subLoss 6108.7 multi -7.96 import weight 0.00
Epoch 201 Acc: 97.22 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 610 train Loss: 6333.9 test Loss: 609.2
Epoch 202 Iter 0 subLoss 5958.3 multi 9.96 import weight 0.00
Epoch 202 Iter 1 subLoss 5850.5 multi 1.00 import weight 0.00
Epoch 202 Iter 2 subLoss 6057.8 multi 6.97 import weight 0.00
Epoch 202 Iter 3 subLoss 5729.6 multi 3.98 import weight 0.00
Epoch 202 Iter 4 subLoss 6018.4 multi 1.00 import weight 0.00
Epoch 202 Iter 5 subLoss 5003.1 multi -1.99 import weight 0.00
Epoch 202 Iter 6 subLoss 5633.5 multi -1.99 import weight 0.00
Epoch 202 Iter 7 subLoss 5592.4 multi -1.98 import weight 0.00
Epoch 202 Iter 8 subLoss 5883.1 multi -1.99 import weight 0.00
Epoch 202 Iter 9 subLoss 5937.7 multi 1.00 import weight 0.00
Epoch 202 Iter 10 subLoss 6300.4 multi -1.99 import weight 0.00
Epoch 202 Iter 11 subLoss 5945.0 multi -1.99 import weight 0.00
Epoch 202 Acc: 94.94 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 594 train Loss: 7461.0 test Loss: 968.9
Epoch 203 Iter 0 subLoss 6872.1 multi 15.93 import weight 1.00
Epoch 203 Iter 1 subLoss 27929.6 multi -1.99 import weight 0.00
Epoch 203 Iter 2 subLoss 71616.3 multi 1.00 import weight 0.00
Epoch 203 Iter 3 subLoss 29073.0 multi 1.00 import weight 0.00
Epoch 203 Iter 4 subLoss 25910.6 multi -4.97 import weight 0.00
Epoch 203 Iter 5 subLoss 40656.2 multi 1.00 import weight 0.00
Epoch 203 Iter 6 subLoss 32819.5 multi 1.00 import weight 0.00
Epoch 203 Iter 7 subLoss 30777.8 multi 1.00 import weight 0.00
Epoch 203 Iter 8 subLoss 29025.4 multi -1.99 import weight 0.00
Epoch 203 Iter 9 subLoss 31394.7 multi 1.00 import weight 0.00
Epoch 203 Iter 10 subLoss 29256.6 multi 1.00 import weight 0.00
Epoch 203 Iter 11 subLoss 28150.6 multi 1.00 import weight 0.00
Epoch 203 Acc: 72.27 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2815 train Loss: 27436.7 test Loss: 4159.1
Epoch 204 Iter 0 subLoss 27724.6 multi 1.00 import weight 0.00
Epoch 204 Iter 1 subLoss 26075.3 multi 1.00 import weight 0.00
Epoch 204 Iter 2 subLoss 25041.1 multi -4.97 import weight 0.00
Epoch 204 Iter 3 subLoss 27671.6 multi 1.00 import weight 0.00
Epoch 204 Iter 4 subLoss 27008.2 multi 1.00 import weight 0.00
Epoch 204 Iter 5 subLoss 26551.2 multi -1.99 import weight 0.00
Epoch 204 Iter 6 subLoss 27965.9 multi -4.97 import weight 0.00
Epoch 204 Iter 7 subLoss 34712.4 multi 1.00 import weight 0.00
Epoch 204 Iter 8 subLoss 31095.6 multi 3.99 import weight 0.00
Epoch 204 Iter 9 subLoss 25510.6 multi -1.99 import weight 0.00
Epoch 204 Iter 10 subLoss 29881.0 multi -1.99 import weight 0.00
Epoch 204 Iter 11 subLoss 30437.6 multi 1.00 import weight 0.00
Epoch 204 Acc: 69.86 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 3043 train Loss: 29359.6 test Loss: 4600.2
Epoch 205 Iter 0 subLoss 28391.0 multi 1.00 import weight 0.00
Epoch 205 Iter 1 subLoss 27968.6 multi -1.98 import weight 0.00
Epoch 205 Iter 2 subLoss 30213.5 multi 3.99 import weight 0.00
Epoch 205 Iter 3 subLoss 25799.3 multi -1.99 import weight 0.00
Epoch 205 Iter 4 subLoss 27847.5 multi -1.99 import weight 0.00
Epoch 205 Iter 5 subLoss 27776.4 multi 1.00 import weight 0.00
Epoch 205 Iter 6 subLoss 27290.7 multi -1.98 import weight 0.00
Epoch 205 Iter 7 subLoss 29697.5 multi 1.00 import weight 0.00
Epoch 205 Iter 8 subLoss 28003.1 multi 3.99 import weight 0.00
Epoch 205 Iter 9 subLoss 26299.5 multi 1.00 import weight 0.00
Epoch 205 Iter 10 subLoss 26470.3 multi 3.99 import weight 0.00
Epoch 205 Iter 11 subLoss 24636.5 multi 1.00 import weight 0.00
Epoch 205 Acc: 74.72 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2463 train Loss: 24295.3 test Loss: 3813.0
Epoch 206 Iter 0 subLoss 24802.1 multi -1.98 import weight 0.00
Epoch 206 Iter 1 subLoss 24276.1 multi 3.99 import weight 0.00
Epoch 206 Iter 2 subLoss 21921.4 multi -1.99 import weight 0.00
Epoch 206 Iter 3 subLoss 23631.2 multi -1.99 import weight 0.00
Epoch 206 Iter 4 subLoss 24731.5 multi 1.00 import weight 0.00
Epoch 206 Iter 5 subLoss 25456.6 multi -1.99 import weight 0.00
Epoch 206 Iter 6 subLoss 24859.1 multi 1.00 import weight 0.00
Epoch 206 Iter 7 subLoss 24575.6 multi -7.96 import weight 0.00
Epoch 206 Iter 8 subLoss 27135.9 multi 3.99 import weight 0.00
Epoch 206 Iter 9 subLoss 24836.4 multi -1.99 import weight 0.00
Epoch 206 Iter 10 subLoss 26890.7 multi 1.00 import weight 0.00
Epoch 206 Iter 11 subLoss 26203.6 multi 1.00 import weight 0.00
Epoch 206 Acc: 73.56 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2620 train Loss: 25795.2 test Loss: 4091.9
Epoch 207 Iter 0 subLoss 26103.6 multi 1.00 import weight 0.00
Epoch 207 Iter 1 subLoss 25615.2 multi -1.98 import weight 0.00
Epoch 207 Iter 2 subLoss 25929.3 multi -1.99 import weight 0.00
Epoch 207 Iter 3 subLoss 26244.0 multi 1.00 import weight 0.00
Epoch 207 Iter 4 subLoss 26668.4 multi 1.00 import weight 0.00
Epoch 207 Iter 5 subLoss 25570.2 multi -1.99 import weight 0.00
Epoch 207 Iter 6 subLoss 25616.1 multi 1.00 import weight 0.00
Epoch 207 Iter 7 subLoss 24958.4 multi 1.00 import weight 0.00
Epoch 207 Iter 8 subLoss 24957.6 multi 3.99 import weight 0.00
Epoch 207 Iter 9 subLoss 24634.7 multi 3.99 import weight 0.00
Epoch 207 Iter 10 subLoss 23816.0 multi -4.97 import weight 0.00
Epoch 207 Iter 11 subLoss 24484.3 multi 1.00 import weight 0.00
Epoch 207 Acc: 73.92 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2448 train Loss: 25080.6 test Loss: 3936.2
Epoch 208 Iter 0 subLoss 25810.7 multi 3.99 import weight 0.00
Epoch 208 Iter 1 subLoss 23713.0 multi -1.99 import weight 0.00
Epoch 208 Iter 2 subLoss 23579.7 multi 6.97 import weight 0.00
Epoch 208 Iter 3 subLoss 22676.0 multi 1.00 import weight 0.00
Epoch 208 Iter 4 subLoss 23115.2 multi 3.99 import weight 0.00
Epoch 208 Iter 5 subLoss 21424.4 multi 1.00 import weight 0.00
Epoch 208 Iter 6 subLoss 20532.0 multi 1.00 import weight 0.00
Epoch 208 Iter 7 subLoss 19745.0 multi -1.99 import weight 0.00
Epoch 208 Iter 8 subLoss 21911.1 multi 3.99 import weight 0.00
Epoch 208 Iter 9 subLoss 22009.5 multi 3.99 import weight 0.00
Epoch 208 Iter 10 subLoss 19591.1 multi -1.99 import weight 0.00
Epoch 208 Iter 11 subLoss 21516.9 multi 3.99 import weight 0.00
Epoch 208 Acc: 76.34 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 2151 train Loss: 21205.2 test Loss: 3355.3
Epoch 209 Iter 0 subLoss 20632.5 multi -13.93 import weight 0.00
Epoch 209 Iter 1 subLoss 22790.3 multi 1.00 import weight 0.00
Epoch 209 Iter 2 subLoss 24579.0 multi -4.97 import weight 0.00
Epoch 209 Iter 3 subLoss 26278.2 multi 1.00 import weight 0.00
Epoch 209 Iter 4 subLoss 24065.5 multi -1.98 import weight 0.00
Epoch 209 Iter 5 subLoss 25755.0 multi -4.97 import weight 0.00
Epoch 209 Iter 6 subLoss 52000.9 multi 1.00 import weight 0.00
Epoch 209 Iter 7 subLoss 27217.8 multi 3.98 import weight 0.00
Epoch 209 Iter 8 subLoss 22614.6 multi 3.98 import weight 0.00
Epoch 209 Iter 9 subLoss 22619.6 multi 6.97 import weight 0.00
Epoch 209 Iter 10 subLoss 22752.8 multi 3.99 import weight 0.00
Epoch 209 Iter 11 subLoss 21282.8 multi 1.00 import weight 0.00
Epoch 209 Acc: 75.99 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2128 train Loss: 22156.8 test Loss: 3460.7
Epoch 210 Iter 0 subLoss 20832.6 multi 9.96 import weight 0.00
Epoch 210 Iter 1 subLoss 21214.7 multi 1.00 import weight 0.00
Epoch 210 Iter 2 subLoss 20425.0 multi 1.00 import weight 0.00
Epoch 210 Iter 3 subLoss 20987.2 multi 1.00 import weight 0.00
Epoch 210 Iter 4 subLoss 21316.8 multi -1.98 import weight 0.00
Epoch 210 Iter 5 subLoss 20591.2 multi 3.99 import weight 0.00
Epoch 210 Iter 6 subLoss 19506.9 multi 1.00 import weight 0.00
Epoch 210 Iter 7 subLoss 19904.4 multi -1.99 import weight 0.00
Epoch 210 Iter 8 subLoss 20136.4 multi 3.98 import weight 0.00
Epoch 210 Iter 9 subLoss 18915.1 multi 1.00 import weight 0.00
Epoch 210 Iter 10 subLoss 19052.6 multi 1.00 import weight 0.00
Epoch 210 Iter 11 subLoss 18668.7 multi 1.00 import weight 0.00
Epoch 210 Acc: 77.00 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1866 train Loss: 19438.7 test Loss: 3023.6
Epoch 211 Iter 0 subLoss 18963.9 multi -1.99 import weight 0.00
Epoch 211 Iter 1 subLoss 19359.0 multi 3.99 import weight 0.00
Epoch 211 Iter 2 subLoss 18180.7 multi 6.97 import weight 0.00
Epoch 211 Iter 3 subLoss 16524.5 multi 1.00 import weight 0.00
Epoch 211 Iter 4 subLoss 14742.2 multi 1.00 import weight 0.00
Epoch 211 Iter 5 subLoss 12653.5 multi 3.99 import weight 0.00
Epoch 211 Iter 6 subLoss 8260.7 multi 6.97 import weight 0.00
Epoch 211 Iter 7 subLoss 7491.4 multi 6.97 import weight 0.00
Epoch 211 Iter 8 subLoss 7243.9 multi -1.99 import weight 0.00
Epoch 211 Iter 9 subLoss 7396.5 multi 12.94 import weight 0.00
Epoch 211 Iter 10 subLoss 6436.2 multi -1.99 import weight 0.00
Epoch 211 Iter 11 subLoss 6895.0 multi -1.99 import weight 0.00
Epoch 211 Acc: 96.67 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 689 train Loss: 6925.9 test Loss: 791.0
Epoch 212 Iter 0 subLoss 6285.3 multi 1.00 import weight 0.00
Epoch 212 Iter 1 subLoss 6991.2 multi -1.99 import weight 0.00
Epoch 212 Iter 2 subLoss 6386.5 multi -1.99 import weight 0.00
Epoch 212 Iter 3 subLoss 7717.0 multi -4.97 import weight 0.00
Epoch 212 Iter 4 subLoss 8851.8 multi 6.97 import weight 0.00
Epoch 212 Iter 5 subLoss 7383.7 multi -1.99 import weight 0.00
Epoch 212 Iter 6 subLoss 7668.6 multi -1.98 import weight 0.00
Epoch 212 Iter 7 subLoss 10760.2 multi -1.98 import weight 0.00
Epoch 212 Iter 8 subLoss 23869.4 multi 3.99 import weight 0.00
Epoch 212 Iter 9 subLoss 18594.8 multi 1.00 import weight 0.00
Epoch 212 Iter 10 subLoss 15026.6 multi -7.96 import weight 0.00
Epoch 212 Iter 11 subLoss 49343.1 multi 1.00 import weight 0.00
Epoch 212 Acc: 50.28 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4934 train Loss: 31032.2 test Loss: 7096.6
Epoch 213 Iter 0 subLoss 30620.8 multi 1.00 import weight 0.00
Epoch 213 Iter 1 subLoss 25819.7 multi 6.97 import weight 0.00
Epoch 213 Iter 2 subLoss 22269.6 multi 1.00 import weight 0.00
Epoch 213 Iter 3 subLoss 17976.2 multi -1.98 import weight 0.00
Epoch 213 Iter 4 subLoss 22718.3 multi 3.99 import weight 0.00
Epoch 213 Iter 5 subLoss 15704.9 multi -4.97 import weight 0.00
Epoch 213 Iter 6 subLoss 26430.0 multi 3.99 import weight 0.00
Epoch 213 Iter 7 subLoss 15424.6 multi 1.00 import weight 0.00
Epoch 213 Iter 8 subLoss 14914.8 multi 1.00 import weight 0.00
Epoch 213 Iter 9 subLoss 14318.3 multi 1.00 import weight 0.00
Epoch 213 Iter 10 subLoss 14255.2 multi -1.99 import weight 0.00
Epoch 213 Iter 11 subLoss 15800.5 multi 1.00 import weight 0.00
Epoch 213 Acc: 79.51 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1580 train Loss: 14776.5 test Loss: 2924.4
Epoch 214 Iter 0 subLoss 13449.0 multi 1.00 import weight 0.00
Epoch 214 Iter 1 subLoss 14088.1 multi 3.98 import weight 0.00
Epoch 214 Iter 2 subLoss 12340.0 multi -4.97 import weight 0.00
Epoch 214 Iter 3 subLoss 14076.6 multi -1.98 import weight 0.00
Epoch 214 Iter 4 subLoss 14721.9 multi 6.97 import weight 0.00
Epoch 214 Iter 5 subLoss 12654.2 multi 6.97 import weight 0.00
Epoch 214 Iter 6 subLoss 12279.0 multi -4.97 import weight 0.00
Epoch 214 Iter 7 subLoss 12293.3 multi -1.98 import weight 0.00
Epoch 214 Iter 8 subLoss 13170.1 multi 1.00 import weight 0.00
Epoch 214 Iter 9 subLoss 12678.7 multi 1.00 import weight 0.00
Epoch 214 Iter 10 subLoss 12758.4 multi 3.98 import weight 0.00
Epoch 214 Iter 11 subLoss 11830.8 multi 1.00 import weight 0.00
Epoch 214 Acc: 89.82 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1183 train Loss: 11718.8 test Loss: 1831.4
Epoch 215 Iter 0 subLoss 11797.2 multi -1.99 import weight 0.00
Epoch 215 Iter 1 subLoss 11306.7 multi -1.99 import weight 0.00
Epoch 215 Iter 2 subLoss 12632.0 multi 3.99 import weight 0.00
Epoch 215 Iter 3 subLoss 11483.4 multi -4.97 import weight 0.00
Epoch 215 Iter 4 subLoss 12035.8 multi 3.99 import weight 0.00
Epoch 215 Iter 5 subLoss 10672.7 multi 12.94 import weight 0.00
Epoch 215 Iter 6 subLoss 10158.1 multi 1.00 import weight 0.00
Epoch 215 Iter 7 subLoss 9336.1 multi -1.98 import weight 0.00
Epoch 215 Iter 8 subLoss 10063.1 multi 1.00 import weight 0.00
Epoch 215 Iter 9 subLoss 10432.6 multi 1.00 import weight 0.00
Epoch 215 Iter 10 subLoss 10227.9 multi 3.99 import weight 0.00
Epoch 215 Iter 11 subLoss 9045.4 multi -4.97 import weight 0.00
Epoch 215 Acc: 91.61 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 904 train Loss: 10267.8 test Loss: 1537.0
Epoch 216 Iter 0 subLoss 10185.8 multi 6.97 import weight 0.00
Epoch 216 Iter 1 subLoss 10029.7 multi 6.97 import weight 0.00
Epoch 216 Iter 2 subLoss 9007.9 multi 1.00 import weight 0.00
Epoch 216 Iter 3 subLoss 8946.6 multi 1.00 import weight 0.00
Epoch 216 Iter 4 subLoss 8645.2 multi -1.98 import weight 0.00
Epoch 216 Iter 5 subLoss 9112.2 multi 3.99 import weight 0.00
Epoch 216 Iter 6 subLoss 8421.2 multi 3.99 import weight 0.00
Epoch 216 Iter 7 subLoss 7333.9 multi 9.96 import weight 0.00
Epoch 216 Iter 8 subLoss 7170.6 multi 1.00 import weight 0.00
Epoch 216 Iter 9 subLoss 7730.5 multi 3.98 import weight 0.00
Epoch 216 Iter 10 subLoss 7211.2 multi 1.00 import weight 0.00
Epoch 216 Iter 11 subLoss 6668.5 multi 1.00 import weight 0.00
Epoch 216 Acc: 95.14 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 666 train Loss: 6931.5 test Loss: 901.1
Epoch 217 Iter 0 subLoss 6872.3 multi 18.91 import weight 1.00
Epoch 217 Iter 1 subLoss 6408.5 multi -1.98 import weight 0.00
Epoch 217 Iter 2 subLoss 7191.1 multi 6.97 import weight 0.00
Epoch 217 Iter 3 subLoss 6408.0 multi 1.00 import weight 0.00
Epoch 217 Iter 4 subLoss 6537.4 multi 6.97 import weight 0.00
Epoch 217 Iter 5 subLoss 6036.1 multi 3.98 import weight 0.00
Epoch 217 Iter 6 subLoss 5270.7 multi 1.00 import weight 0.00
Epoch 217 Iter 7 subLoss 5459.6 multi -1.99 import weight 0.00
Epoch 217 Iter 8 subLoss 5330.9 multi -7.96 import weight 0.00
Epoch 217 Iter 9 subLoss 6964.1 multi 3.99 import weight 0.00
Epoch 217 Iter 10 subLoss 5574.0 multi -4.97 import weight 0.00
Epoch 217 Iter 11 subLoss 6174.0 multi 1.00 import weight 0.00
Epoch 217 Acc: 96.30 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 617 train Loss: 5996.2 test Loss: 729.3
Epoch 218 Iter 0 subLoss 6190.3 multi 3.99 import weight 0.00
Epoch 218 Iter 1 subLoss 5400.2 multi 1.00 import weight 0.00
Epoch 218 Iter 2 subLoss 5515.2 multi 1.00 import weight 0.00
Epoch 218 Iter 3 subLoss 5016.0 multi -1.99 import weight 0.00
Epoch 218 Iter 4 subLoss 6094.4 multi 6.97 import weight 0.00
Epoch 218 Iter 5 subLoss 5752.9 multi -1.98 import weight 0.00
Epoch 218 Iter 6 subLoss 5591.3 multi 1.00 import weight 0.00
Epoch 218 Iter 7 subLoss 5007.1 multi 1.00 import weight 0.00
Epoch 218 Iter 8 subLoss 5481.6 multi -1.98 import weight 0.00
Epoch 218 Iter 9 subLoss 5113.2 multi -1.99 import weight 0.00
Epoch 218 Iter 10 subLoss 5633.5 multi 1.00 import weight 0.00
Epoch 218 Iter 11 subLoss 6248.7 multi 1.00 import weight 0.00
Epoch 218 Acc: 96.83 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 624 train Loss: 5747.6 test Loss: 636.2
Epoch 219 Iter 0 subLoss 6130.4 multi -1.99 import weight 0.00
Epoch 219 Iter 1 subLoss 5395.1 multi -1.99 import weight 0.00
Epoch 219 Iter 2 subLoss 5334.8 multi -4.97 import weight 0.00
Epoch 219 Iter 3 subLoss 6393.7 multi 3.98 import weight 0.00
Epoch 219 Iter 4 subLoss 6102.6 multi -7.96 import weight 0.00
Epoch 219 Iter 5 subLoss 5850.9 multi 3.99 import weight 0.00
Epoch 219 Iter 6 subLoss 6340.0 multi 1.00 import weight 0.00
Epoch 219 Iter 7 subLoss 6250.9 multi -1.98 import weight 0.00
Epoch 219 Iter 8 subLoss 6012.0 multi 3.99 import weight 0.00
Epoch 219 Iter 9 subLoss 5314.2 multi 1.00 import weight 0.00
Epoch 219 Iter 10 subLoss 5619.4 multi 9.96 import weight 0.00
Epoch 219 Iter 11 subLoss 5649.2 multi -4.97 import weight 0.00
Epoch 219 Acc: 96.54 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 564 train Loss: 5994.3 test Loss: 689.2
Epoch 220 Iter 0 subLoss 5469.1 multi 3.98 import weight 0.00
Epoch 220 Iter 1 subLoss 5798.0 multi 3.99 import weight 0.00
Epoch 220 Iter 2 subLoss 5013.1 multi -1.98 import weight 0.00
Epoch 220 Iter 3 subLoss 5184.6 multi 9.96 import weight 0.00
Epoch 220 Iter 4 subLoss 5028.9 multi -1.98 import weight 0.00
Epoch 220 Iter 5 subLoss 5159.7 multi 1.00 import weight 0.00
Epoch 220 Iter 6 subLoss 5606.4 multi -7.96 import weight 0.00
Epoch 220 Iter 7 subLoss 5620.4 multi -7.96 import weight 0.00
Epoch 220 Iter 8 subLoss 8666.3 multi -4.97 import weight 0.00
Epoch 220 Iter 9 subLoss 30897.8 multi 1.00 import weight 0.00
Epoch 220 Iter 10 subLoss 10074.5 multi -1.99 import weight 0.00
Epoch 220 Iter 11 subLoss 14016.2 multi 1.00 import weight 0.00
Epoch 220 Acc: 92.57 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1401 train Loss: 10092.8 test Loss: 1261.0
Epoch 221 Iter 0 subLoss 8793.7 multi 1.00 import weight 0.00
Epoch 221 Iter 1 subLoss 8409.2 multi 1.00 import weight 0.00
Epoch 221 Iter 2 subLoss 8295.6 multi -1.99 import weight 0.00
Epoch 221 Iter 3 subLoss 9673.7 multi 3.98 import weight 0.00
Epoch 221 Iter 4 subLoss 5866.0 multi -4.97 import weight 0.00
Epoch 221 Iter 5 subLoss 6036.5 multi 6.97 import weight 0.00
Epoch 221 Iter 6 subLoss 6006.0 multi 6.97 import weight 0.00
Epoch 221 Iter 7 subLoss 5180.7 multi 12.94 import weight 0.00
Epoch 221 Iter 8 subLoss 5502.9 multi 3.98 import weight 0.00
Epoch 221 Iter 9 subLoss 5366.6 multi 3.98 import weight 0.00
Epoch 221 Iter 10 subLoss 4878.6 multi -1.99 import weight 0.00
Epoch 221 Iter 11 subLoss 4910.4 multi 6.97 import weight 0.00
Epoch 221 Acc: 97.12 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 491 train Loss: 4999.4 test Loss: 533.2
Epoch 222 Iter 0 subLoss 5064.1 multi 3.99 import weight 0.00
Epoch 222 Iter 1 subLoss 5515.5 multi 1.00 import weight 0.00
Epoch 222 Iter 2 subLoss 4172.7 multi 1.00 import weight 0.00
Epoch 222 Iter 3 subLoss 4538.1 multi -1.99 import weight 0.00
Epoch 222 Iter 4 subLoss 4575.9 multi 1.00 import weight 0.00
Epoch 222 Iter 5 subLoss 4943.3 multi 6.97 import weight 0.00
Epoch 222 Iter 6 subLoss 4864.2 multi -1.98 import weight 0.00
Epoch 222 Iter 7 subLoss 4927.8 multi -7.96 import weight 0.00
Epoch 222 Iter 8 subLoss 6640.3 multi -1.99 import weight 0.00
Epoch 222 Iter 9 subLoss 11250.8 multi 6.97 import weight 0.00
Epoch 222 Iter 10 subLoss 39404.1 multi 1.00 import weight 0.00
Epoch 222 Iter 11 subLoss 9229.5 multi -1.98 import weight 0.00
Epoch 222 Acc: 81.18 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 922 train Loss: 15574.8 test Loss: 3120.1
Epoch 223 Iter 0 subLoss 15399.4 multi 3.99 import weight 0.00
Epoch 223 Iter 1 subLoss 6661.5 multi 3.98 import weight 0.00
Epoch 223 Iter 2 subLoss 6426.5 multi -1.98 import weight 0.00
Epoch 223 Iter 3 subLoss 6589.3 multi 6.97 import weight 0.00
Epoch 223 Iter 4 subLoss 5889.7 multi 1.00 import weight 0.00
Epoch 223 Iter 5 subLoss 4848.2 multi -1.98 import weight 0.00
Epoch 223 Iter 6 subLoss 6086.8 multi 1.00 import weight 0.00
Epoch 223 Iter 7 subLoss 5093.2 multi 3.99 import weight 0.00
Epoch 223 Iter 8 subLoss 5310.3 multi 3.98 import weight 0.00
Epoch 223 Iter 9 subLoss 4736.0 multi -1.98 import weight 0.00
Epoch 223 Iter 10 subLoss 4818.3 multi 1.00 import weight 0.00
Epoch 223 Iter 11 subLoss 5599.7 multi 3.99 import weight 0.00
Epoch 223 Acc: 97.33 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 559 train Loss: 5277.1 test Loss: 554.8
Epoch 224 Iter 0 subLoss 5288.3 multi -4.97 import weight 0.00
Epoch 224 Iter 1 subLoss 5446.3 multi 1.00 import weight 0.00
Epoch 224 Iter 2 subLoss 5375.2 multi -1.99 import weight 0.00
Epoch 224 Iter 3 subLoss 5217.6 multi 1.00 import weight 0.00
Epoch 224 Iter 4 subLoss 5113.3 multi 1.00 import weight 0.00
Epoch 224 Iter 5 subLoss 5498.2 multi -1.98 import weight 0.00
Epoch 224 Iter 6 subLoss 5465.4 multi 6.97 import weight 0.00
Epoch 224 Iter 7 subLoss 5267.0 multi 1.00 import weight 0.00
Epoch 224 Iter 8 subLoss 4966.8 multi -4.97 import weight 0.00
Epoch 224 Iter 9 subLoss 5262.0 multi 3.98 import weight 0.00
Epoch 224 Iter 10 subLoss 5154.6 multi 3.99 import weight 0.00
Epoch 224 Iter 11 subLoss 5068.5 multi 6.97 import weight 0.00
Epoch 224 Acc: 97.33 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 506 train Loss: 4992.9 test Loss: 513.0
Epoch 225 Iter 0 subLoss 4801.0 multi 1.00 import weight 0.00
Epoch 225 Iter 1 subLoss 5050.7 multi -1.99 import weight 0.00
Epoch 225 Iter 2 subLoss 5053.3 multi 1.00 import weight 0.00
Epoch 225 Iter 3 subLoss 4558.2 multi 1.00 import weight 0.00
Epoch 225 Iter 4 subLoss 4675.0 multi -1.99 import weight 0.00
Epoch 225 Iter 5 subLoss 5019.4 multi 1.00 import weight 0.00
Epoch 225 Iter 6 subLoss 5337.6 multi -1.99 import weight 0.00
Epoch 225 Iter 7 subLoss 4454.2 multi 1.00 import weight 0.00
Epoch 225 Iter 8 subLoss 4586.1 multi -1.98 import weight 0.00
Epoch 225 Iter 9 subLoss 4547.1 multi -7.96 import weight 0.00
Epoch 225 Iter 10 subLoss 5138.9 multi 1.00 import weight 0.00
Epoch 225 Iter 11 subLoss 4885.6 multi 1.00 import weight 0.00
Epoch 225 Acc: 97.22 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 488 train Loss: 5048.7 test Loss: 545.4
Epoch 226 Iter 0 subLoss 4924.2 multi -4.97 import weight 0.00
Epoch 226 Iter 1 subLoss 5404.4 multi 1.00 import weight 0.00
Epoch 226 Iter 2 subLoss 5348.8 multi -7.96 import weight 0.00
Epoch 226 Iter 3 subLoss 6484.2 multi -1.98 import weight 0.00
Epoch 226 Iter 4 subLoss 6576.3 multi 1.00 import weight 0.00
Epoch 226 Iter 5 subLoss 7200.3 multi -7.96 import weight 0.00
Epoch 226 Iter 6 subLoss 10998.1 multi 1.00 import weight 0.00
Epoch 226 Iter 7 subLoss 8994.3 multi 3.98 import weight 0.00
Epoch 226 Iter 8 subLoss 6756.0 multi 15.93 import weight 0.00
Epoch 226 Iter 9 subLoss 6057.6 multi 9.96 import weight 0.00
Epoch 226 Iter 10 subLoss 5159.4 multi 6.97 import weight 0.00
Epoch 226 Iter 11 subLoss 4627.6 multi 1.00 import weight 0.00
Epoch 226 Acc: 97.30 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 462 train Loss: 4835.1 test Loss: 516.2
Epoch 227 Iter 0 subLoss 4518.1 multi -1.99 import weight 0.00
Epoch 227 Iter 1 subLoss 5177.6 multi -7.96 import weight 0.00
Epoch 227 Iter 2 subLoss 5101.8 multi -1.98 import weight 0.00
Epoch 227 Iter 3 subLoss 5065.1 multi 3.99 import weight 0.00
Epoch 227 Iter 4 subLoss 5701.9 multi 1.00 import weight 0.00
Epoch 227 Iter 5 subLoss 5270.0 multi 6.97 import weight 0.00
Epoch 227 Iter 6 subLoss 4294.3 multi -1.99 import weight 0.00
Epoch 227 Iter 7 subLoss 4547.0 multi -4.97 import weight 0.00
Epoch 227 Iter 8 subLoss 4994.6 multi 1.00 import weight 0.00
Epoch 227 Iter 9 subLoss 5090.7 multi 6.97 import weight 0.00
Epoch 227 Iter 10 subLoss 4300.9 multi -1.99 import weight 0.00
Epoch 227 Iter 11 subLoss 4879.1 multi -1.98 import weight 0.00
Epoch 227 Acc: 97.24 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 487 train Loss: 4884.2 test Loss: 537.8
Epoch 228 Iter 0 subLoss 5034.7 multi 1.00 import weight 0.00
Epoch 228 Iter 1 subLoss 4979.7 multi -1.99 import weight 0.00
Epoch 228 Iter 2 subLoss 4824.7 multi 3.98 import weight 0.00
Epoch 228 Iter 3 subLoss 5123.9 multi -1.98 import weight 0.00
Epoch 228 Iter 4 subLoss 4711.8 multi 1.00 import weight 0.00
Epoch 228 Iter 5 subLoss 5004.4 multi 1.00 import weight 0.00
Epoch 228 Iter 6 subLoss 4364.8 multi 6.97 import weight 0.00
Epoch 228 Iter 7 subLoss 4758.5 multi 3.99 import weight 0.00
Epoch 228 Iter 8 subLoss 4992.3 multi 3.98 import weight 0.00
Epoch 228 Iter 9 subLoss 4858.8 multi 1.00 import weight 0.00
Epoch 228 Iter 10 subLoss 3877.9 multi 1.00 import weight 0.00
Epoch 228 Iter 11 subLoss 4226.9 multi -1.99 import weight 0.00
Epoch 228 Acc: 97.30 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 422 train Loss: 4542.4 test Loss: 496.3
Epoch 229 Iter 0 subLoss 4443.1 multi -1.99 import weight 0.00
Epoch 229 Iter 1 subLoss 4392.8 multi -10.94 import weight 0.00
Epoch 229 Iter 2 subLoss 4917.3 multi 9.96 import weight 0.00
Epoch 229 Iter 3 subLoss 4622.2 multi 3.99 import weight 0.00
Epoch 229 Iter 4 subLoss 4153.7 multi -1.99 import weight 0.00
Epoch 229 Iter 5 subLoss 4765.9 multi -1.98 import weight 0.00
Epoch 229 Iter 6 subLoss 4768.4 multi 1.00 import weight 0.00
Epoch 229 Iter 7 subLoss 4917.7 multi 12.94 import weight 0.00
Epoch 229 Iter 8 subLoss 4594.3 multi -1.98 import weight 0.00
Epoch 229 Iter 9 subLoss 4698.3 multi 3.99 import weight 0.00
Epoch 229 Iter 10 subLoss 4282.2 multi 3.99 import weight 0.00
Epoch 229 Iter 11 subLoss 4645.8 multi 9.96 import weight 0.00
Epoch 229 Acc: 97.31 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 464 train Loss: 4557.9 test Loss: 476.5
Epoch 230 Iter 0 subLoss 4030.8 multi 1.00 import weight 0.00
Epoch 230 Iter 1 subLoss 4307.0 multi 1.00 import weight 0.00
Epoch 230 Iter 2 subLoss 4071.2 multi 1.00 import weight 0.00
Epoch 230 Iter 3 subLoss 4376.2 multi -4.97 import weight 0.00
Epoch 230 Iter 4 subLoss 4620.0 multi 6.97 import weight 0.00
Epoch 230 Iter 5 subLoss 3706.5 multi 1.00 import weight 0.00
Epoch 230 Iter 6 subLoss 4392.1 multi -7.96 import weight 0.00
Epoch 230 Iter 7 subLoss 5382.7 multi -4.97 import weight 0.00
Epoch 230 Iter 8 subLoss 11359.3 multi -4.97 import weight 0.00
Epoch 230 Iter 9 subLoss 115355.5 multi 1.00 import weight 0.00
Epoch 230 Iter 10 subLoss 12734.9 multi 3.99 import weight 0.00
Epoch 230 Iter 11 subLoss 7184.3 multi -1.98 import weight 0.00
Epoch 230 Acc: 95.87 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 718 train Loss: 7939.8 test Loss: 764.5
Epoch 231 Iter 0 subLoss 7939.7 multi 3.99 import weight 0.00
Epoch 231 Iter 1 subLoss 5428.8 multi -1.98 import weight 0.00
Epoch 231 Iter 2 subLoss 5385.0 multi -1.99 import weight 0.00
Epoch 231 Iter 3 subLoss 6038.1 multi 9.96 import weight 0.00
Epoch 231 Iter 4 subLoss 4981.4 multi 1.00 import weight 0.00
Epoch 231 Iter 5 subLoss 5215.4 multi 3.99 import weight 0.00
Epoch 231 Iter 6 subLoss 5006.2 multi 1.00 import weight 0.00
Epoch 231 Iter 7 subLoss 5081.1 multi -7.96 import weight 0.00
Epoch 231 Iter 8 subLoss 5092.5 multi 6.97 import weight 0.00
Epoch 231 Iter 9 subLoss 4991.2 multi 3.99 import weight 0.00
Epoch 231 Iter 10 subLoss 4728.5 multi 3.98 import weight 0.00
Epoch 231 Iter 11 subLoss 4554.0 multi -1.98 import weight 0.00
Epoch 231 Acc: 97.33 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 455 train Loss: 4694.1 test Loss: 502.2
Epoch 232 Iter 0 subLoss 4573.6 multi 3.98 import weight 0.00
Epoch 232 Iter 1 subLoss 4224.7 multi 1.00 import weight 0.00
Epoch 232 Iter 2 subLoss 4583.6 multi -1.99 import weight 0.00
Epoch 232 Iter 3 subLoss 4450.8 multi 1.00 import weight 0.00
Epoch 232 Iter 4 subLoss 4653.2 multi -7.96 import weight 0.00
Epoch 232 Iter 5 subLoss 5259.7 multi 1.00 import weight 0.00
Epoch 232 Iter 6 subLoss 5014.1 multi -1.99 import weight 0.00
Epoch 232 Iter 7 subLoss 4678.3 multi 1.00 import weight 0.00
Epoch 232 Iter 8 subLoss 4810.5 multi 1.00 import weight 0.00
Epoch 232 Iter 9 subLoss 4728.1 multi 6.97 import weight 0.00
Epoch 232 Iter 10 subLoss 5055.6 multi 3.98 import weight 0.00
Epoch 232 Iter 11 subLoss 4635.1 multi -7.96 import weight 0.00
Epoch 232 Acc: 97.37 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 463 train Loss: 4739.3 test Loss: 499.6
Epoch 233 Iter 0 subLoss 4146.7 multi 3.99 import weight 0.00
Epoch 233 Iter 1 subLoss 4273.2 multi 1.00 import weight 0.00
Epoch 233 Iter 2 subLoss 4453.6 multi 3.98 import weight 0.00
Epoch 233 Iter 3 subLoss 4669.9 multi -1.98 import weight 0.00
Epoch 233 Iter 4 subLoss 4005.1 multi 1.00 import weight 0.00
Epoch 233 Iter 5 subLoss 4611.4 multi -1.99 import weight 0.00
Epoch 233 Iter 6 subLoss 4185.1 multi -1.99 import weight 0.00
Epoch 233 Iter 7 subLoss 5083.4 multi -4.97 import weight 0.00
Epoch 233 Iter 8 subLoss 3972.5 multi 1.00 import weight 0.00
Epoch 233 Iter 9 subLoss 4647.1 multi 9.96 import weight 0.00
Epoch 233 Iter 10 subLoss 4136.9 multi -1.99 import weight 0.00
Epoch 233 Iter 11 subLoss 5266.5 multi 6.97 import weight 0.00
Epoch 233 Acc: 97.47 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 526 train Loss: 4485.4 test Loss: 457.4
Epoch 234 Iter 0 subLoss 4979.0 multi 1.00 import weight 0.00
Epoch 234 Iter 1 subLoss 5122.6 multi 1.00 import weight 0.00
Epoch 234 Iter 2 subLoss 4240.1 multi 1.00 import weight 0.00
Epoch 234 Iter 3 subLoss 3880.1 multi -1.99 import weight 0.00
Epoch 234 Iter 4 subLoss 4150.0 multi 3.98 import weight 0.00
Epoch 234 Iter 5 subLoss 4652.6 multi -7.96 import weight 0.00
Epoch 234 Iter 6 subLoss 4395.7 multi -4.97 import weight 0.00
Epoch 234 Iter 7 subLoss 4577.0 multi 6.97 import weight 0.00
Epoch 234 Iter 8 subLoss 4062.7 multi 1.00 import weight 0.00
Epoch 234 Iter 9 subLoss 4421.5 multi -4.97 import weight 0.00
Epoch 234 Iter 10 subLoss 4551.0 multi 1.00 import weight 0.00
Epoch 234 Iter 11 subLoss 4479.3 multi 3.99 import weight 0.00
Epoch 234 Acc: 97.47 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 447 train Loss: 4422.5 test Loss: 465.7
Epoch 235 Iter 0 subLoss 4383.8 multi 6.97 import weight 0.00
Epoch 235 Iter 1 subLoss 4566.4 multi -4.97 import weight 0.00
Epoch 235 Iter 2 subLoss 4004.9 multi 3.98 import weight 0.00
Epoch 235 Iter 3 subLoss 4433.9 multi 1.00 import weight 0.00
Epoch 235 Iter 4 subLoss 4499.8 multi 1.00 import weight 0.00
Epoch 235 Iter 5 subLoss 4044.0 multi -1.99 import weight 0.00
Epoch 235 Iter 6 subLoss 4827.8 multi 3.99 import weight 0.00
Epoch 235 Iter 7 subLoss 3874.0 multi 3.99 import weight 0.00
Epoch 235 Iter 8 subLoss 4052.0 multi -1.99 import weight 0.00
Epoch 235 Iter 9 subLoss 4121.0 multi -1.98 import weight 0.00
Epoch 235 Iter 10 subLoss 4551.3 multi 3.99 import weight 0.00
Epoch 235 Iter 11 subLoss 4151.7 multi -4.97 import weight 0.00
Epoch 235 Acc: 97.31 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 415 train Loss: 4493.8 test Loss: 482.0
Epoch 236 Iter 0 subLoss 4212.9 multi 3.99 import weight 0.00
Epoch 236 Iter 1 subLoss 3945.7 multi 3.99 import weight 0.00
Epoch 236 Iter 2 subLoss 4029.0 multi -1.99 import weight 0.00
Epoch 236 Iter 3 subLoss 4629.8 multi 6.97 import weight 0.00
Epoch 236 Iter 4 subLoss 4290.5 multi -1.98 import weight 0.00
Epoch 236 Iter 5 subLoss 4356.5 multi 1.00 import weight 0.00
Epoch 236 Iter 6 subLoss 3811.8 multi 1.00 import weight 0.00
Epoch 236 Iter 7 subLoss 4818.6 multi 3.98 import weight 0.00
Epoch 236 Iter 8 subLoss 4055.1 multi 1.00 import weight 0.00
Epoch 236 Iter 9 subLoss 4297.0 multi 1.00 import weight 0.00
Epoch 236 Iter 10 subLoss 4348.0 multi -4.97 import weight 0.00
Epoch 236 Iter 11 subLoss 4076.0 multi 1.00 import weight 0.00
Epoch 236 Acc: 97.47 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 407 train Loss: 4295.2 test Loss: 449.6
Epoch 237 Iter 0 subLoss 4754.5 multi 6.97 import weight 0.00
Epoch 237 Iter 1 subLoss 3643.6 multi 1.00 import weight 0.00
Epoch 237 Iter 2 subLoss 4393.1 multi -4.97 import weight 0.00
Epoch 237 Iter 3 subLoss 4456.7 multi 6.97 import weight 0.00
Epoch 237 Iter 4 subLoss 4214.0 multi 6.97 import weight 0.00
Epoch 237 Iter 5 subLoss 3912.9 multi 1.00 import weight 0.00
Epoch 237 Iter 6 subLoss 4100.6 multi 6.97 import weight 0.00
Epoch 237 Iter 7 subLoss 4124.3 multi 1.00 import weight 0.00
Epoch 237 Iter 8 subLoss 3571.3 multi 1.00 import weight 0.00
Epoch 237 Iter 9 subLoss 4025.6 multi 1.00 import weight 0.00
Epoch 237 Iter 10 subLoss 3724.9 multi 1.00 import weight 0.00
Epoch 237 Iter 11 subLoss 3729.7 multi 3.99 import weight 0.00
Epoch 237 Acc: 97.90 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 372 train Loss: 3974.6 test Loss: 410.7
Epoch 238 Iter 0 subLoss 4187.9 multi 1.00 import weight 0.00
Epoch 238 Iter 1 subLoss 3795.8 multi 1.00 import weight 0.00
Epoch 238 Iter 2 subLoss 3765.7 multi 1.00 import weight 0.00
Epoch 238 Iter 3 subLoss 4047.5 multi 1.00 import weight 0.00
Epoch 238 Iter 4 subLoss 3695.6 multi 1.00 import weight 0.00
Epoch 238 Iter 5 subLoss 3904.2 multi 1.00 import weight 0.00
Epoch 238 Iter 6 subLoss 4090.6 multi -1.99 import weight 0.00
Epoch 238 Iter 7 subLoss 3726.6 multi 6.97 import weight 0.00
Epoch 238 Iter 8 subLoss 3974.7 multi 3.99 import weight 0.00
Epoch 238 Iter 9 subLoss 3804.4 multi -1.99 import weight 0.00
Epoch 238 Iter 10 subLoss 3778.0 multi -1.99 import weight 0.00
Epoch 238 Iter 11 subLoss 3327.1 multi 1.00 import weight 0.00
Epoch 238 Acc: 97.68 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 332 train Loss: 3946.9 test Loss: 401.8
Epoch 239 Iter 0 subLoss 3983.6 multi -4.97 import weight 0.00
Epoch 239 Iter 1 subLoss 3727.8 multi 9.96 import weight 0.00
Epoch 239 Iter 2 subLoss 3795.9 multi 3.99 import weight 0.00
Epoch 239 Iter 3 subLoss 3755.4 multi 1.00 import weight 0.00
Epoch 239 Iter 4 subLoss 3656.7 multi -1.99 import weight 0.00
Epoch 239 Iter 5 subLoss 3669.0 multi -1.99 import weight 0.00
Epoch 239 Iter 6 subLoss 3908.2 multi 3.99 import weight 0.00
Epoch 239 Iter 7 subLoss 3732.4 multi -7.96 import weight 0.00
Epoch 239 Iter 8 subLoss 4193.1 multi -4.97 import weight 0.00
Epoch 239 Iter 9 subLoss 5469.8 multi 9.96 import weight 0.00
Epoch 239 Iter 10 subLoss 7876.2 multi 1.00 import weight 0.00
Epoch 239 Iter 11 subLoss 6064.9 multi -10.94 import weight 0.00
Epoch 239 Acc: 79.30 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -10.94 Pidx 606 train Loss: 37745.8 test Loss: 7544.5
Epoch 240 Iter 0 subLoss 38251.7 multi 3.99 import weight 0.00
Epoch 240 Iter 1 subLoss 7099.2 multi -4.97 import weight 0.00
Epoch 240 Iter 2 subLoss 9029.6 multi 1.00 import weight 0.00
Epoch 240 Iter 3 subLoss 8086.3 multi 9.96 import weight 0.00
Epoch 240 Iter 4 subLoss 5514.7 multi 3.99 import weight 0.00
Epoch 240 Iter 5 subLoss 5993.8 multi -4.97 import weight 0.00
Epoch 240 Iter 6 subLoss 5566.1 multi 6.97 import weight 0.00
Epoch 240 Iter 7 subLoss 5035.5 multi 3.99 import weight 0.00
Epoch 240 Iter 8 subLoss 4762.0 multi 1.00 import weight 0.00
Epoch 240 Iter 9 subLoss 5086.1 multi -1.99 import weight 0.00
Epoch 240 Iter 10 subLoss 4686.4 multi -4.97 import weight 0.00
Epoch 240 Iter 11 subLoss 4823.3 multi 3.99 import weight 0.00
Epoch 240 Acc: 97.39 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 482 train Loss: 5095.7 test Loss: 519.9
Epoch 241 Iter 0 subLoss 5633.0 multi 1.00 import weight 0.00
Epoch 241 Iter 1 subLoss 4878.7 multi 1.00 import weight 0.00
Epoch 241 Iter 2 subLoss 5336.4 multi 1.00 import weight 0.00
Epoch 241 Iter 3 subLoss 4928.9 multi -7.96 import weight 0.00
Epoch 241 Iter 4 subLoss 4749.2 multi -4.97 import weight 0.00
Epoch 241 Iter 5 subLoss 5217.3 multi 6.97 import weight 0.00
Epoch 241 Iter 6 subLoss 4762.3 multi 3.99 import weight 0.00
Epoch 241 Iter 7 subLoss 5219.5 multi 9.96 import weight 0.00
Epoch 241 Iter 8 subLoss 4219.2 multi 9.96 import weight 0.00
Epoch 241 Iter 9 subLoss 4350.4 multi 1.00 import weight 0.00
Epoch 241 Iter 10 subLoss 4329.0 multi -1.99 import weight 0.00
Epoch 241 Iter 11 subLoss 5086.8 multi 1.00 import weight 0.00
Epoch 241 Acc: 97.45 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 508 train Loss: 4347.6 test Loss: 467.7
Epoch 242 Iter 0 subLoss 4426.0 multi -1.98 import weight 0.00
Epoch 242 Iter 1 subLoss 3872.5 multi 6.97 import weight 0.00
Epoch 242 Iter 2 subLoss 5205.1 multi -1.99 import weight 0.00
Epoch 242 Iter 3 subLoss 4196.9 multi -1.98 import weight 0.00
Epoch 242 Iter 4 subLoss 4196.6 multi 1.00 import weight 0.00
Epoch 242 Iter 5 subLoss 4220.3 multi -4.97 import weight 0.00
Epoch 242 Iter 6 subLoss 3863.5 multi 1.00 import weight 0.00
Epoch 242 Iter 7 subLoss 4602.7 multi -1.98 import weight 0.00
Epoch 242 Iter 8 subLoss 4795.1 multi 1.00 import weight 0.00
Epoch 242 Iter 9 subLoss 4574.6 multi 6.97 import weight 0.00
Epoch 242 Iter 10 subLoss 4178.2 multi 3.99 import weight 0.00
Epoch 242 Iter 11 subLoss 4320.0 multi 1.00 import weight 0.00
Epoch 242 Acc: 97.53 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 432 train Loss: 4260.5 test Loss: 452.7
Epoch 243 Iter 0 subLoss 3798.4 multi 6.97 import weight 0.00
Epoch 243 Iter 1 subLoss 4014.1 multi -4.97 import weight 0.00
Epoch 243 Iter 2 subLoss 4166.6 multi -4.97 import weight 0.00
Epoch 243 Iter 3 subLoss 4053.3 multi 1.00 import weight 0.00
Epoch 243 Iter 4 subLoss 3962.5 multi -1.99 import weight 0.00
Epoch 243 Iter 5 subLoss 4067.2 multi -4.97 import weight 0.00
Epoch 243 Iter 6 subLoss 4967.1 multi -1.98 import weight 0.00
Epoch 243 Iter 7 subLoss 4866.7 multi -1.99 import weight 0.00
Epoch 243 Iter 8 subLoss 4590.1 multi -1.99 import weight 0.00
Epoch 243 Iter 9 subLoss 5594.4 multi 6.97 import weight 0.00
Epoch 243 Iter 10 subLoss 4391.0 multi -1.98 import weight 0.00
Epoch 243 Iter 11 subLoss 4659.8 multi -4.97 import weight 0.00
Epoch 243 Acc: 96.85 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 465 train Loss: 5198.9 test Loss: 572.3
Epoch 244 Iter 0 subLoss 4697.1 multi 3.98 import weight 0.00
Epoch 244 Iter 1 subLoss 4884.9 multi -1.99 import weight 0.00
Epoch 244 Iter 2 subLoss 3877.1 multi 6.97 import weight 0.00
Epoch 244 Iter 3 subLoss 4406.1 multi -13.93 import weight 0.00
Epoch 244 Iter 4 subLoss 5541.9 multi -1.99 import weight 0.00
Epoch 244 Iter 5 subLoss 7633.5 multi 1.00 import weight 0.00
Epoch 244 Iter 6 subLoss 5515.5 multi 6.97 import weight 0.00
Epoch 244 Iter 7 subLoss 4428.7 multi 1.00 import weight 0.00
Epoch 244 Iter 8 subLoss 4513.5 multi 1.00 import weight 0.00
Epoch 244 Iter 9 subLoss 4375.8 multi -1.99 import weight 0.00
Epoch 244 Iter 10 subLoss 4666.5 multi -4.97 import weight 0.00
Epoch 244 Iter 11 subLoss 5007.8 multi 1.00 import weight 0.00
Epoch 244 Acc: 97.08 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 500 train Loss: 4912.8 test Loss: 526.9
Epoch 245 Iter 0 subLoss 5247.6 multi 1.00 import weight 0.00
Epoch 245 Iter 1 subLoss 5318.3 multi 6.97 import weight 0.00
Epoch 245 Iter 2 subLoss 4090.2 multi 1.00 import weight 0.00
Epoch 245 Iter 3 subLoss 4204.0 multi -7.96 import weight 0.00
Epoch 245 Iter 4 subLoss 4716.6 multi 3.99 import weight 0.00
Epoch 245 Iter 5 subLoss 4544.1 multi -1.99 import weight 0.00
Epoch 245 Iter 6 subLoss 4702.9 multi -7.96 import weight 0.00
Epoch 245 Iter 7 subLoss 5088.8 multi 3.99 import weight 0.00
Epoch 245 Iter 8 subLoss 4107.7 multi 3.99 import weight 0.00
Epoch 245 Iter 9 subLoss 4048.5 multi 3.98 import weight 0.00
Epoch 245 Iter 10 subLoss 4442.0 multi -1.98 import weight 0.00
Epoch 245 Iter 11 subLoss 4369.9 multi 3.99 import weight 0.00
Epoch 245 Acc: 97.33 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 436 train Loss: 4426.8 test Loss: 466.2
Epoch 246 Iter 0 subLoss 4134.6 multi -4.97 import weight 0.00
Epoch 246 Iter 1 subLoss 4339.1 multi 1.00 import weight 0.00
Epoch 246 Iter 2 subLoss 4413.6 multi 3.98 import weight 0.00
Epoch 246 Iter 3 subLoss 4393.6 multi 1.00 import weight 0.00
Epoch 246 Iter 4 subLoss 4638.9 multi -7.96 import weight 0.00
Epoch 246 Iter 5 subLoss 4531.2 multi 1.00 import weight 0.00
Epoch 246 Iter 6 subLoss 4718.2 multi 3.98 import weight 0.00
Epoch 246 Iter 7 subLoss 4659.6 multi -1.98 import weight 0.00
Epoch 246 Iter 8 subLoss 4607.4 multi -1.99 import weight 0.00
Epoch 246 Iter 9 subLoss 3990.4 multi 1.00 import weight 0.00
Epoch 246 Iter 10 subLoss 4522.1 multi 3.99 import weight 0.00
Epoch 246 Iter 11 subLoss 4332.1 multi 3.99 import weight 0.00
Epoch 246 Acc: 97.43 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 433 train Loss: 4451.4 test Loss: 459.6
Epoch 247 Iter 0 subLoss 4173.7 multi 3.98 import weight 0.00
Epoch 247 Iter 1 subLoss 4440.8 multi 1.00 import weight 0.00
Epoch 247 Iter 2 subLoss 4353.8 multi 3.98 import weight 0.00
Epoch 247 Iter 3 subLoss 4108.7 multi 6.97 import weight 0.00
Epoch 247 Iter 4 subLoss 4107.1 multi 9.96 import weight 0.00
Epoch 247 Iter 5 subLoss 4429.3 multi 1.00 import weight 0.00
Epoch 247 Iter 6 subLoss 4286.0 multi 3.98 import weight 0.00
Epoch 247 Iter 7 subLoss 4149.6 multi 3.99 import weight 0.00
Epoch 247 Iter 8 subLoss 4020.3 multi 1.00 import weight 0.00
Epoch 247 Iter 9 subLoss 4131.8 multi -1.99 import weight 0.00
Epoch 247 Iter 10 subLoss 4166.6 multi -1.98 import weight 0.00
Epoch 247 Iter 11 subLoss 4076.6 multi 1.00 import weight 0.00
Epoch 247 Acc: 97.66 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 407 train Loss: 4090.6 test Loss: 419.3
Epoch 248 Iter 0 subLoss 3872.6 multi 9.96 import weight 0.00
Epoch 248 Iter 1 subLoss 3278.7 multi 1.00 import weight 0.00
Epoch 248 Iter 2 subLoss 4130.0 multi 1.00 import weight 0.00
Epoch 248 Iter 3 subLoss 3427.1 multi 1.00 import weight 0.00
Epoch 248 Iter 4 subLoss 4119.8 multi -10.94 import weight 0.00
Epoch 248 Iter 5 subLoss 3994.3 multi 3.98 import weight 0.00
Epoch 248 Iter 6 subLoss 3930.2 multi 1.00 import weight 0.00
Epoch 248 Iter 7 subLoss 3845.4 multi 1.00 import weight 0.00
Epoch 248 Iter 8 subLoss 3891.5 multi -1.99 import weight 0.00
Epoch 248 Iter 9 subLoss 3946.5 multi 3.98 import weight 0.00
Epoch 248 Iter 10 subLoss 4124.1 multi 1.00 import weight 0.00
Epoch 248 Iter 11 subLoss 3924.3 multi -1.99 import weight 0.00
Epoch 248 Acc: 97.51 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 392 train Loss: 3969.2 test Loss: 413.7
Epoch 249 Iter 0 subLoss 3485.3 multi 1.00 import weight 0.00
Epoch 249 Iter 1 subLoss 3343.4 multi 1.00 import weight 0.00
Epoch 249 Iter 2 subLoss 4038.9 multi -4.97 import weight 0.00
Epoch 249 Iter 3 subLoss 3952.9 multi -4.97 import weight 0.00
Epoch 249 Iter 4 subLoss 4182.3 multi -1.99 import weight 0.00
Epoch 249 Iter 5 subLoss 4124.3 multi 3.99 import weight 0.00
Epoch 249 Iter 6 subLoss 3906.2 multi 3.98 import weight 0.00
Epoch 249 Iter 7 subLoss 4166.6 multi 1.00 import weight 0.00
Epoch 249 Iter 8 subLoss 3815.8 multi 1.00 import weight 0.00
Epoch 249 Iter 9 subLoss 3805.8 multi -4.97 import weight 0.00
Epoch 249 Iter 10 subLoss 3543.1 multi 1.00 import weight 0.00
Epoch 249 Iter 11 subLoss 3948.3 multi 6.97 import weight 0.00
Epoch 249 Acc: 97.51 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 394 train Loss: 3965.9 test Loss: 428.6
Epoch 250 Iter 0 subLoss 3993.4 multi 6.97 import weight 0.00
Epoch 250 Iter 1 subLoss 3592.0 multi 3.99 import weight 0.00
Epoch 250 Iter 2 subLoss 4082.6 multi -4.97 import weight 0.00
Epoch 250 Iter 3 subLoss 3690.5 multi 3.99 import weight 0.00
Epoch 250 Iter 4 subLoss 3594.7 multi 6.97 import weight 0.00
Epoch 250 Iter 5 subLoss 4056.8 multi 1.00 import weight 0.00
Epoch 250 Iter 6 subLoss 3656.5 multi 1.00 import weight 0.00
Epoch 250 Iter 7 subLoss 4154.4 multi -4.97 import weight 0.00
Epoch 250 Iter 8 subLoss 3921.6 multi 1.00 import weight 0.00
Epoch 250 Iter 9 subLoss 3099.0 multi 1.00 import weight 0.00
Epoch 250 Iter 10 subLoss 3806.8 multi -1.99 import weight 0.00
Epoch 250 Iter 11 subLoss 3997.2 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.13148 / 7.54
Entropy seen (from low to high)
[3391, 223, 317, 267, 201, 105, 94, 63, 50, 43, 40, 36, 20, 22, 26, 17, 25, 17, 19, 25, 22, 18, 9, 12, 12, 9, 8, 3, 6, 7, 3, 8, 4, 3, 1, 2, 2, 0, 5, 3, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 1, 3, 8, 8, 13, 27, 23, 39, 53, 66, 64, 109, 95, 148, 115, 105, 152, 124, 128, 138, 164, 159, 164, 150, 175, 151, 118, 126, 125, 129, 128, 139, 128, 136, 123, 171, 145, 203, 167, 164, 141, 101, 83, 63, 88]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 34.6, 37.6, 39.6, 44.3, 46.7, 50.6, 53.9, 58.3, 61.0, 64.5, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 42.8, 66.6, 66.6, 46.1, 63.9, 61.5, 57.1, 69.9, 70.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 7, 3, 9, 13, 25, 13, 14, 20, 24]
Epoch 250 Acc: 97.72 BMA: 97.72 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 399 train Loss: 3768.8 test Loss: 397.4
Epoch 251 Iter 0 subLoss 3653.0 multi 3.98 import weight 0.00
Epoch 251 Iter 1 subLoss 3424.6 multi 3.99 import weight 0.00
Epoch 251 Iter 2 subLoss 3468.3 multi 1.00 import weight 0.00
Epoch 251 Iter 3 subLoss 3064.3 multi 1.00 import weight 0.00
Epoch 251 Iter 4 subLoss 3773.0 multi 1.00 import weight 0.00
Epoch 251 Iter 5 subLoss 3236.4 multi 1.00 import weight 0.00
Epoch 251 Iter 6 subLoss 3691.0 multi 6.97 import weight 0.00
Epoch 251 Iter 7 subLoss 3521.8 multi 1.00 import weight 0.00
Epoch 251 Iter 8 subLoss 3617.3 multi 1.00 import weight 0.00
Epoch 251 Iter 9 subLoss 4221.0 multi -1.99 import weight 0.00
Epoch 251 Iter 10 subLoss 3859.4 multi -1.99 import weight 0.00
Epoch 251 Iter 11 subLoss 3640.0 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0072 / 0.13130 / 9.16
Entropy seen (from low to high)
[3356, 292, 326, 265, 174, 100, 89, 60, 51, 38, 40, 28, 28, 25, 26, 27, 11, 19, 21, 28, 20, 15, 16, 12, 7, 7, 9, 6, 3, 7, 6, 5, 4, 3, 1, 2, 4, 2, 1, 3, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 2, 1, 4, 16, 12, 13, 26, 38, 42, 66, 83, 94, 99, 133, 104, 121, 134, 138, 132, 137, 144, 155, 192, 190, 181, 131, 132, 140, 107, 136, 124, 114, 150, 130, 129, 138, 169, 161, 199, 168, 151, 108, 68, 72, 77]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 34.0, 37.7, 39.7, 43.7, 47.8, 50.7, 54.7, 58.2, 61.1, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 33.3, 66.6, 49.9, 44.4, 59.9, 66.6, 57.8, 61.1, 58.8, 42.1]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 3, 8, 9, 20, 18, 19, 18, 17, 19]
Epoch 251 Acc: 97.63 BMA: 97.76 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 363 train Loss: 3849.0 test Loss: 415.1
Epoch 252 Iter 0 subLoss 3910.4 multi -4.97 import weight 0.00
Epoch 252 Iter 1 subLoss 3935.1 multi -1.98 import weight 0.00
Epoch 252 Iter 2 subLoss 4432.7 multi -4.97 import weight 0.00
Epoch 252 Iter 3 subLoss 7717.3 multi -1.98 import weight 0.00
Epoch 252 Iter 4 subLoss 20032.3 multi 3.99 import weight 0.00
Epoch 252 Iter 5 subLoss 15911.4 multi -1.99 import weight 0.00
Epoch 252 Iter 6 subLoss 47409.5 multi -1.99 import weight 0.00
Epoch 252 Iter 7 subLoss 524168.0 multi 1.00 import weight 0.00
Epoch 252 Iter 8 subLoss 34395.3 multi 1.00 import weight 0.00
Epoch 252 Iter 9 subLoss 23174.1 multi -1.99 import weight 0.00
Epoch 252 Iter 10 subLoss 34969.6 multi 1.00 import weight 0.00
Epoch 252 Iter 11 subLoss 26623.6 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0123 / 0.11147 / 21.60
Entropy seen (from low to high)
[1741, 93, 41, 35, 49, 102, 144, 191, 183, 166, 179, 144, 120, 132, 93, 114, 106, 106, 152, 144, 167, 181, 160, 138, 111, 107, 56, 50, 37, 17, 19, 11, 8, 15, 7, 7, 2, 5, 1, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 4, 3, 14, 23, 32, 42, 54, 74, 105, 115, 120, 163, 195, 207, 194, 187, 181, 219, 216, 234, 249, 200, 209, 168, 135, 131, 127, 115, 110, 101, 119, 150, 158, 142, 99, 70, 59, 37, 23, 17, 18, 12, 10, 10, 9]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 34.0, 35.9, 40.0, 43.9, 47.3, 50.6, 54.1, 57.6, 61.6, 65.1, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 33.3, 62.4, 49.9, 36.8, 78.9, 65.2, 51.5, 71.1, 88.3, 96.2]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 8, 14, 19, 19, 23, 33, 52, 77, 266]
Epoch 252 Acc: 78.58 BMA: 97.80 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2662 train Loss: 23310.3 test Loss: 2895.0
Epoch 253 Iter 0 subLoss 22843.9 multi 3.99 import weight 0.00
Epoch 253 Iter 1 subLoss 13643.0 multi 1.00 import weight 0.00
Epoch 253 Iter 2 subLoss 13147.5 multi 1.00 import weight 0.00
Epoch 253 Iter 3 subLoss 12002.2 multi 1.00 import weight 0.00
Epoch 253 Iter 4 subLoss 11196.5 multi 1.00 import weight 0.00
Epoch 253 Iter 5 subLoss 10772.4 multi 6.97 import weight 0.00
Epoch 253 Iter 6 subLoss 8985.1 multi 1.00 import weight 0.00
Epoch 253 Iter 7 subLoss 8302.7 multi 1.00 import weight 0.00
Epoch 253 Iter 8 subLoss 7877.1 multi 3.98 import weight 0.00
Epoch 253 Iter 9 subLoss 7058.9 multi 9.96 import weight 0.00
Epoch 253 Iter 10 subLoss 6262.1 multi 6.97 import weight 0.00
Epoch 253 Iter 11 subLoss 6160.4 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0112 / 0.11373 / 17.45
Entropy seen (from low to high)
[1662, 108, 57, 57, 108, 195, 203, 219, 216, 157, 165, 150, 120, 134, 125, 146, 145, 177, 150, 127, 139, 118, 88, 73, 49, 52, 41, 31, 23, 18, 17, 19, 7, 15, 7, 5, 4, 4, 1, 3, 0, 3, 0, 0, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 6, 3, 17, 23, 32, 42, 74, 55, 87, 111, 141, 148, 185, 210, 187, 160, 185, 200, 216, 207, 223, 200, 192, 141, 155, 146, 116, 107, 129, 129, 113, 100, 118, 164, 148, 135, 80, 58, 42, 32, 13, 12, 5, 8, 5]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.3, 33.1, 35.4, 40.4, 44.2, 47.4, 50.7, 54.3, 57.8, 61.2, 64.5, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 99.9, 49.9, 38.8, 42.8, 83.3, 65.8, 63.6, 94.1, 74.9, 89.0]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 10, 18, 21, 30, 41, 33, 51, 56, 73]
Epoch 253 Acc: 95.52 BMA: 97.65 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 616 train Loss: 6584.5 test Loss: 706.4
Epoch 254 Iter 0 subLoss 6579.7 multi 3.99 import weight 0.00
Epoch 254 Iter 1 subLoss 5851.4 multi 6.97 import weight 0.00
Epoch 254 Iter 2 subLoss 5127.3 multi 3.99 import weight 0.00
Epoch 254 Iter 3 subLoss 5289.8 multi -1.98 import weight 0.00
Epoch 254 Iter 4 subLoss 5457.6 multi -1.98 import weight 0.00
Epoch 254 Iter 5 subLoss 4880.9 multi 1.00 import weight 0.00
Epoch 254 Iter 6 subLoss 4552.1 multi 3.99 import weight 0.00
Epoch 254 Iter 7 subLoss 5058.5 multi 6.97 import weight 0.00
Epoch 254 Iter 8 subLoss 4628.1 multi 9.96 import weight 0.00
Epoch 254 Iter 9 subLoss 4561.4 multi -7.96 import weight 0.00
Epoch 254 Iter 10 subLoss 4482.1 multi -1.98 import weight 0.00
Epoch 254 Iter 11 subLoss 4899.9 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0101 / 0.11635 / 14.30
Entropy seen (from low to high)
[1684, 101, 63, 86, 174, 239, 264, 223, 182, 188, 156, 161, 153, 156, 172, 161, 157, 129, 137, 88, 75, 52, 43, 55, 42, 32, 33, 24, 18, 15, 20, 11, 10, 9, 4, 8, 5, 2, 0, 2, 3, 1, 0, 0, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 3, 8, 10, 18, 25, 41, 62, 70, 77, 104, 119, 138, 175, 187, 166, 182, 182, 176, 170, 219, 213, 204, 176, 158, 149, 156, 136, 122, 135, 131, 132, 126, 112, 127, 162, 146, 123, 67, 59, 40, 20, 11, 8, 9, 5]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.9, 0.0, 34.7, 36.9, 41.2, 43.9, 47.5, 50.9, 54.3, 57.7, 61.2, 64.8, 68.4]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 19.9, 52.9, 49.9, 55.5, 76.9, 67.5, 77.2, 80.4, 88.6]
[0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 4, 5, 17, 22, 27, 39, 37, 44, 46, 44]
Epoch 254 Acc: 96.94 BMA: 97.53 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 489 train Loss: 5927.7 test Loss: 498.9
Epoch 255 Iter 0 subLoss 6104.9 multi -4.97 import weight 0.00
Epoch 255 Iter 1 subLoss 9259.0 multi 12.94 import weight 0.00
Epoch 255 Iter 2 subLoss 44808.1 multi 1.00 import weight 0.00
Epoch 255 Iter 3 subLoss 14092.3 multi -4.97 import weight 0.00
Epoch 255 Iter 4 subLoss 67385.0 multi 1.00 import weight 0.00
Epoch 255 Iter 5 subLoss 21115.2 multi 1.00 import weight 0.00
Epoch 255 Iter 6 subLoss 15146.7 multi 3.99 import weight 0.00
Epoch 255 Iter 7 subLoss 9061.4 multi -4.97 import weight 0.00
Epoch 255 Iter 8 subLoss 9582.4 multi 3.99 import weight 0.00
Epoch 255 Iter 9 subLoss 8366.9 multi 1.00 import weight 0.00
Epoch 255 Iter 10 subLoss 7933.3 multi 6.97 import weight 0.00
Epoch 255 Iter 11 subLoss 6971.8 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0098 / 0.10889 / 12.38
Entropy seen (from low to high)
[1681, 99, 68, 71, 84, 99, 117, 161, 250, 252, 277, 261, 258, 231, 188, 171, 164, 99, 68, 73, 58, 49, 46, 46, 40, 44, 28, 28, 24, 18, 11, 16, 16, 13, 7, 6, 7, 2, 2, 0, 2, 3, 0, 0, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 2, 9, 15, 24, 23, 56, 68, 85, 88, 124, 117, 164, 225, 209, 203, 201, 235, 214, 203, 239, 214, 189, 163, 165, 161, 177, 156, 198, 138, 170, 140, 139, 115, 85, 42, 26, 18, 9, 7, 10, 11, 6, 4, 9, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 32.9, 37.5, 40.3, 43.7, 47.5, 50.8, 54.1, 57.9, 61.3, 64.9, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 99.9, 49.9, 49.9, 30.7, 67.9, 51.6, 56.2, 74.3, 79.9, 76.7, 81.0]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 12, 13, 25, 31, 32, 39, 40, 43, 58]
Epoch 255 Acc: 95.62 BMA: 97.53 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 697 train Loss: 7954.0 test Loss: 844.9
Epoch 256 Iter 0 subLoss 7901.5 multi 9.96 import weight 0.00
Epoch 256 Iter 1 subLoss 6978.0 multi -1.98 import weight 0.00
Epoch 256 Iter 2 subLoss 6955.0 multi 1.00 import weight 0.00
Epoch 256 Iter 3 subLoss 6539.9 multi 9.96 import weight 0.00
Epoch 256 Iter 4 subLoss 5970.0 multi 1.00 import weight 0.00
Epoch 256 Iter 5 subLoss 6378.8 multi 3.99 import weight 0.00
Epoch 256 Iter 6 subLoss 6412.4 multi -1.99 import weight 0.00
Epoch 256 Iter 7 subLoss 5732.4 multi -4.97 import weight 0.00
Epoch 256 Iter 8 subLoss 5797.0 multi 6.97 import weight 0.00
Epoch 256 Iter 9 subLoss 5776.7 multi -1.99 import weight 0.00
Epoch 256 Iter 10 subLoss 6132.5 multi 1.00 import weight 0.00
Epoch 256 Iter 11 subLoss 5324.6 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0096 / 0.10656 / 12.78
Entropy seen (from low to high)
[1682, 107, 84, 88, 94, 109, 122, 161, 211, 255, 302, 330, 266, 210, 197, 166, 106, 66, 73, 45, 69, 41, 38, 40, 40, 46, 34, 27, 23, 16, 13, 18, 15, 10, 13, 7, 4, 3, 2, 0, 1, 4, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 2, 12, 14, 26, 27, 60, 67, 84, 102, 115, 157, 165, 223, 239, 219, 216, 218, 236, 218, 219, 209, 192, 186, 175, 178, 193, 166, 162, 139, 148, 141, 110, 87, 36, 27, 20, 11, 10, 5, 11, 13, 4, 7, 8, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.1, 34.5, 36.9, 40.1, 43.7, 47.7, 50.6, 54.5, 57.7, 61.0, 64.9, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 49.9, 39.9, 64.7, 61.2, 51.6, 59.3, 67.5, 69.9, 88.4, 85.3]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 10, 17, 31, 31, 32, 37, 30, 52, 41]
Epoch 256 Acc: 96.71 BMA: 97.57 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 532 train Loss: 6204.8 test Loss: 636.6
Epoch 257 Iter 0 subLoss 6026.3 multi -7.96 import weight 0.00
Epoch 257 Iter 1 subLoss 6819.3 multi 1.00 import weight 0.00
Epoch 257 Iter 2 subLoss 6728.3 multi 6.97 import weight 0.00
Epoch 257 Iter 3 subLoss 5894.7 multi 1.00 import weight 0.00
Epoch 257 Iter 4 subLoss 5086.1 multi 6.97 import weight 0.00
Epoch 257 Iter 5 subLoss 5643.7 multi -4.97 import weight 0.00
Epoch 257 Iter 6 subLoss 5885.2 multi 3.98 import weight 0.00
Epoch 257 Iter 7 subLoss 5726.4 multi 6.97 import weight 0.00
Epoch 257 Iter 8 subLoss 4789.2 multi 1.00 import weight 0.00
Epoch 257 Iter 9 subLoss 5567.6 multi 9.96 import weight 0.00
Epoch 257 Iter 10 subLoss 5564.0 multi 12.94 import weight 0.00
Epoch 257 Iter 11 subLoss 4681.0 multi -1.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0091 / 0.10702 / 10.60
Entropy seen (from low to high)
[1694, 109, 94, 95, 131, 108, 154, 192, 261, 278, 362, 291, 234, 203, 151, 120, 71, 66, 50, 66, 35, 38, 43, 43, 40, 36, 34, 20, 21, 12, 16, 19, 6, 14, 12, 4, 7, 0, 3, 1, 1, 3, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 3, 10, 15, 19, 36, 55, 70, 78, 99, 124, 140, 160, 235, 222, 233, 210, 217, 230, 228, 215, 200, 187, 192, 174, 191, 162, 179, 147, 142, 145, 146, 109, 103, 53, 32, 19, 15, 10, 8, 10, 9, 9, 5, 8, 6]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.1, 0.0, 36.3, 40.3, 44.1, 47.3, 51.0, 54.4, 58.0, 61.2, 64.9, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.9, 49.9, 55.5, 41.6, 52.7, 65.6, 66.6, 66.6, 79.9, 86.7]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 5, 8, 18, 24, 36, 32, 30, 30, 35, 53]
Epoch 257 Acc: 97.47 BMA: 97.59 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 468 train Loss: 4790.2 test Loss: 463.8
Epoch 258 Iter 0 subLoss 5152.8 multi 9.96 import weight 0.00
Epoch 258 Iter 1 subLoss 5123.4 multi 6.97 import weight 0.00
Epoch 258 Iter 2 subLoss 4540.9 multi -1.99 import weight 0.00
Epoch 258 Iter 3 subLoss 4283.1 multi 6.97 import weight 0.00
Epoch 258 Iter 4 subLoss 4703.3 multi -4.97 import weight 0.00
Epoch 258 Iter 5 subLoss 3901.4 multi 6.97 import weight 0.00
Epoch 258 Iter 6 subLoss 4135.5 multi -1.98 import weight 0.00
Epoch 258 Iter 7 subLoss 4209.8 multi -4.97 import weight 0.00
Epoch 258 Iter 8 subLoss 4503.1 multi -1.98 import weight 0.00
Epoch 258 Iter 9 subLoss 5110.1 multi 1.00 import weight 0.00
Epoch 258 Iter 10 subLoss 4660.3 multi -4.97 import weight 0.00
Epoch 258 Iter 11 subLoss 4670.6 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0091 / 0.10773 / 11.25
Entropy seen (from low to high)
[1676, 125, 101, 121, 143, 146, 176, 238, 290, 350, 321, 267, 216, 136, 128, 79, 55, 57, 58, 46, 34, 38, 42, 40, 41, 33, 34, 19, 17, 21, 19, 14, 15, 13, 9, 7, 1, 6, 1, 1, 1, 2, 1, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 4, 10, 13, 18, 47, 52, 65, 91, 109, 119, 142, 179, 209, 220, 222, 206, 195, 220, 239, 203, 194, 185, 170, 188, 161, 179, 154, 160, 154, 125, 156, 126, 107, 91, 43, 22, 20, 12, 6, 8, 11, 9, 4, 7, 5]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.8, 37.0, 40.4, 44.0, 47.5, 50.8, 54.2, 57.7, 61.3, 64.7, 68.6]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 49.9, 63.6, 41.6, 47.3, 64.9, 57.4, 65.3, 79.0, 72.7, 85.7]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 11, 12, 19, 40, 40, 26, 43, 33, 49]
Epoch 258 Acc: 95.62 BMA: 97.59 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 467 train Loss: 5676.7 test Loss: 655.8
Epoch 259 Iter 0 subLoss 5675.0 multi 3.99 import weight 0.00
Epoch 259 Iter 1 subLoss 4304.3 multi -1.99 import weight 0.00
Epoch 259 Iter 2 subLoss 4676.3 multi -1.99 import weight 0.00
Epoch 259 Iter 3 subLoss 4875.1 multi 1.00 import weight 0.00
Epoch 259 Iter 4 subLoss 5123.4 multi 6.97 import weight 0.00
Epoch 259 Iter 5 subLoss 4045.1 multi 3.99 import weight 0.00
Epoch 259 Iter 6 subLoss 4053.2 multi 1.00 import weight 0.00
Epoch 259 Iter 7 subLoss 4438.0 multi -1.99 import weight 0.00
Epoch 259 Iter 8 subLoss 4443.5 multi -1.99 import weight 0.00
Epoch 259 Iter 9 subLoss 3851.2 multi 1.00 import weight 0.00
Epoch 259 Iter 10 subLoss 4404.9 multi -13.93 import weight 0.00
Epoch 259 Iter 11 subLoss 4428.9 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0088 / 0.10876 / 10.75
Entropy seen (from low to high)
[1684, 130, 119, 141, 137, 174, 219, 278, 326, 364, 304, 243, 158, 124, 86, 66, 62, 56, 52, 35, 29, 39, 42, 38, 40, 28, 28, 20, 18, 15, 16, 19, 6, 16, 9, 4, 2, 5, 1, 1, 0, 3, 1, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 5, 11, 13, 15, 35, 51, 68, 85, 102, 121, 143, 161, 223, 194, 238, 189, 201, 217, 222, 206, 204, 170, 190, 163, 172, 172, 161, 143, 166, 137, 141, 156, 104, 105, 58, 30, 20, 14, 9, 7, 12, 10, 4, 8, 5]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.2, 36.4, 40.2, 43.9, 47.5, 50.7, 54.1, 57.5, 61.3, 64.6, 68.5]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 62.4, 57.1, 44.9, 66.6, 56.0, 70.9, 66.6, 84.8, 81.0]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 6, 8, 14, 20, 27, 41, 31, 36, 33, 37]
Epoch 259 Acc: 97.72 BMA: 97.63 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 442 train Loss: 4505.0 test Loss: 420.1
Epoch 260 Iter 0 subLoss 4087.6 multi -1.99 import weight 0.00
Epoch 260 Iter 1 subLoss 4382.7 multi 6.97 import weight 0.00
Epoch 260 Iter 2 subLoss 5086.6 multi 9.96 import weight 0.00
Epoch 260 Iter 3 subLoss 3966.2 multi -1.98 import weight 0.00
Epoch 260 Iter 4 subLoss 4145.0 multi -1.98 import weight 0.00
Epoch 260 Iter 5 subLoss 4605.2 multi 1.00 import weight 0.00
Epoch 260 Iter 6 subLoss 4719.7 multi 3.99 import weight 0.00
Epoch 260 Iter 7 subLoss 3761.4 multi 1.00 import weight 0.00
Epoch 260 Iter 8 subLoss 4608.5 multi 3.99 import weight 0.00
Epoch 260 Iter 9 subLoss 4686.1 multi -4.97 import weight 0.00
Epoch 260 Iter 10 subLoss 4681.5 multi -1.99 import weight 0.00
Epoch 260 Iter 11 subLoss 4283.4 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0085 / 0.10980 / 12.97
Entropy seen (from low to high)
[1687, 141, 128, 167, 150, 197, 259, 298, 415, 325, 270, 188, 130, 106, 73, 63, 53, 54, 42, 28, 32, 46, 34, 46, 29, 19, 33, 18, 17, 11, 19, 16, 8, 14, 6, 3, 4, 3, 1, 1, 0, 3, 1, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 3, 10, 11, 17, 30, 57, 60, 79, 106, 103, 147, 157, 216, 194, 217, 195, 195, 219, 225, 205, 204, 177, 174, 166, 176, 163, 153, 152, 145, 155, 141, 143, 132, 110, 84, 41, 21, 20, 10, 7, 13, 9, 5, 7, 6]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.2, 37.1, 39.5, 44.2, 47.4, 51.0, 54.3, 57.7, 61.0, 64.7, 68.4]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 59.9, 49.9, 24.9, 73.9, 41.6, 65.6, 66.6, 57.1, 79.9, 83.3]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 5, 8, 12, 23, 24, 32, 33, 35, 35, 30]
Epoch 260 Acc: 97.47 BMA: 97.55 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 428 train Loss: 4328.2 test Loss: 434.0
Epoch 261 Iter 0 subLoss 4464.3 multi -10.94 import weight 0.00
Epoch 261 Iter 1 subLoss 4168.9 multi 1.00 import weight 0.00
Epoch 261 Iter 2 subLoss 4578.6 multi 6.97 import weight 0.00
Epoch 261 Iter 3 subLoss 4174.8 multi -1.99 import weight 0.00
Epoch 261 Iter 4 subLoss 4459.9 multi 1.00 import weight 0.00
Epoch 261 Iter 5 subLoss 4079.2 multi 3.99 import weight 0.00
Epoch 261 Iter 6 subLoss 4240.3 multi 3.99 import weight 0.00
Epoch 261 Iter 7 subLoss 3890.0 multi -10.94 import weight 0.00
Epoch 261 Iter 8 subLoss 4340.8 multi -7.96 import weight 0.00
Epoch 261 Iter 9 subLoss 5083.5 multi 12.94 import weight 1.00
Epoch 261 Iter 10 subLoss 5037.4 multi 6.97 import weight 0.00
Epoch 261 Iter 11 subLoss 4130.4 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0083 / 0.11081 / 9.23
Entropy seen (from low to high)
[1694, 149, 136, 183, 178, 215, 299, 368, 361, 357, 215, 149, 115, 82, 72, 53, 57, 42, 38, 23, 43, 38, 42, 29, 29, 28, 25, 22, 7, 16, 20, 11, 12, 8, 6, 4, 3, 2, 2, 1, 1, 2, 1, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 4, 10, 14, 12, 29, 56, 62, 73, 97, 111, 135, 161, 192, 211, 217, 197, 176, 215, 211, 210, 205, 170, 181, 161, 172, 147, 166, 150, 145, 155, 134, 151, 145, 119, 95, 61, 26, 22, 13, 8, 10, 14, 3, 9, 6]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.3, 31.9, 37.4, 40.0, 43.7, 47.1, 50.5, 54.2, 57.7, 61.5, 64.9, 68.6]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 16.6, 55.5, 61.9, 49.9, 57.1, 59.9, 69.2, 75.8, 89.9]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 6, 6, 9, 21, 24, 35, 30, 39, 29, 30]
Epoch 261 Acc: 97.66 BMA: 97.59 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 413 train Loss: 4247.0 test Loss: 413.3
Epoch 262 Iter 0 subLoss 3853.1 multi 3.98 import weight 0.00
Epoch 262 Iter 1 subLoss 4208.3 multi -1.99 import weight 0.00
Epoch 262 Iter 2 subLoss 4528.4 multi 6.97 import weight 0.00
Epoch 262 Iter 3 subLoss 4743.4 multi -1.98 import weight 0.00
Epoch 262 Iter 4 subLoss 4090.1 multi -1.99 import weight 0.00
Epoch 262 Iter 5 subLoss 4043.3 multi 6.97 import weight 0.00
Epoch 262 Iter 6 subLoss 4255.8 multi -4.97 import weight 0.00
Epoch 262 Iter 7 subLoss 4422.2 multi 6.97 import weight 0.00
Epoch 262 Iter 8 subLoss 3933.4 multi 1.00 import weight 0.00
Epoch 262 Iter 9 subLoss 3580.3 multi -1.99 import weight 0.00
Epoch 262 Iter 10 subLoss 4345.5 multi -4.97 import weight 0.00
Epoch 262 Iter 11 subLoss 4053.4 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0082 / 0.11225 / 8.88
Entropy seen (from low to high)
[1701, 158, 151, 185, 222, 243, 315, 438, 356, 280, 191, 125, 100, 72, 65, 57, 42, 50, 22, 27, 44, 40, 31, 33, 29, 25, 29, 14, 10, 13, 23, 5, 17, 6, 2, 5, 3, 3, 1, 1, 1, 3, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 3, 8, 15, 12, 26, 45, 65, 62, 89, 118, 127, 146, 185, 197, 215, 196, 198, 189, 205, 201, 206, 191, 168, 170, 150, 171, 149, 146, 157, 141, 165, 135, 155, 129, 115, 77, 40, 21, 20, 8, 11, 13, 5, 9, 6]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.8, 34.4, 36.1, 40.6, 42.9, 47.1, 50.7, 54.3, 57.7, 61.2, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 49.9, 24.9, 33.3, 62.4, 35.2, 63.3, 55.1, 53.3, 67.7, 70.5, 85.1]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 4, 6, 8, 17, 30, 29, 30, 31, 34, 27]
Epoch 262 Acc: 97.35 BMA: 97.57 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 405 train Loss: 4203.3 test Loss: 450.0
Epoch 263 Iter 0 subLoss 4012.9 multi -1.99 import weight 0.00
Epoch 263 Iter 1 subLoss 4261.2 multi -1.99 import weight 0.00
Epoch 263 Iter 2 subLoss 4736.2 multi -4.97 import weight 0.00
Epoch 263 Iter 3 subLoss 6688.4 multi -7.96 import weight 0.00
Epoch 263 Iter 4 subLoss 60648.3 multi 1.00 import weight 0.00
Epoch 263 Iter 5 subLoss 5574.8 multi -10.94 import weight 0.00
Epoch 263 Iter 6 subLoss 10616.1 multi 3.98 import weight 0.00
Epoch 263 Iter 7 subLoss 4650.3 multi 1.00 import weight 0.00
Epoch 263 Iter 8 subLoss 4447.3 multi 1.00 import weight 0.00
Epoch 263 Iter 9 subLoss 4885.3 multi 1.00 import weight 0.00
Epoch 263 Iter 10 subLoss 4201.8 multi 1.00 import weight 0.00
Epoch 263 Iter 11 subLoss 4753.0 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0082 / 0.11258 / 8.71
Entropy seen (from low to high)
[1710, 158, 175, 191, 230, 274, 341, 422, 373, 235, 169, 113, 90, 78, 53, 57, 41, 43, 26, 33, 41, 38, 27, 36, 27, 25, 25, 16, 15, 13, 17, 8, 14, 6, 1, 5, 3, 1, 3, 1, 1, 3, 1, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 3, 7, 12, 15, 26, 45, 59, 66, 93, 111, 124, 148, 181, 205, 199, 218, 189, 179, 201, 199, 210, 179, 184, 166, 143, 183, 133, 152, 151, 146, 157, 149, 145, 131, 120, 81, 51, 22, 23, 7, 14, 12, 5, 9, 6]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.1, 33.8, 36.6, 40.8, 43.3, 47.4, 50.6, 54.5, 57.7, 61.1, 64.6, 68.4]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 33.3, 33.3, 45.4, 42.8, 65.6, 57.6, 48.3, 63.3, 71.4, 86.2]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 6, 3, 11, 14, 32, 26, 31, 30, 35, 29]
Epoch 263 Acc: 97.28 BMA: 97.55 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 475 train Loss: 4643.9 test Loss: 479.2
Epoch 264 Iter 0 subLoss 4852.9 multi 3.99 import weight 0.00
Epoch 264 Iter 1 subLoss 4240.2 multi 6.97 import weight 0.00
Epoch 264 Iter 2 subLoss 4544.6 multi 1.00 import weight 0.00
Epoch 264 Iter 3 subLoss 3765.7 multi 3.98 import weight 0.00
Epoch 264 Iter 4 subLoss 4497.9 multi 1.00 import weight 0.00
Epoch 264 Iter 5 subLoss 4814.8 multi 6.97 import weight 0.00
Epoch 264 Iter 6 subLoss 4220.2 multi 1.00 import weight 0.00
Epoch 264 Iter 7 subLoss 3739.4 multi -4.97 import weight 0.00
Epoch 264 Iter 8 subLoss 4260.2 multi 1.00 import weight 0.00
Epoch 264 Iter 9 subLoss 4491.0 multi 3.99 import weight 0.00
Epoch 264 Iter 10 subLoss 4062.8 multi -10.94 import weight 0.00
Epoch 264 Iter 11 subLoss 4916.0 multi 15.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0082 / 0.11315 / 11.16
Entropy seen (from low to high)
[1692, 173, 196, 207, 240, 306, 400, 397, 346, 203, 148, 98, 90, 68, 63, 47, 48, 34, 26, 39, 42, 30, 26, 37, 29, 21, 27, 12, 15, 14, 19, 10, 13, 4, 1, 4, 3, 2, 3, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 3, 6, 11, 17, 27, 39, 56, 66, 92, 110, 115, 141, 188, 202, 202, 194, 212, 172, 207, 177, 220, 186, 173, 178, 152, 161, 144, 146, 146, 142, 163, 147, 143, 151, 126, 91, 48, 31, 21, 10, 15, 9, 6, 7, 6]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.2, 33.8, 36.1, 41.0, 43.7, 47.2, 50.5, 54.3, 57.7, 61.7, 64.5, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 99.9, 0.0, 39.9, 54.5, 49.9, 52.1, 71.8, 39.9, 70.8, 66.6, 81.8]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 3, 5, 11, 16, 23, 32, 35, 24, 33, 33]
Epoch 264 Acc: 96.79 BMA: 97.53 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 15.93 Pidx 491 train Loss: 4772.3 test Loss: 555.7
Epoch 265 Iter 0 subLoss 4610.7 multi -10.94 import weight 0.00
Epoch 265 Iter 1 subLoss 7933.8 multi 9.96 import weight 0.00
Epoch 265 Iter 2 subLoss 6024.8 multi -4.97 import weight 0.00
Epoch 265 Iter 3 subLoss 16901.4 multi 1.00 import weight 0.00
Epoch 265 Iter 4 subLoss 8550.4 multi 3.98 import weight 0.00
Epoch 265 Iter 5 subLoss 4514.8 multi 1.00 import weight 0.00
Epoch 265 Iter 6 subLoss 4253.2 multi -4.97 import weight 0.00
Epoch 265 Iter 7 subLoss 4813.4 multi 9.96 import weight 0.00
Epoch 265 Iter 8 subLoss 4206.6 multi 3.99 import weight 0.00
Epoch 265 Iter 9 subLoss 4435.4 multi -4.97 import weight 0.00
Epoch 265 Iter 10 subLoss 4146.3 multi -1.99 import weight 0.00
Epoch 265 Iter 11 subLoss 4415.5 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0081 / 0.11324 / 8.38
Entropy seen (from low to high)
[1699, 184, 200, 218, 259, 330, 433, 391, 292, 187, 137, 96, 83, 61, 63, 47, 48, 31, 29, 37, 41, 27, 33, 33, 28, 20, 27, 16, 13, 11, 20, 13, 8, 5, 1, 4, 3, 2, 3, 1, 1, 3, 1, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 4, 6, 11, 15, 29, 39, 60, 64, 89, 109, 121, 137, 172, 223, 176, 220, 203, 173, 205, 192, 204, 195, 167, 178, 155, 146, 160, 125, 148, 153, 148, 149, 150, 138, 126, 105, 47, 41, 23, 12, 12, 9, 7, 7, 6]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.7, 33.7, 37.0, 40.7, 43.2, 47.1, 50.4, 54.4, 57.4, 61.4, 64.7, 68.6]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 66.6, 0.0, 24.9, 66.6, 49.9, 61.9, 54.5, 49.9, 75.9, 64.7, 80.6]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 2, 4, 9, 18, 21, 33, 34, 25, 34, 31]
Epoch 265 Acc: 97.47 BMA: 97.55 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 441 train Loss: 4350.2 test Loss: 463.7
Epoch 266 Iter 0 subLoss 4427.5 multi 6.97 import weight 0.00
Epoch 266 Iter 1 subLoss 4081.0 multi -1.99 import weight 0.00
Epoch 266 Iter 2 subLoss 4124.0 multi 6.97 import weight 0.00
Epoch 266 Iter 3 subLoss 4180.1 multi -1.99 import weight 0.00
Epoch 266 Iter 4 subLoss 4237.4 multi -13.93 import weight 0.00
Epoch 266 Iter 5 subLoss 4142.3 multi 1.00 import weight 0.00
Epoch 266 Iter 6 subLoss 4506.6 multi -4.97 import weight 0.00
Epoch 266 Iter 7 subLoss 4442.4 multi 1.00 import weight 0.00
Epoch 266 Iter 8 subLoss 4749.6 multi -1.99 import weight 0.00
Epoch 266 Iter 9 subLoss 5073.0 multi -1.99 import weight 0.00
Epoch 266 Iter 10 subLoss 5939.4 multi 3.99 import weight 0.00
Epoch 266 Iter 11 subLoss 4721.9 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0081 / 0.11357 / 7.98
Entropy seen (from low to high)
[1701, 193, 213, 252, 258, 359, 438, 378, 265, 169, 134, 84, 77, 65, 51, 51, 43, 28, 35, 37, 37, 30, 31, 35, 26, 20, 24, 17, 12, 14, 17, 15, 6, 4, 3, 3, 3, 1, 3, 2, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 4, 7, 11, 15, 27, 37, 64, 62, 88, 101, 131, 129, 165, 216, 188, 222, 184, 188, 193, 198, 205, 190, 172, 170, 159, 156, 145, 128, 161, 136, 157, 156, 134, 145, 124, 117, 44, 52, 24, 12, 14, 8, 8, 8, 4]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.4, 33.0, 37.0, 40.1, 43.8, 47.6, 50.2, 54.6, 57.7, 61.1, 64.6, 68.7]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 66.6, 0.0, 33.3, 57.1, 62.4, 47.0, 56.7, 49.9, 70.8, 67.6, 79.9]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 2, 3, 14, 16, 17, 37, 30, 24, 34, 30]
Epoch 266 Acc: 97.16 BMA: 97.51 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 472 train Loss: 4477.5 test Loss: 485.7
Epoch 267 Iter 0 subLoss 4556.7 multi 1.00 import weight 0.00
Epoch 267 Iter 1 subLoss 3579.0 multi 3.99 import weight 0.00
Epoch 267 Iter 2 subLoss 4005.2 multi -4.97 import weight 0.00
Epoch 267 Iter 3 subLoss 4570.1 multi 9.96 import weight 0.00
Epoch 267 Iter 4 subLoss 4283.8 multi 12.94 import weight 0.00
Epoch 267 Iter 5 subLoss 4332.7 multi 6.97 import weight 0.00
Epoch 267 Iter 6 subLoss 3833.3 multi 1.00 import weight 0.00
Epoch 267 Iter 7 subLoss 3714.5 multi -1.99 import weight 0.00
Epoch 267 Iter 8 subLoss 3795.2 multi 9.96 import weight 0.00
Epoch 267 Iter 9 subLoss 4131.2 multi 1.00 import weight 0.00
Epoch 267 Iter 10 subLoss 3579.4 multi 6.97 import weight 0.00
Epoch 267 Iter 11 subLoss 3702.1 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0081 / 0.11443 / 6.77
Entropy seen (from low to high)
[1710, 195, 228, 271, 275, 416, 436, 351, 231, 158, 113, 78, 73, 64, 61, 32, 46, 27, 36, 38, 30, 36, 29, 33, 32, 16, 21, 18, 12, 12, 19, 13, 4, 6, 2, 3, 4, 0, 4, 2, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 4, 7, 10, 16, 21, 44, 60, 56, 88, 99, 126, 126, 160, 203, 202, 200, 198, 181, 205, 181, 191, 189, 180, 175, 160, 149, 157, 125, 146, 141, 150, 164, 152, 135, 130, 110, 80, 55, 24, 17, 14, 8, 7, 8, 5]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.3, 33.1, 36.6, 40.3, 43.7, 47.1, 50.7, 54.1, 57.4, 60.9, 64.7, 68.6]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 0.0, 49.9, 59.9, 44.9, 62.4, 45.1, 57.5, 67.8, 73.3, 73.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 2, 4, 10, 20, 16, 31, 33, 28, 30, 34]
Epoch 267 Acc: 96.77 BMA: 97.49 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 370 train Loss: 4178.2 test Loss: 489.0
Epoch 268 Iter 0 subLoss 3554.5 multi -1.99 import weight 0.00
Epoch 268 Iter 1 subLoss 4568.3 multi -7.96 import weight 0.00
Epoch 268 Iter 2 subLoss 8650.3 multi 1.00 import weight 0.00
Epoch 268 Iter 3 subLoss 6142.8 multi -4.97 import weight 0.00
Epoch 268 Iter 4 subLoss 13357.1 multi 9.96 import weight 0.00
Epoch 268 Iter 5 subLoss 11949.8 multi 1.00 import weight 0.00
Epoch 268 Iter 6 subLoss 11081.3 multi 3.99 import weight 0.00
Epoch 268 Iter 7 subLoss 7214.9 multi 1.00 import weight 0.00
Epoch 268 Iter 8 subLoss 6300.1 multi 1.00 import weight 0.00
Epoch 268 Iter 9 subLoss 6601.8 multi -1.99 import weight 0.00
Epoch 268 Iter 10 subLoss 7139.0 multi -1.99 import weight 0.00
Epoch 268 Iter 11 subLoss 6386.7 multi -1.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0081 / 0.11226 / 7.72
Entropy seen (from low to high)
[1708, 202, 241, 276, 255, 320, 333, 304, 291, 186, 154, 126, 86, 80, 58, 55, 36, 41, 32, 38, 35, 36, 27, 36, 31, 25, 16, 21, 13, 12, 17, 14, 10, 4, 3, 2, 5, 1, 2, 3, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 4, 7, 12, 17, 27, 51, 60, 62, 95, 103, 135, 124, 190, 198, 224, 220, 181, 194, 208, 196, 206, 191, 185, 163, 145, 169, 144, 129, 162, 145, 139, 154, 144, 121, 112, 84, 47, 35, 19, 16, 14, 9, 5, 8, 5]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.4, 32.4, 36.4, 39.7, 43.3, 47.2, 51.2, 54.6, 57.4, 61.0, 64.5, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 33.3, 39.9, 61.9, 54.5, 51.6, 54.5, 65.2, 68.7, 86.1]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 4, 3, 10, 21, 22, 31, 33, 23, 32, 36]
Epoch 268 Acc: 95.37 BMA: 97.55 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 638 train Loss: 7637.0 test Loss: 861.7
Epoch 269 Iter 0 subLoss 6626.5 multi 1.00 import weight 0.00
Epoch 269 Iter 1 subLoss 7737.7 multi 6.97 import weight 0.00
Epoch 269 Iter 2 subLoss 6954.5 multi 3.99 import weight 0.00
Epoch 269 Iter 3 subLoss 6131.6 multi 3.98 import weight 0.00
Epoch 269 Iter 4 subLoss 6649.7 multi 1.00 import weight 0.00
Epoch 269 Iter 5 subLoss 6193.1 multi 6.97 import weight 0.00
Epoch 269 Iter 6 subLoss 5414.7 multi 1.00 import weight 0.00
Epoch 269 Iter 7 subLoss 6214.2 multi 1.00 import weight 0.00
Epoch 269 Iter 8 subLoss 5891.4 multi 1.00 import weight 0.00
Epoch 269 Iter 9 subLoss 5565.2 multi 15.93 import weight 0.00
Epoch 269 Iter 10 subLoss 5769.1 multi 3.99 import weight 0.00
Epoch 269 Iter 11 subLoss 5233.4 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0081 / 0.11121 / 7.84
Entropy seen (from low to high)
[1707, 217, 250, 291, 252, 320, 278, 267, 283, 210, 152, 139, 100, 79, 59, 58, 48, 31, 42, 37, 31, 36, 28, 37, 34, 24, 19, 19, 14, 11, 15, 14, 13, 3, 2, 3, 6, 1, 3, 2, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 5, 5, 14, 16, 30, 56, 59, 68, 95, 120, 126, 136, 187, 213, 232, 201, 196, 203, 209, 198, 221, 176, 200, 145, 166, 156, 130, 147, 139, 157, 150, 142, 131, 121, 94, 66, 43, 28, 20, 16, 15, 8, 6, 8, 5]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.5, 36.7, 40.8, 43.6, 47.7, 50.5, 54.2, 57.3, 61.1, 64.5, 68.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 24.9, 33.3, 52.6, 52.3, 57.5, 61.1, 54.1, 78.5, 85.2]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 5, 4, 9, 19, 21, 33, 36, 24, 28, 34]
Epoch 269 Acc: 96.98 BMA: 97.65 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 523 train Loss: 5397.0 test Loss: 602.3
Epoch 270 Iter 0 subLoss 5220.4 multi -1.99 import weight 0.00
Epoch 270 Iter 1 subLoss 5777.7 multi -1.99 import weight 0.00
Epoch 270 Iter 2 subLoss 5822.8 multi 1.00 import weight 0.00
Epoch 270 Iter 3 subLoss 5396.2 multi -4.97 import weight 0.00
Epoch 270 Iter 4 subLoss 6468.5 multi 6.97 import weight 0.00
Epoch 270 Iter 5 subLoss 5456.3 multi 1.00 import weight 0.00
Epoch 270 Iter 6 subLoss 5281.2 multi 1.00 import weight 0.00
Epoch 270 Iter 7 subLoss 5680.7 multi -1.98 import weight 0.00
Epoch 270 Iter 8 subLoss 5176.9 multi -4.97 import weight 0.00
Epoch 270 Iter 9 subLoss 5936.1 multi 6.97 import weight 0.00
Epoch 270 Iter 10 subLoss 5475.2 multi -7.96 import weight 0.00
Epoch 270 Iter 11 subLoss 5700.9 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0081 / 0.11037 / 10.11
Entropy seen (from low to high)
[1707, 234, 263, 292, 273, 315, 234, 212, 253, 245, 162, 136, 114, 86, 67, 54, 52, 32, 44, 44, 31, 30, 34, 34, 38, 20, 23, 15, 14, 18, 10, 15, 13, 4, 2, 4, 5, 1, 2, 3, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 7, 4, 15, 18, 35, 58, 58, 71, 99, 117, 125, 157, 191, 219, 229, 196, 204, 211, 208, 219, 199, 192, 180, 150, 174, 134, 140, 147, 152, 141, 143, 145, 124, 114, 80, 55, 45, 22, 22, 17, 15, 8, 5, 9, 5]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.3, 34.9, 36.4, 40.1, 43.9, 47.7, 50.5, 54.4, 57.4, 61.0, 64.7, 68.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 24.9, 66.6, 24.9, 63.6, 59.3, 58.0, 57.5, 57.6, 81.4, 84.8]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 4, 6, 12, 11, 32, 31, 33, 26, 27, 33]
Epoch 270 Acc: 97.08 BMA: 97.66 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 570 train Loss: 5468.7 test Loss: 602.4
Epoch 271 Iter 0 subLoss 5219.6 multi 9.96 import weight 0.00
Epoch 271 Iter 1 subLoss 4979.3 multi 1.00 import weight 0.00
Epoch 271 Iter 2 subLoss 4550.0 multi 3.99 import weight 0.00
Epoch 271 Iter 3 subLoss 5369.0 multi 6.97 import weight 0.00
Epoch 271 Iter 4 subLoss 5247.5 multi 1.00 import weight 0.00
Epoch 271 Iter 5 subLoss 4732.5 multi -4.97 import weight 0.00
Epoch 271 Iter 6 subLoss 5315.5 multi 9.96 import weight 0.00
Epoch 271 Iter 7 subLoss 4254.3 multi -1.99 import weight 0.00
Epoch 271 Iter 8 subLoss 4716.2 multi 6.97 import weight 0.00
Epoch 271 Iter 9 subLoss 4436.0 multi -4.97 import weight 0.00
Epoch 271 Iter 10 subLoss 4659.4 multi 3.99 import weight 0.00
Epoch 271 Iter 11 subLoss 4595.5 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0080 / 0.11012 / 13.13
Entropy seen (from low to high)
[1713, 245, 284, 292, 284, 315, 211, 193, 244, 239, 174, 127, 123, 81, 67, 55, 52, 31, 42, 50, 29, 29, 35, 26, 41, 24, 22, 16, 13, 18, 11, 15, 9, 8, 1, 5, 5, 3, 0, 2, 2, 1, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 7, 5, 15, 16, 42, 52, 64, 69, 102, 113, 120, 172, 183, 227, 228, 189, 228, 194, 204, 219, 212, 187, 183, 156, 171, 130, 138, 140, 151, 143, 145, 141, 119, 113, 77, 53, 43, 25, 23, 20, 13, 8, 5, 9, 5]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.8, 34.2, 37.3, 40.6, 43.9, 47.5, 50.8, 54.4, 57.9, 61.4, 64.8, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 24.9, 83.3, 38.4, 18.1, 65.6, 61.7, 54.5, 66.6, 78.2, 90.9]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 4, 6, 13, 11, 32, 34, 33, 24, 23, 33]
Epoch 271 Acc: 97.70 BMA: 97.66 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 459 train Loss: 4485.2 test Loss: 468.9
Epoch 272 Iter 0 subLoss 4407.1 multi -10.94 import weight 0.00
Epoch 272 Iter 1 subLoss 5348.8 multi -7.96 import weight 0.00
Epoch 272 Iter 2 subLoss 5674.5 multi 6.97 import weight 0.00
Epoch 272 Iter 3 subLoss 5054.9 multi 9.96 import weight 0.00
Epoch 272 Iter 4 subLoss 4471.4 multi 3.98 import weight 0.00
Epoch 272 Iter 5 subLoss 4642.1 multi 9.96 import weight 0.00
Epoch 272 Iter 6 subLoss 4698.1 multi -1.99 import weight 0.00
Epoch 272 Iter 7 subLoss 4267.6 multi -1.99 import weight 0.00
Epoch 272 Iter 8 subLoss 4401.1 multi -7.96 import weight 0.00
Epoch 272 Iter 9 subLoss 4849.6 multi 1.00 import weight 0.00
Epoch 272 Iter 10 subLoss 4519.6 multi 1.00 import weight 0.00
Epoch 272 Iter 11 subLoss 4305.1 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.10984 / 12.80
Entropy seen (from low to high)
[1719, 256, 292, 298, 315, 299, 191, 170, 238, 248, 166, 129, 123, 84, 62, 60, 43, 39, 43, 46, 31, 31, 31, 31, 39, 22, 23, 13, 16, 15, 13, 12, 12, 7, 2, 5, 6, 1, 3, 1, 2, 0, 1, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 7, 6, 15, 20, 37, 52, 69, 73, 106, 110, 135, 176, 187, 221, 213, 206, 218, 199, 205, 215, 213, 179, 194, 156, 147, 139, 135, 140, 148, 146, 145, 147, 108, 106, 83, 47, 47, 22, 20, 22, 17, 9, 4, 10, 5]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.3, 34.3, 36.2, 39.9, 43.4, 47.1, 51.0, 53.9, 57.8, 61.3, 64.5, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 74.9, 56.2, 19.9, 57.6, 65.7, 54.2, 72.7, 76.9, 86.6]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 4, 16, 15, 26, 35, 35, 22, 26, 30]
Epoch 272 Acc: 97.53 BMA: 97.68 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 430 train Loss: 4634.0 test Loss: 485.5
Epoch 273 Iter 0 subLoss 4368.5 multi 3.99 import weight 0.00
Epoch 273 Iter 1 subLoss 4583.8 multi -10.94 import weight 0.00
Epoch 273 Iter 2 subLoss 4822.1 multi 1.00 import weight 0.00
Epoch 273 Iter 3 subLoss 4651.6 multi 3.99 import weight 1.00
Epoch 273 Iter 4 subLoss 4356.1 multi 1.00 import weight 0.00
Epoch 273 Iter 5 subLoss 4575.7 multi 9.96 import weight 1.00
Epoch 273 Iter 6 subLoss 4457.2 multi -1.99 import weight 0.00
Epoch 273 Iter 7 subLoss 4823.1 multi 3.99 import weight 0.00
Epoch 273 Iter 8 subLoss 4068.9 multi -7.96 import weight 0.00
Epoch 273 Iter 9 subLoss 4529.2 multi 3.98 import weight 0.00
Epoch 273 Iter 10 subLoss 4346.9 multi -4.97 import weight 0.00
Epoch 273 Iter 11 subLoss 4685.3 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.10969 / 13.90
Entropy seen (from low to high)
[1727, 268, 306, 299, 327, 292, 165, 165, 238, 234, 172, 137, 122, 79, 62, 55, 47, 39, 47, 40, 33, 32, 31, 30, 40, 20, 23, 12, 15, 15, 14, 12, 13, 4, 5, 4, 6, 1, 3, 1, 2, 0, 1, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 3, 6, 6, 14, 23, 36, 54, 68, 86, 97, 104, 146, 155, 204, 218, 215, 202, 218, 213, 197, 225, 203, 185, 192, 155, 136, 150, 132, 148, 137, 150, 145, 136, 117, 97, 83, 48, 43, 22, 21, 27, 19, 5, 7, 8, 5]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.8, 34.9, 36.4, 41.0, 44.1, 47.2, 51.0, 54.1, 57.5, 61.3, 64.3, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 59.9, 47.3, 49.9, 37.4, 85.1, 54.0, 69.9, 79.3, 89.6]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 5, 19, 10, 32, 27, 37, 20, 29, 29]
Epoch 273 Acc: 97.78 BMA: 97.70 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 468 train Loss: 4617.9 test Loss: 452.8
Epoch 274 Iter 0 subLoss 4357.3 multi 1.00 import weight 0.00
Epoch 274 Iter 1 subLoss 4502.7 multi -1.99 import weight 0.00
Epoch 274 Iter 2 subLoss 4536.5 multi -4.97 import weight 0.00
Epoch 274 Iter 3 subLoss 4472.6 multi 6.97 import weight 0.00
Epoch 274 Iter 4 subLoss 4320.6 multi 3.98 import weight 0.00
Epoch 274 Iter 5 subLoss 4352.3 multi 3.98 import weight 0.00
Epoch 274 Iter 6 subLoss 4483.6 multi -4.97 import weight 0.00
Epoch 274 Iter 7 subLoss 4129.8 multi 9.96 import weight 0.00
Epoch 274 Iter 8 subLoss 4407.8 multi -4.97 import weight 0.00
Epoch 274 Iter 9 subLoss 4472.0 multi 9.96 import weight 0.00
Epoch 274 Iter 10 subLoss 4423.2 multi 9.96 import weight 1.00
Epoch 274 Iter 11 subLoss 3829.3 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0078 / 0.10974 / 12.38
Entropy seen (from low to high)
[1729, 287, 320, 304, 328, 274, 160, 170, 239, 238, 166, 134, 108, 74, 63, 60, 44, 41, 45, 38, 34, 33, 28, 34, 39, 18, 19, 17, 16, 13, 12, 14, 12, 4, 5, 6, 5, 0, 2, 3, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 3, 6, 7, 16, 23, 35, 54, 71, 84, 94, 112, 144, 153, 200, 221, 212, 201, 216, 213, 202, 217, 197, 199, 195, 146, 138, 148, 127, 148, 142, 147, 134, 142, 118, 102, 84, 50, 43, 24, 22, 27, 19, 5, 6, 9, 5]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.4, 34.5, 36.7, 41.3, 44.1, 47.1, 50.8, 54.2, 57.5, 61.2, 64.8, 68.7]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 59.9, 54.9, 28.5, 47.0, 74.0, 61.7, 61.5, 86.2, 92.3]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 5, 20, 7, 34, 27, 34, 26, 29, 26]
Epoch 274 Acc: 97.61 BMA: 97.72 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 382 train Loss: 4398.3 test Loss: 442.5
Epoch 275 Iter 0 subLoss 4151.3 multi -10.94 import weight 0.00
Epoch 275 Iter 1 subLoss 4974.5 multi 3.99 import weight 0.00
Epoch 275 Iter 2 subLoss 4587.4 multi -10.94 import weight 0.00
Epoch 275 Iter 3 subLoss 6195.3 multi 9.96 import weight 0.00
Epoch 275 Iter 4 subLoss 3939.8 multi 3.99 import weight 0.00
Epoch 275 Iter 5 subLoss 4196.3 multi -1.99 import weight 0.00
Epoch 275 Iter 6 subLoss 4230.7 multi -10.94 import weight 0.00
Epoch 275 Iter 7 subLoss 4401.7 multi -1.99 import weight 0.00
Epoch 275 Iter 8 subLoss 4721.5 multi 1.00 import weight 0.00
Epoch 275 Iter 9 subLoss 4217.1 multi -1.98 import weight 0.00
Epoch 275 Iter 10 subLoss 4251.3 multi 1.00 import weight 0.00
Epoch 275 Iter 11 subLoss 4145.0 multi 1.00 import weight 1.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0076 / 0.11822 / 13.29
Entropy seen (from low to high)
[2994, 267, 135, 110, 67, 62, 106, 235, 225, 168, 143, 71, 68, 44, 38, 39, 32, 29, 35, 36, 32, 35, 17, 17, 18, 15, 15, 11, 17, 6, 9, 11, 9, 7, 2, 4, 2, 2, 2, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 0, 3, 6, 13, 23, 37, 36, 65, 70, 82, 103, 142, 146, 196, 219, 178, 170, 172, 174, 170, 208, 202, 179, 148, 152, 155, 182, 165, 169, 164, 154, 152, 139, 128, 98, 85, 64, 60, 36, 33, 30, 41, 45, 37, 29]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.6, 33.5, 36.6, 39.8, 43.4, 47.4, 50.4, 54.1, 57.6, 61.2, 64.4, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 0.0, 49.9, 49.9, 42.8, 52.6, 36.3, 64.7, 65.5, 94.7, 49.9]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 3, 6, 4, 14, 19, 22, 17, 29, 19, 26]
Epoch 275 Acc: 97.55 BMA: 97.55 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 1.00 Pidx 414 train Loss: 4582.5 test Loss: 442.0
Epoch 276 Iter 0 subLoss 4553.4 multi 6.97 import weight 1.00
Epoch 276 Iter 1 subLoss 4099.1 multi -1.99 import weight 0.00
Epoch 276 Iter 2 subLoss 4297.4 multi -7.96 import weight 0.00
Epoch 276 Iter 3 subLoss 4845.6 multi 3.99 import weight 0.00
Epoch 276 Iter 4 subLoss 4323.0 multi 6.97 import weight 0.00
Epoch 276 Iter 5 subLoss 4449.9 multi 1.00 import weight 0.00
Epoch 276 Iter 6 subLoss 4408.8 multi 1.00 import weight 0.00
Epoch 276 Iter 7 subLoss 4273.8 multi -4.97 import weight 0.00
Epoch 276 Iter 8 subLoss 4297.0 multi -4.97 import weight 0.00
Epoch 276 Iter 9 subLoss 4793.3 multi 1.00 import weight 0.00
Epoch 276 Iter 10 subLoss 3873.0 multi 12.94 import weight 0.00
Epoch 276 Iter 11 subLoss 3794.4 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0076 / 0.11822 / 13.29
Entropy seen (from low to high)
[2994, 267, 135, 110, 67, 62, 106, 235, 225, 168, 143, 71, 68, 44, 38, 39, 32, 29, 35, 36, 32, 35, 17, 17, 18, 15, 15, 11, 17, 6, 9, 11, 9, 7, 2, 4, 2, 2, 2, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 0, 3, 6, 13, 23, 37, 36, 65, 70, 82, 103, 142, 146, 196, 219, 178, 170, 172, 174, 170, 208, 202, 179, 148, 152, 155, 182, 165, 169, 164, 154, 152, 139, 128, 98, 85, 64, 60, 36, 33, 30, 41, 45, 37, 29]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.6, 33.5, 36.6, 39.8, 43.4, 47.4, 50.4, 54.1, 57.6, 61.2, 64.4, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 0.0, 49.9, 49.9, 42.8, 52.6, 36.3, 64.7, 65.5, 94.7, 49.9]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 3, 6, 4, 14, 19, 22, 17, 29, 19, 26]
Epoch 276 Acc: 97.61 BMA: 97.55 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 379 train Loss: 4024.3 test Loss: 409.2
Epoch 277 Iter 0 subLoss 3972.4 multi 1.00 import weight 0.00
Epoch 277 Iter 1 subLoss 3673.0 multi -1.99 import weight 0.00
Epoch 277 Iter 2 subLoss 4438.7 multi -4.97 import weight 0.00
Epoch 277 Iter 3 subLoss 4127.4 multi 12.94 import weight 1.00
Epoch 277 Iter 4 subLoss 3718.9 multi -1.98 import weight 0.00
Epoch 277 Iter 5 subLoss 3850.1 multi 6.97 import weight 0.00
Epoch 277 Iter 6 subLoss 3794.4 multi 15.93 import weight 0.00
Epoch 277 Iter 7 subLoss 3486.6 multi 3.99 import weight 0.00
Epoch 277 Iter 8 subLoss 3502.8 multi 1.00 import weight 0.00
Epoch 277 Iter 9 subLoss 3715.1 multi 1.00 import weight 0.00
Epoch 277 Iter 10 subLoss 3467.3 multi 3.99 import weight 0.00
Epoch 277 Iter 11 subLoss 3842.6 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0076 / 0.11822 / 13.29
Entropy seen (from low to high)
[2994, 267, 135, 110, 67, 62, 106, 235, 225, 168, 143, 71, 68, 44, 38, 39, 32, 29, 35, 36, 32, 35, 17, 17, 18, 15, 15, 11, 17, 6, 9, 11, 9, 7, 2, 4, 2, 2, 2, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 0, 3, 6, 13, 23, 37, 36, 65, 70, 82, 103, 142, 146, 196, 219, 178, 170, 172, 174, 170, 208, 202, 179, 148, 152, 155, 182, 165, 169, 164, 154, 152, 139, 128, 98, 85, 64, 60, 36, 33, 30, 41, 45, 37, 29]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.6, 33.5, 36.6, 39.8, 43.4, 47.4, 50.4, 54.1, 57.6, 61.2, 64.4, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 0.0, 49.9, 49.9, 42.8, 52.6, 36.3, 64.7, 65.5, 94.7, 49.9]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 3, 6, 4, 14, 19, 22, 17, 29, 19, 26]
Epoch 277 Acc: 97.78 BMA: 97.55 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 384 train Loss: 3616.3 test Loss: 371.9
Epoch 278 Iter 0 subLoss 3881.4 multi -10.94 import weight 0.00
Epoch 278 Iter 1 subLoss 4020.8 multi 1.00 import weight 0.00
Epoch 278 Iter 2 subLoss 3480.5 multi 6.97 import weight 0.00
Epoch 278 Iter 3 subLoss 3234.2 multi 3.99 import weight 0.00
Epoch 278 Iter 4 subLoss 4040.4 multi 9.96 import weight 0.00
Epoch 278 Iter 5 subLoss 3532.5 multi -1.99 import weight 0.00
Epoch 278 Iter 6 subLoss 3807.5 multi -7.96 import weight 0.00
Epoch 278 Iter 7 subLoss 3477.3 multi -4.97 import weight 0.00
Epoch 278 Iter 8 subLoss 4606.7 multi 3.98 import weight 0.00
Epoch 278 Iter 9 subLoss 3759.2 multi 3.99 import weight 0.00
Epoch 278 Iter 10 subLoss 3313.5 multi 1.00 import weight 0.00
Epoch 278 Iter 11 subLoss 3695.0 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0076 / 0.11822 / 13.29
Entropy seen (from low to high)
[2994, 267, 135, 110, 67, 62, 106, 235, 225, 168, 143, 71, 68, 44, 38, 39, 32, 29, 35, 36, 32, 35, 17, 17, 18, 15, 15, 11, 17, 6, 9, 11, 9, 7, 2, 4, 2, 2, 2, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 0, 3, 6, 13, 23, 37, 36, 65, 70, 82, 103, 142, 146, 196, 219, 178, 170, 172, 174, 170, 208, 202, 179, 148, 152, 155, 182, 165, 169, 164, 154, 152, 139, 128, 98, 85, 64, 60, 36, 33, 30, 41, 45, 37, 29]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.6, 33.5, 36.6, 39.8, 43.4, 47.4, 50.4, 54.1, 57.6, 61.2, 64.4, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 0.0, 49.9, 49.9, 42.8, 52.6, 36.3, 64.7, 65.5, 94.7, 49.9]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 3, 6, 4, 14, 19, 22, 17, 29, 19, 26]
Epoch 278 Acc: 97.92 BMA: 97.55 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 369 train Loss: 3617.2 test Loss: 354.6
Epoch 279 Iter 0 subLoss 2930.4 multi 1.00 import weight 0.00
Epoch 279 Iter 1 subLoss 3183.7 multi 1.00 import weight 0.00
Epoch 279 Iter 2 subLoss 3366.8 multi 1.00 import weight 0.00
Epoch 279 Iter 3 subLoss 3339.9 multi -1.99 import weight 0.00
Epoch 279 Iter 4 subLoss 3610.3 multi 3.99 import weight 0.00
Epoch 279 Iter 5 subLoss 3883.8 multi -7.96 import weight 0.00
Epoch 279 Iter 6 subLoss 3376.7 multi -1.99 import weight 0.00
Epoch 279 Iter 7 subLoss 3904.6 multi 9.96 import weight 0.00
Epoch 279 Iter 8 subLoss 3690.5 multi 12.94 import weight 0.00
Epoch 279 Iter 9 subLoss 4436.3 multi -1.98 import weight 1.00
Epoch 279 Iter 10 subLoss 2893.1 multi 1.00 import weight 0.00
Epoch 279 Iter 11 subLoss 3385.1 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0076 / 0.11822 / 13.29
Entropy seen (from low to high)
[2994, 267, 135, 110, 67, 62, 106, 235, 225, 168, 143, 71, 68, 44, 38, 39, 32, 29, 35, 36, 32, 35, 17, 17, 18, 15, 15, 11, 17, 6, 9, 11, 9, 7, 2, 4, 2, 2, 2, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 0, 3, 6, 13, 23, 37, 36, 65, 70, 82, 103, 142, 146, 196, 219, 178, 170, 172, 174, 170, 208, 202, 179, 148, 152, 155, 182, 165, 169, 164, 154, 152, 139, 128, 98, 85, 64, 60, 36, 33, 30, 41, 45, 37, 29]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.6, 33.5, 36.6, 39.8, 43.4, 47.4, 50.4, 54.1, 57.6, 61.2, 64.4, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 0.0, 49.9, 49.9, 42.8, 52.6, 36.3, 64.7, 65.5, 94.7, 49.9]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 3, 6, 4, 14, 19, 22, 17, 29, 19, 26]
Epoch 279 Acc: 97.65 BMA: 97.55 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 338 train Loss: 3634.7 test Loss: 387.1
Epoch 280 Iter 0 subLoss 3855.0 multi 6.97 import weight 0.00
Epoch 280 Iter 1 subLoss 2984.1 multi 1.00 import weight 0.00
Epoch 280 Iter 2 subLoss 3194.7 multi -1.99 import weight 0.00
Epoch 280 Iter 3 subLoss 3353.3 multi -1.99 import weight 0.00
Epoch 280 Iter 4 subLoss 3472.3 multi -1.98 import weight 0.00
Epoch 280 Iter 5 subLoss 3430.4 multi -4.97 import weight 0.00
Epoch 280 Iter 6 subLoss 4162.5 multi 1.00 import weight 0.00
Epoch 280 Iter 7 subLoss 3723.7 multi 3.99 import weight 0.00
Epoch 280 Iter 8 subLoss 3709.2 multi -7.96 import weight 0.00
Epoch 280 Iter 9 subLoss 3294.8 multi 3.99 import weight 0.00
Epoch 280 Iter 10 subLoss 3559.5 multi 1.00 import weight 0.00
Epoch 280 Iter 11 subLoss 3083.4 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0076 / 0.11822 / 13.29
Entropy seen (from low to high)
[2994, 267, 135, 110, 67, 62, 106, 235, 225, 168, 143, 71, 68, 44, 38, 39, 32, 29, 35, 36, 32, 35, 17, 17, 18, 15, 15, 11, 17, 6, 9, 11, 9, 7, 2, 4, 2, 2, 2, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 0, 3, 6, 13, 23, 37, 36, 65, 70, 82, 103, 142, 146, 196, 219, 178, 170, 172, 174, 170, 208, 202, 179, 148, 152, 155, 182, 165, 169, 164, 154, 152, 139, 128, 98, 85, 64, 60, 36, 33, 30, 41, 45, 37, 29]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.6, 33.5, 36.6, 39.8, 43.4, 47.4, 50.4, 54.1, 57.6, 61.2, 64.4, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 0.0, 49.9, 49.9, 42.8, 52.6, 36.3, 64.7, 65.5, 94.7, 49.9]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 3, 6, 4, 14, 19, 22, 17, 29, 19, 26]
Epoch 280 Acc: 97.84 BMA: 97.55 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 308 train Loss: 3499.1 test Loss: 358.5
Epoch 281 Iter 0 subLoss 3258.4 multi 1.00 import weight 0.00
Epoch 281 Iter 1 subLoss 4221.4 multi 1.00 import weight 0.00
Epoch 281 Iter 2 subLoss 3575.5 multi 9.96 import weight 0.00
Epoch 281 Iter 3 subLoss 3445.6 multi -1.99 import weight 0.00
Epoch 281 Iter 4 subLoss 3191.3 multi 1.00 import weight 0.00
Epoch 281 Iter 5 subLoss 3222.2 multi 1.00 import weight 0.00
Epoch 281 Iter 6 subLoss 3097.9 multi 1.00 import weight 0.00
Epoch 281 Iter 7 subLoss 3241.0 multi -4.97 import weight 0.00
Epoch 281 Iter 8 subLoss 3564.4 multi -4.97 import weight 0.00
Epoch 281 Iter 9 subLoss 3977.2 multi 3.99 import weight 0.00
Epoch 281 Iter 10 subLoss 3395.2 multi -1.99 import weight 0.00
Epoch 281 Iter 11 subLoss 3859.2 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0076 / 0.11822 / 13.29
Entropy seen (from low to high)
[2994, 267, 135, 110, 67, 62, 106, 235, 225, 168, 143, 71, 68, 44, 38, 39, 32, 29, 35, 36, 32, 35, 17, 17, 18, 15, 15, 11, 17, 6, 9, 11, 9, 7, 2, 4, 2, 2, 2, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 0, 3, 6, 13, 23, 37, 36, 65, 70, 82, 103, 142, 146, 196, 219, 178, 170, 172, 174, 170, 208, 202, 179, 148, 152, 155, 182, 165, 169, 164, 154, 152, 139, 128, 98, 85, 64, 60, 36, 33, 30, 41, 45, 37, 29]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.6, 33.5, 36.6, 39.8, 43.4, 47.4, 50.4, 54.1, 57.6, 61.2, 64.4, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 0.0, 49.9, 49.9, 42.8, 52.6, 36.3, 64.7, 65.5, 94.7, 49.9]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 3, 6, 4, 14, 19, 22, 17, 29, 19, 26]
Epoch 281 Acc: 97.78 BMA: 97.55 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 385 train Loss: 3602.5 test Loss: 358.2
Epoch 282 Iter 0 subLoss 3235.8 multi 3.98 import weight 0.00
Epoch 282 Iter 1 subLoss 3430.5 multi -1.98 import weight 0.00
Epoch 282 Iter 2 subLoss 3774.7 multi -1.99 import weight 0.00
Epoch 282 Iter 3 subLoss 3655.7 multi 6.97 import weight 0.00
Epoch 282 Iter 4 subLoss 3138.6 multi 1.00 import weight 0.00
Epoch 282 Iter 5 subLoss 3410.7 multi 1.00 import weight 0.00
Epoch 282 Iter 6 subLoss 3021.7 multi 1.00 import weight 0.00
Epoch 282 Iter 7 subLoss 3627.0 multi -1.98 import weight 0.00
Epoch 282 Iter 8 subLoss 3398.8 multi 1.00 import weight 0.00
Epoch 282 Iter 9 subLoss 3651.9 multi 9.96 import weight 0.00
Epoch 282 Iter 10 subLoss 3709.9 multi -4.97 import weight 0.00
Epoch 282 Iter 11 subLoss 3022.6 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0076 / 0.11822 / 13.29
Entropy seen (from low to high)
[2994, 267, 135, 110, 67, 62, 106, 235, 225, 168, 143, 71, 68, 44, 38, 39, 32, 29, 35, 36, 32, 35, 17, 17, 18, 15, 15, 11, 17, 6, 9, 11, 9, 7, 2, 4, 2, 2, 2, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 0, 3, 6, 13, 23, 37, 36, 65, 70, 82, 103, 142, 146, 196, 219, 178, 170, 172, 174, 170, 208, 202, 179, 148, 152, 155, 182, 165, 169, 164, 154, 152, 139, 128, 98, 85, 64, 60, 36, 33, 30, 41, 45, 37, 29]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.6, 33.5, 36.6, 39.8, 43.4, 47.4, 50.4, 54.1, 57.6, 61.2, 64.4, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 0.0, 49.9, 49.9, 42.8, 52.6, 36.3, 64.7, 65.5, 94.7, 49.9]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 3, 6, 4, 14, 19, 22, 17, 29, 19, 26]
Epoch 282 Acc: 97.90 BMA: 97.55 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 302 train Loss: 3391.5 test Loss: 347.9
Epoch 283 Iter 0 subLoss 3223.0 multi 3.99 import weight 0.00
Epoch 283 Iter 1 subLoss 3433.4 multi 1.00 import weight 0.00
Epoch 283 Iter 2 subLoss 2932.5 multi 3.99 import weight 0.00
Epoch 283 Iter 3 subLoss 2925.2 multi 1.00 import weight 0.00
Epoch 283 Iter 4 subLoss 3928.7 multi 1.00 import weight 0.00
Epoch 283 Iter 5 subLoss 3075.0 multi -1.99 import weight 0.00
Epoch 283 Iter 6 subLoss 2942.5 multi -4.97 import weight 0.00
Epoch 283 Iter 7 subLoss 3344.9 multi 1.00 import weight 0.00
Epoch 283 Iter 8 subLoss 3364.5 multi 1.00 import weight 0.00
Epoch 283 Iter 9 subLoss 2912.4 multi 1.00 import weight 0.00
Epoch 283 Iter 10 subLoss 3100.7 multi -4.97 import weight 0.00
Epoch 283 Iter 11 subLoss 3095.7 multi 3.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0076 / 0.11822 / 13.29
Entropy seen (from low to high)
[2994, 267, 135, 110, 67, 62, 106, 235, 225, 168, 143, 71, 68, 44, 38, 39, 32, 29, 35, 36, 32, 35, 17, 17, 18, 15, 15, 11, 17, 6, 9, 11, 9, 7, 2, 4, 2, 2, 2, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 0, 3, 6, 13, 23, 37, 36, 65, 70, 82, 103, 142, 146, 196, 219, 178, 170, 172, 174, 170, 208, 202, 179, 148, 152, 155, 182, 165, 169, 164, 154, 152, 139, 128, 98, 85, 64, 60, 36, 33, 30, 41, 45, 37, 29]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.6, 33.5, 36.6, 39.8, 43.4, 47.4, 50.4, 54.1, 57.6, 61.2, 64.4, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 0.0, 49.9, 49.9, 42.8, 52.6, 36.3, 64.7, 65.5, 94.7, 49.9]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 3, 6, 4, 14, 19, 22, 17, 29, 19, 26]
Epoch 283 Acc: 97.84 BMA: 97.55 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 309 train Loss: 3303.9 test Loss: 343.2
Epoch 284 Iter 0 subLoss 3045.8 multi 1.00 import weight 0.00
Epoch 284 Iter 1 subLoss 3362.5 multi 3.98 import weight 0.00
Epoch 284 Iter 2 subLoss 3862.2 multi -13.93 import weight 0.00
Epoch 284 Iter 3 subLoss 3762.4 multi 3.99 import weight 0.00
Epoch 284 Iter 4 subLoss 3520.4 multi 3.99 import weight 0.00
Epoch 284 Iter 5 subLoss 3848.2 multi 3.98 import weight 0.00
Epoch 284 Iter 6 subLoss 3168.5 multi 1.00 import weight 0.00
Epoch 284 Iter 7 subLoss 3096.7 multi 6.97 import weight 0.00
Epoch 284 Iter 8 subLoss 3060.0 multi -1.99 import weight 0.00
Epoch 284 Iter 9 subLoss 3381.6 multi 1.00 import weight 0.00
Epoch 284 Iter 10 subLoss 2928.6 multi 1.00 import weight 0.00
Epoch 284 Iter 11 subLoss 3204.5 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0076 / 0.11822 / 13.29
Entropy seen (from low to high)
[2994, 267, 135, 110, 67, 62, 106, 235, 225, 168, 143, 71, 68, 44, 38, 39, 32, 29, 35, 36, 32, 35, 17, 17, 18, 15, 15, 11, 17, 6, 9, 11, 9, 7, 2, 4, 2, 2, 2, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 0, 3, 6, 13, 23, 37, 36, 65, 70, 82, 103, 142, 146, 196, 219, 178, 170, 172, 174, 170, 208, 202, 179, 148, 152, 155, 182, 165, 169, 164, 154, 152, 139, 128, 98, 85, 64, 60, 36, 33, 30, 41, 45, 37, 29]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.6, 33.5, 36.6, 39.8, 43.4, 47.4, 50.4, 54.1, 57.6, 61.2, 64.4, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 0.0, 49.9, 49.9, 42.8, 52.6, 36.3, 64.7, 65.5, 94.7, 49.9]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 3, 6, 4, 14, 19, 22, 17, 29, 19, 26]
Epoch 284 Acc: 97.76 BMA: 97.55 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 320 train Loss: 3521.4 test Loss: 375.4
Epoch 285 Iter 0 subLoss 2787.1 multi 1.00 import weight 0.00
Epoch 285 Iter 1 subLoss 3390.0 multi 1.00 import weight 0.00
Epoch 285 Iter 2 subLoss 3323.2 multi 1.00 import weight 0.00
Epoch 285 Iter 3 subLoss 3360.3 multi 6.97 import weight 0.00
Epoch 285 Iter 4 subLoss 3203.3 multi -1.98 import weight 0.00
Epoch 285 Iter 5 subLoss 2883.0 multi 1.00 import weight 0.00
Epoch 285 Iter 6 subLoss 2967.3 multi 1.00 import weight 0.00
Epoch 285 Iter 7 subLoss 2916.4 multi 3.99 import weight 0.00
Epoch 285 Iter 8 subLoss 3101.1 multi -7.96 import weight 0.00
Epoch 285 Iter 9 subLoss 3698.9 multi 15.93 import weight 0.00
Epoch 285 Iter 10 subLoss 3236.0 multi 3.99 import weight 0.00
Epoch 285 Iter 11 subLoss 3789.8 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0076 / 0.11822 / 13.29
Entropy seen (from low to high)
[2994, 267, 135, 110, 67, 62, 106, 235, 225, 168, 143, 71, 68, 44, 38, 39, 32, 29, 35, 36, 32, 35, 17, 17, 18, 15, 15, 11, 17, 6, 9, 11, 9, 7, 2, 4, 2, 2, 2, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 0, 3, 6, 13, 23, 37, 36, 65, 70, 82, 103, 142, 146, 196, 219, 178, 170, 172, 174, 170, 208, 202, 179, 148, 152, 155, 182, 165, 169, 164, 154, 152, 139, 128, 98, 85, 64, 60, 36, 33, 30, 41, 45, 37, 29]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.6, 33.5, 36.6, 39.8, 43.4, 47.4, 50.4, 54.1, 57.6, 61.2, 64.4, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 0.0, 49.9, 49.9, 42.8, 52.6, 36.3, 64.7, 65.5, 94.7, 49.9]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 3, 6, 4, 14, 19, 22, 17, 29, 19, 26]
Epoch 285 Acc: 97.84 BMA: 97.55 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 378 train Loss: 3452.4 test Loss: 352.7
Epoch 286 Iter 0 subLoss 3861.4 multi -10.94 import weight 0.00
Epoch 286 Iter 1 subLoss 4690.5 multi -1.98 import weight 0.00
Epoch 286 Iter 2 subLoss 6259.6 multi 1.00 import weight 0.00
Epoch 286 Iter 3 subLoss 4262.2 multi -1.99 import weight 0.00
Epoch 286 Iter 4 subLoss 5768.1 multi 6.97 import weight 0.00
Epoch 286 Iter 5 subLoss 3220.1 multi 6.97 import weight 0.00
Epoch 286 Iter 6 subLoss 3321.0 multi 3.98 import weight 0.00
Epoch 286 Iter 7 subLoss 3265.3 multi -1.99 import weight 0.00
Epoch 286 Iter 8 subLoss 3201.0 multi 1.00 import weight 0.00
Epoch 286 Iter 9 subLoss 3262.9 multi 1.00 import weight 0.00
Epoch 286 Iter 10 subLoss 3226.7 multi 9.96 import weight 0.00
Epoch 286 Iter 11 subLoss 3318.9 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0076 / 0.11822 / 13.29
Entropy seen (from low to high)
[2994, 267, 135, 110, 67, 62, 106, 235, 225, 168, 143, 71, 68, 44, 38, 39, 32, 29, 35, 36, 32, 35, 17, 17, 18, 15, 15, 11, 17, 6, 9, 11, 9, 7, 2, 4, 2, 2, 2, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 0, 3, 6, 13, 23, 37, 36, 65, 70, 82, 103, 142, 146, 196, 219, 178, 170, 172, 174, 170, 208, 202, 179, 148, 152, 155, 182, 165, 169, 164, 154, 152, 139, 128, 98, 85, 64, 60, 36, 33, 30, 41, 45, 37, 29]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.6, 33.5, 36.6, 39.8, 43.4, 47.4, 50.4, 54.1, 57.6, 61.2, 64.4, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 0.0, 49.9, 49.9, 42.8, 52.6, 36.3, 64.7, 65.5, 94.7, 49.9]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 3, 6, 4, 14, 19, 22, 17, 29, 19, 26]
Epoch 286 Acc: 98.00 BMA: 97.55 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 331 train Loss: 3281.3 test Loss: 326.6
Epoch 287 Iter 0 subLoss 3264.0 multi 3.98 import weight 0.00
Epoch 287 Iter 1 subLoss 2723.3 multi 1.00 import weight 0.00
Epoch 287 Iter 2 subLoss 3115.2 multi -4.97 import weight 0.00
Epoch 287 Iter 3 subLoss 2904.6 multi -1.99 import weight 0.00
Epoch 287 Iter 4 subLoss 3353.1 multi -1.98 import weight 0.00
Epoch 287 Iter 5 subLoss 3201.2 multi 3.99 import weight 0.00
Epoch 287 Iter 6 subLoss 3139.8 multi 3.99 import weight 0.00
Epoch 287 Iter 7 subLoss 3000.1 multi 1.00 import weight 0.00
Epoch 287 Iter 8 subLoss 2815.4 multi 1.00 import weight 0.00
Epoch 287 Iter 9 subLoss 3205.4 multi 6.97 import weight 0.00
Epoch 287 Iter 10 subLoss 3551.8 multi 3.98 import weight 0.00
Epoch 287 Iter 11 subLoss 2939.8 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0076 / 0.11822 / 13.29
Entropy seen (from low to high)
[2994, 267, 135, 110, 67, 62, 106, 235, 225, 168, 143, 71, 68, 44, 38, 39, 32, 29, 35, 36, 32, 35, 17, 17, 18, 15, 15, 11, 17, 6, 9, 11, 9, 7, 2, 4, 2, 2, 2, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 0, 3, 6, 13, 23, 37, 36, 65, 70, 82, 103, 142, 146, 196, 219, 178, 170, 172, 174, 170, 208, 202, 179, 148, 152, 155, 182, 165, 169, 164, 154, 152, 139, 128, 98, 85, 64, 60, 36, 33, 30, 41, 45, 37, 29]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.6, 33.5, 36.6, 39.8, 43.4, 47.4, 50.4, 54.1, 57.6, 61.2, 64.4, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 0.0, 49.9, 49.9, 42.8, 52.6, 36.3, 64.7, 65.5, 94.7, 49.9]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 3, 6, 4, 14, 19, 22, 17, 29, 19, 26]
Epoch 287 Acc: 98.15 BMA: 97.55 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 293 train Loss: 3127.7 test Loss: 307.8
Epoch 288 Iter 0 subLoss 3602.9 multi -7.96 import weight 0.00
Epoch 288 Iter 1 subLoss 2874.4 multi 1.00 import weight 0.00
Epoch 288 Iter 2 subLoss 3604.8 multi -4.97 import weight 0.00
Epoch 288 Iter 3 subLoss 3692.9 multi 18.91 import weight 0.00
Epoch 288 Iter 4 subLoss 4676.5 multi 1.00 import weight 0.00
Epoch 288 Iter 5 subLoss 4711.7 multi 9.96 import weight 0.00
Epoch 288 Iter 6 subLoss 3949.7 multi 1.00 import weight 0.00
Epoch 288 Iter 7 subLoss 3432.8 multi 3.99 import weight 0.00
Epoch 288 Iter 8 subLoss 3023.3 multi 6.97 import weight 0.00
Epoch 288 Iter 9 subLoss 3041.9 multi 3.99 import weight 0.00
Epoch 288 Iter 10 subLoss 3360.9 multi 6.97 import weight 0.00
Epoch 288 Iter 11 subLoss 3124.1 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0076 / 0.11822 / 13.29
Entropy seen (from low to high)
[2994, 267, 135, 110, 67, 62, 106, 235, 225, 168, 143, 71, 68, 44, 38, 39, 32, 29, 35, 36, 32, 35, 17, 17, 18, 15, 15, 11, 17, 6, 9, 11, 9, 7, 2, 4, 2, 2, 2, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 0, 3, 6, 13, 23, 37, 36, 65, 70, 82, 103, 142, 146, 196, 219, 178, 170, 172, 174, 170, 208, 202, 179, 148, 152, 155, 182, 165, 169, 164, 154, 152, 139, 128, 98, 85, 64, 60, 36, 33, 30, 41, 45, 37, 29]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.6, 33.5, 36.6, 39.8, 43.4, 47.4, 50.4, 54.1, 57.6, 61.2, 64.4, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 0.0, 49.9, 49.9, 42.8, 52.6, 36.3, 64.7, 65.5, 94.7, 49.9]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 3, 6, 4, 14, 19, 22, 17, 29, 19, 26]
Epoch 288 Acc: 98.02 BMA: 97.55 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 312 train Loss: 3090.7 test Loss: 312.0
Epoch 289 Iter 0 subLoss 2820.7 multi -1.99 import weight 0.00
Epoch 289 Iter 1 subLoss 2836.4 multi -1.99 import weight 0.00
Epoch 289 Iter 2 subLoss 2782.8 multi 3.99 import weight 0.00
Epoch 289 Iter 3 subLoss 2672.1 multi 1.00 import weight 0.00
Epoch 289 Iter 4 subLoss 3426.5 multi 3.98 import weight 0.00
Epoch 289 Iter 5 subLoss 2927.1 multi 1.00 import weight 0.00
Epoch 289 Iter 6 subLoss 3584.0 multi -7.96 import weight 0.00
Epoch 289 Iter 7 subLoss 3665.3 multi -10.94 import weight 0.00
Epoch 289 Iter 8 subLoss 3738.1 multi -4.97 import weight 0.00
Epoch 289 Iter 9 subLoss 7814.5 multi 6.97 import weight 0.00
Epoch 289 Iter 10 subLoss 11375.3 multi 1.00 import weight 0.00
Epoch 289 Iter 11 subLoss 5558.1 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0076 / 0.11822 / 13.29
Entropy seen (from low to high)
[2994, 267, 135, 110, 67, 62, 106, 235, 225, 168, 143, 71, 68, 44, 38, 39, 32, 29, 35, 36, 32, 35, 17, 17, 18, 15, 15, 11, 17, 6, 9, 11, 9, 7, 2, 4, 2, 2, 2, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 0, 3, 6, 13, 23, 37, 36, 65, 70, 82, 103, 142, 146, 196, 219, 178, 170, 172, 174, 170, 208, 202, 179, 148, 152, 155, 182, 165, 169, 164, 154, 152, 139, 128, 98, 85, 64, 60, 36, 33, 30, 41, 45, 37, 29]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.6, 33.5, 36.6, 39.8, 43.4, 47.4, 50.4, 54.1, 57.6, 61.2, 64.4, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 0.0, 49.9, 49.9, 42.8, 52.6, 36.3, 64.7, 65.5, 94.7, 49.9]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 3, 6, 4, 14, 19, 22, 17, 29, 19, 26]
Epoch 289 Acc: 89.53 BMA: 97.55 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 555 train Loss: 10299.7 test Loss: 1792.3
Epoch 290 Iter 0 subLoss 9927.9 multi 6.97 import weight 0.00
Epoch 290 Iter 1 subLoss 6526.0 multi -1.99 import weight 0.00
Epoch 290 Iter 2 subLoss 11654.7 multi -1.98 import weight 0.00
Epoch 290 Iter 3 subLoss 35805.6 multi 3.99 import weight 0.00
Epoch 290 Iter 4 subLoss 8514.7 multi -10.94 import weight 0.00
Epoch 290 Iter 5 subLoss 49288.5 multi 1.00 import weight 0.00
Epoch 290 Iter 6 subLoss 10449.1 multi -7.96 import weight 0.00
Epoch 290 Iter 7 subLoss 50066.7 multi 1.00 import weight 0.00
Epoch 290 Iter 8 subLoss 16630.4 multi 1.00 import weight 0.00
Epoch 290 Iter 9 subLoss 14449.0 multi -1.99 import weight 0.00
Epoch 290 Iter 10 subLoss 19032.4 multi 1.00 import weight 0.00
Epoch 290 Iter 11 subLoss 14424.5 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0076 / 0.11822 / 13.29
Entropy seen (from low to high)
[2994, 267, 135, 110, 67, 62, 106, 235, 225, 168, 143, 71, 68, 44, 38, 39, 32, 29, 35, 36, 32, 35, 17, 17, 18, 15, 15, 11, 17, 6, 9, 11, 9, 7, 2, 4, 2, 2, 2, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 0, 3, 6, 13, 23, 37, 36, 65, 70, 82, 103, 142, 146, 196, 219, 178, 170, 172, 174, 170, 208, 202, 179, 148, 152, 155, 182, 165, 169, 164, 154, 152, 139, 128, 98, 85, 64, 60, 36, 33, 30, 41, 45, 37, 29]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.6, 33.5, 36.6, 39.8, 43.4, 47.4, 50.4, 54.1, 57.6, 61.2, 64.4, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 0.0, 49.9, 49.9, 42.8, 52.6, 36.3, 64.7, 65.5, 94.7, 49.9]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 3, 6, 4, 14, 19, 22, 17, 29, 19, 26]
Epoch 290 Acc: 81.34 BMA: 97.55 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 1442 train Loss: 20741.0 test Loss: 2991.3
Epoch 291 Iter 0 subLoss 19795.1 multi 1.00 import weight 0.00
Epoch 291 Iter 1 subLoss 15493.7 multi 3.99 import weight 0.00
Epoch 291 Iter 2 subLoss 9341.3 multi 1.00 import weight 0.00
Epoch 291 Iter 3 subLoss 8559.0 multi 6.97 import weight 0.00
Epoch 291 Iter 4 subLoss 7083.9 multi 3.98 import weight 0.00
Epoch 291 Iter 5 subLoss 5917.5 multi 3.99 import weight 0.00
Epoch 291 Iter 6 subLoss 5231.1 multi -4.97 import weight 0.00
Epoch 291 Iter 7 subLoss 6760.3 multi -7.96 import weight 0.00
Epoch 291 Iter 8 subLoss 8374.4 multi -4.97 import weight 0.00
Epoch 291 Iter 9 subLoss 8490.4 multi 3.99 import weight 0.00
Epoch 291 Iter 10 subLoss 7412.3 multi 3.99 import weight 0.00
Epoch 291 Iter 11 subLoss 6802.8 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0076 / 0.11822 / 13.29
Entropy seen (from low to high)
[2994, 267, 135, 110, 67, 62, 106, 235, 225, 168, 143, 71, 68, 44, 38, 39, 32, 29, 35, 36, 32, 35, 17, 17, 18, 15, 15, 11, 17, 6, 9, 11, 9, 7, 2, 4, 2, 2, 2, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 0, 3, 6, 13, 23, 37, 36, 65, 70, 82, 103, 142, 146, 196, 219, 178, 170, 172, 174, 170, 208, 202, 179, 148, 152, 155, 182, 165, 169, 164, 154, 152, 139, 128, 98, 85, 64, 60, 36, 33, 30, 41, 45, 37, 29]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.6, 33.5, 36.6, 39.8, 43.4, 47.4, 50.4, 54.1, 57.6, 61.2, 64.4, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 0.0, 49.9, 49.9, 42.8, 52.6, 36.3, 64.7, 65.5, 94.7, 49.9]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 3, 6, 4, 14, 19, 22, 17, 29, 19, 26]
Epoch 291 Acc: 93.99 BMA: 97.55 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 680 train Loss: 6682.8 test Loss: 1049.0
Epoch 292 Iter 0 subLoss 6469.5 multi 9.96 import weight 0.00
Epoch 292 Iter 1 subLoss 6120.6 multi 3.99 import weight 0.00
Epoch 292 Iter 2 subLoss 4752.5 multi 3.99 import weight 0.00
Epoch 292 Iter 3 subLoss 5422.1 multi -1.99 import weight 0.00
Epoch 292 Iter 4 subLoss 5394.1 multi -1.99 import weight 0.00
Epoch 292 Iter 5 subLoss 5312.4 multi 12.94 import weight 0.00
Epoch 292 Iter 6 subLoss 4341.6 multi -1.98 import weight 0.00
Epoch 292 Iter 7 subLoss 4287.3 multi 12.94 import weight 0.00
Epoch 292 Iter 8 subLoss 4244.9 multi 3.99 import weight 0.00
Epoch 292 Iter 9 subLoss 4120.3 multi 15.93 import weight 1.00
Epoch 292 Iter 10 subLoss 3823.5 multi -1.98 import weight 0.00
Epoch 292 Iter 11 subLoss 4429.2 multi 12.94 import weight 1.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 292 Acc: 96.91 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 12.94 Pidx 442 train Loss: 4346.8 test Loss: 558.7
Epoch 293 Iter 0 subLoss 4589.7 multi -7.96 import weight 0.00
Epoch 293 Iter 1 subLoss 6941.8 multi -1.99 import weight 0.00
Epoch 293 Iter 2 subLoss 9335.8 multi 1.00 import weight 0.00
Epoch 293 Iter 3 subLoss 7011.5 multi 1.00 import weight 0.00
Epoch 293 Iter 4 subLoss 5484.8 multi -1.99 import weight 0.00
Epoch 293 Iter 5 subLoss 6999.0 multi 1.00 import weight 0.00
Epoch 293 Iter 6 subLoss 6335.2 multi 3.99 import weight 0.00
Epoch 293 Iter 7 subLoss 3945.4 multi 3.98 import weight 0.00
Epoch 293 Iter 8 subLoss 3504.7 multi 3.99 import weight 0.00
Epoch 293 Iter 9 subLoss 3657.4 multi 12.94 import weight 0.00
Epoch 293 Iter 10 subLoss 3514.1 multi -4.97 import weight 0.00
Epoch 293 Iter 11 subLoss 3658.5 multi 15.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 293 Acc: 97.74 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 15.93 Pidx 365 train Loss: 3471.8 test Loss: 383.6
Epoch 294 Iter 0 subLoss 3315.2 multi 6.97 import weight 0.00
Epoch 294 Iter 1 subLoss 3728.2 multi 6.97 import weight 0.00
Epoch 294 Iter 2 subLoss 3272.2 multi -4.97 import weight 0.00
Epoch 294 Iter 3 subLoss 3197.2 multi 3.98 import weight 0.00
Epoch 294 Iter 4 subLoss 3254.9 multi 1.00 import weight 0.00
Epoch 294 Iter 5 subLoss 3569.0 multi -4.97 import weight 0.00
Epoch 294 Iter 6 subLoss 3086.7 multi 1.00 import weight 0.00
Epoch 294 Iter 7 subLoss 3107.5 multi -4.97 import weight 0.00
Epoch 294 Iter 8 subLoss 3577.8 multi 6.97 import weight 0.00
Epoch 294 Iter 9 subLoss 3548.5 multi 1.00 import weight 0.00
Epoch 294 Iter 10 subLoss 3381.2 multi 3.98 import weight 0.00
Epoch 294 Iter 11 subLoss 3172.4 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 294 Acc: 97.80 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 317 train Loss: 3337.7 test Loss: 368.1
Epoch 295 Iter 0 subLoss 3461.2 multi 6.97 import weight 0.00
Epoch 295 Iter 1 subLoss 2948.1 multi -4.97 import weight 0.00
Epoch 295 Iter 2 subLoss 3424.8 multi 6.97 import weight 0.00
Epoch 295 Iter 3 subLoss 3601.9 multi -1.99 import weight 0.00
Epoch 295 Iter 4 subLoss 3506.4 multi 6.97 import weight 0.00
Epoch 295 Iter 5 subLoss 3309.1 multi -4.97 import weight 0.00
Epoch 295 Iter 6 subLoss 2894.8 multi 1.00 import weight 0.00
Epoch 295 Iter 7 subLoss 3209.5 multi 6.97 import weight 0.00
Epoch 295 Iter 8 subLoss 2796.6 multi -4.97 import weight 0.00
Epoch 295 Iter 9 subLoss 3423.0 multi 9.96 import weight 0.00
Epoch 295 Iter 10 subLoss 3358.3 multi 1.00 import weight 0.00
Epoch 295 Iter 11 subLoss 3425.1 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 295 Acc: 97.35 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 342 train Loss: 3460.5 test Loss: 411.6
Epoch 296 Iter 0 subLoss 3742.1 multi -10.94 import weight 0.00
Epoch 296 Iter 1 subLoss 5246.2 multi 1.00 import weight 0.00
Epoch 296 Iter 2 subLoss 4080.3 multi 1.00 import weight 0.00
Epoch 296 Iter 3 subLoss 5092.0 multi -10.94 import weight 0.00
Epoch 296 Iter 4 subLoss 12353.5 multi 3.98 import weight 0.00
Epoch 296 Iter 5 subLoss 4745.7 multi -1.99 import weight 0.00
Epoch 296 Iter 6 subLoss 5082.9 multi 12.94 import weight 1.00
Epoch 296 Iter 7 subLoss 3408.2 multi -7.96 import weight 0.00
Epoch 296 Iter 8 subLoss 4530.2 multi -1.99 import weight 0.00
Epoch 296 Iter 9 subLoss 5391.5 multi 1.00 import weight 0.00
Epoch 296 Iter 10 subLoss 4185.6 multi 1.00 import weight 0.00
Epoch 296 Iter 11 subLoss 4159.7 multi -10.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 296 Acc: 83.46 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -10.94 Pidx 415 train Loss: 15750.9 test Loss: 2516.8
Epoch 297 Iter 0 subLoss 15330.2 multi 3.99 import weight 0.00
Epoch 297 Iter 1 subLoss 6887.0 multi -19.90 import weight 0.00
Epoch 297 Iter 2 subLoss 180643.2 multi 1.00 import weight 0.00
Epoch 297 Iter 3 subLoss 16625.5 multi -4.97 import weight 0.00
Epoch 297 Iter 4 subLoss 76570.3 multi 1.00 import weight 0.00
Epoch 297 Iter 5 subLoss 20988.1 multi 3.98 import weight 0.00
Epoch 297 Iter 6 subLoss 10964.2 multi 6.97 import weight 0.00
Epoch 297 Iter 7 subLoss 7027.8 multi -1.98 import weight 0.00
Epoch 297 Iter 8 subLoss 8962.0 multi -1.99 import weight 0.00
Epoch 297 Iter 9 subLoss 9531.7 multi -1.99 import weight 0.00
Epoch 297 Iter 10 subLoss 14491.1 multi -1.99 import weight 0.00
Epoch 297 Iter 11 subLoss 25342.1 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 297 Acc: 95.74 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 2534 train Loss: 8553.4 test Loss: 902.6
Epoch 298 Iter 0 subLoss 8066.7 multi -7.96 import weight 0.00
Epoch 298 Iter 1 subLoss 16002.9 multi 1.00 import weight 0.00
Epoch 298 Iter 2 subLoss 14333.5 multi 9.96 import weight 0.00
Epoch 298 Iter 3 subLoss 6533.2 multi 9.96 import weight 0.00
Epoch 298 Iter 4 subLoss 5320.9 multi -4.97 import weight 0.00
Epoch 298 Iter 5 subLoss 5891.6 multi 3.99 import weight 0.00
Epoch 298 Iter 6 subLoss 4647.8 multi 12.94 import weight 0.00
Epoch 298 Iter 7 subLoss 4145.9 multi 3.98 import weight 1.00
Epoch 298 Iter 8 subLoss 4285.6 multi 15.93 import weight 0.00
Epoch 298 Iter 9 subLoss 4536.5 multi 1.00 import weight 0.00
Epoch 298 Iter 10 subLoss 3654.5 multi 18.91 import weight 0.00
Epoch 298 Iter 11 subLoss 3962.7 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 298 Acc: 97.88 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 396 train Loss: 3838.6 test Loss: 375.8
Epoch 299 Iter 0 subLoss 4128.8 multi 18.91 import weight 1.00
Epoch 299 Iter 1 subLoss 4357.5 multi 3.99 import weight 0.00
Epoch 299 Iter 2 subLoss 3163.0 multi 3.99 import weight 0.00
Epoch 299 Iter 3 subLoss 3151.9 multi 1.00 import weight 0.00
Epoch 299 Iter 4 subLoss 3413.3 multi 1.00 import weight 0.00
Epoch 299 Iter 5 subLoss 3367.2 multi 6.97 import weight 0.00
Epoch 299 Iter 6 subLoss 3510.7 multi -4.97 import weight 0.00
Epoch 299 Iter 7 subLoss 3319.0 multi 6.97 import weight 0.00
Epoch 299 Iter 8 subLoss 3619.2 multi -1.99 import weight 0.00
Epoch 299 Iter 9 subLoss 3105.8 multi -1.99 import weight 0.00
Epoch 299 Iter 10 subLoss 3410.2 multi 3.98 import weight 0.00
Epoch 299 Iter 11 subLoss 3003.7 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 299 Acc: 97.94 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 300 train Loss: 3257.6 test Loss: 344.6
Epoch 300 Iter 0 subLoss 2720.5 multi 3.99 import weight 0.00
Epoch 300 Iter 1 subLoss 3193.8 multi 6.97 import weight 0.00
Epoch 300 Iter 2 subLoss 3469.8 multi 9.96 import weight 0.00
Epoch 300 Iter 3 subLoss 3391.6 multi 1.00 import weight 0.00
Epoch 300 Iter 4 subLoss 2647.1 multi 1.00 import weight 0.00
Epoch 300 Iter 5 subLoss 3586.1 multi -7.96 import weight 0.00
Epoch 300 Iter 6 subLoss 3667.8 multi -16.91 import weight 0.00
Epoch 300 Iter 7 subLoss 4129.4 multi 21.90 import weight 1.00
Epoch 300 Iter 8 subLoss 5266.0 multi 9.96 import weight 0.00
Epoch 300 Iter 9 subLoss 4774.8 multi -13.93 import weight 0.00
Epoch 300 Iter 10 subLoss 12502.4 multi -4.97 import weight 0.00
Epoch 300 Iter 11 subLoss 44206.9 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 300 Acc: 79.30 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4420 train Loss: 19182.0 test Loss: 4387.9
Epoch 301 Iter 0 subLoss 19623.7 multi 1.00 import weight 0.00
Epoch 301 Iter 1 subLoss 14381.2 multi 1.00 import weight 0.00
Epoch 301 Iter 2 subLoss 11408.2 multi -7.96 import weight 0.00
Epoch 301 Iter 3 subLoss 33306.3 multi 1.00 import weight 0.00
Epoch 301 Iter 4 subLoss 24653.5 multi -1.98 import weight 0.00
Epoch 301 Iter 5 subLoss 39080.6 multi 1.00 import weight 0.00
Epoch 301 Iter 6 subLoss 25972.5 multi -4.97 import weight 0.00
Epoch 301 Iter 7 subLoss 73631.1 multi 1.00 import weight 0.00
Epoch 301 Iter 8 subLoss 39511.8 multi 1.00 import weight 0.00
Epoch 301 Iter 9 subLoss 30744.4 multi 1.00 import weight 0.00
Epoch 301 Iter 10 subLoss 28012.5 multi -4.97 import weight 0.00
Epoch 301 Iter 11 subLoss 53158.1 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 301 Acc: 77.72 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 5315 train Loss: 40163.6 test Loss: 7358.2
Epoch 302 Iter 0 subLoss 39549.1 multi 1.00 import weight 0.00
Epoch 302 Iter 1 subLoss 32307.0 multi 3.99 import weight 0.00
Epoch 302 Iter 2 subLoss 18639.5 multi 3.98 import weight 0.00
Epoch 302 Iter 3 subLoss 15507.6 multi -1.98 import weight 0.00
Epoch 302 Iter 4 subLoss 16756.2 multi -1.99 import weight 0.00
Epoch 302 Iter 5 subLoss 18464.6 multi -1.99 import weight 0.00
Epoch 302 Iter 6 subLoss 19758.3 multi 1.00 import weight 0.00
Epoch 302 Iter 7 subLoss 18111.6 multi 1.00 import weight 0.00
Epoch 302 Iter 8 subLoss 18816.8 multi -1.99 import weight 0.00
Epoch 302 Iter 9 subLoss 19073.2 multi -4.97 import weight 0.00
Epoch 302 Iter 10 subLoss 24777.1 multi -1.99 import weight 0.00
Epoch 302 Iter 11 subLoss 27646.9 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 302 Acc: 78.36 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2764 train Loss: 25883.9 test Loss: 4516.7
Epoch 303 Iter 0 subLoss 24049.7 multi 1.00 import weight 0.00
Epoch 303 Iter 1 subLoss 23648.5 multi -1.99 import weight 0.00
Epoch 303 Iter 2 subLoss 28134.4 multi -1.99 import weight 0.00
Epoch 303 Iter 3 subLoss 31237.7 multi 1.00 import weight 0.00
Epoch 303 Iter 4 subLoss 28865.2 multi -1.99 import weight 0.00
Epoch 303 Iter 5 subLoss 32019.0 multi 1.00 import weight 0.00
Epoch 303 Iter 6 subLoss 28825.8 multi -1.99 import weight 0.00
Epoch 303 Iter 7 subLoss 34510.1 multi 3.99 import weight 0.00
Epoch 303 Iter 8 subLoss 21739.1 multi 6.97 import weight 0.00
Epoch 303 Iter 9 subLoss 19212.9 multi 1.00 import weight 0.00
Epoch 303 Iter 10 subLoss 19041.8 multi -1.99 import weight 0.00
Epoch 303 Iter 11 subLoss 20313.6 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 303 Acc: 77.97 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 2031 train Loss: 22748.7 test Loss: 3819.8
Epoch 304 Iter 0 subLoss 22659.8 multi 1.00 import weight 0.00
Epoch 304 Iter 1 subLoss 20782.1 multi -1.99 import weight 0.00
Epoch 304 Iter 2 subLoss 21819.7 multi -1.99 import weight 0.00
Epoch 304 Iter 3 subLoss 23930.1 multi 1.00 import weight 0.00
Epoch 304 Iter 4 subLoss 22205.5 multi -1.99 import weight 0.00
Epoch 304 Iter 5 subLoss 25324.5 multi 1.00 import weight 0.00
Epoch 304 Iter 6 subLoss 24269.6 multi -1.99 import weight 0.00
Epoch 304 Iter 7 subLoss 26042.6 multi 1.00 import weight 0.00
Epoch 304 Iter 8 subLoss 23877.5 multi -4.97 import weight 0.00
Epoch 304 Iter 9 subLoss 31039.8 multi 1.00 import weight 0.00
Epoch 304 Iter 10 subLoss 27911.3 multi 1.00 import weight 0.00
Epoch 304 Iter 11 subLoss 25690.1 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 304 Acc: 77.29 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2569 train Loss: 24916.7 test Loss: 4074.8
Epoch 305 Iter 0 subLoss 24061.9 multi 1.00 import weight 0.00
Epoch 305 Iter 1 subLoss 24962.4 multi -4.97 import weight 0.00
Epoch 305 Iter 2 subLoss 27148.6 multi -4.97 import weight 0.00
Epoch 305 Iter 3 subLoss 40897.1 multi 1.00 import weight 0.00
Epoch 305 Iter 4 subLoss 32264.5 multi 1.00 import weight 0.00
Epoch 305 Iter 5 subLoss 29982.9 multi 1.00 import weight 0.00
Epoch 305 Iter 6 subLoss 27558.8 multi 1.00 import weight 0.00
Epoch 305 Iter 7 subLoss 26929.7 multi 1.00 import weight 0.00
Epoch 305 Iter 8 subLoss 25018.2 multi 1.00 import weight 0.00
Epoch 305 Iter 9 subLoss 24559.1 multi 3.99 import weight 0.00
Epoch 305 Iter 10 subLoss 23210.6 multi 1.00 import weight 0.00
Epoch 305 Iter 11 subLoss 21333.9 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 305 Acc: 77.76 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 2133 train Loss: 25849.1 test Loss: 4159.6
Epoch 306 Iter 0 subLoss 24705.7 multi 1.00 import weight 0.00
Epoch 306 Iter 1 subLoss 25034.0 multi 6.97 import weight 0.00
Epoch 306 Iter 2 subLoss 21746.2 multi -7.96 import weight 0.00
Epoch 306 Iter 3 subLoss 24712.9 multi -1.99 import weight 0.00
Epoch 306 Iter 4 subLoss 26299.6 multi 3.99 import weight 0.00
Epoch 306 Iter 5 subLoss 23190.2 multi -1.99 import weight 0.00
Epoch 306 Iter 6 subLoss 23555.6 multi 1.00 import weight 0.00
Epoch 306 Iter 7 subLoss 24168.5 multi 1.00 import weight 0.00
Epoch 306 Iter 8 subLoss 24475.3 multi 1.00 import weight 0.00
Epoch 306 Iter 9 subLoss 22215.4 multi -1.99 import weight 0.00
Epoch 306 Iter 10 subLoss 24417.2 multi 3.99 import weight 0.00
Epoch 306 Iter 11 subLoss 22779.1 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 306 Acc: 78.30 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2277 train Loss: 22726.4 test Loss: 3766.1
Epoch 307 Iter 0 subLoss 22273.8 multi -1.99 import weight 0.00
Epoch 307 Iter 1 subLoss 23599.1 multi 6.97 import weight 0.00
Epoch 307 Iter 2 subLoss 21624.0 multi 1.00 import weight 0.00
Epoch 307 Iter 3 subLoss 19478.1 multi 1.00 import weight 0.00
Epoch 307 Iter 4 subLoss 19963.6 multi 1.00 import weight 0.00
Epoch 307 Iter 5 subLoss 20693.2 multi -7.96 import weight 0.00
Epoch 307 Iter 6 subLoss 23222.2 multi -1.99 import weight 0.00
Epoch 307 Iter 7 subLoss 21870.2 multi -1.99 import weight 0.00
Epoch 307 Iter 8 subLoss 23797.2 multi 1.00 import weight 0.00
Epoch 307 Iter 9 subLoss 22294.1 multi 1.00 import weight 0.00
Epoch 307 Iter 10 subLoss 22714.2 multi 6.97 import weight 0.00
Epoch 307 Iter 11 subLoss 21377.8 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 307 Acc: 78.46 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2137 train Loss: 21384.7 test Loss: 3552.1
Epoch 308 Iter 0 subLoss 20448.5 multi 1.00 import weight 0.00
Epoch 308 Iter 1 subLoss 21149.0 multi -1.99 import weight 0.00
Epoch 308 Iter 2 subLoss 21583.5 multi 6.97 import weight 0.00
Epoch 308 Iter 3 subLoss 21296.1 multi -1.99 import weight 0.00
Epoch 308 Iter 4 subLoss 20700.5 multi -1.99 import weight 0.00
Epoch 308 Iter 5 subLoss 19635.9 multi -1.99 import weight 0.00
Epoch 308 Iter 6 subLoss 21500.7 multi 1.00 import weight 0.00
Epoch 308 Iter 7 subLoss 20360.9 multi 1.00 import weight 0.00
Epoch 308 Iter 8 subLoss 21352.4 multi 1.00 import weight 0.00
Epoch 308 Iter 9 subLoss 20800.1 multi 6.97 import weight 0.00
Epoch 308 Iter 10 subLoss 19349.1 multi 1.00 import weight 0.00
Epoch 308 Iter 11 subLoss 19261.5 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 308 Acc: 78.63 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 1926 train Loss: 20388.7 test Loss: 3370.9
Epoch 309 Iter 0 subLoss 19647.0 multi 1.00 import weight 0.00
Epoch 309 Iter 1 subLoss 19751.3 multi 3.98 import weight 0.00
Epoch 309 Iter 2 subLoss 18762.1 multi 1.00 import weight 0.00
Epoch 309 Iter 3 subLoss 17944.1 multi -1.98 import weight 0.00
Epoch 309 Iter 4 subLoss 19070.6 multi -1.98 import weight 0.00
Epoch 309 Iter 5 subLoss 19308.6 multi 1.00 import weight 0.00
Epoch 309 Iter 6 subLoss 20305.3 multi -1.99 import weight 0.00
Epoch 309 Iter 7 subLoss 19580.3 multi 3.99 import weight 0.00
Epoch 309 Iter 8 subLoss 19349.8 multi 3.99 import weight 0.00
Epoch 309 Iter 9 subLoss 17453.9 multi 3.98 import weight 0.00
Epoch 309 Iter 10 subLoss 15971.2 multi 1.00 import weight 0.00
Epoch 309 Iter 11 subLoss 17062.3 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 309 Acc: 79.68 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 1706 train Loss: 15634.4 test Loss: 2540.6
Epoch 310 Iter 0 subLoss 15002.2 multi 3.99 import weight 0.00
Epoch 310 Iter 1 subLoss 13808.9 multi 3.99 import weight 0.00
Epoch 310 Iter 2 subLoss 12567.4 multi 3.99 import weight 0.00
Epoch 310 Iter 3 subLoss 10988.1 multi 1.00 import weight 0.00
Epoch 310 Iter 4 subLoss 10624.4 multi 1.00 import weight 0.00
Epoch 310 Iter 5 subLoss 9505.2 multi 3.98 import weight 0.00
Epoch 310 Iter 6 subLoss 8356.7 multi -7.96 import weight 0.00
Epoch 310 Iter 7 subLoss 10844.5 multi 3.98 import weight 0.00
Epoch 310 Iter 8 subLoss 9686.4 multi 1.00 import weight 0.00
Epoch 310 Iter 9 subLoss 9574.8 multi -7.96 import weight 0.00
Epoch 310 Iter 10 subLoss 10286.5 multi 3.98 import weight 0.00
Epoch 310 Iter 11 subLoss 9961.4 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 310 Acc: 91.22 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 996 train Loss: 9984.7 test Loss: 1319.5
Epoch 311 Iter 0 subLoss 9639.1 multi 1.00 import weight 0.00
Epoch 311 Iter 1 subLoss 9233.5 multi 3.99 import weight 0.00
Epoch 311 Iter 2 subLoss 9247.2 multi -10.94 import weight 0.00
Epoch 311 Iter 3 subLoss 11654.7 multi 1.00 import weight 0.00
Epoch 311 Iter 4 subLoss 11857.8 multi -4.97 import weight 0.00
Epoch 311 Iter 5 subLoss 12677.9 multi 3.98 import weight 0.00
Epoch 311 Iter 6 subLoss 11195.0 multi 3.98 import weight 0.00
Epoch 311 Iter 7 subLoss 11108.6 multi 1.00 import weight 0.00
Epoch 311 Iter 8 subLoss 9922.5 multi 9.96 import weight 0.00
Epoch 311 Iter 9 subLoss 7643.4 multi -7.96 import weight 0.00
Epoch 311 Iter 10 subLoss 9787.4 multi -4.97 import weight 0.00
Epoch 311 Iter 11 subLoss 10191.8 multi -16.91 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 311 Acc: 78.79 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -16.91 Pidx 1019 train Loss: 22897.1 test Loss: 3231.9
Epoch 312 Iter 0 subLoss 23864.3 multi 6.97 import weight 0.00
Epoch 312 Iter 1 subLoss 29599.1 multi -1.99 import weight 0.00
Epoch 312 Iter 2 subLoss 56949.4 multi 1.00 import weight 0.00
Epoch 312 Iter 3 subLoss 49658.5 multi 1.00 import weight 0.00
Epoch 312 Iter 4 subLoss 37344.6 multi 1.00 import weight 0.00
Epoch 312 Iter 5 subLoss 26520.5 multi 1.00 import weight 0.00
Epoch 312 Iter 6 subLoss 18861.6 multi -7.96 import weight 0.00
Epoch 312 Iter 7 subLoss 55535.5 multi 1.00 import weight 0.00
Epoch 312 Iter 8 subLoss 51329.4 multi 1.00 import weight 0.00
Epoch 312 Iter 9 subLoss 47381.7 multi 3.99 import weight 0.00
Epoch 312 Iter 10 subLoss 35080.0 multi 1.00 import weight 0.00
Epoch 312 Iter 11 subLoss 29679.4 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 312 Acc: 62.00 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2967 train Loss: 26914.6 test Loss: 4873.9
Epoch 313 Iter 0 subLoss 27811.5 multi 1.00 import weight 0.00
Epoch 313 Iter 1 subLoss 25582.9 multi -1.99 import weight 0.00
Epoch 313 Iter 2 subLoss 29072.1 multi 3.99 import weight 0.00
Epoch 313 Iter 3 subLoss 21423.2 multi 3.99 import weight 0.00
Epoch 313 Iter 4 subLoss 16103.5 multi -1.99 import weight 0.00
Epoch 313 Iter 5 subLoss 18402.0 multi 1.00 import weight 0.00
Epoch 313 Iter 6 subLoss 16818.9 multi 3.99 import weight 0.00
Epoch 313 Iter 7 subLoss 13132.2 multi -4.97 import weight 0.00
Epoch 313 Iter 8 subLoss 16933.5 multi 1.00 import weight 0.00
Epoch 313 Iter 9 subLoss 16485.4 multi -1.99 import weight 0.00
Epoch 313 Iter 10 subLoss 17700.1 multi -1.98 import weight 0.00
Epoch 313 Iter 11 subLoss 18889.0 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 313 Acc: 72.95 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1888 train Loss: 18673.5 test Loss: 3045.4
Epoch 314 Iter 0 subLoss 18288.8 multi -4.97 import weight 0.00
Epoch 314 Iter 1 subLoss 22933.7 multi 1.00 import weight 0.00
Epoch 314 Iter 2 subLoss 21434.6 multi 1.00 import weight 0.00
Epoch 314 Iter 3 subLoss 21100.6 multi 1.00 import weight 0.00
Epoch 314 Iter 4 subLoss 20128.7 multi 3.99 import weight 0.00
Epoch 314 Iter 5 subLoss 17037.6 multi 6.97 import weight 0.00
Epoch 314 Iter 6 subLoss 14213.3 multi 3.99 import weight 0.00
Epoch 314 Iter 7 subLoss 12499.0 multi -1.99 import weight 0.00
Epoch 314 Iter 8 subLoss 14217.8 multi 6.97 import weight 0.00
Epoch 314 Iter 9 subLoss 14076.6 multi 1.00 import weight 0.00
Epoch 314 Iter 10 subLoss 13474.0 multi -1.98 import weight 0.00
Epoch 314 Iter 11 subLoss 14518.0 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 314 Acc: 80.35 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1451 train Loss: 13918.0 test Loss: 2352.3
Epoch 315 Iter 0 subLoss 13259.3 multi -1.98 import weight 0.00
Epoch 315 Iter 1 subLoss 15692.2 multi 6.97 import weight 0.00
Epoch 315 Iter 2 subLoss 10420.0 multi -1.99 import weight 0.00
Epoch 315 Iter 3 subLoss 10434.8 multi 1.00 import weight 0.00
Epoch 315 Iter 4 subLoss 10756.0 multi 6.97 import weight 0.00
Epoch 315 Iter 5 subLoss 8166.4 multi 1.00 import weight 0.00
Epoch 315 Iter 6 subLoss 8593.8 multi 6.97 import weight 0.00
Epoch 315 Iter 7 subLoss 6586.7 multi 3.99 import weight 0.00
Epoch 315 Iter 8 subLoss 6574.0 multi 6.97 import weight 0.00
Epoch 315 Iter 9 subLoss 5809.4 multi -7.96 import weight 0.00
Epoch 315 Iter 10 subLoss 6558.0 multi 1.00 import weight 0.00
Epoch 315 Iter 11 subLoss 6800.5 multi 3.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 315 Acc: 97.30 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 680 train Loss: 6083.1 test Loss: 597.6
Epoch 316 Iter 0 subLoss 5838.7 multi -1.99 import weight 0.00
Epoch 316 Iter 1 subLoss 5955.9 multi 9.96 import weight 0.00
Epoch 316 Iter 2 subLoss 5065.4 multi -1.98 import weight 0.00
Epoch 316 Iter 3 subLoss 5997.3 multi -1.98 import weight 0.00
Epoch 316 Iter 4 subLoss 5653.7 multi -4.97 import weight 0.00
Epoch 316 Iter 5 subLoss 5830.0 multi 3.99 import weight 0.00
Epoch 316 Iter 6 subLoss 6030.5 multi 6.97 import weight 0.00
Epoch 316 Iter 7 subLoss 4766.5 multi 1.00 import weight 0.00
Epoch 316 Iter 8 subLoss 5041.9 multi -10.94 import weight 0.00
Epoch 316 Iter 9 subLoss 5986.8 multi 1.00 import weight 0.00
Epoch 316 Iter 10 subLoss 5758.0 multi 1.00 import weight 0.00
Epoch 316 Iter 11 subLoss 5750.9 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 316 Acc: 97.51 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 575 train Loss: 5438.9 test Loss: 534.7
Epoch 317 Iter 0 subLoss 5431.9 multi -4.97 import weight 0.00
Epoch 317 Iter 1 subLoss 5572.6 multi -10.94 import weight 0.00
Epoch 317 Iter 2 subLoss 7006.6 multi -1.98 import weight 0.00
Epoch 317 Iter 3 subLoss 7267.8 multi 3.99 import weight 0.00
Epoch 317 Iter 4 subLoss 6681.8 multi -4.97 import weight 0.00
Epoch 317 Iter 5 subLoss 6957.9 multi 3.98 import weight 0.00
Epoch 317 Iter 6 subLoss 6513.0 multi 6.97 import weight 0.00
Epoch 317 Iter 7 subLoss 5850.3 multi 9.96 import weight 0.00
Epoch 317 Iter 8 subLoss 5140.6 multi -4.97 import weight 0.00
Epoch 317 Iter 9 subLoss 5730.2 multi -4.97 import weight 0.00
Epoch 317 Iter 10 subLoss 5885.7 multi 6.97 import weight 0.00
Epoch 317 Iter 11 subLoss 5030.3 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 317 Acc: 97.61 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 503 train Loss: 4867.1 test Loss: 480.7
Epoch 318 Iter 0 subLoss 5092.9 multi -10.94 import weight 0.00
Epoch 318 Iter 1 subLoss 6769.7 multi -4.97 import weight 0.00
Epoch 318 Iter 2 subLoss 7470.3 multi -1.98 import weight 0.00
Epoch 318 Iter 3 subLoss 8907.8 multi 1.00 import weight 0.00
Epoch 318 Iter 4 subLoss 7792.6 multi -1.99 import weight 0.00
Epoch 318 Iter 5 subLoss 10480.2 multi 6.97 import weight 0.00
Epoch 318 Iter 6 subLoss 5680.8 multi -1.99 import weight 0.00
Epoch 318 Iter 7 subLoss 5886.2 multi 9.96 import weight 0.00
Epoch 318 Iter 8 subLoss 5272.9 multi -10.94 import weight 0.00
Epoch 318 Iter 9 subLoss 5833.1 multi -1.99 import weight 0.00
Epoch 318 Iter 10 subLoss 6318.5 multi -4.97 import weight 0.00
Epoch 318 Iter 11 subLoss 6943.0 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 318 Acc: 95.31 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 694 train Loss: 6806.4 test Loss: 801.2
Epoch 319 Iter 0 subLoss 6219.9 multi 3.99 import weight 0.00
Epoch 319 Iter 1 subLoss 6332.6 multi 6.97 import weight 0.00
Epoch 319 Iter 2 subLoss 5306.8 multi 1.00 import weight 0.00
Epoch 319 Iter 3 subLoss 5352.2 multi -1.98 import weight 0.00
Epoch 319 Iter 4 subLoss 5472.2 multi -4.97 import weight 0.00
Epoch 319 Iter 5 subLoss 6331.7 multi 9.96 import weight 0.00
Epoch 319 Iter 6 subLoss 5729.8 multi 9.96 import weight 0.00
Epoch 319 Iter 7 subLoss 4911.1 multi 18.91 import weight 0.00
Epoch 319 Iter 8 subLoss 3725.3 multi 9.96 import weight 0.00
Epoch 319 Iter 9 subLoss 3715.2 multi -1.99 import weight 0.00
Epoch 319 Iter 10 subLoss 3765.5 multi 6.97 import weight 0.00
Epoch 319 Iter 11 subLoss 3729.4 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 319 Acc: 97.98 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 372 train Loss: 3550.7 test Loss: 345.9
Epoch 320 Iter 0 subLoss 3499.9 multi -7.96 import weight 0.00
Epoch 320 Iter 1 subLoss 3545.0 multi 3.98 import weight 0.00
Epoch 320 Iter 2 subLoss 3343.8 multi 3.98 import weight 0.00
Epoch 320 Iter 3 subLoss 3489.2 multi 3.99 import weight 0.00
Epoch 320 Iter 4 subLoss 3512.8 multi -1.99 import weight 0.00
Epoch 320 Iter 5 subLoss 3730.4 multi -10.94 import weight 0.00
Epoch 320 Iter 6 subLoss 3456.0 multi -1.99 import weight 0.00
Epoch 320 Iter 7 subLoss 3251.7 multi 3.98 import weight 0.00
Epoch 320 Iter 8 subLoss 3663.6 multi -13.93 import weight 0.00
Epoch 320 Iter 9 subLoss 4312.6 multi -7.96 import weight 0.00
Epoch 320 Iter 10 subLoss 4234.7 multi -10.94 import weight 0.00
Epoch 320 Iter 11 subLoss 5045.1 multi -10.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 320 Acc: 89.63 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -10.94 Pidx 504 train Loss: 12673.3 test Loss: 1610.3
Epoch 321 Iter 0 subLoss 11470.4 multi 3.98 import weight 0.00
Epoch 321 Iter 1 subLoss 5374.0 multi -1.99 import weight 0.00
Epoch 321 Iter 2 subLoss 6566.8 multi -1.99 import weight 0.00
Epoch 321 Iter 3 subLoss 7890.3 multi -1.99 import weight 0.00
Epoch 321 Iter 4 subLoss 12663.6 multi -4.97 import weight 0.00
Epoch 321 Iter 5 subLoss 232176.2 multi 1.00 import weight 0.00
Epoch 321 Iter 6 subLoss 15639.3 multi -4.97 import weight 0.00
Epoch 321 Iter 7 subLoss 57220.9 multi 1.00 import weight 0.00
Epoch 321 Iter 8 subLoss 27679.0 multi 3.98 import weight 0.00
Epoch 321 Iter 9 subLoss 10600.2 multi 3.99 import weight 0.00
Epoch 321 Iter 10 subLoss 9128.4 multi -4.97 import weight 0.00
Epoch 321 Iter 11 subLoss 10015.6 multi -1.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 321 Acc: 85.37 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 1001 train Loss: 11502.8 test Loss: 2543.4
Epoch 322 Iter 0 subLoss 12210.9 multi 9.96 import weight 0.00
Epoch 322 Iter 1 subLoss 7217.7 multi 3.99 import weight 0.00
Epoch 322 Iter 2 subLoss 6453.1 multi -1.98 import weight 0.00
Epoch 322 Iter 3 subLoss 7281.8 multi -1.99 import weight 0.00
Epoch 322 Iter 4 subLoss 8020.3 multi -1.98 import weight 0.00
Epoch 322 Iter 5 subLoss 7719.6 multi 1.00 import weight 0.00
Epoch 322 Iter 6 subLoss 8147.3 multi -1.98 import weight 0.00
Epoch 322 Iter 7 subLoss 8238.5 multi 1.00 import weight 0.00
Epoch 322 Iter 8 subLoss 8259.9 multi 1.00 import weight 0.00
Epoch 322 Iter 9 subLoss 7459.3 multi 6.97 import weight 0.00
Epoch 322 Iter 10 subLoss 6868.1 multi 1.00 import weight 0.00
Epoch 322 Iter 11 subLoss 6369.1 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 322 Acc: 93.77 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 636 train Loss: 6306.5 test Loss: 1001.9
Epoch 323 Iter 0 subLoss 6491.1 multi -1.98 import weight 0.00
Epoch 323 Iter 1 subLoss 5866.7 multi -7.96 import weight 0.00
Epoch 323 Iter 2 subLoss 8370.6 multi -1.98 import weight 0.00
Epoch 323 Iter 3 subLoss 8006.0 multi -1.98 import weight 0.00
Epoch 323 Iter 4 subLoss 8684.5 multi -7.96 import weight 0.00
Epoch 323 Iter 5 subLoss 9829.5 multi 3.98 import weight 0.00
Epoch 323 Iter 6 subLoss 9507.7 multi 6.97 import weight 0.00
Epoch 323 Iter 7 subLoss 7011.3 multi 1.00 import weight 0.00
Epoch 323 Iter 8 subLoss 6929.8 multi 9.96 import weight 0.00
Epoch 323 Iter 9 subLoss 6083.5 multi 3.98 import weight 0.00
Epoch 323 Iter 10 subLoss 6224.5 multi -1.99 import weight 0.00
Epoch 323 Iter 11 subLoss 6332.8 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 323 Acc: 96.22 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 633 train Loss: 5105.7 test Loss: 649.1
Epoch 324 Iter 0 subLoss 5253.0 multi -4.97 import weight 0.00
Epoch 324 Iter 1 subLoss 6031.9 multi 9.96 import weight 0.00
Epoch 324 Iter 2 subLoss 4479.4 multi 12.94 import weight 0.00
Epoch 324 Iter 3 subLoss 4549.6 multi -4.97 import weight 0.00
Epoch 324 Iter 4 subLoss 4528.1 multi 6.97 import weight 0.00
Epoch 324 Iter 5 subLoss 4209.3 multi 3.98 import weight 0.00
Epoch 324 Iter 6 subLoss 3913.2 multi -7.96 import weight 0.00
Epoch 324 Iter 7 subLoss 4061.7 multi -4.97 import weight 0.00
Epoch 324 Iter 8 subLoss 4821.9 multi 6.97 import weight 0.00
Epoch 324 Iter 9 subLoss 4086.1 multi 3.98 import weight 0.00
Epoch 324 Iter 10 subLoss 4308.2 multi -1.98 import weight 0.00
Epoch 324 Iter 11 subLoss 4052.7 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 324 Acc: 97.53 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 405 train Loss: 4136.0 test Loss: 449.2
Epoch 325 Iter 0 subLoss 4134.2 multi -10.94 import weight 0.00
Epoch 325 Iter 1 subLoss 4872.5 multi 3.99 import weight 0.00
Epoch 325 Iter 2 subLoss 4151.0 multi -10.94 import weight 0.00
Epoch 325 Iter 3 subLoss 4652.3 multi 3.98 import weight 0.00
Epoch 325 Iter 4 subLoss 4499.0 multi 3.99 import weight 0.00
Epoch 325 Iter 5 subLoss 4444.4 multi -1.98 import weight 0.00
Epoch 325 Iter 6 subLoss 4452.8 multi -4.97 import weight 0.00
Epoch 325 Iter 7 subLoss 4747.1 multi 1.00 import weight 0.00
Epoch 325 Iter 8 subLoss 4564.2 multi -10.94 import weight 0.00
Epoch 325 Iter 9 subLoss 4912.0 multi 21.90 import weight 0.00
Epoch 325 Iter 10 subLoss 4200.0 multi 6.97 import weight 0.00
Epoch 325 Iter 11 subLoss 3644.1 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 325 Acc: 97.45 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 364 train Loss: 4001.2 test Loss: 430.0
Epoch 326 Iter 0 subLoss 3802.2 multi -4.97 import weight 0.00
Epoch 326 Iter 1 subLoss 4035.5 multi -4.97 import weight 0.00
Epoch 326 Iter 2 subLoss 4237.9 multi -7.96 import weight 0.00
Epoch 326 Iter 3 subLoss 5212.9 multi 12.94 import weight 0.00
Epoch 326 Iter 4 subLoss 4113.5 multi -7.96 import weight 0.00
Epoch 326 Iter 5 subLoss 5218.2 multi 15.93 import weight 0.00
Epoch 326 Iter 6 subLoss 5345.4 multi -4.97 import weight 0.00
Epoch 326 Iter 7 subLoss 7477.4 multi 1.00 import weight 0.00
Epoch 326 Iter 8 subLoss 5820.8 multi 6.97 import weight 0.00
Epoch 326 Iter 9 subLoss 4194.0 multi -1.98 import weight 0.00
Epoch 326 Iter 10 subLoss 4105.5 multi 6.97 import weight 0.00
Epoch 326 Iter 11 subLoss 3997.8 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 326 Acc: 97.88 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 399 train Loss: 3600.6 test Loss: 363.5
Epoch 327 Iter 0 subLoss 3673.2 multi -7.96 import weight 0.00
Epoch 327 Iter 1 subLoss 4147.8 multi 3.99 import weight 0.00
Epoch 327 Iter 2 subLoss 3499.5 multi -7.96 import weight 0.00
Epoch 327 Iter 3 subLoss 4295.1 multi -7.96 import weight 0.00
Epoch 327 Iter 4 subLoss 4886.5 multi 1.00 import weight 0.00
Epoch 327 Iter 5 subLoss 4335.8 multi 3.98 import weight 0.00
Epoch 327 Iter 6 subLoss 4153.8 multi -10.94 import weight 0.00
Epoch 327 Iter 7 subLoss 4341.3 multi -1.99 import weight 0.00
Epoch 327 Iter 8 subLoss 4961.6 multi 1.00 import weight 0.00
Epoch 327 Iter 9 subLoss 5413.1 multi 3.99 import weight 0.00
Epoch 327 Iter 10 subLoss 4033.2 multi -1.99 import weight 0.00
Epoch 327 Iter 11 subLoss 3970.4 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 327 Acc: 97.70 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 397 train Loss: 4075.6 test Loss: 408.9
Epoch 328 Iter 0 subLoss 4375.0 multi -4.97 import weight 0.00
Epoch 328 Iter 1 subLoss 4534.6 multi 1.00 import weight 0.00
Epoch 328 Iter 2 subLoss 4727.2 multi 1.00 import weight 0.00
Epoch 328 Iter 3 subLoss 3832.9 multi -1.98 import weight 0.00
Epoch 328 Iter 4 subLoss 4285.5 multi 18.91 import weight 0.00
Epoch 328 Iter 5 subLoss 3695.1 multi 21.90 import weight 0.00
Epoch 328 Iter 6 subLoss 4043.5 multi 6.97 import weight 0.00
Epoch 328 Iter 7 subLoss 3143.4 multi -4.97 import weight 0.00
Epoch 328 Iter 8 subLoss 3502.9 multi 3.99 import weight 0.00
Epoch 328 Iter 9 subLoss 3084.3 multi 3.98 import weight 0.00
Epoch 328 Iter 10 subLoss 3103.1 multi 1.00 import weight 0.00
Epoch 328 Iter 11 subLoss 3135.4 multi 3.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 328 Acc: 98.03 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 313 train Loss: 3409.6 test Loss: 328.5
Epoch 329 Iter 0 subLoss 2961.7 multi 3.99 import weight 0.00
Epoch 329 Iter 1 subLoss 3270.4 multi -1.99 import weight 0.00
Epoch 329 Iter 2 subLoss 3667.1 multi -10.94 import weight 0.00
Epoch 329 Iter 3 subLoss 3442.8 multi -7.96 import weight 0.00
Epoch 329 Iter 4 subLoss 3223.0 multi 12.94 import weight 0.00
Epoch 329 Iter 5 subLoss 3624.5 multi -1.99 import weight 0.00
Epoch 329 Iter 6 subLoss 3237.2 multi -1.98 import weight 0.00
Epoch 329 Iter 7 subLoss 3487.3 multi 6.97 import weight 0.00
Epoch 329 Iter 8 subLoss 3668.8 multi -7.96 import weight 0.00
Epoch 329 Iter 9 subLoss 3373.3 multi -13.93 import weight 0.00
Epoch 329 Iter 10 subLoss 4995.4 multi 6.97 import weight 0.00
Epoch 329 Iter 11 subLoss 3535.9 multi -1.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 329 Acc: 98.03 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 353 train Loss: 3669.0 test Loss: 342.4
Epoch 330 Iter 0 subLoss 2963.1 multi 6.97 import weight 0.00
Epoch 330 Iter 1 subLoss 3446.6 multi -4.97 import weight 0.00
Epoch 330 Iter 2 subLoss 3289.6 multi -7.96 import weight 0.00
Epoch 330 Iter 3 subLoss 4123.8 multi 21.90 import weight 1.00
Epoch 330 Iter 4 subLoss 3626.2 multi 1.00 import weight 0.00
Epoch 330 Iter 5 subLoss 3648.7 multi 3.98 import weight 0.00
Epoch 330 Iter 6 subLoss 3375.3 multi -10.94 import weight 0.00
Epoch 330 Iter 7 subLoss 3016.6 multi -4.97 import weight 0.00
Epoch 330 Iter 8 subLoss 3884.8 multi -4.97 import weight 0.00
Epoch 330 Iter 9 subLoss 4109.9 multi 9.96 import weight 0.00
Epoch 330 Iter 10 subLoss 3182.7 multi 1.00 import weight 0.00
Epoch 330 Iter 11 subLoss 4455.1 multi -1.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 330 Acc: 97.61 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 445 train Loss: 3675.6 test Loss: 391.7
Epoch 331 Iter 0 subLoss 3828.9 multi 1.00 import weight 0.00
Epoch 331 Iter 1 subLoss 3573.0 multi 9.96 import weight 0.00
Epoch 331 Iter 2 subLoss 3557.0 multi 1.00 import weight 0.00
Epoch 331 Iter 3 subLoss 2683.6 multi -1.99 import weight 0.00
Epoch 331 Iter 4 subLoss 3715.1 multi 1.00 import weight 0.00
Epoch 331 Iter 5 subLoss 3243.0 multi -10.94 import weight 0.00
Epoch 331 Iter 6 subLoss 3583.7 multi -7.96 import weight 0.00
Epoch 331 Iter 7 subLoss 3853.2 multi 9.96 import weight 0.00
Epoch 331 Iter 8 subLoss 3292.2 multi 3.98 import weight 0.00
Epoch 331 Iter 9 subLoss 3449.2 multi -1.99 import weight 0.00
Epoch 331 Iter 10 subLoss 3103.3 multi 3.98 import weight 0.00
Epoch 331 Iter 11 subLoss 3465.8 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 331 Acc: 98.09 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 346 train Loss: 3307.9 test Loss: 324.3
Epoch 332 Iter 0 subLoss 3251.0 multi 3.99 import weight 0.00
Epoch 332 Iter 1 subLoss 2955.0 multi -4.97 import weight 0.00
Epoch 332 Iter 2 subLoss 3444.2 multi 1.00 import weight 0.00
Epoch 332 Iter 3 subLoss 3575.1 multi 12.94 import weight 0.00
Epoch 332 Iter 4 subLoss 3432.7 multi -4.97 import weight 0.00
Epoch 332 Iter 5 subLoss 3051.1 multi -1.98 import weight 0.00
Epoch 332 Iter 6 subLoss 2976.8 multi -7.96 import weight 0.00
Epoch 332 Iter 7 subLoss 3668.1 multi -4.97 import weight 0.00
Epoch 332 Iter 8 subLoss 3663.6 multi -1.98 import weight 0.00
Epoch 332 Iter 9 subLoss 4212.7 multi -4.97 import weight 0.00
Epoch 332 Iter 10 subLoss 6361.7 multi 3.99 import weight 0.00
Epoch 332 Iter 11 subLoss 3121.6 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 332 Acc: 97.74 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 312 train Loss: 3591.9 test Loss: 378.0
Epoch 333 Iter 0 subLoss 3560.8 multi -4.97 import weight 0.00
Epoch 333 Iter 1 subLoss 3823.6 multi 3.99 import weight 0.00
Epoch 333 Iter 2 subLoss 3432.0 multi -1.99 import weight 0.00
Epoch 333 Iter 3 subLoss 3534.4 multi 1.00 import weight 0.00
Epoch 333 Iter 4 subLoss 3776.4 multi -4.97 import weight 0.00
Epoch 333 Iter 5 subLoss 3955.5 multi -10.94 import weight 0.00
Epoch 333 Iter 6 subLoss 5327.5 multi -1.99 import weight 0.00
Epoch 333 Iter 7 subLoss 6325.4 multi 3.98 import weight 0.00
Epoch 333 Iter 8 subLoss 3888.8 multi -1.99 import weight 0.00
Epoch 333 Iter 9 subLoss 4600.0 multi 6.97 import weight 0.00
Epoch 333 Iter 10 subLoss 3429.0 multi 9.96 import weight 0.00
Epoch 333 Iter 11 subLoss 3291.1 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 333 Acc: 98.15 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 329 train Loss: 3526.3 test Loss: 319.4
Epoch 334 Iter 0 subLoss 3596.2 multi -1.99 import weight 0.00
Epoch 334 Iter 1 subLoss 3292.4 multi 9.96 import weight 0.00
Epoch 334 Iter 2 subLoss 3501.4 multi 6.97 import weight 0.00
Epoch 334 Iter 3 subLoss 3136.1 multi 3.99 import weight 0.00
Epoch 334 Iter 4 subLoss 3065.3 multi -1.98 import weight 0.00
Epoch 334 Iter 5 subLoss 3517.4 multi -4.97 import weight 0.00
Epoch 334 Iter 6 subLoss 3897.8 multi -13.93 import weight 0.00
Epoch 334 Iter 7 subLoss 3163.9 multi 3.98 import weight 0.00
Epoch 334 Iter 8 subLoss 3580.7 multi -7.96 import weight 0.00
Epoch 334 Iter 9 subLoss 3431.1 multi -1.99 import weight 0.00
Epoch 334 Iter 10 subLoss 3180.7 multi 3.98 import weight 0.00
Epoch 334 Iter 11 subLoss 3611.3 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 334 Acc: 97.96 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 361 train Loss: 3622.5 test Loss: 326.1
Epoch 335 Iter 0 subLoss 3757.2 multi 3.98 import weight 0.00
Epoch 335 Iter 1 subLoss 3088.1 multi 6.97 import weight 0.00
Epoch 335 Iter 2 subLoss 2592.5 multi 1.00 import weight 0.00
Epoch 335 Iter 3 subLoss 3192.2 multi 3.99 import weight 0.00
Epoch 335 Iter 4 subLoss 3236.9 multi 1.00 import weight 0.00
Epoch 335 Iter 5 subLoss 3189.9 multi 6.97 import weight 0.00
Epoch 335 Iter 6 subLoss 3016.4 multi -1.98 import weight 0.00
Epoch 335 Iter 7 subLoss 3709.5 multi -10.94 import weight 0.00
Epoch 335 Iter 8 subLoss 3378.9 multi -7.96 import weight 0.00
Epoch 335 Iter 9 subLoss 3084.6 multi 9.96 import weight 0.00
Epoch 335 Iter 10 subLoss 3777.9 multi -1.98 import weight 0.00
Epoch 335 Iter 11 subLoss 3262.6 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 335 Acc: 98.02 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 326 train Loss: 3538.7 test Loss: 311.8
Epoch 336 Iter 0 subLoss 3663.6 multi 1.00 import weight 0.00
Epoch 336 Iter 1 subLoss 3337.2 multi -4.97 import weight 0.00
Epoch 336 Iter 2 subLoss 3825.5 multi 6.97 import weight 0.00
Epoch 336 Iter 3 subLoss 3410.7 multi 6.97 import weight 0.00
Epoch 336 Iter 4 subLoss 3371.9 multi -4.97 import weight 0.00
Epoch 336 Iter 5 subLoss 3129.4 multi 3.98 import weight 0.00
Epoch 336 Iter 6 subLoss 3023.4 multi 3.99 import weight 0.00
Epoch 336 Iter 7 subLoss 3266.2 multi 1.00 import weight 0.00
Epoch 336 Iter 8 subLoss 3250.7 multi 6.97 import weight 0.00
Epoch 336 Iter 9 subLoss 3299.8 multi 12.94 import weight 0.00
Epoch 336 Iter 10 subLoss 3002.9 multi 6.97 import weight 0.00
Epoch 336 Iter 11 subLoss 3146.5 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 336 Acc: 98.05 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 314 train Loss: 3273.7 test Loss: 310.9
Epoch 337 Iter 0 subLoss 3013.0 multi -1.99 import weight 0.00
Epoch 337 Iter 1 subLoss 2827.8 multi 1.00 import weight 0.00
Epoch 337 Iter 2 subLoss 3417.1 multi 9.96 import weight 0.00
Epoch 337 Iter 3 subLoss 2992.4 multi -1.99 import weight 0.00
Epoch 337 Iter 4 subLoss 3188.8 multi 9.96 import weight 0.00
Epoch 337 Iter 5 subLoss 3050.6 multi 1.00 import weight 0.00
Epoch 337 Iter 6 subLoss 3138.2 multi 3.99 import weight 0.00
Epoch 337 Iter 7 subLoss 2844.8 multi -1.99 import weight 0.00
Epoch 337 Iter 8 subLoss 3593.7 multi -1.98 import weight 0.00
Epoch 337 Iter 9 subLoss 3204.4 multi 3.99 import weight 0.00
Epoch 337 Iter 10 subLoss 2730.7 multi -4.97 import weight 0.00
Epoch 337 Iter 11 subLoss 3892.1 multi -10.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 337 Acc: 96.65 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -10.94 Pidx 389 train Loss: 4059.3 test Loss: 481.4
Epoch 338 Iter 0 subLoss 3929.8 multi 1.00 import weight 0.00
Epoch 338 Iter 1 subLoss 3478.8 multi -7.96 import weight 0.00
Epoch 338 Iter 2 subLoss 4783.8 multi 1.00 import weight 0.00
Epoch 338 Iter 3 subLoss 4183.7 multi 3.98 import weight 0.00
Epoch 338 Iter 4 subLoss 3360.2 multi 9.96 import weight 0.00
Epoch 338 Iter 5 subLoss 2888.8 multi 1.00 import weight 0.00
Epoch 338 Iter 6 subLoss 3550.7 multi 3.99 import weight 0.00
Epoch 338 Iter 7 subLoss 3027.6 multi 3.99 import weight 0.00
Epoch 338 Iter 8 subLoss 2579.0 multi 1.00 import weight 0.00
Epoch 338 Iter 9 subLoss 3296.2 multi 15.93 import weight 0.00
Epoch 338 Iter 10 subLoss 3228.8 multi 15.93 import weight 0.00
Epoch 338 Iter 11 subLoss 2651.4 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 338 Acc: 98.27 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 265 train Loss: 3149.7 test Loss: 281.0
Epoch 339 Iter 0 subLoss 3060.3 multi -1.99 import weight 0.00
Epoch 339 Iter 1 subLoss 3155.1 multi -1.98 import weight 0.00
Epoch 339 Iter 2 subLoss 3368.4 multi 12.94 import weight 0.00
Epoch 339 Iter 3 subLoss 3035.9 multi -13.93 import weight 0.00
Epoch 339 Iter 4 subLoss 3886.2 multi 1.00 import weight 0.00
Epoch 339 Iter 5 subLoss 3794.1 multi 15.93 import weight 0.00
Epoch 339 Iter 6 subLoss 3468.1 multi 12.94 import weight 0.00
Epoch 339 Iter 7 subLoss 2644.6 multi 3.99 import weight 0.00
Epoch 339 Iter 8 subLoss 2663.1 multi -1.99 import weight 0.00
Epoch 339 Iter 9 subLoss 2948.5 multi -1.99 import weight 0.00
Epoch 339 Iter 10 subLoss 2818.9 multi 3.99 import weight 0.00
Epoch 339 Iter 11 subLoss 2639.7 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 339 Acc: 98.33 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 263 train Loss: 3072.9 test Loss: 286.8
Epoch 340 Iter 0 subLoss 2635.2 multi 3.99 import weight 0.00
Epoch 340 Iter 1 subLoss 2719.6 multi 1.00 import weight 0.00
Epoch 340 Iter 2 subLoss 3093.3 multi -1.98 import weight 0.00
Epoch 340 Iter 3 subLoss 3240.6 multi -10.94 import weight 0.00
Epoch 340 Iter 4 subLoss 3173.3 multi -4.97 import weight 0.00
Epoch 340 Iter 5 subLoss 3327.9 multi -1.99 import weight 0.00
Epoch 340 Iter 6 subLoss 3343.7 multi 3.99 import weight 0.00
Epoch 340 Iter 7 subLoss 3406.9 multi -7.96 import weight 0.00
Epoch 340 Iter 8 subLoss 3008.0 multi 6.97 import weight 0.00
Epoch 340 Iter 9 subLoss 3711.3 multi 1.00 import weight 0.00
Epoch 340 Iter 10 subLoss 3365.2 multi 15.93 import weight 0.00
Epoch 340 Iter 11 subLoss 3237.0 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 340 Acc: 98.29 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 323 train Loss: 3137.7 test Loss: 290.7
Epoch 341 Iter 0 subLoss 3117.5 multi -13.93 import weight 0.00
Epoch 341 Iter 1 subLoss 3856.3 multi 12.94 import weight 0.00
Epoch 341 Iter 2 subLoss 3077.0 multi -4.97 import weight 0.00
Epoch 341 Iter 3 subLoss 3132.2 multi 6.97 import weight 0.00
Epoch 341 Iter 4 subLoss 3085.3 multi 9.96 import weight 0.00
Epoch 341 Iter 5 subLoss 2836.8 multi -1.98 import weight 0.00
Epoch 341 Iter 6 subLoss 3062.3 multi 1.00 import weight 0.00
Epoch 341 Iter 7 subLoss 3175.6 multi -1.99 import weight 0.00
Epoch 341 Iter 8 subLoss 2703.9 multi 1.00 import weight 0.00
Epoch 341 Iter 9 subLoss 3345.0 multi 6.97 import weight 0.00
Epoch 341 Iter 10 subLoss 3076.2 multi -4.97 import weight 0.00
Epoch 341 Iter 11 subLoss 2775.1 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 341 Acc: 98.50 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 277 train Loss: 3045.6 test Loss: 271.6
Epoch 342 Iter 0 subLoss 3320.2 multi 1.00 import weight 0.00
Epoch 342 Iter 1 subLoss 3170.5 multi 1.00 import weight 0.00
Epoch 342 Iter 2 subLoss 2475.6 multi 1.00 import weight 0.00
Epoch 342 Iter 3 subLoss 2979.1 multi -4.97 import weight 0.00
Epoch 342 Iter 4 subLoss 2947.3 multi 1.00 import weight 0.00
Epoch 342 Iter 5 subLoss 2731.2 multi -1.98 import weight 0.00
Epoch 342 Iter 6 subLoss 2990.4 multi 1.00 import weight 0.00
Epoch 342 Iter 7 subLoss 3483.0 multi 6.97 import weight 0.00
Epoch 342 Iter 8 subLoss 2700.3 multi 3.99 import weight 0.00
Epoch 342 Iter 9 subLoss 2792.3 multi -1.98 import weight 0.00
Epoch 342 Iter 10 subLoss 3069.2 multi 3.99 import weight 0.00
Epoch 342 Iter 11 subLoss 3130.0 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 342 Acc: 98.40 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 312 train Loss: 2935.2 test Loss: 276.3
Epoch 343 Iter 0 subLoss 3290.3 multi 18.91 import weight 0.00
Epoch 343 Iter 1 subLoss 3045.6 multi 3.98 import weight 0.00
Epoch 343 Iter 2 subLoss 2577.1 multi 3.99 import weight 0.00
Epoch 343 Iter 3 subLoss 2469.3 multi 1.00 import weight 0.00
Epoch 343 Iter 4 subLoss 2496.0 multi 1.00 import weight 0.00
Epoch 343 Iter 5 subLoss 3032.7 multi -10.94 import weight 0.00
Epoch 343 Iter 6 subLoss 2954.0 multi -7.96 import weight 0.00
Epoch 343 Iter 7 subLoss 2640.4 multi 1.00 import weight 0.00
Epoch 343 Iter 8 subLoss 3078.0 multi -4.97 import weight 0.00
Epoch 343 Iter 9 subLoss 2699.9 multi -1.99 import weight 0.00
Epoch 343 Iter 10 subLoss 3605.8 multi -4.97 import weight 0.00
Epoch 343 Iter 11 subLoss 4681.1 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 343 Acc: 97.70 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 468 train Loss: 3698.2 test Loss: 383.9
Epoch 344 Iter 0 subLoss 3325.7 multi 3.98 import weight 0.00
Epoch 344 Iter 1 subLoss 2950.3 multi -4.97 import weight 0.00
Epoch 344 Iter 2 subLoss 4115.7 multi -10.94 import weight 0.00
Epoch 344 Iter 3 subLoss 5383.8 multi -1.99 import weight 0.00
Epoch 344 Iter 4 subLoss 6767.0 multi -1.99 import weight 0.00
Epoch 344 Iter 5 subLoss 10708.0 multi -7.96 import weight 0.00
Epoch 344 Iter 6 subLoss 121094.8 multi 1.00 import weight 0.00
Epoch 344 Iter 7 subLoss 29294.0 multi 1.00 import weight 0.00
Epoch 344 Iter 8 subLoss 21242.8 multi 3.99 import weight 0.00
Epoch 344 Iter 9 subLoss 7750.6 multi -7.96 import weight 0.00
Epoch 344 Iter 10 subLoss 20870.8 multi 1.00 import weight 0.00
Epoch 344 Iter 11 subLoss 16228.8 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 344 Acc: 93.89 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 1622 train Loss: 6712.3 test Loss: 914.1
Epoch 345 Iter 0 subLoss 6288.3 multi 3.99 import weight 0.00
Epoch 345 Iter 1 subLoss 4513.2 multi 1.00 import weight 0.00
Epoch 345 Iter 2 subLoss 4755.7 multi 1.00 import weight 0.00
Epoch 345 Iter 3 subLoss 4094.5 multi -4.97 import weight 0.00
Epoch 345 Iter 4 subLoss 4783.0 multi 3.98 import weight 0.00
Epoch 345 Iter 5 subLoss 4039.0 multi 1.00 import weight 0.00
Epoch 345 Iter 6 subLoss 4538.4 multi 3.98 import weight 0.00
Epoch 345 Iter 7 subLoss 3676.8 multi -19.90 import weight 0.00
Epoch 345 Iter 8 subLoss 5444.4 multi 1.00 import weight 0.00
Epoch 345 Iter 9 subLoss 5074.8 multi -1.98 import weight 0.00
Epoch 345 Iter 10 subLoss 6004.2 multi 3.99 import weight 0.00
Epoch 345 Iter 11 subLoss 4466.0 multi -19.90 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 345 Acc: 85.78 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -19.90 Pidx 446 train Loss: 12010.5 test Loss: 1977.6
Epoch 346 Iter 0 subLoss 12234.8 multi -4.97 import weight 0.00
Epoch 346 Iter 1 subLoss 23928.2 multi 1.00 import weight 0.00
Epoch 346 Iter 2 subLoss 19215.2 multi 3.98 import weight 0.00
Epoch 346 Iter 3 subLoss 9902.7 multi 3.99 import weight 0.00
Epoch 346 Iter 4 subLoss 6872.1 multi 18.91 import weight 0.00
Epoch 346 Iter 5 subLoss 4648.6 multi 15.93 import weight 0.00
Epoch 346 Iter 6 subLoss 4644.5 multi 18.91 import weight 0.00
Epoch 346 Iter 7 subLoss 4499.3 multi 6.97 import weight 0.00
Epoch 346 Iter 8 subLoss 3344.1 multi 9.96 import weight 0.00
Epoch 346 Iter 9 subLoss 2894.2 multi 1.00 import weight 0.00
Epoch 346 Iter 10 subLoss 3177.2 multi 3.99 import weight 0.00
Epoch 346 Iter 11 subLoss 2960.9 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 346 Acc: 98.44 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 296 train Loss: 2988.7 test Loss: 275.9
Epoch 347 Iter 0 subLoss 3211.7 multi -19.90 import weight 0.00
Epoch 347 Iter 1 subLoss 2792.1 multi 1.00 import weight 0.00
Epoch 347 Iter 2 subLoss 3254.8 multi 6.97 import weight 0.00
Epoch 347 Iter 3 subLoss 2751.9 multi 1.00 import weight 0.00
Epoch 347 Iter 4 subLoss 3278.2 multi -4.97 import weight 0.00
Epoch 347 Iter 5 subLoss 2855.2 multi -1.99 import weight 0.00
Epoch 347 Iter 6 subLoss 2972.6 multi -4.97 import weight 0.00
Epoch 347 Iter 7 subLoss 2854.8 multi 1.00 import weight 0.00
Epoch 347 Iter 8 subLoss 3107.9 multi 3.99 import weight 0.00
Epoch 347 Iter 9 subLoss 3096.2 multi -1.99 import weight 0.00
Epoch 347 Iter 10 subLoss 3099.8 multi 1.00 import weight 0.00
Epoch 347 Iter 11 subLoss 2812.5 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 347 Acc: 98.42 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 281 train Loss: 3024.9 test Loss: 279.7
Epoch 348 Iter 0 subLoss 2541.2 multi 1.00 import weight 0.00
Epoch 348 Iter 1 subLoss 3618.2 multi 1.00 import weight 0.00
Epoch 348 Iter 2 subLoss 3056.0 multi 1.00 import weight 0.00
Epoch 348 Iter 3 subLoss 3057.5 multi 3.99 import weight 0.00
Epoch 348 Iter 4 subLoss 2773.0 multi 3.99 import weight 0.00
Epoch 348 Iter 5 subLoss 3247.8 multi -10.94 import weight 0.00
Epoch 348 Iter 6 subLoss 2809.4 multi -7.96 import weight 0.00
Epoch 348 Iter 7 subLoss 3449.3 multi -4.97 import weight 0.00
Epoch 348 Iter 8 subLoss 3857.5 multi 15.93 import weight 0.00
Epoch 348 Iter 9 subLoss 3022.3 multi 6.97 import weight 0.00
Epoch 348 Iter 10 subLoss 2927.9 multi 3.99 import weight 0.00
Epoch 348 Iter 11 subLoss 2778.8 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 348 Acc: 98.35 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 277 train Loss: 3014.8 test Loss: 288.7
Epoch 349 Iter 0 subLoss 3022.4 multi 9.96 import weight 0.00
Epoch 349 Iter 1 subLoss 2883.0 multi 3.98 import weight 0.00
Epoch 349 Iter 2 subLoss 2953.8 multi -1.99 import weight 0.00
Epoch 349 Iter 3 subLoss 3069.0 multi 1.00 import weight 0.00
Epoch 349 Iter 4 subLoss 3454.4 multi -13.93 import weight 0.00
Epoch 349 Iter 5 subLoss 3147.8 multi -10.94 import weight 0.00
Epoch 349 Iter 6 subLoss 2995.3 multi 3.98 import weight 0.00
Epoch 349 Iter 7 subLoss 2977.2 multi -1.99 import weight 0.00
Epoch 349 Iter 8 subLoss 3040.9 multi 3.99 import weight 0.00
Epoch 349 Iter 9 subLoss 3220.9 multi 15.93 import weight 0.00
Epoch 349 Iter 10 subLoss 2625.4 multi 1.00 import weight 0.00
Epoch 349 Iter 11 subLoss 2811.9 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 349 Acc: 98.58 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 281 train Loss: 2992.9 test Loss: 257.9
Epoch 350 Iter 0 subLoss 3034.4 multi -13.93 import weight 0.00
Epoch 350 Iter 1 subLoss 3015.4 multi -1.99 import weight 0.00
Epoch 350 Iter 2 subLoss 3410.9 multi 9.96 import weight 0.00
Epoch 350 Iter 3 subLoss 2718.1 multi -1.98 import weight 0.00
Epoch 350 Iter 4 subLoss 2945.7 multi 3.99 import weight 0.00
Epoch 350 Iter 5 subLoss 2514.3 multi 1.00 import weight 0.00
Epoch 350 Iter 6 subLoss 3174.3 multi 6.97 import weight 0.00
Epoch 350 Iter 7 subLoss 2856.6 multi 3.98 import weight 0.00
Epoch 350 Iter 8 subLoss 2198.9 multi 1.00 import weight 0.00
Epoch 350 Iter 9 subLoss 2767.9 multi -1.99 import weight 0.00
Epoch 350 Iter 10 subLoss 2491.4 multi 3.99 import weight 0.00
Epoch 350 Iter 11 subLoss 2891.1 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 350 Acc: 98.44 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 289 train Loss: 2893.5 test Loss: 262.6
Epoch 351 Iter 0 subLoss 3180.8 multi -1.99 import weight 0.00
Epoch 351 Iter 1 subLoss 2872.1 multi 3.99 import weight 0.00
Epoch 351 Iter 2 subLoss 2623.6 multi 3.99 import weight 0.00
Epoch 351 Iter 3 subLoss 2971.0 multi 1.00 import weight 0.00
Epoch 351 Iter 4 subLoss 3068.5 multi 3.99 import weight 0.00
Epoch 351 Iter 5 subLoss 2853.5 multi 6.97 import weight 0.00
Epoch 351 Iter 6 subLoss 2794.0 multi 3.99 import weight 0.00
Epoch 351 Iter 7 subLoss 2027.0 multi 1.00 import weight 0.00
Epoch 351 Iter 8 subLoss 2667.0 multi 1.00 import weight 0.00
Epoch 351 Iter 9 subLoss 2241.9 multi 1.00 import weight 0.00
Epoch 351 Iter 10 subLoss 2982.5 multi -10.94 import weight 0.00
Epoch 351 Iter 11 subLoss 2193.9 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 351 Acc: 98.50 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 219 train Loss: 2922.5 test Loss: 262.1
Epoch 352 Iter 0 subLoss 3336.2 multi -10.94 import weight 0.00
Epoch 352 Iter 1 subLoss 3127.5 multi 6.97 import weight 0.00
Epoch 352 Iter 2 subLoss 2407.2 multi 1.00 import weight 0.00
Epoch 352 Iter 3 subLoss 2452.2 multi 1.00 import weight 0.00
Epoch 352 Iter 4 subLoss 2481.9 multi -1.99 import weight 0.00
Epoch 352 Iter 5 subLoss 2505.7 multi -4.97 import weight 0.00
Epoch 352 Iter 6 subLoss 3103.5 multi 1.00 import weight 0.00
Epoch 352 Iter 7 subLoss 2652.3 multi -4.97 import weight 0.00
Epoch 352 Iter 8 subLoss 3023.9 multi 9.96 import weight 0.00
Epoch 352 Iter 9 subLoss 2990.5 multi 3.99 import weight 0.00
Epoch 352 Iter 10 subLoss 2753.5 multi 3.99 import weight 0.00
Epoch 352 Iter 11 subLoss 2930.2 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 352 Acc: 98.37 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 293 train Loss: 2868.4 test Loss: 282.5
Epoch 353 Iter 0 subLoss 2937.7 multi 1.00 import weight 0.00
Epoch 353 Iter 1 subLoss 2860.7 multi -10.94 import weight 0.00
Epoch 353 Iter 2 subLoss 3206.4 multi 6.97 import weight 0.00
Epoch 353 Iter 3 subLoss 2738.2 multi 1.00 import weight 0.00
Epoch 353 Iter 4 subLoss 2585.0 multi -4.97 import weight 0.00
Epoch 353 Iter 5 subLoss 3059.8 multi 3.98 import weight 0.00
Epoch 353 Iter 6 subLoss 2977.9 multi 3.98 import weight 0.00
Epoch 353 Iter 7 subLoss 2888.9 multi 3.99 import weight 0.00
Epoch 353 Iter 8 subLoss 3016.2 multi 1.00 import weight 0.00
Epoch 353 Iter 9 subLoss 2490.4 multi 3.98 import weight 0.00
Epoch 353 Iter 10 subLoss 2659.2 multi -1.99 import weight 0.00
Epoch 353 Iter 11 subLoss 2776.9 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 353 Acc: 98.42 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 277 train Loss: 2715.5 test Loss: 277.5
Epoch 354 Iter 0 subLoss 2659.7 multi 1.00 import weight 0.00
Epoch 354 Iter 1 subLoss 2652.7 multi 3.99 import weight 0.00
Epoch 354 Iter 2 subLoss 3044.6 multi 3.99 import weight 0.00
Epoch 354 Iter 3 subLoss 2642.2 multi 3.99 import weight 0.00
Epoch 354 Iter 4 subLoss 2440.0 multi 1.00 import weight 0.00
Epoch 354 Iter 5 subLoss 2630.1 multi 1.00 import weight 0.00
Epoch 354 Iter 6 subLoss 3260.6 multi -1.99 import weight 0.00
Epoch 354 Iter 7 subLoss 2894.1 multi 1.00 import weight 0.00
Epoch 354 Iter 8 subLoss 3175.7 multi 9.96 import weight 0.00
Epoch 354 Iter 9 subLoss 2749.8 multi -7.96 import weight 0.00
Epoch 354 Iter 10 subLoss 3150.0 multi -7.96 import weight 0.00
Epoch 354 Iter 11 subLoss 2220.9 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 354 Acc: 98.00 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 222 train Loss: 2828.7 test Loss: 335.9
Epoch 355 Iter 0 subLoss 2928.3 multi 6.97 import weight 0.00
Epoch 355 Iter 1 subLoss 2833.2 multi 1.00 import weight 0.00
Epoch 355 Iter 2 subLoss 2817.3 multi 9.96 import weight 0.00
Epoch 355 Iter 3 subLoss 2950.9 multi -1.98 import weight 0.00
Epoch 355 Iter 4 subLoss 2912.2 multi 3.98 import weight 0.00
Epoch 355 Iter 5 subLoss 2618.8 multi 1.00 import weight 0.00
Epoch 355 Iter 6 subLoss 2758.2 multi 3.98 import weight 0.00
Epoch 355 Iter 7 subLoss 2049.7 multi 1.00 import weight 0.00
Epoch 355 Iter 8 subLoss 2470.3 multi 1.00 import weight 0.00
Epoch 355 Iter 9 subLoss 2683.6 multi 1.00 import weight 0.00
Epoch 355 Iter 10 subLoss 2756.6 multi 6.97 import weight 0.00
Epoch 355 Iter 11 subLoss 2426.3 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 355 Acc: 98.48 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 242 train Loss: 2773.8 test Loss: 273.9
Epoch 356 Iter 0 subLoss 2421.8 multi 3.99 import weight 0.00
Epoch 356 Iter 1 subLoss 2386.5 multi 1.00 import weight 0.00
Epoch 356 Iter 2 subLoss 3163.1 multi 3.99 import weight 0.00
Epoch 356 Iter 3 subLoss 2703.3 multi 3.98 import weight 0.00
Epoch 356 Iter 4 subLoss 2682.2 multi 3.98 import weight 0.00
Epoch 356 Iter 5 subLoss 2561.8 multi 1.00 import weight 0.00
Epoch 356 Iter 6 subLoss 2787.4 multi -4.97 import weight 0.00
Epoch 356 Iter 7 subLoss 2573.6 multi 3.98 import weight 0.00
Epoch 356 Iter 8 subLoss 2495.4 multi 6.97 import weight 0.00
Epoch 356 Iter 9 subLoss 2516.2 multi 1.00 import weight 0.00
Epoch 356 Iter 10 subLoss 2677.1 multi -1.98 import weight 0.00
Epoch 356 Iter 11 subLoss 2264.9 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 356 Acc: 98.56 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 226 train Loss: 2649.5 test Loss: 259.0
Epoch 357 Iter 0 subLoss 2934.7 multi 1.00 import weight 0.00
Epoch 357 Iter 1 subLoss 2798.5 multi 3.99 import weight 0.00
Epoch 357 Iter 2 subLoss 2941.5 multi -1.99 import weight 0.00
Epoch 357 Iter 3 subLoss 2693.8 multi -4.97 import weight 0.00
Epoch 357 Iter 4 subLoss 2471.6 multi 3.98 import weight 0.00
Epoch 357 Iter 5 subLoss 2324.8 multi 1.00 import weight 0.00
Epoch 357 Iter 6 subLoss 2823.0 multi -7.96 import weight 0.00
Epoch 357 Iter 7 subLoss 2806.0 multi -10.94 import weight 0.00
Epoch 357 Iter 8 subLoss 2447.5 multi -1.99 import weight 0.00
Epoch 357 Iter 9 subLoss 2973.0 multi 6.97 import weight 0.00
Epoch 357 Iter 10 subLoss 2692.8 multi -1.99 import weight 0.00
Epoch 357 Iter 11 subLoss 3049.8 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 357 Acc: 98.50 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 304 train Loss: 2742.3 test Loss: 267.0
Epoch 358 Iter 0 subLoss 2848.0 multi -4.97 import weight 0.00
Epoch 358 Iter 1 subLoss 2702.5 multi 1.00 import weight 0.00
Epoch 358 Iter 2 subLoss 2680.6 multi 3.99 import weight 0.00
Epoch 358 Iter 3 subLoss 2530.9 multi 1.00 import weight 0.00
Epoch 358 Iter 4 subLoss 2726.9 multi 1.00 import weight 0.00
Epoch 358 Iter 5 subLoss 2764.3 multi -7.96 import weight 0.00
Epoch 358 Iter 6 subLoss 2298.6 multi 1.00 import weight 0.00
Epoch 358 Iter 7 subLoss 2342.4 multi 1.00 import weight 0.00
Epoch 358 Iter 8 subLoss 2412.5 multi -1.99 import weight 0.00
Epoch 358 Iter 9 subLoss 2279.1 multi -1.99 import weight 0.00
Epoch 358 Iter 10 subLoss 2690.8 multi -1.99 import weight 0.00
Epoch 358 Iter 11 subLoss 2798.4 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 358 Acc: 98.38 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 279 train Loss: 2628.5 test Loss: 280.5
Epoch 359 Iter 0 subLoss 2974.4 multi 9.96 import weight 0.00
Epoch 359 Iter 1 subLoss 2173.0 multi 1.00 import weight 0.00
Epoch 359 Iter 2 subLoss 2298.4 multi 3.99 import weight 0.00
Epoch 359 Iter 3 subLoss 2724.6 multi 3.99 import weight 0.00
Epoch 359 Iter 4 subLoss 2886.8 multi 6.97 import weight 0.00
Epoch 359 Iter 5 subLoss 2588.7 multi -4.97 import weight 0.00
Epoch 359 Iter 6 subLoss 2341.8 multi 3.99 import weight 0.00
Epoch 359 Iter 7 subLoss 2206.2 multi -4.97 import weight 0.00
Epoch 359 Iter 8 subLoss 2772.2 multi 6.97 import weight 0.00
Epoch 359 Iter 9 subLoss 2902.6 multi -10.94 import weight 0.00
Epoch 359 Iter 10 subLoss 2657.7 multi 3.98 import weight 0.00
Epoch 359 Iter 11 subLoss 2810.7 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 359 Acc: 98.44 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 281 train Loss: 2597.0 test Loss: 276.4
Epoch 360 Iter 0 subLoss 2708.5 multi 1.00 import weight 0.00
Epoch 360 Iter 1 subLoss 2866.8 multi -7.96 import weight 0.00
Epoch 360 Iter 2 subLoss 2416.8 multi 1.00 import weight 0.00
Epoch 360 Iter 3 subLoss 2832.2 multi 1.00 import weight 0.00
Epoch 360 Iter 4 subLoss 2637.4 multi 3.99 import weight 0.00
Epoch 360 Iter 5 subLoss 2484.3 multi -4.97 import weight 0.00
Epoch 360 Iter 6 subLoss 2823.0 multi -7.96 import weight 0.00
Epoch 360 Iter 7 subLoss 2606.6 multi -1.99 import weight 0.00
Epoch 360 Iter 8 subLoss 2476.0 multi 6.97 import weight 0.00
Epoch 360 Iter 9 subLoss 2610.2 multi 1.00 import weight 0.00
Epoch 360 Iter 10 subLoss 2233.8 multi -1.99 import weight 0.00
Epoch 360 Iter 11 subLoss 2124.6 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 360 Acc: 98.50 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 212 train Loss: 2717.0 test Loss: 268.7
Epoch 361 Iter 0 subLoss 3008.4 multi 1.00 import weight 0.00
Epoch 361 Iter 1 subLoss 2517.3 multi 3.98 import weight 0.00
Epoch 361 Iter 2 subLoss 2621.2 multi 1.00 import weight 0.00
Epoch 361 Iter 3 subLoss 2678.6 multi 1.00 import weight 0.00
Epoch 361 Iter 4 subLoss 2130.8 multi -1.99 import weight 0.00
Epoch 361 Iter 5 subLoss 2473.7 multi 9.96 import weight 0.00
Epoch 361 Iter 6 subLoss 2485.9 multi -7.96 import weight 0.00
Epoch 361 Iter 7 subLoss 2172.6 multi 3.99 import weight 0.00
Epoch 361 Iter 8 subLoss 2755.1 multi 9.96 import weight 0.00
Epoch 361 Iter 9 subLoss 2538.1 multi 3.99 import weight 0.00
Epoch 361 Iter 10 subLoss 2343.5 multi 6.97 import weight 0.00
Epoch 361 Iter 11 subLoss 2647.5 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 361 Acc: 98.52 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 264 train Loss: 2521.3 test Loss: 254.6
Epoch 362 Iter 0 subLoss 2902.0 multi -7.96 import weight 0.00
Epoch 362 Iter 1 subLoss 2364.1 multi 1.00 import weight 0.00
Epoch 362 Iter 2 subLoss 2842.7 multi -4.97 import weight 0.00
Epoch 362 Iter 3 subLoss 2716.4 multi -7.96 import weight 0.00
Epoch 362 Iter 4 subLoss 2049.9 multi 3.99 import weight 0.00
Epoch 362 Iter 5 subLoss 2846.1 multi -1.99 import weight 0.00
Epoch 362 Iter 6 subLoss 2585.4 multi -1.99 import weight 0.00
Epoch 362 Iter 7 subLoss 2288.9 multi -1.99 import weight 0.00
Epoch 362 Iter 8 subLoss 2689.1 multi 3.99 import weight 0.00
Epoch 362 Iter 9 subLoss 2378.6 multi -1.99 import weight 0.00
Epoch 362 Iter 10 subLoss 3165.8 multi 6.97 import weight 0.00
Epoch 362 Iter 11 subLoss 2278.9 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 362 Acc: 98.52 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 227 train Loss: 2671.7 test Loss: 266.0
Epoch 363 Iter 0 subLoss 2424.1 multi 1.00 import weight 0.00
Epoch 363 Iter 1 subLoss 2684.1 multi 6.97 import weight 0.00
Epoch 363 Iter 2 subLoss 2410.2 multi 3.98 import weight 0.00
Epoch 363 Iter 3 subLoss 2784.6 multi -4.97 import weight 0.00
Epoch 363 Iter 4 subLoss 2471.7 multi 12.94 import weight 0.00
Epoch 363 Iter 5 subLoss 2352.1 multi -7.96 import weight 0.00
Epoch 363 Iter 6 subLoss 2847.6 multi 1.00 import weight 0.00
Epoch 363 Iter 7 subLoss 2998.2 multi 6.97 import weight 0.00
Epoch 363 Iter 8 subLoss 3202.5 multi 9.96 import weight 0.00
Epoch 363 Iter 9 subLoss 2614.1 multi 3.98 import weight 0.00
Epoch 363 Iter 10 subLoss 3032.9 multi -13.93 import weight 0.00
Epoch 363 Iter 11 subLoss 2441.9 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 363 Acc: 98.38 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 244 train Loss: 2727.5 test Loss: 281.8
Epoch 364 Iter 0 subLoss 2531.7 multi 6.97 import weight 0.00
Epoch 364 Iter 1 subLoss 2093.1 multi 1.00 import weight 0.00
Epoch 364 Iter 2 subLoss 2303.5 multi -4.97 import weight 0.00
Epoch 364 Iter 3 subLoss 2594.7 multi -4.97 import weight 0.00
Epoch 364 Iter 4 subLoss 2447.6 multi 3.98 import weight 0.00
Epoch 364 Iter 5 subLoss 2637.4 multi 3.99 import weight 0.00
Epoch 364 Iter 6 subLoss 2704.9 multi 3.98 import weight 0.00
Epoch 364 Iter 7 subLoss 2467.3 multi 1.00 import weight 0.00
Epoch 364 Iter 8 subLoss 2914.0 multi 1.00 import weight 0.00
Epoch 364 Iter 9 subLoss 2820.5 multi -4.97 import weight 0.00
Epoch 364 Iter 10 subLoss 2472.9 multi 12.94 import weight 0.00
Epoch 364 Iter 11 subLoss 2590.6 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 364 Acc: 98.33 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 259 train Loss: 2684.6 test Loss: 299.6
Epoch 365 Iter 0 subLoss 2583.0 multi 1.00 import weight 0.00
Epoch 365 Iter 1 subLoss 2637.1 multi 6.97 import weight 0.00
Epoch 365 Iter 2 subLoss 2568.2 multi 3.99 import weight 0.00
Epoch 365 Iter 3 subLoss 2513.1 multi 6.97 import weight 0.00
Epoch 365 Iter 4 subLoss 2471.6 multi 15.93 import weight 0.00
Epoch 365 Iter 5 subLoss 2179.4 multi 6.97 import weight 0.00
Epoch 365 Iter 6 subLoss 2645.3 multi -1.99 import weight 0.00
Epoch 365 Iter 7 subLoss 3017.8 multi 1.00 import weight 0.00
Epoch 365 Iter 8 subLoss 2323.8 multi 3.99 import weight 0.00
Epoch 365 Iter 9 subLoss 2636.4 multi 9.96 import weight 0.00
Epoch 365 Iter 10 subLoss 2139.0 multi 1.00 import weight 0.00
Epoch 365 Iter 11 subLoss 2489.3 multi -13.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 365 Acc: 98.56 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -13.93 Pidx 248 train Loss: 2535.2 test Loss: 250.6
Epoch 366 Iter 0 subLoss 2584.9 multi 3.99 import weight 0.00
Epoch 366 Iter 1 subLoss 2327.5 multi 6.97 import weight 0.00
Epoch 366 Iter 2 subLoss 2409.7 multi 3.99 import weight 0.00
Epoch 366 Iter 3 subLoss 2416.2 multi 3.99 import weight 0.00
Epoch 366 Iter 4 subLoss 2201.2 multi -1.98 import weight 0.00
Epoch 366 Iter 5 subLoss 2086.2 multi 1.00 import weight 0.00
Epoch 366 Iter 6 subLoss 1900.8 multi 1.00 import weight 0.00
Epoch 366 Iter 7 subLoss 2307.8 multi -1.98 import weight 0.00
Epoch 366 Iter 8 subLoss 2543.5 multi -4.97 import weight 0.00
Epoch 366 Iter 9 subLoss 2519.8 multi 9.96 import weight 0.00
Epoch 366 Iter 10 subLoss 2768.0 multi -7.96 import weight 0.00
Epoch 366 Iter 11 subLoss 2895.4 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 366 Acc: 98.27 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 289 train Loss: 2614.1 test Loss: 290.5
Epoch 367 Iter 0 subLoss 2710.3 multi -7.96 import weight 0.00
Epoch 367 Iter 1 subLoss 3413.0 multi 12.94 import weight 0.00
Epoch 367 Iter 2 subLoss 4061.2 multi -4.97 import weight 0.00
Epoch 367 Iter 3 subLoss 11334.3 multi 1.00 import weight 0.00
Epoch 367 Iter 4 subLoss 3792.9 multi 18.91 import weight 0.00
Epoch 367 Iter 5 subLoss 9508.9 multi 9.96 import weight 0.00
Epoch 367 Iter 6 subLoss 4836.9 multi -16.91 import weight 0.00
Epoch 367 Iter 7 subLoss 29261.3 multi -4.97 import weight 0.00
Epoch 367 Iter 8 subLoss 99279.5 multi 1.00 import weight 0.00
Epoch 367 Iter 9 subLoss 33690.5 multi 3.99 import weight 0.00
Epoch 367 Iter 10 subLoss 19870.2 multi 3.99 import weight 0.00
Epoch 367 Iter 11 subLoss 7266.2 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 367 Acc: 98.17 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 726 train Loss: 4513.6 test Loss: 411.6
Epoch 368 Iter 0 subLoss 4390.3 multi 1.00 import weight 0.00
Epoch 368 Iter 1 subLoss 4195.6 multi -1.99 import weight 0.00
Epoch 368 Iter 2 subLoss 4513.9 multi 3.98 import weight 0.00
Epoch 368 Iter 3 subLoss 3996.7 multi 15.93 import weight 0.00
Epoch 368 Iter 4 subLoss 3120.7 multi 9.96 import weight 0.00
Epoch 368 Iter 5 subLoss 2840.7 multi 3.98 import weight 0.00
Epoch 368 Iter 6 subLoss 2898.8 multi 3.99 import weight 0.00
Epoch 368 Iter 7 subLoss 2811.5 multi 12.94 import weight 0.00
Epoch 368 Iter 8 subLoss 2774.2 multi 6.97 import weight 0.00
Epoch 368 Iter 9 subLoss 2823.0 multi -4.97 import weight 0.00
Epoch 368 Iter 10 subLoss 2706.4 multi 6.97 import weight 0.00
Epoch 368 Iter 11 subLoss 2775.3 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 368 Acc: 98.60 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 277 train Loss: 2616.5 test Loss: 259.4
Epoch 369 Iter 0 subLoss 2429.1 multi -1.99 import weight 0.00
Epoch 369 Iter 1 subLoss 2360.3 multi 1.00 import weight 0.00
Epoch 369 Iter 2 subLoss 2651.0 multi 1.00 import weight 0.00
Epoch 369 Iter 3 subLoss 3003.1 multi 1.00 import weight 0.00
Epoch 369 Iter 4 subLoss 2445.5 multi 6.97 import weight 0.00
Epoch 369 Iter 5 subLoss 3173.6 multi 6.97 import weight 0.00
Epoch 369 Iter 6 subLoss 2287.9 multi -1.98 import weight 0.00
Epoch 369 Iter 7 subLoss 2551.4 multi -4.97 import weight 0.00
Epoch 369 Iter 8 subLoss 3540.0 multi 3.99 import weight 0.00
Epoch 369 Iter 9 subLoss 2644.2 multi -1.99 import weight 0.00
Epoch 369 Iter 10 subLoss 2013.7 multi 1.00 import weight 0.00
Epoch 369 Iter 11 subLoss 2350.1 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 369 Acc: 98.52 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 235 train Loss: 2660.2 test Loss: 253.0
Epoch 370 Iter 0 subLoss 2191.1 multi 6.97 import weight 0.00
Epoch 370 Iter 1 subLoss 2547.5 multi -1.99 import weight 0.00
Epoch 370 Iter 2 subLoss 2511.6 multi 12.94 import weight 0.00
Epoch 370 Iter 3 subLoss 1952.5 multi 1.00 import weight 0.00
Epoch 370 Iter 4 subLoss 2840.8 multi 6.97 import weight 0.00
Epoch 370 Iter 5 subLoss 3065.5 multi 3.99 import weight 0.00
Epoch 370 Iter 6 subLoss 2491.8 multi 1.00 import weight 0.00
Epoch 370 Iter 7 subLoss 2538.3 multi 9.96 import weight 0.00
Epoch 370 Iter 8 subLoss 2346.3 multi 9.96 import weight 0.00
Epoch 370 Iter 9 subLoss 2298.2 multi 1.00 import weight 0.00
Epoch 370 Iter 10 subLoss 2854.0 multi -7.96 import weight 0.00
Epoch 370 Iter 11 subLoss 2800.2 multi -10.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 370 Acc: 97.98 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -10.94 Pidx 280 train Loss: 3372.6 test Loss: 356.7
Epoch 371 Iter 0 subLoss 3104.4 multi 3.98 import weight 0.00
Epoch 371 Iter 1 subLoss 2733.7 multi -1.99 import weight 0.00
Epoch 371 Iter 2 subLoss 2782.6 multi -7.96 import weight 0.00
Epoch 371 Iter 3 subLoss 3894.0 multi -10.94 import weight 0.00
Epoch 371 Iter 4 subLoss 23587.4 multi -7.96 import weight 0.00
Epoch 371 Iter 5 subLoss 1098669.4 multi 1.00 import weight 0.00
Epoch 371 Iter 6 subLoss 55347.7 multi 1.00 import weight 0.00
Epoch 371 Iter 7 subLoss 49948.4 multi 1.00 import weight 0.00
Epoch 371 Iter 8 subLoss 46658.6 multi 1.00 import weight 0.00
Epoch 371 Iter 9 subLoss 43868.5 multi 1.00 import weight 0.00
Epoch 371 Iter 10 subLoss 42778.8 multi 1.00 import weight 0.00
Epoch 371 Iter 11 subLoss 41310.8 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 371 Acc: 58.57 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4131 train Loss: 39454.4 test Loss: 5701.3
Epoch 372 Iter 0 subLoss 39103.1 multi 1.00 import weight 0.00
Epoch 372 Iter 1 subLoss 36656.3 multi 1.00 import weight 0.00
Epoch 372 Iter 2 subLoss 35285.6 multi 1.00 import weight 0.00
Epoch 372 Iter 3 subLoss 34957.3 multi 1.00 import weight 0.00
Epoch 372 Iter 4 subLoss 32100.9 multi 1.00 import weight 0.00
Epoch 372 Iter 5 subLoss 32602.8 multi 1.00 import weight 0.00
Epoch 372 Iter 6 subLoss 32094.0 multi 1.00 import weight 0.00
Epoch 372 Iter 7 subLoss 30173.8 multi 1.00 import weight 0.00
Epoch 372 Iter 8 subLoss 30307.3 multi 1.00 import weight 0.00
Epoch 372 Iter 9 subLoss 28766.3 multi 1.00 import weight 0.00
Epoch 372 Iter 10 subLoss 27363.4 multi 6.97 import weight 0.00
Epoch 372 Iter 11 subLoss 33626.2 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 372 Acc: 41.18 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 3362 train Loss: 219976.7 test Loss: 38874.4
Epoch 373 Iter 0 subLoss 193461.1 multi 1.00 import weight 0.00
Epoch 373 Iter 1 subLoss 28590.8 multi 1.00 import weight 0.00
Epoch 373 Iter 2 subLoss 25119.0 multi 3.99 import weight 0.00
Epoch 373 Iter 3 subLoss 21317.0 multi 1.00 import weight 0.00
Epoch 373 Iter 4 subLoss 20712.5 multi 1.00 import weight 0.00
Epoch 373 Iter 5 subLoss 19519.0 multi -1.99 import weight 0.00
Epoch 373 Iter 6 subLoss 22100.6 multi -1.98 import weight 0.00
Epoch 373 Iter 7 subLoss 24357.7 multi -1.98 import weight 0.00
Epoch 373 Iter 8 subLoss 24895.7 multi 1.00 import weight 0.00
Epoch 373 Iter 9 subLoss 25071.3 multi -1.99 import weight 0.00
Epoch 373 Iter 10 subLoss 25984.3 multi 1.00 import weight 0.00
Epoch 373 Iter 11 subLoss 25675.0 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 373 Acc: 73.98 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 2567 train Loss: 22205.3 test Loss: 4011.6
Epoch 374 Iter 0 subLoss 22111.4 multi -1.98 import weight 0.00
Epoch 374 Iter 1 subLoss 23574.7 multi 9.96 import weight 0.00
Epoch 374 Iter 2 subLoss 21808.1 multi 1.00 import weight 0.00
Epoch 374 Iter 3 subLoss 19983.9 multi -1.99 import weight 0.00
Epoch 374 Iter 4 subLoss 24488.0 multi 1.00 import weight 0.00
Epoch 374 Iter 5 subLoss 21924.2 multi -1.98 import weight 0.00
Epoch 374 Iter 6 subLoss 26479.6 multi 6.97 import weight 0.00
Epoch 374 Iter 7 subLoss 16338.9 multi 3.99 import weight 0.00
Epoch 374 Iter 8 subLoss 15317.2 multi 1.00 import weight 0.00
Epoch 374 Iter 9 subLoss 14613.8 multi 3.99 import weight 0.00
Epoch 374 Iter 10 subLoss 13735.6 multi -1.98 import weight 0.00
Epoch 374 Iter 11 subLoss 14065.7 multi 3.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 374 Acc: 79.53 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 1406 train Loss: 13160.4 test Loss: 2472.0
Epoch 375 Iter 0 subLoss 12868.0 multi 6.97 import weight 0.00
Epoch 375 Iter 1 subLoss 10924.5 multi -1.98 import weight 0.00
Epoch 375 Iter 2 subLoss 11715.1 multi 1.00 import weight 0.00
Epoch 375 Iter 3 subLoss 11160.3 multi -1.99 import weight 0.00
Epoch 375 Iter 4 subLoss 12026.6 multi 1.00 import weight 0.00
Epoch 375 Iter 5 subLoss 11051.8 multi 3.99 import weight 0.00
Epoch 375 Iter 6 subLoss 10818.7 multi 1.00 import weight 0.00
Epoch 375 Iter 7 subLoss 11030.5 multi 9.96 import weight 0.00
Epoch 375 Iter 8 subLoss 9200.5 multi 1.00 import weight 0.00
Epoch 375 Iter 9 subLoss 9163.0 multi 3.99 import weight 0.00
Epoch 375 Iter 10 subLoss 8594.5 multi 9.96 import weight 0.00
Epoch 375 Iter 11 subLoss 6905.6 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 375 Acc: 91.61 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 690 train Loss: 7451.4 test Loss: 1394.6
Epoch 376 Iter 0 subLoss 7293.5 multi 6.97 import weight 0.00
Epoch 376 Iter 1 subLoss 7452.8 multi 9.96 import weight 0.00
Epoch 376 Iter 2 subLoss 6336.9 multi 12.94 import weight 0.00
Epoch 376 Iter 3 subLoss 5396.8 multi 1.00 import weight 0.00
Epoch 376 Iter 4 subLoss 5469.5 multi 6.97 import weight 0.00
Epoch 376 Iter 5 subLoss 5599.5 multi 9.96 import weight 0.00
Epoch 376 Iter 6 subLoss 5285.9 multi 1.00 import weight 0.00
Epoch 376 Iter 7 subLoss 4674.2 multi 3.98 import weight 0.00
Epoch 376 Iter 8 subLoss 5120.5 multi 9.96 import weight 0.00
Epoch 376 Iter 9 subLoss 4813.0 multi 12.94 import weight 0.00
Epoch 376 Iter 10 subLoss 4697.1 multi -1.99 import weight 0.00
Epoch 376 Iter 11 subLoss 5625.1 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 376 Acc: 83.34 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 562 train Loss: 11702.2 test Loss: 2695.6
Epoch 377 Iter 0 subLoss 11430.7 multi -1.99 import weight 0.00
Epoch 377 Iter 1 subLoss 130840.0 multi 1.00 import weight 0.00
Epoch 377 Iter 2 subLoss 9566.0 multi 6.97 import weight 0.00
Epoch 377 Iter 3 subLoss 8729.7 multi 1.00 import weight 0.00
Epoch 377 Iter 4 subLoss 6962.8 multi -1.99 import weight 0.00
Epoch 377 Iter 5 subLoss 9286.0 multi 6.97 import weight 0.00
Epoch 377 Iter 6 subLoss 7745.9 multi 3.98 import weight 0.00
Epoch 377 Iter 7 subLoss 5620.7 multi -1.99 import weight 0.00
Epoch 377 Iter 8 subLoss 5930.7 multi 9.96 import weight 0.00
Epoch 377 Iter 9 subLoss 5892.3 multi 1.00 import weight 0.00
Epoch 377 Iter 10 subLoss 5182.2 multi 9.96 import weight 0.00
Epoch 377 Iter 11 subLoss 4705.6 multi -10.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 377 Acc: 96.65 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -10.94 Pidx 470 train Loss: 5709.0 test Loss: 808.3
Epoch 378 Iter 0 subLoss 5140.7 multi -1.98 import weight 0.00
Epoch 378 Iter 1 subLoss 5708.0 multi 6.97 import weight 0.00
Epoch 378 Iter 2 subLoss 5213.6 multi 18.91 import weight 0.00
Epoch 378 Iter 3 subLoss 4854.4 multi 1.00 import weight 0.00
Epoch 378 Iter 4 subLoss 5015.1 multi -1.98 import weight 0.00
Epoch 378 Iter 5 subLoss 5214.2 multi 21.90 import weight 0.00
Epoch 378 Iter 6 subLoss 10776.6 multi 9.96 import weight 0.00
Epoch 378 Iter 7 subLoss 21898.3 multi -4.97 import weight 0.00
Epoch 378 Iter 8 subLoss 372729.8 multi 1.00 import weight 0.00
Epoch 378 Iter 9 subLoss 14901.3 multi 1.00 import weight 0.00
Epoch 378 Iter 10 subLoss 12902.0 multi -1.98 import weight 0.00
Epoch 378 Iter 11 subLoss 15996.0 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 378 Acc: 90.87 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 1599 train Loss: 11478.1 test Loss: 1638.2
Epoch 379 Iter 0 subLoss 11360.6 multi -1.99 import weight 0.00
Epoch 379 Iter 1 subLoss 13454.0 multi -1.98 import weight 0.00
Epoch 379 Iter 2 subLoss 15301.4 multi -1.99 import weight 0.00
Epoch 379 Iter 3 subLoss 23363.1 multi 1.00 import weight 0.00
Epoch 379 Iter 4 subLoss 17076.4 multi -4.97 import weight 0.00
Epoch 379 Iter 5 subLoss 37321.9 multi -1.99 import weight 0.00
Epoch 379 Iter 6 subLoss 56822.0 multi 1.00 import weight 0.00
Epoch 379 Iter 7 subLoss 52637.3 multi 1.00 import weight 0.00
Epoch 379 Iter 8 subLoss 45771.6 multi 1.00 import weight 0.00
Epoch 379 Iter 9 subLoss 39731.2 multi 1.00 import weight 0.00
Epoch 379 Iter 10 subLoss 32846.3 multi 1.00 import weight 0.00
Epoch 379 Iter 11 subLoss 30754.2 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 379 Acc: 69.47 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 3075 train Loss: 23928.3 test Loss: 3778.8
Epoch 380 Iter 0 subLoss 23623.5 multi 3.99 import weight 0.00
Epoch 380 Iter 1 subLoss 15992.8 multi 6.97 import weight 0.00
Epoch 380 Iter 2 subLoss 12328.5 multi 3.99 import weight 0.00
Epoch 380 Iter 3 subLoss 9263.6 multi -7.96 import weight 0.00
Epoch 380 Iter 4 subLoss 12212.7 multi 12.94 import weight 0.00
Epoch 380 Iter 5 subLoss 17880.5 multi 3.99 import weight 0.00
Epoch 380 Iter 6 subLoss 8521.4 multi -4.97 import weight 0.00
Epoch 380 Iter 7 subLoss 12654.1 multi 9.96 import weight 0.00
Epoch 380 Iter 8 subLoss 14123.8 multi -7.96 import weight 0.00
Epoch 380 Iter 9 subLoss 55096.8 multi 1.00 import weight 0.00
Epoch 380 Iter 10 subLoss 46841.9 multi 1.00 import weight 0.00
Epoch 380 Iter 11 subLoss 41321.8 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 380 Acc: 38.24 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 4132 train Loss: 51218.4 test Loss: 9855.5
Epoch 381 Iter 0 subLoss 51212.1 multi 1.00 import weight 0.00
Epoch 381 Iter 1 subLoss 43460.4 multi 3.99 import weight 0.00
Epoch 381 Iter 2 subLoss 32235.5 multi 1.00 import weight 0.00
Epoch 381 Iter 3 subLoss 30653.6 multi 1.00 import weight 0.00
Epoch 381 Iter 4 subLoss 29441.2 multi -1.99 import weight 0.00
Epoch 381 Iter 5 subLoss 33341.7 multi 6.97 import weight 0.00
Epoch 381 Iter 6 subLoss 20002.3 multi 1.00 import weight 0.00
Epoch 381 Iter 7 subLoss 18600.5 multi -1.99 import weight 0.00
Epoch 381 Iter 8 subLoss 21972.4 multi 1.00 import weight 0.00
Epoch 381 Iter 9 subLoss 20772.8 multi 3.99 import weight 0.00
Epoch 381 Iter 10 subLoss 15561.9 multi 1.00 import weight 0.00
Epoch 381 Iter 11 subLoss 14405.4 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 381 Acc: 87.99 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 1440 train Loss: 11884.3 test Loss: 1949.0
Epoch 382 Iter 0 subLoss 12144.3 multi 12.94 import weight 0.00
Epoch 382 Iter 1 subLoss 8355.3 multi -4.97 import weight 0.00
Epoch 382 Iter 2 subLoss 18069.6 multi -1.99 import weight 0.00
Epoch 382 Iter 3 subLoss 47544.4 multi 1.00 import weight 0.00
Epoch 382 Iter 4 subLoss 12234.1 multi -1.98 import weight 0.00
Epoch 382 Iter 5 subLoss 23383.6 multi 3.99 import weight 0.00
Epoch 382 Iter 6 subLoss 10216.6 multi -1.99 import weight 0.00
Epoch 382 Iter 7 subLoss 11720.0 multi 3.98 import weight 0.00
Epoch 382 Iter 8 subLoss 7999.0 multi 3.98 import weight 0.00
Epoch 382 Iter 9 subLoss 7053.4 multi 12.94 import weight 0.00
Epoch 382 Iter 10 subLoss 5893.9 multi 3.99 import weight 0.00
Epoch 382 Iter 11 subLoss 5517.4 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 382 Acc: 96.56 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 551 train Loss: 5250.6 test Loss: 717.8
Epoch 383 Iter 0 subLoss 4963.0 multi 3.99 import weight 0.00
Epoch 383 Iter 1 subLoss 4489.3 multi -7.96 import weight 0.00
Epoch 383 Iter 2 subLoss 5641.8 multi -1.99 import weight 0.00
Epoch 383 Iter 3 subLoss 5213.4 multi 24.88 import weight 0.00
Epoch 383 Iter 4 subLoss 4010.4 multi -1.99 import weight 0.00
Epoch 383 Iter 5 subLoss 5285.6 multi 3.99 import weight 0.00
Epoch 383 Iter 6 subLoss 4880.3 multi 3.99 import weight 0.00
Epoch 383 Iter 7 subLoss 4965.6 multi 6.97 import weight 0.00
Epoch 383 Iter 8 subLoss 4911.1 multi 24.88 import weight 0.00
Epoch 383 Iter 9 subLoss 4867.5 multi -4.97 import weight 0.00
Epoch 383 Iter 10 subLoss 4733.7 multi -7.96 import weight 0.00
Epoch 383 Iter 11 subLoss 12938.2 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 383 Acc: 91.15 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1293 train Loss: 7022.2 test Loss: 1319.9
Epoch 384 Iter 0 subLoss 6989.5 multi -1.98 import weight 0.00
Epoch 384 Iter 1 subLoss 10382.5 multi 6.97 import weight 0.00
Epoch 384 Iter 2 subLoss 7264.6 multi 9.96 import weight 0.00
Epoch 384 Iter 3 subLoss 4934.3 multi -7.96 import weight 0.00
Epoch 384 Iter 4 subLoss 5145.9 multi 1.00 import weight 0.00
Epoch 384 Iter 5 subLoss 5223.2 multi -16.91 import weight 0.00
Epoch 384 Iter 6 subLoss 10614.8 multi 3.99 import weight 0.00
Epoch 384 Iter 7 subLoss 5627.1 multi 1.00 import weight 0.00
Epoch 384 Iter 8 subLoss 5312.2 multi 12.94 import weight 0.00
Epoch 384 Iter 9 subLoss 4028.5 multi 1.00 import weight 0.00
Epoch 384 Iter 10 subLoss 4347.1 multi 1.00 import weight 0.00
Epoch 384 Iter 11 subLoss 4051.7 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 384 Acc: 97.33 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 405 train Loss: 4442.5 test Loss: 603.3
Epoch 385 Iter 0 subLoss 4659.6 multi 1.00 import weight 0.00
Epoch 385 Iter 1 subLoss 3583.3 multi -4.97 import weight 0.00
Epoch 385 Iter 2 subLoss 4688.0 multi 1.00 import weight 0.00
Epoch 385 Iter 3 subLoss 3979.9 multi 6.97 import weight 0.00
Epoch 385 Iter 4 subLoss 4073.5 multi -4.97 import weight 0.00
Epoch 385 Iter 5 subLoss 4209.5 multi 3.99 import weight 0.00
Epoch 385 Iter 6 subLoss 3815.2 multi -7.96 import weight 0.00
Epoch 385 Iter 7 subLoss 4385.0 multi 6.97 import weight 0.00
Epoch 385 Iter 8 subLoss 4257.5 multi 1.00 import weight 0.00
Epoch 385 Iter 9 subLoss 4516.2 multi 6.97 import weight 0.00
Epoch 385 Iter 10 subLoss 3880.4 multi 3.99 import weight 0.00
Epoch 385 Iter 11 subLoss 4102.8 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 385 Acc: 97.55 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 410 train Loss: 3974.5 test Loss: 544.7
Epoch 386 Iter 0 subLoss 4021.2 multi 3.98 import weight 0.00
Epoch 386 Iter 1 subLoss 4016.4 multi 1.00 import weight 0.00
Epoch 386 Iter 2 subLoss 3814.3 multi -4.97 import weight 0.00
Epoch 386 Iter 3 subLoss 4379.8 multi -1.98 import weight 0.00
Epoch 386 Iter 4 subLoss 4004.9 multi -7.96 import weight 0.00
Epoch 386 Iter 5 subLoss 3695.4 multi 24.88 import weight 0.00
Epoch 386 Iter 6 subLoss 4353.5 multi 1.00 import weight 0.00
Epoch 386 Iter 7 subLoss 3861.1 multi -16.91 import weight 0.00
Epoch 386 Iter 8 subLoss 3771.9 multi 1.00 import weight 0.00
Epoch 386 Iter 9 subLoss 4249.9 multi 1.00 import weight 0.00
Epoch 386 Iter 10 subLoss 4451.1 multi 1.00 import weight 0.00
Epoch 386 Iter 11 subLoss 3978.4 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 386 Acc: 97.41 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 397 train Loss: 3947.4 test Loss: 589.5
Epoch 387 Iter 0 subLoss 4235.4 multi -4.97 import weight 0.00
Epoch 387 Iter 1 subLoss 4013.0 multi 1.00 import weight 0.00
Epoch 387 Iter 2 subLoss 3968.3 multi 1.00 import weight 0.00
Epoch 387 Iter 3 subLoss 4008.2 multi -4.97 import weight 0.00
Epoch 387 Iter 4 subLoss 3769.6 multi 6.97 import weight 0.00
Epoch 387 Iter 5 subLoss 3915.7 multi -4.97 import weight 0.00
Epoch 387 Iter 6 subLoss 4044.8 multi 6.97 import weight 0.00
Epoch 387 Iter 7 subLoss 4188.1 multi 6.97 import weight 0.00
Epoch 387 Iter 8 subLoss 3789.2 multi -13.93 import weight 0.00
Epoch 387 Iter 9 subLoss 4050.6 multi 1.00 import weight 0.00
Epoch 387 Iter 10 subLoss 4373.1 multi 1.00 import weight 0.00
Epoch 387 Iter 11 subLoss 4670.9 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 387 Acc: 97.37 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 467 train Loss: 3953.3 test Loss: 599.7
Epoch 388 Iter 0 subLoss 3603.4 multi -1.98 import weight 0.00
Epoch 388 Iter 1 subLoss 3750.5 multi 6.97 import weight 0.00
Epoch 388 Iter 2 subLoss 4354.3 multi 3.98 import weight 0.00
Epoch 388 Iter 3 subLoss 3966.2 multi 3.99 import weight 0.00
Epoch 388 Iter 4 subLoss 3966.4 multi 6.97 import weight 0.00
Epoch 388 Iter 5 subLoss 3781.9 multi -10.94 import weight 0.00
Epoch 388 Iter 6 subLoss 3755.6 multi 9.96 import weight 0.00
Epoch 388 Iter 7 subLoss 3978.5 multi 3.99 import weight 0.00
Epoch 388 Iter 8 subLoss 3868.6 multi -13.93 import weight 0.00
Epoch 388 Iter 9 subLoss 3801.0 multi -7.96 import weight 0.00
Epoch 388 Iter 10 subLoss 3888.3 multi 6.97 import weight 0.00
Epoch 388 Iter 11 subLoss 3537.7 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 388 Acc: 97.28 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 353 train Loss: 3907.5 test Loss: 564.6
Epoch 389 Iter 0 subLoss 3775.7 multi 1.00 import weight 0.00
Epoch 389 Iter 1 subLoss 3664.7 multi 3.99 import weight 0.00
Epoch 389 Iter 2 subLoss 3516.1 multi -1.98 import weight 0.00
Epoch 389 Iter 3 subLoss 3627.0 multi -1.98 import weight 0.00
Epoch 389 Iter 4 subLoss 4128.2 multi 21.90 import weight 1.00
Epoch 389 Iter 5 subLoss 3685.2 multi -7.96 import weight 0.00
Epoch 389 Iter 6 subLoss 4190.3 multi -1.99 import weight 0.00
Epoch 389 Iter 7 subLoss 5018.4 multi 1.00 import weight 0.00
Epoch 389 Iter 8 subLoss 4859.4 multi 3.98 import weight 0.00
Epoch 389 Iter 9 subLoss 4456.1 multi 3.99 import weight 0.00
Epoch 389 Iter 10 subLoss 3501.6 multi 9.96 import weight 0.00
Epoch 389 Iter 11 subLoss 3625.3 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 389 Acc: 97.57 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 362 train Loss: 3596.9 test Loss: 501.8
Epoch 390 Iter 0 subLoss 3538.3 multi 9.96 import weight 0.00
Epoch 390 Iter 1 subLoss 3689.9 multi -4.97 import weight 0.00
Epoch 390 Iter 2 subLoss 3742.5 multi -10.94 import weight 0.00
Epoch 390 Iter 3 subLoss 3976.6 multi 6.97 import weight 0.00
Epoch 390 Iter 4 subLoss 3548.7 multi -7.96 import weight 0.00
Epoch 390 Iter 5 subLoss 4134.2 multi -13.93 import weight 0.00
Epoch 390 Iter 6 subLoss 4344.1 multi 3.99 import weight 0.00
Epoch 390 Iter 7 subLoss 3951.8 multi -7.96 import weight 0.00
Epoch 390 Iter 8 subLoss 4321.7 multi 6.97 import weight 0.00
Epoch 390 Iter 9 subLoss 3165.1 multi 9.96 import weight 0.00
Epoch 390 Iter 10 subLoss 3633.6 multi -13.93 import weight 0.00
Epoch 390 Iter 11 subLoss 4288.7 multi 21.90 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 390 Acc: 97.57 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 21.90 Pidx 428 train Loss: 3960.7 test Loss: 528.5
Epoch 391 Iter 0 subLoss 3639.4 multi -10.94 import weight 0.00
Epoch 391 Iter 1 subLoss 4634.4 multi -7.96 import weight 0.00
Epoch 391 Iter 2 subLoss 9024.2 multi 3.99 import weight 0.00
Epoch 391 Iter 3 subLoss 4065.8 multi -7.96 import weight 0.00
Epoch 391 Iter 4 subLoss 4655.6 multi 3.99 import weight 0.00
Epoch 391 Iter 5 subLoss 4139.6 multi -10.94 import weight 0.00
Epoch 391 Iter 6 subLoss 5920.3 multi -4.97 import weight 0.00
Epoch 391 Iter 7 subLoss 5495.8 multi -1.99 import weight 0.00
Epoch 391 Iter 8 subLoss 6449.9 multi 3.98 import weight 0.00
Epoch 391 Iter 9 subLoss 4503.5 multi -4.97 import weight 0.00
Epoch 391 Iter 10 subLoss 5464.7 multi 9.96 import weight 0.00
Epoch 391 Iter 11 subLoss 4400.9 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 391 Acc: 97.63 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 440 train Loss: 4507.6 test Loss: 594.9
Epoch 392 Iter 0 subLoss 4403.5 multi 3.98 import weight 0.00
Epoch 392 Iter 1 subLoss 4035.9 multi -1.99 import weight 0.00
Epoch 392 Iter 2 subLoss 4321.0 multi 9.96 import weight 0.00
Epoch 392 Iter 3 subLoss 4314.0 multi -7.96 import weight 0.00
Epoch 392 Iter 4 subLoss 4360.7 multi -10.94 import weight 0.00
Epoch 392 Iter 5 subLoss 4407.5 multi 6.97 import weight 0.00
Epoch 392 Iter 6 subLoss 4156.9 multi -7.96 import weight 0.00
Epoch 392 Iter 7 subLoss 4392.9 multi 1.00 import weight 0.00
Epoch 392 Iter 8 subLoss 4576.2 multi 9.96 import weight 0.00
Epoch 392 Iter 9 subLoss 4197.7 multi 1.00 import weight 0.00
Epoch 392 Iter 10 subLoss 4256.8 multi 1.00 import weight 0.00
Epoch 392 Iter 11 subLoss 3776.4 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 392 Acc: 97.65 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 377 train Loss: 4111.3 test Loss: 565.3
Epoch 393 Iter 0 subLoss 4022.6 multi 1.00 import weight 0.00
Epoch 393 Iter 1 subLoss 3745.2 multi -7.96 import weight 0.00
Epoch 393 Iter 2 subLoss 4102.8 multi 12.94 import weight 0.00
Epoch 393 Iter 3 subLoss 4019.0 multi 1.00 import weight 0.00
Epoch 393 Iter 4 subLoss 3857.3 multi 18.91 import weight 0.00
Epoch 393 Iter 5 subLoss 4196.2 multi 3.98 import weight 0.00
Epoch 393 Iter 6 subLoss 3446.0 multi -1.99 import weight 0.00
Epoch 393 Iter 7 subLoss 3407.2 multi -4.97 import weight 0.00
Epoch 393 Iter 8 subLoss 3649.0 multi 1.00 import weight 0.00
Epoch 393 Iter 9 subLoss 4200.9 multi -1.99 import weight 0.00
Epoch 393 Iter 10 subLoss 4054.4 multi 3.99 import weight 0.00
Epoch 393 Iter 11 subLoss 3842.7 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 393 Acc: 97.74 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 384 train Loss: 3694.3 test Loss: 516.5
Epoch 394 Iter 0 subLoss 3685.2 multi -1.99 import weight 0.00
Epoch 394 Iter 1 subLoss 3430.5 multi 1.00 import weight 0.00
Epoch 394 Iter 2 subLoss 3888.6 multi 9.96 import weight 0.00
Epoch 394 Iter 3 subLoss 3535.5 multi 12.94 import weight 0.00
Epoch 394 Iter 4 subLoss 3500.1 multi 12.94 import weight 0.00
Epoch 394 Iter 5 subLoss 3571.4 multi 12.94 import weight 0.00
Epoch 394 Iter 6 subLoss 3242.9 multi -7.96 import weight 0.00
Epoch 394 Iter 7 subLoss 3541.3 multi -7.96 import weight 0.00
Epoch 394 Iter 8 subLoss 3672.0 multi -19.90 import weight 0.00
Epoch 394 Iter 9 subLoss 3504.1 multi 15.93 import weight 0.00
Epoch 394 Iter 10 subLoss 3892.0 multi -16.91 import weight 0.00
Epoch 394 Iter 11 subLoss 4687.6 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 394 Acc: 96.89 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 468 train Loss: 4883.8 test Loss: 670.7
Epoch 395 Iter 0 subLoss 5168.0 multi -1.99 import weight 0.00
Epoch 395 Iter 1 subLoss 5154.0 multi 3.99 import weight 0.00
Epoch 395 Iter 2 subLoss 4568.1 multi -7.96 import weight 0.00
Epoch 395 Iter 3 subLoss 4923.1 multi -16.91 import weight 0.00
Epoch 395 Iter 4 subLoss 39604.7 multi 1.00 import weight 0.00
Epoch 395 Iter 5 subLoss 14278.2 multi 1.00 import weight 0.00
Epoch 395 Iter 6 subLoss 8802.3 multi -1.98 import weight 0.00
Epoch 395 Iter 7 subLoss 12955.4 multi 1.00 import weight 0.00
Epoch 395 Iter 8 subLoss 8499.9 multi 6.97 import weight 0.00
Epoch 395 Iter 9 subLoss 4164.7 multi -7.96 import weight 0.00
Epoch 395 Iter 10 subLoss 4619.8 multi -13.93 import weight 0.00
Epoch 395 Iter 11 subLoss 6983.2 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 395 Acc: 92.76 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 698 train Loss: 6138.2 test Loss: 1136.1
Epoch 396 Iter 0 subLoss 5833.8 multi -1.98 import weight 0.00
Epoch 396 Iter 1 subLoss 7022.7 multi -1.99 import weight 0.00
Epoch 396 Iter 2 subLoss 7808.1 multi -4.97 import weight 0.00
Epoch 396 Iter 3 subLoss 15209.0 multi -7.96 import weight 0.00
Epoch 396 Iter 4 subLoss 197459.3 multi 1.00 import weight 0.00
Epoch 396 Iter 5 subLoss 14164.3 multi 1.00 import weight 0.00
Epoch 396 Iter 6 subLoss 12446.4 multi -4.97 import weight 0.00
Epoch 396 Iter 7 subLoss 20374.9 multi 3.98 import weight 0.00
Epoch 396 Iter 8 subLoss 12603.4 multi 1.00 import weight 0.00
Epoch 396 Iter 9 subLoss 11399.0 multi 9.96 import weight 0.00
Epoch 396 Iter 10 subLoss 6619.5 multi -1.99 import weight 0.00
Epoch 396 Iter 11 subLoss 6872.9 multi 21.90 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 396 Acc: 96.71 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 21.90 Pidx 687 train Loss: 5653.9 test Loss: 752.3
Epoch 397 Iter 0 subLoss 6156.2 multi -1.99 import weight 0.00
Epoch 397 Iter 1 subLoss 6753.9 multi 18.91 import weight 0.00
Epoch 397 Iter 2 subLoss 6813.8 multi -1.99 import weight 0.00
Epoch 397 Iter 3 subLoss 8750.2 multi 1.00 import weight 0.00
Epoch 397 Iter 4 subLoss 7115.4 multi 1.00 import weight 0.00
Epoch 397 Iter 5 subLoss 7295.2 multi 9.96 import weight 0.00
Epoch 397 Iter 6 subLoss 4489.7 multi -4.97 import weight 0.00
Epoch 397 Iter 7 subLoss 6043.8 multi -19.90 import weight 0.00
Epoch 397 Iter 8 subLoss 15406.8 multi -1.98 import weight 0.00
Epoch 397 Iter 9 subLoss 22843.3 multi 6.97 import weight 0.00
Epoch 397 Iter 10 subLoss 7231.3 multi 6.97 import weight 0.00
Epoch 397 Iter 11 subLoss 5200.3 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 397 Acc: 94.10 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 520 train Loss: 5625.1 test Loss: 1043.4
Epoch 398 Iter 0 subLoss 5221.6 multi -13.93 import weight 0.00
Epoch 398 Iter 1 subLoss 7139.9 multi 1.00 import weight 0.00
Epoch 398 Iter 2 subLoss 7169.8 multi -1.98 import weight 0.00
Epoch 398 Iter 3 subLoss 7627.2 multi 9.96 import weight 0.00
Epoch 398 Iter 4 subLoss 5620.8 multi 3.98 import weight 0.00
Epoch 398 Iter 5 subLoss 5795.4 multi 9.96 import weight 0.00
Epoch 398 Iter 6 subLoss 4257.1 multi 3.99 import weight 0.00
Epoch 398 Iter 7 subLoss 4456.6 multi 6.97 import weight 0.00
Epoch 398 Iter 8 subLoss 4272.9 multi -4.97 import weight 0.00
Epoch 398 Iter 9 subLoss 4276.7 multi -1.99 import weight 0.00
Epoch 398 Iter 10 subLoss 4339.8 multi 1.00 import weight 0.00
Epoch 398 Iter 11 subLoss 4457.2 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 398 Acc: 97.45 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 445 train Loss: 4084.7 test Loss: 596.9
Epoch 399 Iter 0 subLoss 3546.9 multi -4.97 import weight 0.00
Epoch 399 Iter 1 subLoss 4087.3 multi 3.99 import weight 0.00
Epoch 399 Iter 2 subLoss 4013.9 multi 3.99 import weight 0.00
Epoch 399 Iter 3 subLoss 4004.9 multi -1.99 import weight 0.00
Epoch 399 Iter 4 subLoss 4339.6 multi 3.99 import weight 0.00
Epoch 399 Iter 5 subLoss 3954.9 multi -4.97 import weight 0.00
Epoch 399 Iter 6 subLoss 4087.8 multi 6.97 import weight 0.00
Epoch 399 Iter 7 subLoss 4057.1 multi 6.97 import weight 0.00
Epoch 399 Iter 8 subLoss 3869.5 multi -13.93 import weight 0.00
Epoch 399 Iter 9 subLoss 4523.2 multi 1.00 import weight 0.00
Epoch 399 Iter 10 subLoss 4080.6 multi 9.96 import weight 0.00
Epoch 399 Iter 11 subLoss 3970.3 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 399 Acc: 97.66 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 397 train Loss: 3758.4 test Loss: 517.0
Epoch 400 Iter 0 subLoss 3794.0 multi 15.93 import weight 0.00
Epoch 400 Iter 1 subLoss 3130.5 multi 1.00 import weight 0.00
Epoch 400 Iter 2 subLoss 2946.5 multi 1.00 import weight 0.00
Epoch 400 Iter 3 subLoss 3667.0 multi 6.97 import weight 0.00
Epoch 400 Iter 4 subLoss 3633.1 multi -7.96 import weight 0.00
Epoch 400 Iter 5 subLoss 3541.6 multi -1.99 import weight 0.00
Epoch 400 Iter 6 subLoss 3644.9 multi 1.00 import weight 0.00
Epoch 400 Iter 7 subLoss 3750.3 multi 6.97 import weight 0.00
Epoch 400 Iter 8 subLoss 4260.1 multi -7.96 import weight 0.00
Epoch 400 Iter 9 subLoss 3282.1 multi -7.96 import weight 0.00
Epoch 400 Iter 10 subLoss 3902.1 multi 1.00 import weight 0.00
Epoch 400 Iter 11 subLoss 3326.4 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 400 Acc: 97.98 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 332 train Loss: 3790.7 test Loss: 494.4
Epoch 401 Iter 0 subLoss 3348.9 multi 9.96 import weight 0.00
Epoch 401 Iter 1 subLoss 3790.8 multi 18.91 import weight 0.00
Epoch 401 Iter 2 subLoss 3693.4 multi 18.91 import weight 0.00
Epoch 401 Iter 3 subLoss 3511.2 multi -7.96 import weight 0.00
Epoch 401 Iter 4 subLoss 3784.0 multi -13.93 import weight 0.00
Epoch 401 Iter 5 subLoss 4643.9 multi 18.91 import weight 0.00
Epoch 401 Iter 6 subLoss 3736.0 multi -7.96 import weight 0.00
Epoch 401 Iter 7 subLoss 5505.7 multi 1.00 import weight 0.00
Epoch 401 Iter 8 subLoss 5049.0 multi -7.96 import weight 0.00
Epoch 401 Iter 9 subLoss 10846.9 multi 6.97 import weight 0.00
Epoch 401 Iter 10 subLoss 4240.0 multi -1.99 import weight 0.00
Epoch 401 Iter 11 subLoss 4754.0 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 401 Acc: 97.70 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 475 train Loss: 3949.7 test Loss: 511.3
Epoch 402 Iter 0 subLoss 3429.9 multi 1.00 import weight 0.00
Epoch 402 Iter 1 subLoss 3592.8 multi -1.99 import weight 0.00
Epoch 402 Iter 2 subLoss 4615.4 multi -10.94 import weight 0.00
Epoch 402 Iter 3 subLoss 4580.2 multi -7.96 import weight 0.00
Epoch 402 Iter 4 subLoss 6682.8 multi -1.99 import weight 0.00
Epoch 402 Iter 5 subLoss 9316.2 multi 3.98 import weight 0.00
Epoch 402 Iter 6 subLoss 4599.7 multi -7.96 import weight 0.00
Epoch 402 Iter 7 subLoss 5884.9 multi 12.94 import weight 0.00
Epoch 402 Iter 8 subLoss 4338.0 multi 6.97 import weight 0.00
Epoch 402 Iter 9 subLoss 3811.8 multi -4.97 import weight 0.00
Epoch 402 Iter 10 subLoss 3912.3 multi -4.97 import weight 0.00
Epoch 402 Iter 11 subLoss 4133.7 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 402 Acc: 96.98 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 413 train Loss: 4762.2 test Loss: 654.7
Epoch 403 Iter 0 subLoss 4618.3 multi -7.96 import weight 0.00
Epoch 403 Iter 1 subLoss 5796.9 multi 12.94 import weight 0.00
Epoch 403 Iter 2 subLoss 4248.6 multi -1.99 import weight 0.00
Epoch 403 Iter 3 subLoss 4500.1 multi -1.99 import weight 0.00
Epoch 403 Iter 4 subLoss 4468.9 multi -28.85 import weight 0.00
Epoch 403 Iter 5 subLoss 17569.1 multi -4.97 import weight 0.00
Epoch 403 Iter 6 subLoss 51988.7 multi 1.00 import weight 0.00
Epoch 403 Iter 7 subLoss 37827.3 multi 1.00 import weight 0.00
Epoch 403 Iter 8 subLoss 32679.9 multi 3.99 import weight 0.00
Epoch 403 Iter 9 subLoss 15911.7 multi 1.00 import weight 0.00
Epoch 403 Iter 10 subLoss 13061.9 multi 1.00 import weight 0.00
Epoch 403 Iter 11 subLoss 11185.8 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 403 Acc: 93.50 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 1118 train Loss: 5896.5 test Loss: 1094.1
Epoch 404 Iter 0 subLoss 6410.5 multi 1.00 import weight 0.00
Epoch 404 Iter 1 subLoss 5812.3 multi -1.99 import weight 0.00
Epoch 404 Iter 2 subLoss 5692.6 multi -1.99 import weight 0.00
Epoch 404 Iter 3 subLoss 6219.4 multi 6.97 import weight 0.00
Epoch 404 Iter 4 subLoss 4504.0 multi 1.00 import weight 0.00
Epoch 404 Iter 5 subLoss 4515.1 multi 1.00 import weight 0.00
Epoch 404 Iter 6 subLoss 5127.5 multi 12.94 import weight 0.00
Epoch 404 Iter 7 subLoss 4095.6 multi -10.94 import weight 0.00
Epoch 404 Iter 8 subLoss 4676.1 multi 9.96 import weight 0.00
Epoch 404 Iter 9 subLoss 3883.9 multi 12.94 import weight 0.00
Epoch 404 Iter 10 subLoss 3935.1 multi 1.00 import weight 0.00
Epoch 404 Iter 11 subLoss 4265.2 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 404 Acc: 98.03 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 426 train Loss: 3928.9 test Loss: 505.9
Epoch 405 Iter 0 subLoss 3997.1 multi 18.91 import weight 0.00
Epoch 405 Iter 1 subLoss 4066.9 multi -10.94 import weight 0.00
Epoch 405 Iter 2 subLoss 4211.5 multi -7.96 import weight 0.00
Epoch 405 Iter 3 subLoss 4535.7 multi 3.99 import weight 0.00
Epoch 405 Iter 4 subLoss 4225.4 multi -1.99 import weight 0.00
Epoch 405 Iter 5 subLoss 4041.4 multi 6.97 import weight 0.00
Epoch 405 Iter 6 subLoss 4364.4 multi -7.96 import weight 0.00
Epoch 405 Iter 7 subLoss 4050.3 multi 6.97 import weight 0.00
Epoch 405 Iter 8 subLoss 3760.7 multi 1.00 import weight 0.00
Epoch 405 Iter 9 subLoss 3692.6 multi 21.90 import weight 0.00
Epoch 405 Iter 10 subLoss 3773.1 multi 3.98 import weight 0.00
Epoch 405 Iter 11 subLoss 3959.2 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 405 Acc: 97.86 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 395 train Loss: 3683.7 test Loss: 495.0
Epoch 406 Iter 0 subLoss 3420.2 multi 3.98 import weight 0.00
Epoch 406 Iter 1 subLoss 3802.8 multi -10.94 import weight 0.00
Epoch 406 Iter 2 subLoss 4210.6 multi -4.97 import weight 0.00
Epoch 406 Iter 3 subLoss 3811.4 multi -4.97 import weight 0.00
Epoch 406 Iter 4 subLoss 4384.1 multi 3.99 import weight 0.00
Epoch 406 Iter 5 subLoss 4417.1 multi -16.91 import weight 0.00
Epoch 406 Iter 6 subLoss 4115.8 multi -13.93 import weight 0.00
Epoch 406 Iter 7 subLoss 8592.5 multi 12.94 import weight 0.00
Epoch 406 Iter 8 subLoss 6280.0 multi -7.96 import weight 0.00
Epoch 406 Iter 9 subLoss 12411.7 multi 1.00 import weight 0.00
Epoch 406 Iter 10 subLoss 9665.2 multi -4.97 import weight 0.00
Epoch 406 Iter 11 subLoss 34434.8 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 406 Acc: 88.87 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 3443 train Loss: 13650.1 test Loss: 2144.9
Epoch 407 Iter 0 subLoss 13312.4 multi 3.99 import weight 0.00
Epoch 407 Iter 1 subLoss 4695.9 multi -4.97 import weight 0.00
Epoch 407 Iter 2 subLoss 5239.9 multi -7.96 import weight 0.00
Epoch 407 Iter 3 subLoss 9292.7 multi -4.97 import weight 0.00
Epoch 407 Iter 4 subLoss 16204.1 multi 1.00 import weight 0.00
Epoch 407 Iter 5 subLoss 10378.4 multi 1.00 import weight 0.00
Epoch 407 Iter 6 subLoss 10094.7 multi 3.99 import weight 0.00
Epoch 407 Iter 7 subLoss 5732.3 multi -4.97 import weight 0.00
Epoch 407 Iter 8 subLoss 7037.6 multi -1.99 import weight 0.00
Epoch 407 Iter 9 subLoss 8614.8 multi -7.96 import weight 0.00
Epoch 407 Iter 10 subLoss 14366.0 multi 6.97 import weight 0.00
Epoch 407 Iter 11 subLoss 7994.6 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 407 Acc: 95.19 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 799 train Loss: 5718.4 test Loss: 942.2
Epoch 408 Iter 0 subLoss 5761.9 multi 3.98 import weight 0.00
Epoch 408 Iter 1 subLoss 5103.4 multi -10.94 import weight 0.00
Epoch 408 Iter 2 subLoss 5963.5 multi -10.94 import weight 0.00
Epoch 408 Iter 3 subLoss 8692.5 multi -1.98 import weight 0.00
Epoch 408 Iter 4 subLoss 10842.0 multi 9.96 import weight 0.00
Epoch 408 Iter 5 subLoss 7412.4 multi 6.97 import weight 0.00
Epoch 408 Iter 6 subLoss 5428.2 multi -1.99 import weight 0.00
Epoch 408 Iter 7 subLoss 4591.8 multi -4.97 import weight 0.00
Epoch 408 Iter 8 subLoss 6234.8 multi -7.96 import weight 0.00
Epoch 408 Iter 9 subLoss 6922.7 multi 12.94 import weight 0.00
Epoch 408 Iter 10 subLoss 5316.5 multi 15.93 import weight 0.00
Epoch 408 Iter 11 subLoss 4253.6 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 408 Acc: 97.53 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 425 train Loss: 4426.9 test Loss: 563.0
Epoch 409 Iter 0 subLoss 4149.5 multi -1.98 import weight 0.00
Epoch 409 Iter 1 subLoss 4114.1 multi -10.94 import weight 0.00
Epoch 409 Iter 2 subLoss 5143.7 multi 3.99 import weight 0.00
Epoch 409 Iter 3 subLoss 4314.9 multi -4.97 import weight 0.00
Epoch 409 Iter 4 subLoss 5237.5 multi -4.97 import weight 0.00
Epoch 409 Iter 5 subLoss 5462.3 multi 12.94 import weight 0.00
Epoch 409 Iter 6 subLoss 4018.9 multi 3.98 import weight 0.00
Epoch 409 Iter 7 subLoss 4406.3 multi 6.97 import weight 0.00
Epoch 409 Iter 8 subLoss 4269.1 multi -4.97 import weight 0.00
Epoch 409 Iter 9 subLoss 3851.9 multi 18.91 import weight 0.00
Epoch 409 Iter 10 subLoss 3812.6 multi -1.99 import weight 0.00
Epoch 409 Iter 11 subLoss 4472.9 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 409 Acc: 97.92 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 447 train Loss: 3752.0 test Loss: 494.8
Epoch 410 Iter 0 subLoss 3635.2 multi -4.97 import weight 0.00
Epoch 410 Iter 1 subLoss 3476.9 multi -7.96 import weight 0.00
Epoch 410 Iter 2 subLoss 4044.2 multi 9.96 import weight 0.00
Epoch 410 Iter 3 subLoss 3925.4 multi -1.98 import weight 0.00
Epoch 410 Iter 4 subLoss 3741.6 multi -7.96 import weight 0.00
Epoch 410 Iter 5 subLoss 4367.5 multi -4.97 import weight 0.00
Epoch 410 Iter 6 subLoss 4132.9 multi -4.97 import weight 0.00
Epoch 410 Iter 7 subLoss 5221.8 multi -10.94 import weight 0.00
Epoch 410 Iter 8 subLoss 9037.2 multi 1.00 import weight 0.00
Epoch 410 Iter 9 subLoss 7226.3 multi -7.96 import weight 0.00
Epoch 410 Iter 10 subLoss 23567.6 multi -4.97 import weight 0.00
Epoch 410 Iter 11 subLoss 252232.0 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 410 Acc: 59.78 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 25223 train Loss: 39236.9 test Loss: 5022.2
Epoch 411 Iter 0 subLoss 37685.1 multi -1.99 import weight 0.00
Epoch 411 Iter 1 subLoss 58917.9 multi -1.99 import weight 0.00
Epoch 411 Iter 2 subLoss 87599.6 multi 1.00 import weight 0.00
Epoch 411 Iter 3 subLoss 64285.0 multi 1.00 import weight 0.00
Epoch 411 Iter 4 subLoss 56140.3 multi 1.00 import weight 0.00
Epoch 411 Iter 5 subLoss 48602.7 multi -1.99 import weight 0.00
Epoch 411 Iter 6 subLoss 60848.6 multi 1.00 import weight 0.00
Epoch 411 Iter 7 subLoss 55113.8 multi 1.00 import weight 0.00
Epoch 411 Iter 8 subLoss 49376.8 multi 1.00 import weight 0.00
Epoch 411 Iter 9 subLoss 43397.0 multi -1.99 import weight 0.00
Epoch 411 Iter 10 subLoss 55472.3 multi 1.00 import weight 0.00
Epoch 411 Iter 11 subLoss 50482.7 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 411 Acc: 47.85 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 5048 train Loss: 45260.3 test Loss: 6101.6
Epoch 412 Iter 0 subLoss 44571.5 multi 1.00 import weight 0.00
Epoch 412 Iter 1 subLoss 40050.7 multi 3.99 import weight 0.00
Epoch 412 Iter 2 subLoss 20614.0 multi 1.00 import weight 0.00
Epoch 412 Iter 3 subLoss 19018.2 multi 1.00 import weight 0.00
Epoch 412 Iter 4 subLoss 15666.4 multi 1.00 import weight 0.00
Epoch 412 Iter 5 subLoss 14238.3 multi -1.98 import weight 0.00
Epoch 412 Iter 6 subLoss 17661.2 multi 3.98 import weight 0.00
Epoch 412 Iter 7 subLoss 11244.6 multi -7.96 import weight 0.00
Epoch 412 Iter 8 subLoss 19112.1 multi 3.99 import weight 0.00
Epoch 412 Iter 9 subLoss 12237.0 multi 1.00 import weight 0.00
Epoch 412 Iter 10 subLoss 12003.3 multi 3.99 import weight 0.00
Epoch 412 Iter 11 subLoss 9055.6 multi 3.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 412 Acc: 96.61 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 905 train Loss: 8485.6 test Loss: 820.2
Epoch 413 Iter 0 subLoss 8436.0 multi -7.96 import weight 0.00
Epoch 413 Iter 1 subLoss 10360.0 multi 3.99 import weight 0.00
Epoch 413 Iter 2 subLoss 9131.3 multi 6.97 import weight 0.00
Epoch 413 Iter 3 subLoss 7683.2 multi 6.97 import weight 0.00
Epoch 413 Iter 4 subLoss 6552.1 multi 3.99 import weight 0.00
Epoch 413 Iter 5 subLoss 6311.4 multi -1.98 import weight 0.00
Epoch 413 Iter 6 subLoss 6656.5 multi -1.98 import weight 0.00
Epoch 413 Iter 7 subLoss 7039.4 multi 1.00 import weight 0.00
Epoch 413 Iter 8 subLoss 6546.5 multi -19.90 import weight 0.00
Epoch 413 Iter 9 subLoss 9298.4 multi -1.99 import weight 0.00
Epoch 413 Iter 10 subLoss 9762.4 multi 9.96 import weight 0.00
Epoch 413 Iter 11 subLoss 7579.7 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 413 Acc: 96.03 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 757 train Loss: 8620.3 test Loss: 877.8
Epoch 414 Iter 0 subLoss 8389.3 multi -1.98 import weight 0.00
Epoch 414 Iter 1 subLoss 8509.5 multi 6.97 import weight 0.00
Epoch 414 Iter 2 subLoss 8228.1 multi 1.00 import weight 0.00
Epoch 414 Iter 3 subLoss 7119.9 multi 3.99 import weight 0.00
Epoch 414 Iter 4 subLoss 7018.1 multi 3.99 import weight 0.00
Epoch 414 Iter 5 subLoss 7110.7 multi 6.97 import weight 0.00
Epoch 414 Iter 6 subLoss 6221.2 multi -1.98 import weight 0.00
Epoch 414 Iter 7 subLoss 6443.7 multi 6.97 import weight 0.00
Epoch 414 Iter 8 subLoss 6155.4 multi 1.00 import weight 0.00
Epoch 414 Iter 9 subLoss 6082.1 multi 6.97 import weight 0.00
Epoch 414 Iter 10 subLoss 5148.6 multi 6.97 import weight 0.00
Epoch 414 Iter 11 subLoss 5179.6 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 414 Acc: 97.26 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 517 train Loss: 5382.8 test Loss: 600.6
Epoch 415 Iter 0 subLoss 5153.9 multi 1.00 import weight 0.00
Epoch 415 Iter 1 subLoss 4939.6 multi -7.96 import weight 0.00
Epoch 415 Iter 2 subLoss 5599.5 multi 12.94 import weight 0.00
Epoch 415 Iter 3 subLoss 5585.7 multi -1.99 import weight 0.00
Epoch 415 Iter 4 subLoss 5210.3 multi 24.88 import weight 0.00
Epoch 415 Iter 5 subLoss 4175.0 multi -4.97 import weight 0.00
Epoch 415 Iter 6 subLoss 5748.0 multi -4.97 import weight 0.00
Epoch 415 Iter 7 subLoss 8904.7 multi 3.99 import weight 0.00
Epoch 415 Iter 8 subLoss 5486.0 multi -1.99 import weight 0.00
Epoch 415 Iter 9 subLoss 4677.7 multi 12.94 import weight 0.00
Epoch 415 Iter 10 subLoss 4317.4 multi -1.98 import weight 0.00
Epoch 415 Iter 11 subLoss 4901.9 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 415 Acc: 97.18 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 490 train Loss: 4846.8 test Loss: 602.1
Epoch 416 Iter 0 subLoss 5335.1 multi -4.97 import weight 0.00
Epoch 416 Iter 1 subLoss 6027.8 multi -1.99 import weight 0.00
Epoch 416 Iter 2 subLoss 6358.3 multi -7.96 import weight 0.00
Epoch 416 Iter 3 subLoss 17926.3 multi -4.97 import weight 0.00
Epoch 416 Iter 4 subLoss 258288.6 multi 1.00 import weight 0.00
Epoch 416 Iter 5 subLoss 18120.2 multi -4.97 import weight 0.00
Epoch 416 Iter 6 subLoss 55334.9 multi 1.00 import weight 0.00
Epoch 416 Iter 7 subLoss 37536.1 multi 1.00 import weight 0.00
Epoch 416 Iter 8 subLoss 29274.1 multi 1.00 import weight 0.00
Epoch 416 Iter 9 subLoss 24704.8 multi 3.99 import weight 0.00
Epoch 416 Iter 10 subLoss 12664.9 multi -4.97 import weight 0.00
Epoch 416 Iter 11 subLoss 16043.9 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 416 Acc: 86.42 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1604 train Loss: 15131.1 test Loss: 1871.0
Epoch 417 Iter 0 subLoss 14551.2 multi -1.99 import weight 0.00
Epoch 417 Iter 1 subLoss 17905.5 multi 3.99 import weight 0.00
Epoch 417 Iter 2 subLoss 13101.4 multi -1.98 import weight 0.00
Epoch 417 Iter 3 subLoss 13548.6 multi 1.00 import weight 0.00
Epoch 417 Iter 4 subLoss 12992.6 multi -1.99 import weight 0.00
Epoch 417 Iter 5 subLoss 14184.3 multi -1.99 import weight 0.00
Epoch 417 Iter 6 subLoss 15528.8 multi 1.00 import weight 0.00
Epoch 417 Iter 7 subLoss 14092.3 multi -1.99 import weight 0.00
Epoch 417 Iter 8 subLoss 16397.1 multi -10.94 import weight 0.00
Epoch 417 Iter 9 subLoss 32459.8 multi 1.00 import weight 0.00
Epoch 417 Iter 10 subLoss 27508.5 multi 1.00 import weight 0.00
Epoch 417 Iter 11 subLoss 25492.2 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 417 Acc: 80.35 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 2549 train Loss: 19389.8 test Loss: 2419.4
Epoch 418 Iter 0 subLoss 19547.1 multi 1.00 import weight 0.00
Epoch 418 Iter 1 subLoss 18009.6 multi -1.99 import weight 0.00
Epoch 418 Iter 2 subLoss 19052.7 multi 1.00 import weight 0.00
Epoch 418 Iter 3 subLoss 20041.8 multi -1.98 import weight 0.00
Epoch 418 Iter 4 subLoss 20465.0 multi 1.00 import weight 0.00
Epoch 418 Iter 5 subLoss 19633.0 multi 1.00 import weight 0.00
Epoch 418 Iter 6 subLoss 20212.5 multi 1.00 import weight 0.00
Epoch 418 Iter 7 subLoss 18257.7 multi -1.99 import weight 0.00
Epoch 418 Iter 8 subLoss 18849.5 multi 3.98 import weight 0.00
Epoch 418 Iter 9 subLoss 16095.2 multi 3.99 import weight 0.00
Epoch 418 Iter 10 subLoss 13927.1 multi -1.99 import weight 0.00
Epoch 418 Iter 11 subLoss 16129.9 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 418 Acc: 85.97 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1612 train Loss: 15135.9 test Loss: 1918.6
Epoch 419 Iter 0 subLoss 14785.7 multi 3.99 import weight 0.00
Epoch 419 Iter 1 subLoss 14058.5 multi 3.99 import weight 0.00
Epoch 419 Iter 2 subLoss 11744.5 multi 6.97 import weight 0.00
Epoch 419 Iter 3 subLoss 9751.4 multi -1.99 import weight 0.00
Epoch 419 Iter 4 subLoss 10168.9 multi -1.98 import weight 0.00
Epoch 419 Iter 5 subLoss 10593.7 multi -4.97 import weight 0.00
Epoch 419 Iter 6 subLoss 11598.5 multi 3.99 import weight 0.00
Epoch 419 Iter 7 subLoss 10508.0 multi 1.00 import weight 0.00
Epoch 419 Iter 8 subLoss 10217.7 multi 1.00 import weight 0.00
Epoch 419 Iter 9 subLoss 9872.8 multi -7.96 import weight 0.00
Epoch 419 Iter 10 subLoss 13129.6 multi 6.97 import weight 0.00
Epoch 419 Iter 11 subLoss 10816.7 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 419 Acc: 93.56 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 1081 train Loss: 9836.3 test Loss: 1198.9
Epoch 420 Iter 0 subLoss 9787.6 multi -1.99 import weight 0.00
Epoch 420 Iter 1 subLoss 10298.9 multi 1.00 import weight 0.00
Epoch 420 Iter 2 subLoss 9578.7 multi -7.96 import weight 0.00
Epoch 420 Iter 3 subLoss 10705.9 multi -4.97 import weight 0.00
Epoch 420 Iter 4 subLoss 13050.9 multi 1.00 import weight 0.00
Epoch 420 Iter 5 subLoss 12092.0 multi -1.99 import weight 0.00
Epoch 420 Iter 6 subLoss 12830.1 multi 6.97 import weight 0.00
Epoch 420 Iter 7 subLoss 11470.2 multi 6.97 import weight 0.00
Epoch 420 Iter 8 subLoss 10182.3 multi 9.96 import weight 0.00
Epoch 420 Iter 9 subLoss 7936.3 multi 12.94 import weight 0.00
Epoch 420 Iter 10 subLoss 6800.6 multi 6.97 import weight 0.00
Epoch 420 Iter 11 subLoss 6007.2 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 420 Acc: 97.14 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 600 train Loss: 5764.9 test Loss: 717.6
Epoch 421 Iter 0 subLoss 5798.5 multi 15.93 import weight 0.00
Epoch 421 Iter 1 subLoss 5071.4 multi 1.00 import weight 0.00
Epoch 421 Iter 2 subLoss 4931.2 multi -4.97 import weight 0.00
Epoch 421 Iter 3 subLoss 4777.4 multi -13.93 import weight 0.00
Epoch 421 Iter 4 subLoss 5637.9 multi -7.96 import weight 0.00
Epoch 421 Iter 5 subLoss 9664.4 multi -1.99 import weight 0.00
Epoch 421 Iter 6 subLoss 16000.5 multi -1.99 import weight 0.00
Epoch 421 Iter 7 subLoss 40434.9 multi 1.00 import weight 0.00
Epoch 421 Iter 8 subLoss 12511.5 multi -1.99 import weight 0.00
Epoch 421 Iter 9 subLoss 23269.8 multi 1.00 import weight 0.00
Epoch 421 Iter 10 subLoss 13125.1 multi 9.96 import weight 0.00
Epoch 421 Iter 11 subLoss 10322.3 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 421 Acc: 89.92 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1032 train Loss: 8853.1 test Loss: 1617.0
Epoch 422 Iter 0 subLoss 8393.0 multi 1.00 import weight 0.00
Epoch 422 Iter 1 subLoss 7833.2 multi 1.00 import weight 0.00
Epoch 422 Iter 2 subLoss 7551.2 multi -1.99 import weight 0.00
Epoch 422 Iter 3 subLoss 8087.0 multi 12.94 import weight 0.00
Epoch 422 Iter 4 subLoss 5124.9 multi 15.93 import weight 0.00
Epoch 422 Iter 5 subLoss 4332.1 multi 9.96 import weight 0.00
Epoch 422 Iter 6 subLoss 4267.6 multi -1.98 import weight 0.00
Epoch 422 Iter 7 subLoss 4576.5 multi 9.96 import weight 0.00
Epoch 422 Iter 8 subLoss 4201.5 multi 1.00 import weight 0.00
Epoch 422 Iter 9 subLoss 4446.1 multi 1.00 import weight 0.00
Epoch 422 Iter 10 subLoss 3944.7 multi 3.99 import weight 0.00
Epoch 422 Iter 11 subLoss 3655.4 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 422 Acc: 97.90 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 365 train Loss: 4016.3 test Loss: 513.5
Epoch 423 Iter 0 subLoss 3926.9 multi 1.00 import weight 0.00
Epoch 423 Iter 1 subLoss 4050.0 multi 6.97 import weight 1.00
Epoch 423 Iter 2 subLoss 3766.1 multi 3.99 import weight 0.00
Epoch 423 Iter 3 subLoss 4127.6 multi 18.91 import weight 1.00
Epoch 423 Iter 4 subLoss 4226.5 multi -1.98 import weight 0.00
Epoch 423 Iter 5 subLoss 4172.9 multi -1.99 import weight 0.00
Epoch 423 Iter 6 subLoss 4061.9 multi -13.93 import weight 0.00
Epoch 423 Iter 7 subLoss 3945.4 multi 6.97 import weight 0.00
Epoch 423 Iter 8 subLoss 3979.3 multi 12.94 import weight 0.00
Epoch 423 Iter 9 subLoss 3448.1 multi -1.98 import weight 0.00
Epoch 423 Iter 10 subLoss 3509.0 multi 18.91 import weight 0.00
Epoch 423 Iter 11 subLoss 3355.5 multi -10.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 423 Acc: 98.13 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -10.94 Pidx 335 train Loss: 3855.9 test Loss: 460.4
Epoch 424 Iter 0 subLoss 3768.5 multi 6.97 import weight 0.00
Epoch 424 Iter 1 subLoss 3076.0 multi -10.94 import weight 0.00
Epoch 424 Iter 2 subLoss 3641.9 multi 1.00 import weight 0.00
Epoch 424 Iter 3 subLoss 3527.4 multi -10.94 import weight 0.00
Epoch 424 Iter 4 subLoss 3898.7 multi -16.91 import weight 0.00
Epoch 424 Iter 5 subLoss 5068.4 multi 1.00 import weight 0.00
Epoch 424 Iter 6 subLoss 4789.0 multi 3.99 import weight 0.00
Epoch 424 Iter 7 subLoss 4306.1 multi -1.99 import weight 0.00
Epoch 424 Iter 8 subLoss 4602.0 multi 3.99 import weight 0.00
Epoch 424 Iter 9 subLoss 4732.1 multi -4.97 import weight 0.00
Epoch 424 Iter 10 subLoss 4768.7 multi -1.99 import weight 0.00
Epoch 424 Iter 11 subLoss 4476.0 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 424 Acc: 98.00 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 447 train Loss: 3858.8 test Loss: 485.2
Epoch 425 Iter 0 subLoss 4171.8 multi 1.00 import weight 0.00
Epoch 425 Iter 1 subLoss 3778.5 multi 1.00 import weight 0.00
Epoch 425 Iter 2 subLoss 3569.9 multi -4.97 import weight 0.00
Epoch 425 Iter 3 subLoss 3850.5 multi 21.90 import weight 0.00
Epoch 425 Iter 4 subLoss 4049.2 multi 12.94 import weight 0.00
Epoch 425 Iter 5 subLoss 3961.6 multi 1.00 import weight 0.00
Epoch 425 Iter 6 subLoss 3695.2 multi 24.88 import weight 0.00
Epoch 425 Iter 7 subLoss 3496.8 multi -10.94 import weight 0.00
Epoch 425 Iter 8 subLoss 3486.9 multi 6.97 import weight 0.00
Epoch 425 Iter 9 subLoss 3630.9 multi -1.99 import weight 0.00
Epoch 425 Iter 10 subLoss 3638.3 multi 1.00 import weight 0.00
Epoch 425 Iter 11 subLoss 3219.9 multi -22.88 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 425 Acc: 97.63 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -22.88 Pidx 321 train Loss: 4561.5 test Loss: 576.2
Epoch 426 Iter 0 subLoss 4722.7 multi 3.99 import weight 0.00
Epoch 426 Iter 1 subLoss 3960.1 multi 3.99 import weight 0.00
Epoch 426 Iter 2 subLoss 3671.1 multi -19.90 import weight 0.00
Epoch 426 Iter 3 subLoss 4767.9 multi 1.00 import weight 0.00
Epoch 426 Iter 4 subLoss 4667.7 multi -19.90 import weight 0.00
Epoch 426 Iter 5 subLoss 9582.0 multi 1.00 import weight 0.00
Epoch 426 Iter 6 subLoss 7496.3 multi 9.96 import weight 0.00
Epoch 426 Iter 7 subLoss 4454.2 multi 9.96 import weight 0.00
Epoch 426 Iter 8 subLoss 3889.4 multi 15.93 import weight 0.00
Epoch 426 Iter 9 subLoss 3644.3 multi -1.99 import weight 0.00
Epoch 426 Iter 10 subLoss 3835.9 multi -7.96 import weight 0.00
Epoch 426 Iter 11 subLoss 3808.5 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 426 Acc: 97.26 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 380 train Loss: 4433.1 test Loss: 570.5
Epoch 427 Iter 0 subLoss 4624.4 multi 1.00 import weight 0.00
Epoch 427 Iter 1 subLoss 3913.5 multi -1.99 import weight 0.00
Epoch 427 Iter 2 subLoss 4089.2 multi 12.94 import weight 0.00
Epoch 427 Iter 3 subLoss 3380.7 multi -4.97 import weight 0.00
Epoch 427 Iter 4 subLoss 3482.0 multi 9.96 import weight 0.00
Epoch 427 Iter 5 subLoss 3662.1 multi 6.97 import weight 0.00
Epoch 427 Iter 6 subLoss 3790.2 multi 18.91 import weight 0.00
Epoch 427 Iter 7 subLoss 3543.2 multi 1.00 import weight 0.00
Epoch 427 Iter 8 subLoss 3787.4 multi -16.91 import weight 0.00
Epoch 427 Iter 9 subLoss 4314.9 multi -1.99 import weight 0.00
Epoch 427 Iter 10 subLoss 3545.0 multi 3.98 import weight 0.00
Epoch 427 Iter 11 subLoss 3413.4 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 427 Acc: 98.07 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 341 train Loss: 3535.6 test Loss: 438.0
Epoch 428 Iter 0 subLoss 3008.7 multi 3.99 import weight 0.00
Epoch 428 Iter 1 subLoss 3477.9 multi -4.97 import weight 0.00
Epoch 428 Iter 2 subLoss 3637.7 multi 3.99 import weight 0.00
Epoch 428 Iter 3 subLoss 3417.1 multi 15.93 import weight 0.00
Epoch 428 Iter 4 subLoss 3543.9 multi 6.97 import weight 0.00
Epoch 428 Iter 5 subLoss 3097.7 multi 3.99 import weight 0.00
Epoch 428 Iter 6 subLoss 3381.1 multi -1.98 import weight 0.00
Epoch 428 Iter 7 subLoss 3075.8 multi -7.96 import weight 0.00
Epoch 428 Iter 8 subLoss 3294.8 multi 18.91 import weight 0.00
Epoch 428 Iter 9 subLoss 3240.1 multi -4.97 import weight 0.00
Epoch 428 Iter 10 subLoss 3918.0 multi 1.00 import weight 0.00
Epoch 428 Iter 11 subLoss 3029.9 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 428 Acc: 98.15 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 302 train Loss: 3340.8 test Loss: 399.2
Epoch 429 Iter 0 subLoss 3362.6 multi 15.93 import weight 0.00
Epoch 429 Iter 1 subLoss 3011.3 multi -1.99 import weight 0.00
Epoch 429 Iter 2 subLoss 3991.5 multi 21.90 import weight 0.00
Epoch 429 Iter 3 subLoss 3197.9 multi -1.99 import weight 0.00
Epoch 429 Iter 4 subLoss 3591.1 multi 1.00 import weight 0.00
Epoch 429 Iter 5 subLoss 3750.6 multi 6.97 import weight 0.00
Epoch 429 Iter 6 subLoss 2886.2 multi 9.96 import weight 0.00
Epoch 429 Iter 7 subLoss 3295.8 multi 21.90 import weight 0.00
Epoch 429 Iter 8 subLoss 2960.1 multi -1.98 import weight 0.00
Epoch 429 Iter 9 subLoss 3606.4 multi -4.97 import weight 0.00
Epoch 429 Iter 10 subLoss 3771.7 multi 3.99 import weight 0.00
Epoch 429 Iter 11 subLoss 3559.2 multi -13.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 429 Acc: 96.32 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -13.93 Pidx 355 train Loss: 4704.3 test Loss: 723.4
Epoch 430 Iter 0 subLoss 5327.8 multi -4.97 import weight 0.00
Epoch 430 Iter 1 subLoss 7502.9 multi -7.96 import weight 0.00
Epoch 430 Iter 2 subLoss 37310.2 multi 3.99 import weight 0.00
Epoch 430 Iter 3 subLoss 4951.0 multi -1.99 import weight 0.00
Epoch 430 Iter 4 subLoss 7218.8 multi 6.97 import weight 0.00
Epoch 430 Iter 5 subLoss 3541.3 multi 9.96 import weight 0.00
Epoch 430 Iter 6 subLoss 3472.1 multi -1.99 import weight 0.00
Epoch 430 Iter 7 subLoss 3379.9 multi -13.93 import weight 0.00
Epoch 430 Iter 8 subLoss 3803.0 multi -7.96 import weight 0.00
Epoch 430 Iter 9 subLoss 3963.8 multi 6.97 import weight 0.00
Epoch 430 Iter 10 subLoss 3331.1 multi -10.94 import weight 0.00
Epoch 430 Iter 11 subLoss 4317.7 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 430 Acc: 97.78 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 431 train Loss: 4191.4 test Loss: 442.9
Epoch 431 Iter 0 subLoss 3937.3 multi -1.99 import weight 0.00
Epoch 431 Iter 1 subLoss 4148.2 multi -1.99 import weight 0.00
Epoch 431 Iter 2 subLoss 4095.5 multi -10.94 import weight 0.00
Epoch 431 Iter 3 subLoss 8697.6 multi 1.00 import weight 0.00
Epoch 431 Iter 4 subLoss 5468.0 multi 15.93 import weight 0.00
Epoch 431 Iter 5 subLoss 4262.1 multi 1.00 import weight 0.00
Epoch 431 Iter 6 subLoss 4210.2 multi -4.97 import weight 0.00
Epoch 431 Iter 7 subLoss 6083.1 multi 9.96 import weight 0.00
Epoch 431 Iter 8 subLoss 3187.0 multi -4.97 import weight 0.00
Epoch 431 Iter 9 subLoss 3378.7 multi -10.94 import weight 0.00
Epoch 431 Iter 10 subLoss 4064.4 multi -10.94 import weight 0.00
Epoch 431 Iter 11 subLoss 5625.6 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 431 Acc: 97.74 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 562 train Loss: 3744.4 test Loss: 449.7
Epoch 432 Iter 0 subLoss 3664.6 multi 9.96 import weight 0.00
Epoch 432 Iter 1 subLoss 3664.0 multi 12.94 import weight 1.00
Epoch 432 Iter 2 subLoss 3663.2 multi 15.93 import weight 1.00
Epoch 432 Iter 3 subLoss 3279.7 multi -4.97 import weight 0.00
Epoch 432 Iter 4 subLoss 2955.2 multi -4.97 import weight 0.00
Epoch 432 Iter 5 subLoss 3066.8 multi 6.97 import weight 0.00
Epoch 432 Iter 6 subLoss 3187.7 multi -1.98 import weight 0.00
Epoch 432 Iter 7 subLoss 3590.4 multi 3.99 import weight 0.00
Epoch 432 Iter 8 subLoss 3103.8 multi 3.99 import weight 0.00
Epoch 432 Iter 9 subLoss 3903.0 multi 1.00 import weight 0.00
Epoch 432 Iter 10 subLoss 3311.8 multi 9.96 import weight 0.00
Epoch 432 Iter 11 subLoss 3640.7 multi -1.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 432 Acc: 98.23 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 364 train Loss: 3187.2 test Loss: 355.6
Epoch 433 Iter 0 subLoss 3432.6 multi -1.99 import weight 0.00
Epoch 433 Iter 1 subLoss 3349.2 multi 9.96 import weight 0.00
Epoch 433 Iter 2 subLoss 2789.8 multi -4.97 import weight 0.00
Epoch 433 Iter 3 subLoss 3539.9 multi 12.94 import weight 0.00
Epoch 433 Iter 4 subLoss 3448.0 multi -1.99 import weight 0.00
Epoch 433 Iter 5 subLoss 3613.4 multi -1.99 import weight 0.00
Epoch 433 Iter 6 subLoss 3266.5 multi 1.00 import weight 0.00
Epoch 433 Iter 7 subLoss 3140.3 multi -7.96 import weight 0.00
Epoch 433 Iter 8 subLoss 3508.9 multi 18.91 import weight 0.00
Epoch 433 Iter 9 subLoss 3068.9 multi 9.96 import weight 0.00
Epoch 433 Iter 10 subLoss 2983.7 multi -16.91 import weight 0.00
Epoch 433 Iter 11 subLoss 3152.2 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 433 Acc: 97.98 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 315 train Loss: 3383.1 test Loss: 373.1
Epoch 434 Iter 0 subLoss 2667.0 multi -13.93 import weight 0.00
Epoch 434 Iter 1 subLoss 4172.8 multi 3.99 import weight 0.00
Epoch 434 Iter 2 subLoss 3657.4 multi 3.99 import weight 0.00
Epoch 434 Iter 3 subLoss 3709.7 multi -19.90 import weight 0.00
Epoch 434 Iter 4 subLoss 4269.2 multi 3.99 import weight 0.00
Epoch 434 Iter 5 subLoss 3788.9 multi -16.91 import weight 0.00
Epoch 434 Iter 6 subLoss 6026.6 multi 1.00 import weight 0.00
Epoch 434 Iter 7 subLoss 5091.0 multi -7.96 import weight 0.00
Epoch 434 Iter 8 subLoss 9697.8 multi -10.94 import weight 0.00
Epoch 434 Iter 9 subLoss 65509.2 multi 1.00 import weight 0.00
Epoch 434 Iter 10 subLoss 23517.5 multi 1.00 import weight 0.00
Epoch 434 Iter 11 subLoss 15078.9 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 434 Acc: 97.10 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 1507 train Loss: 5134.0 test Loss: 594.5
Epoch 435 Iter 0 subLoss 5007.4 multi 1.00 import weight 0.00
Epoch 435 Iter 1 subLoss 4615.8 multi -7.96 import weight 0.00
Epoch 435 Iter 2 subLoss 5734.2 multi -1.98 import weight 0.00
Epoch 435 Iter 3 subLoss 7427.5 multi -10.94 import weight 0.00
Epoch 435 Iter 4 subLoss 15085.6 multi -4.97 import weight 0.00
Epoch 435 Iter 5 subLoss 31313.9 multi 1.00 import weight 0.00
Epoch 435 Iter 6 subLoss 22705.2 multi 1.00 import weight 0.00
Epoch 435 Iter 7 subLoss 19004.4 multi 3.99 import weight 0.00
Epoch 435 Iter 8 subLoss 10190.8 multi -16.91 import weight 0.00
Epoch 435 Iter 9 subLoss 22825.0 multi 1.00 import weight 0.00
Epoch 435 Iter 10 subLoss 22500.9 multi 1.00 import weight 0.00
Epoch 435 Iter 11 subLoss 20321.4 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 435 Acc: 78.01 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2032 train Loss: 18973.7 test Loss: 2643.7
Epoch 436 Iter 0 subLoss 18645.6 multi -7.96 import weight 0.00
Epoch 436 Iter 1 subLoss 30476.0 multi 1.00 import weight 0.00
Epoch 436 Iter 2 subLoss 26480.8 multi -4.97 import weight 0.00
Epoch 436 Iter 3 subLoss 44853.2 multi 1.00 import weight 0.00
Epoch 436 Iter 4 subLoss 35177.7 multi 3.99 import weight 0.00
Epoch 436 Iter 5 subLoss 20824.6 multi 1.00 import weight 0.00
Epoch 436 Iter 6 subLoss 20757.5 multi 1.00 import weight 0.00
Epoch 436 Iter 7 subLoss 19041.3 multi 1.00 import weight 0.00
Epoch 436 Iter 8 subLoss 19083.2 multi -4.97 import weight 0.00
Epoch 436 Iter 9 subLoss 22564.0 multi -1.99 import weight 0.00
Epoch 436 Iter 10 subLoss 25506.7 multi -1.98 import weight 0.00
Epoch 436 Iter 11 subLoss 29957.5 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 436 Acc: 72.66 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 2995 train Loss: 25283.3 test Loss: 3543.3
Epoch 437 Iter 0 subLoss 25596.8 multi -1.99 import weight 0.00
Epoch 437 Iter 1 subLoss 30031.7 multi 1.00 import weight 0.00
Epoch 437 Iter 2 subLoss 27636.0 multi -1.99 import weight 0.00
Epoch 437 Iter 3 subLoss 32156.8 multi 1.00 import weight 0.00
Epoch 437 Iter 4 subLoss 28943.1 multi 1.00 import weight 0.00
Epoch 437 Iter 5 subLoss 27094.1 multi 1.00 import weight 0.00
Epoch 437 Iter 6 subLoss 26194.3 multi -1.99 import weight 0.00
Epoch 437 Iter 7 subLoss 29797.0 multi 1.00 import weight 0.00
Epoch 437 Iter 8 subLoss 27083.8 multi -1.99 import weight 0.00
Epoch 437 Iter 9 subLoss 32175.4 multi 1.00 import weight 0.00
Epoch 437 Iter 10 subLoss 30137.8 multi 1.00 import weight 0.00
Epoch 437 Iter 11 subLoss 27722.4 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 437 Acc: 78.42 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 2772 train Loss: 21192.9 test Loss: 2884.6
Epoch 438 Iter 0 subLoss 20241.0 multi 3.99 import weight 0.00
Epoch 438 Iter 1 subLoss 15932.8 multi 3.98 import weight 0.00
Epoch 438 Iter 2 subLoss 14334.0 multi 12.94 import weight 0.00
Epoch 438 Iter 3 subLoss 8232.3 multi 1.00 import weight 0.00
Epoch 438 Iter 4 subLoss 7436.7 multi 3.99 import weight 0.00
Epoch 438 Iter 5 subLoss 6047.5 multi -16.91 import weight 0.00
Epoch 438 Iter 6 subLoss 10796.4 multi 9.96 import weight 0.00
Epoch 438 Iter 7 subLoss 7501.9 multi -4.97 import weight 0.00
Epoch 438 Iter 8 subLoss 9723.4 multi 3.99 import weight 0.00
Epoch 438 Iter 9 subLoss 8388.2 multi 1.00 import weight 0.00
Epoch 438 Iter 10 subLoss 7641.8 multi -4.97 import weight 0.00
Epoch 438 Iter 11 subLoss 9675.9 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 438 Acc: 91.79 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 967 train Loss: 9178.6 test Loss: 1136.0
Epoch 439 Iter 0 subLoss 8384.9 multi 3.99 import weight 0.00
Epoch 439 Iter 1 subLoss 7460.2 multi -4.97 import weight 0.00
Epoch 439 Iter 2 subLoss 8368.8 multi -1.99 import weight 0.00
Epoch 439 Iter 3 subLoss 9739.5 multi -4.97 import weight 0.00
Epoch 439 Iter 4 subLoss 12305.3 multi 3.99 import weight 0.00
Epoch 439 Iter 5 subLoss 10094.1 multi 6.97 import weight 0.00
Epoch 439 Iter 6 subLoss 7360.0 multi 9.96 import weight 0.00
Epoch 439 Iter 7 subLoss 5167.6 multi -4.97 import weight 0.00
Epoch 439 Iter 8 subLoss 6151.5 multi 3.98 import weight 0.00
Epoch 439 Iter 9 subLoss 5855.6 multi 12.94 import weight 0.00
Epoch 439 Iter 10 subLoss 4785.3 multi 6.97 import weight 0.00
Epoch 439 Iter 11 subLoss 3487.5 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 439 Acc: 98.07 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 348 train Loss: 3964.0 test Loss: 433.7
Epoch 440 Iter 0 subLoss 3649.5 multi 1.00 import weight 0.00
Epoch 440 Iter 1 subLoss 3607.6 multi -4.97 import weight 0.00
Epoch 440 Iter 2 subLoss 4095.0 multi -7.96 import weight 0.00
Epoch 440 Iter 3 subLoss 4820.5 multi 6.97 import weight 0.00
Epoch 440 Iter 4 subLoss 3703.4 multi -16.91 import weight 0.00
Epoch 440 Iter 5 subLoss 4702.5 multi -10.94 import weight 0.00
Epoch 440 Iter 6 subLoss 5029.3 multi -10.94 import weight 0.00
Epoch 440 Iter 7 subLoss 6116.7 multi -7.96 import weight 0.00
Epoch 440 Iter 8 subLoss 7551.5 multi 1.00 import weight 0.00
Epoch 440 Iter 9 subLoss 7578.3 multi -1.99 import weight 0.00
Epoch 440 Iter 10 subLoss 8050.8 multi 6.97 import weight 0.00
Epoch 440 Iter 11 subLoss 5777.0 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 440 Acc: 96.19 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 577 train Loss: 6448.7 test Loss: 723.0
Epoch 441 Iter 0 subLoss 6184.1 multi -10.94 import weight 0.00
Epoch 441 Iter 1 subLoss 8684.2 multi -4.97 import weight 0.00
Epoch 441 Iter 2 subLoss 10841.9 multi 12.94 import weight 0.00
Epoch 441 Iter 3 subLoss 6326.1 multi 3.99 import weight 0.00
Epoch 441 Iter 4 subLoss 5828.0 multi 6.97 import weight 0.00
Epoch 441 Iter 5 subLoss 5228.5 multi -10.94 import weight 0.00
Epoch 441 Iter 6 subLoss 6184.0 multi -7.96 import weight 0.00
Epoch 441 Iter 7 subLoss 6730.1 multi 3.99 import weight 0.00
Epoch 441 Iter 8 subLoss 6050.6 multi 6.97 import weight 0.00
Epoch 441 Iter 9 subLoss 5492.9 multi -1.99 import weight 0.00
Epoch 441 Iter 10 subLoss 5678.5 multi 9.96 import weight 0.00
Epoch 441 Iter 11 subLoss 5410.1 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 441 Acc: 97.72 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 541 train Loss: 4744.7 test Loss: 530.4
Epoch 442 Iter 0 subLoss 4258.4 multi 6.97 import weight 0.00
Epoch 442 Iter 1 subLoss 4362.4 multi -1.99 import weight 0.00
Epoch 442 Iter 2 subLoss 4344.2 multi -4.97 import weight 0.00
Epoch 442 Iter 3 subLoss 4892.1 multi -13.93 import weight 0.00
Epoch 442 Iter 4 subLoss 5688.0 multi -1.99 import weight 0.00
Epoch 442 Iter 5 subLoss 5891.3 multi 3.99 import weight 0.00
Epoch 442 Iter 6 subLoss 4600.5 multi 6.97 import weight 0.00
Epoch 442 Iter 7 subLoss 5259.9 multi -1.99 import weight 0.00
Epoch 442 Iter 8 subLoss 4811.2 multi 15.93 import weight 0.00
Epoch 442 Iter 9 subLoss 4233.2 multi -4.97 import weight 0.00
Epoch 442 Iter 10 subLoss 4692.7 multi -1.98 import weight 0.00
Epoch 442 Iter 11 subLoss 5041.2 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 442 Acc: 97.24 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 504 train Loss: 5185.7 test Loss: 620.5
Epoch 443 Iter 0 subLoss 5386.0 multi 1.00 import weight 0.00
Epoch 443 Iter 1 subLoss 5136.5 multi -19.90 import weight 0.00
Epoch 443 Iter 2 subLoss 10524.6 multi 1.00 import weight 0.00
Epoch 443 Iter 3 subLoss 9184.0 multi 3.98 import weight 0.00
Epoch 443 Iter 4 subLoss 6185.6 multi -4.97 import weight 0.00
Epoch 443 Iter 5 subLoss 7661.5 multi 1.00 import weight 0.00
Epoch 443 Iter 6 subLoss 7499.8 multi 12.94 import weight 0.00
Epoch 443 Iter 7 subLoss 4664.2 multi -16.91 import weight 0.00
Epoch 443 Iter 8 subLoss 7907.6 multi 9.96 import weight 0.00
Epoch 443 Iter 9 subLoss 5001.4 multi 3.99 import weight 0.00
Epoch 443 Iter 10 subLoss 4333.8 multi 12.94 import weight 0.00
Epoch 443 Iter 11 subLoss 3745.8 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 443 Acc: 98.05 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 374 train Loss: 4362.4 test Loss: 480.4
Epoch 444 Iter 0 subLoss 4659.4 multi 3.98 import weight 0.00
Epoch 444 Iter 1 subLoss 4695.0 multi 1.00 import weight 0.00
Epoch 444 Iter 2 subLoss 3602.4 multi -1.98 import weight 0.00
Epoch 444 Iter 3 subLoss 4606.8 multi 9.96 import weight 0.00
Epoch 444 Iter 4 subLoss 4113.2 multi -7.96 import weight 0.00
Epoch 444 Iter 5 subLoss 4613.8 multi -10.94 import weight 0.00
Epoch 444 Iter 6 subLoss 4215.2 multi -1.99 import weight 0.00
Epoch 444 Iter 7 subLoss 4873.5 multi 3.98 import weight 0.00
Epoch 444 Iter 8 subLoss 4618.9 multi -7.96 import weight 0.00
Epoch 444 Iter 9 subLoss 4815.2 multi 18.91 import weight 0.00
Epoch 444 Iter 10 subLoss 4260.7 multi 3.99 import weight 0.00
Epoch 444 Iter 11 subLoss 4060.5 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 444 Acc: 97.70 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 406 train Loss: 4557.8 test Loss: 511.5
Epoch 445 Iter 0 subLoss 5153.5 multi 3.99 import weight 0.00
Epoch 445 Iter 1 subLoss 4229.8 multi -4.97 import weight 0.00
Epoch 445 Iter 2 subLoss 4670.2 multi 9.96 import weight 0.00
Epoch 445 Iter 3 subLoss 4111.4 multi -4.97 import weight 0.00
Epoch 445 Iter 4 subLoss 3908.1 multi 3.99 import weight 0.00
Epoch 445 Iter 5 subLoss 4420.3 multi 12.94 import weight 0.00
Epoch 445 Iter 6 subLoss 3714.6 multi -1.99 import weight 0.00
Epoch 445 Iter 7 subLoss 4241.4 multi -1.99 import weight 0.00
Epoch 445 Iter 8 subLoss 3723.2 multi 3.98 import weight 0.00
Epoch 445 Iter 9 subLoss 3944.2 multi 6.97 import weight 0.00
Epoch 445 Iter 10 subLoss 3585.0 multi -4.97 import weight 0.00
Epoch 445 Iter 11 subLoss 4109.7 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 445 Acc: 97.90 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 410 train Loss: 3876.4 test Loss: 443.9
Epoch 446 Iter 0 subLoss 3470.3 multi 1.00 import weight 0.00
Epoch 446 Iter 1 subLoss 3978.4 multi 6.97 import weight 0.00
Epoch 446 Iter 2 subLoss 3367.4 multi 18.91 import weight 0.00
Epoch 446 Iter 3 subLoss 3553.4 multi -13.93 import weight 0.00
Epoch 446 Iter 4 subLoss 4125.9 multi 15.93 import weight 1.00
Epoch 446 Iter 5 subLoss 3563.8 multi -7.96 import weight 0.00
Epoch 446 Iter 6 subLoss 3953.7 multi -7.96 import weight 0.00
Epoch 446 Iter 7 subLoss 3972.8 multi 9.96 import weight 0.00
Epoch 446 Iter 8 subLoss 3638.1 multi 6.97 import weight 0.00
Epoch 446 Iter 9 subLoss 3549.0 multi 9.96 import weight 0.00
Epoch 446 Iter 10 subLoss 3471.7 multi 3.99 import weight 0.00
Epoch 446 Iter 11 subLoss 3363.5 multi 21.90 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 446 Acc: 97.96 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 21.90 Pidx 336 train Loss: 3534.1 test Loss: 387.3
Epoch 447 Iter 0 subLoss 3547.2 multi 12.94 import weight 0.00
Epoch 447 Iter 1 subLoss 3640.6 multi 1.00 import weight 0.00
Epoch 447 Iter 2 subLoss 3058.3 multi 1.00 import weight 0.00
Epoch 447 Iter 3 subLoss 3363.6 multi 24.88 import weight 0.00
Epoch 447 Iter 4 subLoss 3078.8 multi -10.94 import weight 0.00
Epoch 447 Iter 5 subLoss 3160.3 multi 9.96 import weight 0.00
Epoch 447 Iter 6 subLoss 3228.0 multi 15.93 import weight 0.00
Epoch 447 Iter 7 subLoss 3633.9 multi 9.96 import weight 0.00
Epoch 447 Iter 8 subLoss 2943.9 multi 3.99 import weight 0.00
Epoch 447 Iter 9 subLoss 3473.3 multi 6.97 import weight 0.00
Epoch 447 Iter 10 subLoss 3015.0 multi 1.00 import weight 0.00
Epoch 447 Iter 11 subLoss 3233.9 multi -1.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 447 Acc: 98.02 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 323 train Loss: 3171.3 test Loss: 343.7
Epoch 448 Iter 0 subLoss 3121.0 multi 12.94 import weight 0.00
Epoch 448 Iter 1 subLoss 3046.8 multi 6.97 import weight 0.00
Epoch 448 Iter 2 subLoss 3134.5 multi 1.00 import weight 0.00
Epoch 448 Iter 3 subLoss 3119.5 multi -22.88 import weight 0.00
Epoch 448 Iter 4 subLoss 3515.7 multi -10.94 import weight 0.00
Epoch 448 Iter 5 subLoss 3493.1 multi -16.91 import weight 0.00
Epoch 448 Iter 6 subLoss 4882.0 multi 3.99 import weight 0.00
Epoch 448 Iter 7 subLoss 3810.2 multi -4.97 import weight 0.00
Epoch 448 Iter 8 subLoss 4415.0 multi -16.91 import weight 0.00
Epoch 448 Iter 9 subLoss 14335.6 multi 15.93 import weight 0.00
Epoch 448 Iter 10 subLoss 12822.8 multi -1.98 import weight 0.00
Epoch 448 Iter 11 subLoss 23728.7 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 448 Acc: 85.17 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2372 train Loss: 12892.8 test Loss: 2495.8
Epoch 449 Iter 0 subLoss 12869.3 multi 9.96 import weight 0.00
Epoch 449 Iter 1 subLoss 8829.4 multi 1.00 import weight 0.00
Epoch 449 Iter 2 subLoss 7342.8 multi -4.97 import weight 0.00
Epoch 449 Iter 3 subLoss 12963.8 multi -1.98 import weight 0.00
Epoch 449 Iter 4 subLoss 19573.0 multi 1.00 import weight 0.00
Epoch 449 Iter 5 subLoss 15278.9 multi -4.97 import weight 0.00
Epoch 449 Iter 6 subLoss 39827.4 multi 3.99 import weight 0.00
Epoch 449 Iter 7 subLoss 15610.9 multi 3.98 import weight 0.00
Epoch 449 Iter 8 subLoss 8221.6 multi 3.99 import weight 0.00
Epoch 449 Iter 9 subLoss 6424.3 multi -4.97 import weight 0.00
Epoch 449 Iter 10 subLoss 7423.7 multi -7.96 import weight 0.00
Epoch 449 Iter 11 subLoss 9994.0 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 449 Acc: 71.26 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 999 train Loss: 20320.4 test Loss: 3194.6
Epoch 450 Iter 0 subLoss 19970.2 multi -1.98 import weight 0.00
Epoch 450 Iter 1 subLoss 26422.6 multi 6.97 import weight 0.00
Epoch 450 Iter 2 subLoss 11501.0 multi -4.97 import weight 0.00
Epoch 450 Iter 3 subLoss 15610.6 multi 6.97 import weight 0.00
Epoch 450 Iter 4 subLoss 8326.9 multi 6.97 import weight 0.00
Epoch 450 Iter 5 subLoss 7128.8 multi -10.94 import weight 0.00
Epoch 450 Iter 6 subLoss 8679.7 multi 9.96 import weight 0.00
Epoch 450 Iter 7 subLoss 7156.6 multi 6.97 import weight 0.00
Epoch 450 Iter 8 subLoss 5174.8 multi -4.97 import weight 0.00
Epoch 450 Iter 9 subLoss 6624.9 multi 1.00 import weight 0.00
Epoch 450 Iter 10 subLoss 6115.3 multi -4.97 import weight 0.00
Epoch 450 Iter 11 subLoss 6786.3 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 450 Acc: 92.76 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 678 train Loss: 7473.7 test Loss: 1148.8
Epoch 451 Iter 0 subLoss 7206.8 multi -4.97 import weight 0.00
Epoch 451 Iter 1 subLoss 7854.5 multi 1.00 import weight 0.00
Epoch 451 Iter 2 subLoss 8661.6 multi -4.97 import weight 0.00
Epoch 451 Iter 3 subLoss 10579.1 multi -4.97 import weight 0.00
Epoch 451 Iter 4 subLoss 22134.1 multi 1.00 import weight 0.00
Epoch 451 Iter 5 subLoss 12734.4 multi 6.97 import weight 0.00
Epoch 451 Iter 6 subLoss 8461.0 multi 1.00 import weight 0.00
Epoch 451 Iter 7 subLoss 8725.5 multi 3.99 import weight 0.00
Epoch 451 Iter 8 subLoss 6905.4 multi 3.98 import weight 0.00
Epoch 451 Iter 9 subLoss 6848.3 multi 1.00 import weight 0.00
Epoch 451 Iter 10 subLoss 6253.9 multi 3.99 import weight 0.00
Epoch 451 Iter 11 subLoss 5389.1 multi 3.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 451 Acc: 95.08 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 538 train Loss: 5392.7 test Loss: 884.7
Epoch 452 Iter 0 subLoss 5316.2 multi 18.91 import weight 0.00
Epoch 452 Iter 1 subLoss 4124.9 multi 18.91 import weight 1.00
Epoch 452 Iter 2 subLoss 4355.3 multi 1.00 import weight 0.00
Epoch 452 Iter 3 subLoss 4404.0 multi 9.96 import weight 0.00
Epoch 452 Iter 4 subLoss 3941.4 multi 9.96 import weight 0.00
Epoch 452 Iter 5 subLoss 3902.5 multi 6.97 import weight 0.00
Epoch 452 Iter 6 subLoss 3452.4 multi -19.90 import weight 0.00
Epoch 452 Iter 7 subLoss 4113.1 multi -4.97 import weight 0.00
Epoch 452 Iter 8 subLoss 4319.7 multi 3.99 import weight 0.00
Epoch 452 Iter 9 subLoss 4189.0 multi -1.98 import weight 0.00
Epoch 452 Iter 10 subLoss 3925.3 multi -1.99 import weight 0.00
Epoch 452 Iter 11 subLoss 4177.4 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0079 / 0.11461 / 12.38
Entropy seen (from low to high)
[2920, 287, 147, 95, 73, 128, 192, 198, 168, 122, 96, 51, 59, 58, 54, 45, 32, 38, 28, 30, 31, 35, 26, 23, 25, 23, 34, 21, 19, 12, 20, 13, 7, 4, 5, 5, 4, 2, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 0, 7, 16, 25, 27, 37, 72, 74, 101, 118, 147, 186, 210, 174, 208, 184, 165, 163, 150, 176, 189, 160, 174, 156, 143, 152, 132, 125, 141, 118, 113, 128, 129, 119, 125, 108, 87, 74, 45, 41, 26, 28, 38, 36, 32]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 0.0, 36.5, 40.0, 44.3, 47.1, 50.5, 54.6, 57.5, 60.6, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 49.9, 52.9, 58.8, 74.0, 67.6, 70.8, 87.4, 78.5]
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 12, 12, 17, 34, 27, 34, 24, 32, 42]
Epoch 452 Acc: 97.20 BMA: 97.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 417 train Loss: 3978.6 test Loss: 566.0
Epoch 453 Iter 0 subLoss 3495.2 multi -13.93 import weight 0.00
Epoch 453 Iter 1 subLoss 3630.9 multi 12.94 import weight 0.00
Epoch 453 Iter 2 subLoss 3922.1 multi 1.00 import weight 0.00
Epoch 453 Iter 3 subLoss 3909.5 multi 9.96 import weight 0.00
Epoch 453 Iter 4 subLoss 3704.2 multi -13.93 import weight 0.00
Epoch 453 Iter 5 subLoss 4119.0 multi -1.98 import weight 0.00
Epoch 453 Iter 6 subLoss 3923.6 multi 3.98 import weight 0.00
Epoch 453 Iter 7 subLoss 3964.8 multi 6.97 import weight 0.00
Epoch 453 Iter 8 subLoss 3776.0 multi 6.97 import weight 0.00
Epoch 453 Iter 9 subLoss 3319.5 multi 12.94 import weight 0.00
Epoch 453 Iter 10 subLoss 4238.6 multi -4.97 import weight 0.00
Epoch 453 Iter 11 subLoss 3664.9 multi 15.93 import weight 1.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 453 Acc: 97.66 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 15.93 Pidx 366 train Loss: 3698.2 test Loss: 475.0
Epoch 454 Iter 0 subLoss 3350.0 multi -10.94 import weight 0.00
Epoch 454 Iter 1 subLoss 3056.9 multi 1.00 import weight 0.00
Epoch 454 Iter 2 subLoss 3210.6 multi -19.90 import weight 0.00
Epoch 454 Iter 3 subLoss 5164.2 multi -4.97 import weight 0.00
Epoch 454 Iter 4 subLoss 11409.2 multi -7.96 import weight 0.00
Epoch 454 Iter 5 subLoss 320418.3 multi 1.00 import weight 0.00
Epoch 454 Iter 6 subLoss 24661.0 multi -4.97 import weight 0.00
Epoch 454 Iter 7 subLoss 45943.0 multi 1.00 import weight 0.00
Epoch 454 Iter 8 subLoss 34906.8 multi 1.00 import weight 0.00
Epoch 454 Iter 9 subLoss 29929.6 multi 1.00 import weight 0.00
Epoch 454 Iter 10 subLoss 26239.2 multi -1.99 import weight 0.00
Epoch 454 Iter 11 subLoss 31339.3 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 454 Acc: 73.28 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 3133 train Loss: 29336.1 test Loss: 4416.3
Epoch 455 Iter 0 subLoss 28824.7 multi 1.00 import weight 0.00
Epoch 455 Iter 1 subLoss 27124.3 multi -4.97 import weight 0.00
Epoch 455 Iter 2 subLoss 38607.8 multi 1.00 import weight 0.00
Epoch 455 Iter 3 subLoss 34548.9 multi 3.99 import weight 0.00
Epoch 455 Iter 4 subLoss 27105.8 multi -1.99 import weight 0.00
Epoch 455 Iter 5 subLoss 32223.4 multi 1.00 import weight 0.00
Epoch 455 Iter 6 subLoss 28083.4 multi 1.00 import weight 0.00
Epoch 455 Iter 7 subLoss 25894.9 multi -1.99 import weight 0.00
Epoch 455 Iter 8 subLoss 29749.6 multi -1.99 import weight 0.00
Epoch 455 Iter 9 subLoss 33543.2 multi 1.00 import weight 0.00
Epoch 455 Iter 10 subLoss 30604.8 multi 1.00 import weight 0.00
Epoch 455 Iter 11 subLoss 29395.9 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 455 Acc: 72.54 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2939 train Loss: 27838.6 test Loss: 4279.8
Epoch 456 Iter 0 subLoss 26775.9 multi 1.00 import weight 0.00
Epoch 456 Iter 1 subLoss 26025.3 multi -1.99 import weight 0.00
Epoch 456 Iter 2 subLoss 29086.9 multi -4.97 import weight 0.00
Epoch 456 Iter 3 subLoss 36208.0 multi 1.00 import weight 0.00
Epoch 456 Iter 4 subLoss 34168.6 multi 1.00 import weight 0.00
Epoch 456 Iter 5 subLoss 34517.5 multi 6.97 import weight 0.00
Epoch 456 Iter 6 subLoss 22694.7 multi -1.99 import weight 0.00
Epoch 456 Iter 7 subLoss 26149.8 multi 1.00 import weight 0.00
Epoch 456 Iter 8 subLoss 25522.8 multi -1.99 import weight 0.00
Epoch 456 Iter 9 subLoss 27009.9 multi 3.99 import weight 0.00
Epoch 456 Iter 10 subLoss 22824.4 multi 3.99 import weight 0.00
Epoch 456 Iter 11 subLoss 17781.4 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 456 Acc: 79.32 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 1778 train Loss: 23878.4 test Loss: 3262.4
Epoch 457 Iter 0 subLoss 24269.8 multi 1.00 import weight 0.00
Epoch 457 Iter 1 subLoss 21367.8 multi -1.99 import weight 0.00
Epoch 457 Iter 2 subLoss 25373.3 multi -4.97 import weight 0.00
Epoch 457 Iter 3 subLoss 37715.1 multi 1.00 import weight 0.00
Epoch 457 Iter 4 subLoss 33884.0 multi 3.99 import weight 0.00
Epoch 457 Iter 5 subLoss 25535.3 multi -1.99 import weight 0.00
Epoch 457 Iter 6 subLoss 27657.8 multi -1.99 import weight 0.00
Epoch 457 Iter 7 subLoss 38888.5 multi 1.00 import weight 0.00
Epoch 457 Iter 8 subLoss 30478.2 multi 3.99 import weight 0.00
Epoch 457 Iter 9 subLoss 26471.5 multi 9.96 import weight 0.00
Epoch 457 Iter 10 subLoss 24596.4 multi 1.00 import weight 0.00
Epoch 457 Iter 11 subLoss 17209.3 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 457 Acc: 90.33 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 1720 train Loss: 10517.7 test Loss: 1383.8
Epoch 458 Iter 0 subLoss 10177.4 multi 3.99 import weight 0.00
Epoch 458 Iter 1 subLoss 8475.3 multi -1.98 import weight 0.00
Epoch 458 Iter 2 subLoss 9805.9 multi 1.00 import weight 0.00
Epoch 458 Iter 3 subLoss 8997.9 multi 3.99 import weight 0.00
Epoch 458 Iter 4 subLoss 7768.7 multi 1.00 import weight 0.00
Epoch 458 Iter 5 subLoss 8210.3 multi 1.00 import weight 0.00
Epoch 458 Iter 6 subLoss 6687.7 multi 1.00 import weight 0.00
Epoch 458 Iter 7 subLoss 7257.9 multi -1.99 import weight 0.00
Epoch 458 Iter 8 subLoss 7364.1 multi 12.94 import weight 0.00
Epoch 458 Iter 9 subLoss 5455.8 multi 1.00 import weight 0.00
Epoch 458 Iter 10 subLoss 5315.5 multi 21.90 import weight 0.00
Epoch 458 Iter 11 subLoss 3813.1 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 458 Acc: 97.41 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 381 train Loss: 4494.6 test Loss: 564.3
Epoch 459 Iter 0 subLoss 4506.1 multi 3.99 import weight 0.00
Epoch 459 Iter 1 subLoss 3915.4 multi -7.96 import weight 0.00
Epoch 459 Iter 2 subLoss 4317.5 multi 6.97 import weight 0.00
Epoch 459 Iter 3 subLoss 4432.6 multi -4.97 import weight 0.00
Epoch 459 Iter 4 subLoss 4256.8 multi 6.97 import weight 0.00
Epoch 459 Iter 5 subLoss 3886.6 multi 18.91 import weight 0.00
Epoch 459 Iter 6 subLoss 4098.0 multi -4.97 import weight 0.00
Epoch 459 Iter 7 subLoss 4176.4 multi 9.96 import weight 0.00
Epoch 459 Iter 8 subLoss 3270.6 multi -4.97 import weight 0.00
Epoch 459 Iter 9 subLoss 3683.8 multi -4.97 import weight 0.00
Epoch 459 Iter 10 subLoss 3887.4 multi 21.90 import weight 0.00
Epoch 459 Iter 11 subLoss 4027.5 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 459 Acc: 97.45 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 402 train Loss: 4178.2 test Loss: 524.4
Epoch 460 Iter 0 subLoss 4194.2 multi 3.99 import weight 0.00
Epoch 460 Iter 1 subLoss 3243.7 multi -4.97 import weight 0.00
Epoch 460 Iter 2 subLoss 4072.1 multi -16.91 import weight 0.00
Epoch 460 Iter 3 subLoss 7959.9 multi 6.97 import weight 0.00
Epoch 460 Iter 4 subLoss 4543.6 multi -10.94 import weight 0.00
Epoch 460 Iter 5 subLoss 5909.5 multi -22.88 import weight 0.00
Epoch 460 Iter 6 subLoss 46755.2 multi 1.00 import weight 0.00
Epoch 460 Iter 7 subLoss 21548.6 multi 1.00 import weight 0.00
Epoch 460 Iter 8 subLoss 16154.8 multi 1.00 import weight 0.00
Epoch 460 Iter 9 subLoss 13617.5 multi -1.99 import weight 0.00
Epoch 460 Iter 10 subLoss 19644.5 multi 1.00 import weight 0.00
Epoch 460 Iter 11 subLoss 14969.9 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 460 Acc: 65.87 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 1496 train Loss: 36159.2 test Loss: 4813.1
Epoch 461 Iter 0 subLoss 35230.5 multi 1.00 import weight 0.00
Epoch 461 Iter 1 subLoss 25683.0 multi -4.97 import weight 0.00
Epoch 461 Iter 2 subLoss 65896.7 multi 1.00 import weight 0.00
Epoch 461 Iter 3 subLoss 44842.7 multi 1.00 import weight 0.00
Epoch 461 Iter 4 subLoss 39039.7 multi 1.00 import weight 0.00
Epoch 461 Iter 5 subLoss 33900.0 multi 1.00 import weight 0.00
Epoch 461 Iter 6 subLoss 30403.2 multi -1.99 import weight 0.00
Epoch 461 Iter 7 subLoss 38881.2 multi 3.99 import weight 0.00
Epoch 461 Iter 8 subLoss 24373.4 multi 3.99 import weight 0.00
Epoch 461 Iter 9 subLoss 14728.9 multi 9.96 import weight 0.00
Epoch 461 Iter 10 subLoss 6930.8 multi -10.94 import weight 0.00
Epoch 461 Iter 11 subLoss 11850.3 multi -1.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 461 Acc: 79.37 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 1185 train Loss: 17002.4 test Loss: 3680.3
Epoch 462 Iter 0 subLoss 15844.9 multi 12.94 import weight 0.00
Epoch 462 Iter 1 subLoss 11939.5 multi -4.97 import weight 0.00
Epoch 462 Iter 2 subLoss 35004.5 multi 1.00 import weight 0.00
Epoch 462 Iter 3 subLoss 18511.4 multi 1.00 import weight 0.00
Epoch 462 Iter 4 subLoss 14446.0 multi 1.00 import weight 0.00
Epoch 462 Iter 5 subLoss 10223.2 multi 1.00 import weight 0.00
Epoch 462 Iter 6 subLoss 9646.9 multi 9.96 import weight 0.00
Epoch 462 Iter 7 subLoss 4793.0 multi -7.96 import weight 0.00
Epoch 462 Iter 8 subLoss 6635.6 multi -1.98 import weight 0.00
Epoch 462 Iter 9 subLoss 8387.5 multi 6.97 import weight 0.00
Epoch 462 Iter 10 subLoss 4818.2 multi 21.90 import weight 0.00
Epoch 462 Iter 11 subLoss 3882.7 multi 24.88 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 462 Acc: 97.72 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 24.88 Pidx 388 train Loss: 3753.5 test Loss: 457.9
Epoch 463 Iter 0 subLoss 3534.3 multi 15.93 import weight 0.00
Epoch 463 Iter 1 subLoss 3591.4 multi 3.98 import weight 0.00
Epoch 463 Iter 2 subLoss 3743.3 multi -1.99 import weight 0.00
Epoch 463 Iter 3 subLoss 3472.3 multi 9.96 import weight 0.00
Epoch 463 Iter 4 subLoss 3160.2 multi 12.94 import weight 0.00
Epoch 463 Iter 5 subLoss 3211.8 multi -16.91 import weight 0.00
Epoch 463 Iter 6 subLoss 3193.3 multi -4.97 import weight 0.00
Epoch 463 Iter 7 subLoss 3359.1 multi -7.96 import weight 0.00
Epoch 463 Iter 8 subLoss 4454.0 multi 12.94 import weight 0.00
Epoch 463 Iter 9 subLoss 3156.2 multi -4.97 import weight 0.00
Epoch 463 Iter 10 subLoss 3788.0 multi -16.91 import weight 0.00
Epoch 463 Iter 11 subLoss 4150.6 multi -10.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 463 Acc: 93.99 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -10.94 Pidx 415 train Loss: 8066.3 test Loss: 996.7
Epoch 464 Iter 0 subLoss 7520.7 multi -1.99 import weight 0.00
Epoch 464 Iter 1 subLoss 9467.1 multi 6.97 import weight 0.00
Epoch 464 Iter 2 subLoss 3709.0 multi -10.94 import weight 0.00
Epoch 464 Iter 3 subLoss 4677.4 multi 12.94 import weight 0.00
Epoch 464 Iter 4 subLoss 3565.9 multi -4.97 import weight 0.00
Epoch 464 Iter 5 subLoss 3676.1 multi -31.84 import weight 0.00
Epoch 464 Iter 6 subLoss 6832.4 multi -1.99 import weight 0.00
Epoch 464 Iter 7 subLoss 8003.9 multi -4.97 import weight 0.00
Epoch 464 Iter 8 subLoss 17962.9 multi 3.98 import weight 0.00
Epoch 464 Iter 9 subLoss 4463.6 multi -31.84 import weight 0.00
Epoch 464 Iter 10 subLoss 11907.6 multi 1.00 import weight 0.00
Epoch 464 Iter 11 subLoss 8550.7 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 464 Acc: 96.87 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 855 train Loss: 4597.6 test Loss: 638.0
Epoch 465 Iter 0 subLoss 3557.8 multi -16.91 import weight 0.00
Epoch 465 Iter 1 subLoss 5262.9 multi 6.97 import weight 0.00
Epoch 465 Iter 2 subLoss 4689.4 multi -7.96 import weight 0.00
Epoch 465 Iter 3 subLoss 6010.5 multi -1.98 import weight 0.00
Epoch 465 Iter 4 subLoss 5686.2 multi 1.00 import weight 0.00
Epoch 465 Iter 5 subLoss 5757.8 multi 3.99 import weight 0.00
Epoch 465 Iter 6 subLoss 4977.7 multi -1.98 import weight 0.00
Epoch 465 Iter 7 subLoss 4569.9 multi -4.97 import weight 0.00
Epoch 465 Iter 8 subLoss 6319.0 multi 1.00 import weight 0.00
Epoch 465 Iter 9 subLoss 5357.6 multi -1.99 import weight 0.00
Epoch 465 Iter 10 subLoss 5245.1 multi -1.98 import weight 0.00
Epoch 465 Iter 11 subLoss 5877.5 multi -1.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 465 Acc: 95.25 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 587 train Loss: 6786.4 test Loss: 895.9
Epoch 466 Iter 0 subLoss 5954.4 multi 12.94 import weight 0.00
Epoch 466 Iter 1 subLoss 4573.0 multi 9.96 import weight 0.00
Epoch 466 Iter 2 subLoss 4374.9 multi -7.96 import weight 0.00
Epoch 466 Iter 3 subLoss 4753.0 multi 6.97 import weight 0.00
Epoch 466 Iter 4 subLoss 4527.2 multi 1.00 import weight 0.00
Epoch 466 Iter 5 subLoss 4290.7 multi -10.94 import weight 0.00
Epoch 466 Iter 6 subLoss 4585.6 multi -10.94 import weight 0.00
Epoch 466 Iter 7 subLoss 4834.1 multi -16.91 import weight 0.00
Epoch 466 Iter 8 subLoss 6979.3 multi -1.99 import weight 0.00
Epoch 466 Iter 9 subLoss 9959.1 multi -4.97 import weight 0.00
Epoch 466 Iter 10 subLoss 26002.3 multi 1.00 import weight 0.00
Epoch 466 Iter 11 subLoss 12297.5 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 466 Acc: 87.84 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1229 train Loss: 8772.9 test Loss: 1699.3
Epoch 467 Iter 0 subLoss 9046.9 multi -4.97 import weight 0.00
Epoch 467 Iter 1 subLoss 20993.8 multi -4.97 import weight 0.00
Epoch 467 Iter 2 subLoss 147794.9 multi 1.00 import weight 0.00
Epoch 467 Iter 3 subLoss 31823.1 multi 1.00 import weight 0.00
Epoch 467 Iter 4 subLoss 24606.4 multi 1.00 import weight 0.00
Epoch 467 Iter 5 subLoss 19337.9 multi 1.00 import weight 0.00
Epoch 467 Iter 6 subLoss 16926.9 multi -4.97 import weight 0.00
Epoch 467 Iter 7 subLoss 30657.9 multi 3.99 import weight 0.00
Epoch 467 Iter 8 subLoss 16350.4 multi 1.00 import weight 0.00
Epoch 467 Iter 9 subLoss 15144.9 multi 6.97 import weight 0.00
Epoch 467 Iter 10 subLoss 8698.8 multi 1.00 import weight 0.00
Epoch 467 Iter 11 subLoss 8268.4 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 467 Acc: 94.20 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 826 train Loss: 6569.3 test Loss: 1083.5
Epoch 468 Iter 0 subLoss 6244.3 multi 1.00 import weight 0.00
Epoch 468 Iter 1 subLoss 6388.6 multi 1.00 import weight 0.00
Epoch 468 Iter 2 subLoss 6447.3 multi 9.96 import weight 0.00
Epoch 468 Iter 3 subLoss 5184.7 multi 6.97 import weight 0.00
Epoch 468 Iter 4 subLoss 5163.9 multi -1.99 import weight 0.00
Epoch 468 Iter 5 subLoss 4732.1 multi -4.97 import weight 0.00
Epoch 468 Iter 6 subLoss 5236.8 multi -7.96 import weight 0.00
Epoch 468 Iter 7 subLoss 5869.7 multi -7.96 import weight 0.00
Epoch 468 Iter 8 subLoss 6576.8 multi 6.97 import weight 0.00
Epoch 468 Iter 9 subLoss 6117.1 multi -1.99 import weight 0.00
Epoch 468 Iter 10 subLoss 5907.6 multi -19.90 import weight 0.00
Epoch 468 Iter 11 subLoss 8710.0 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 468 Acc: 88.89 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 870 train Loss: 12610.1 test Loss: 1888.1
Epoch 469 Iter 0 subLoss 12677.8 multi 1.00 import weight 0.00
Epoch 469 Iter 1 subLoss 10706.7 multi -1.98 import weight 0.00
Epoch 469 Iter 2 subLoss 13306.8 multi 1.00 import weight 0.00
Epoch 469 Iter 3 subLoss 11302.8 multi 1.00 import weight 0.00
Epoch 469 Iter 4 subLoss 10575.7 multi -1.98 import weight 0.00
Epoch 469 Iter 5 subLoss 12554.6 multi 1.00 import weight 0.00
Epoch 469 Iter 6 subLoss 12003.3 multi 6.97 import weight 0.00
Epoch 469 Iter 7 subLoss 7390.9 multi 12.94 import weight 0.00
Epoch 469 Iter 8 subLoss 5731.4 multi 1.00 import weight 0.00
Epoch 469 Iter 9 subLoss 5814.7 multi 1.00 import weight 0.00
Epoch 469 Iter 10 subLoss 5560.8 multi 15.93 import weight 0.00
Epoch 469 Iter 11 subLoss 4759.0 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 469 Acc: 96.15 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 475 train Loss: 4836.2 test Loss: 737.5
Epoch 470 Iter 0 subLoss 4111.4 multi 1.00 import weight 0.00
Epoch 470 Iter 1 subLoss 4845.6 multi 1.00 import weight 0.00
Epoch 470 Iter 2 subLoss 4206.0 multi 1.00 import weight 0.00
Epoch 470 Iter 3 subLoss 4494.8 multi 3.99 import weight 0.00
Epoch 470 Iter 4 subLoss 4688.1 multi -4.97 import weight 0.00
Epoch 470 Iter 5 subLoss 5099.1 multi -4.97 import weight 0.00
Epoch 470 Iter 6 subLoss 4858.2 multi 3.99 import weight 0.00
Epoch 470 Iter 7 subLoss 4221.4 multi -1.99 import weight 0.00
Epoch 470 Iter 8 subLoss 5601.3 multi -16.91 import weight 0.00
Epoch 470 Iter 9 subLoss 5209.3 multi 3.98 import weight 0.00
Epoch 470 Iter 10 subLoss 5502.2 multi 1.00 import weight 0.00
Epoch 470 Iter 11 subLoss 5224.9 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 470 Acc: 94.61 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 522 train Loss: 5801.4 test Loss: 977.8
Epoch 471 Iter 0 subLoss 5660.4 multi -1.99 import weight 0.00
Epoch 471 Iter 1 subLoss 6379.1 multi 1.00 import weight 0.00
Epoch 471 Iter 2 subLoss 5898.1 multi 6.97 import weight 0.00
Epoch 471 Iter 3 subLoss 5137.6 multi -16.91 import weight 0.00
Epoch 471 Iter 4 subLoss 5986.4 multi 3.99 import weight 0.00
Epoch 471 Iter 5 subLoss 6329.7 multi 3.99 import weight 0.00
Epoch 471 Iter 6 subLoss 5148.7 multi 3.98 import weight 0.00
Epoch 471 Iter 7 subLoss 5027.1 multi -7.96 import weight 0.00
Epoch 471 Iter 8 subLoss 5610.1 multi 6.97 import weight 0.00
Epoch 471 Iter 9 subLoss 4716.5 multi 6.97 import weight 0.00
Epoch 471 Iter 10 subLoss 4417.1 multi -16.91 import weight 0.00
Epoch 471 Iter 11 subLoss 5777.1 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 471 Acc: 93.42 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 577 train Loss: 6001.1 test Loss: 1107.9
Epoch 472 Iter 0 subLoss 5493.0 multi 1.00 import weight 0.00
Epoch 472 Iter 1 subLoss 6023.1 multi 1.00 import weight 0.00
Epoch 472 Iter 2 subLoss 5520.8 multi -19.90 import weight 0.00
Epoch 472 Iter 3 subLoss 7420.7 multi -4.97 import weight 0.00
Epoch 472 Iter 4 subLoss 9165.7 multi 6.97 import weight 0.00
Epoch 472 Iter 5 subLoss 6754.6 multi 21.90 import weight 0.00
Epoch 472 Iter 6 subLoss 4980.9 multi -7.96 import weight 0.00
Epoch 472 Iter 7 subLoss 5322.8 multi -7.96 import weight 0.00
Epoch 472 Iter 8 subLoss 7170.0 multi 1.00 import weight 0.00
Epoch 472 Iter 9 subLoss 6390.4 multi 1.00 import weight 0.00
Epoch 472 Iter 10 subLoss 6334.7 multi 9.96 import weight 0.00
Epoch 472 Iter 11 subLoss 4956.7 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 472 Acc: 95.23 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 495 train Loss: 5237.1 test Loss: 908.2
Epoch 473 Iter 0 subLoss 5341.5 multi -4.97 import weight 0.00
Epoch 473 Iter 1 subLoss 5154.5 multi 3.99 import weight 0.00
Epoch 473 Iter 2 subLoss 5421.8 multi -1.98 import weight 0.00
Epoch 473 Iter 3 subLoss 5642.8 multi -1.99 import weight 0.00
Epoch 473 Iter 4 subLoss 5483.7 multi 1.00 import weight 0.00
Epoch 473 Iter 5 subLoss 4863.8 multi -7.96 import weight 0.00
Epoch 473 Iter 6 subLoss 5481.6 multi 3.98 import weight 0.00
Epoch 473 Iter 7 subLoss 5223.7 multi -4.97 import weight 0.00
Epoch 473 Iter 8 subLoss 5623.0 multi 6.97 import weight 0.00
Epoch 473 Iter 9 subLoss 5372.8 multi 1.00 import weight 0.00
Epoch 473 Iter 10 subLoss 4922.9 multi -13.93 import weight 0.00
Epoch 473 Iter 11 subLoss 5717.9 multi -10.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 473 Acc: 91.69 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -10.94 Pidx 571 train Loss: 7035.7 test Loss: 1421.3
Epoch 474 Iter 0 subLoss 6736.6 multi 6.97 import weight 0.00
Epoch 474 Iter 1 subLoss 5984.1 multi 6.97 import weight 0.00
Epoch 474 Iter 2 subLoss 5297.6 multi -10.94 import weight 0.00
Epoch 474 Iter 3 subLoss 5959.8 multi 15.93 import weight 0.00
Epoch 474 Iter 4 subLoss 5444.7 multi 3.99 import weight 0.00
Epoch 474 Iter 5 subLoss 5230.7 multi -10.94 import weight 0.00
Epoch 474 Iter 6 subLoss 5554.2 multi 1.00 import weight 0.00
Epoch 474 Iter 7 subLoss 5442.9 multi 6.97 import weight 0.00
Epoch 474 Iter 8 subLoss 4770.9 multi -16.91 import weight 0.00
Epoch 474 Iter 9 subLoss 5815.6 multi 3.99 import weight 0.00
Epoch 474 Iter 10 subLoss 5461.1 multi 15.93 import weight 0.00
Epoch 474 Iter 11 subLoss 5414.0 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 474 Acc: 95.89 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 541 train Loss: 5068.7 test Loss: 808.2
Epoch 475 Iter 0 subLoss 4383.4 multi 3.98 import weight 0.00
Epoch 475 Iter 1 subLoss 4776.9 multi -13.93 import weight 0.00
Epoch 475 Iter 2 subLoss 5054.2 multi 1.00 import weight 0.00
Epoch 475 Iter 3 subLoss 5203.2 multi 6.97 import weight 0.00
Epoch 475 Iter 4 subLoss 5083.4 multi 9.96 import weight 0.00
Epoch 475 Iter 5 subLoss 4782.5 multi 3.98 import weight 0.00
Epoch 475 Iter 6 subLoss 4436.3 multi -1.99 import weight 0.00
Epoch 475 Iter 7 subLoss 4590.6 multi -4.97 import weight 0.00
Epoch 475 Iter 8 subLoss 4101.1 multi 6.97 import weight 0.00
Epoch 475 Iter 9 subLoss 5123.4 multi 18.91 import weight 0.00
Epoch 475 Iter 10 subLoss 4366.2 multi -1.99 import weight 0.00
Epoch 475 Iter 11 subLoss 4459.1 multi 15.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 475 Acc: 97.24 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 15.93 Pidx 445 train Loss: 4327.2 test Loss: 583.0
Epoch 476 Iter 0 subLoss 4692.9 multi -1.99 import weight 0.00
Epoch 476 Iter 1 subLoss 4366.0 multi 1.00 import weight 0.00
Epoch 476 Iter 2 subLoss 4579.1 multi 12.94 import weight 0.00
Epoch 476 Iter 3 subLoss 4482.9 multi -7.96 import weight 0.00
Epoch 476 Iter 4 subLoss 4473.9 multi 12.94 import weight 0.00
Epoch 476 Iter 5 subLoss 3847.3 multi 3.99 import weight 0.00
Epoch 476 Iter 6 subLoss 4105.5 multi 9.96 import weight 0.00
Epoch 476 Iter 7 subLoss 3681.2 multi -4.97 import weight 0.00
Epoch 476 Iter 8 subLoss 4196.6 multi 6.97 import weight 0.00
Epoch 476 Iter 9 subLoss 4260.3 multi 3.98 import weight 0.00
Epoch 476 Iter 10 subLoss 3808.8 multi -4.97 import weight 0.00
Epoch 476 Iter 11 subLoss 3606.1 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 476 Acc: 97.68 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 360 train Loss: 4012.4 test Loss: 488.9
Epoch 477 Iter 0 subLoss 4122.2 multi 12.94 import weight 1.00
Epoch 477 Iter 1 subLoss 3309.2 multi -25.87 import weight 0.00
Epoch 477 Iter 2 subLoss 4393.1 multi -1.99 import weight 0.00
Epoch 477 Iter 3 subLoss 4431.3 multi 1.00 import weight 0.00
Epoch 477 Iter 4 subLoss 4371.6 multi -10.94 import weight 0.00
Epoch 477 Iter 5 subLoss 5192.6 multi -16.91 import weight 0.00
Epoch 477 Iter 6 subLoss 6550.7 multi 3.98 import weight 0.00
Epoch 477 Iter 7 subLoss 5739.1 multi 3.99 import weight 0.00
Epoch 477 Iter 8 subLoss 4778.2 multi -10.94 import weight 0.00
Epoch 477 Iter 9 subLoss 5501.4 multi 1.00 import weight 0.00
Epoch 477 Iter 10 subLoss 5269.3 multi 9.96 import weight 0.00
Epoch 477 Iter 11 subLoss 4868.8 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 477 Acc: 95.62 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 486 train Loss: 4857.2 test Loss: 801.8
Epoch 478 Iter 0 subLoss 4476.2 multi 15.93 import weight 0.00
Epoch 478 Iter 1 subLoss 3993.9 multi 24.88 import weight 0.00
Epoch 478 Iter 2 subLoss 3780.3 multi -13.93 import weight 0.00
Epoch 478 Iter 3 subLoss 4859.7 multi 6.97 import weight 0.00
Epoch 478 Iter 4 subLoss 4734.0 multi -1.98 import weight 0.00
Epoch 478 Iter 5 subLoss 4058.5 multi 6.97 import weight 0.00
Epoch 478 Iter 6 subLoss 4358.3 multi 3.99 import weight 0.00
Epoch 478 Iter 7 subLoss 3788.3 multi -10.94 import weight 0.00
Epoch 478 Iter 8 subLoss 3778.8 multi 9.96 import weight 0.00
Epoch 478 Iter 9 subLoss 4085.6 multi 12.94 import weight 0.00
Epoch 478 Iter 10 subLoss 3399.4 multi -1.98 import weight 0.00
Epoch 478 Iter 11 subLoss 3965.0 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 478 Acc: 97.66 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 396 train Loss: 3830.1 test Loss: 489.6
Epoch 479 Iter 0 subLoss 3412.6 multi 18.91 import weight 0.00
Epoch 479 Iter 1 subLoss 3069.5 multi 6.97 import weight 0.00
Epoch 479 Iter 2 subLoss 3190.8 multi -1.98 import weight 0.00
Epoch 479 Iter 3 subLoss 3506.3 multi 15.93 import weight 0.00
Epoch 479 Iter 4 subLoss 3240.5 multi -1.98 import weight 0.00
Epoch 479 Iter 5 subLoss 3593.8 multi 6.97 import weight 0.00
Epoch 479 Iter 6 subLoss 3930.7 multi -7.96 import weight 0.00
Epoch 479 Iter 7 subLoss 3467.2 multi 9.96 import weight 0.00
Epoch 479 Iter 8 subLoss 3334.8 multi -7.96 import weight 0.00
Epoch 479 Iter 9 subLoss 3705.3 multi -7.96 import weight 0.00
Epoch 479 Iter 10 subLoss 3590.9 multi 9.96 import weight 0.00
Epoch 479 Iter 11 subLoss 3515.6 multi -10.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 479 Acc: 97.90 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -10.94 Pidx 351 train Loss: 3739.8 test Loss: 425.6
Epoch 480 Iter 0 subLoss 3810.1 multi -1.99 import weight 0.00
Epoch 480 Iter 1 subLoss 3537.8 multi 18.91 import weight 0.00
Epoch 480 Iter 2 subLoss 3266.0 multi 3.99 import weight 0.00
Epoch 480 Iter 3 subLoss 3156.0 multi -1.98 import weight 0.00
Epoch 480 Iter 4 subLoss 3646.3 multi -1.98 import weight 0.00
Epoch 480 Iter 5 subLoss 3445.7 multi 1.00 import weight 0.00
Epoch 480 Iter 6 subLoss 3418.7 multi 21.90 import weight 0.00
Epoch 480 Iter 7 subLoss 3502.9 multi 18.91 import weight 0.00
Epoch 480 Iter 8 subLoss 3057.6 multi 3.98 import weight 0.00
Epoch 480 Iter 9 subLoss 3009.0 multi 6.97 import weight 0.00
Epoch 480 Iter 10 subLoss 3418.2 multi 24.88 import weight 0.00
Epoch 480 Iter 11 subLoss 3175.6 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 480 Acc: 98.29 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 317 train Loss: 3231.9 test Loss: 362.3
Epoch 481 Iter 0 subLoss 3575.9 multi 6.97 import weight 0.00
Epoch 481 Iter 1 subLoss 3128.6 multi 12.94 import weight 0.00
Epoch 481 Iter 2 subLoss 3280.2 multi -10.94 import weight 0.00
Epoch 481 Iter 3 subLoss 3037.7 multi -13.93 import weight 0.00
Epoch 481 Iter 4 subLoss 3806.7 multi -1.98 import weight 0.00
Epoch 481 Iter 5 subLoss 3123.2 multi 15.93 import weight 0.00
Epoch 481 Iter 6 subLoss 2966.5 multi -1.99 import weight 0.00
Epoch 481 Iter 7 subLoss 3416.8 multi 27.87 import weight 0.00
Epoch 481 Iter 8 subLoss 2822.8 multi -1.99 import weight 0.00
Epoch 481 Iter 9 subLoss 3515.6 multi -10.94 import weight 0.00
Epoch 481 Iter 10 subLoss 3988.7 multi -34.82 import weight 0.00
Epoch 481 Iter 11 subLoss 10563.3 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 481 Acc: 97.10 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 1056 train Loss: 4357.3 test Loss: 533.4
Epoch 482 Iter 0 subLoss 3790.8 multi 6.97 import weight 0.00
Epoch 482 Iter 1 subLoss 3467.0 multi 12.94 import weight 0.00
Epoch 482 Iter 2 subLoss 3220.2 multi 12.94 import weight 0.00
Epoch 482 Iter 3 subLoss 2910.8 multi 3.99 import weight 0.00
Epoch 482 Iter 4 subLoss 2969.1 multi 1.00 import weight 0.00
Epoch 482 Iter 5 subLoss 3460.2 multi 15.93 import weight 0.00
Epoch 482 Iter 6 subLoss 3257.4 multi -4.97 import weight 0.00
Epoch 482 Iter 7 subLoss 3484.7 multi -1.99 import weight 0.00
Epoch 482 Iter 8 subLoss 3340.7 multi 9.96 import weight 0.00
Epoch 482 Iter 9 subLoss 3150.9 multi 1.00 import weight 0.00
Epoch 482 Iter 10 subLoss 2874.9 multi 1.00 import weight 0.00
Epoch 482 Iter 11 subLoss 2975.5 multi 3.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 482 Acc: 98.64 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 297 train Loss: 3081.9 test Loss: 305.8
Epoch 483 Iter 0 subLoss 3095.1 multi 6.97 import weight 0.00
Epoch 483 Iter 1 subLoss 2881.3 multi 9.96 import weight 0.00
Epoch 483 Iter 2 subLoss 2751.6 multi 12.94 import weight 0.00
Epoch 483 Iter 3 subLoss 2975.7 multi 6.97 import weight 0.00
Epoch 483 Iter 4 subLoss 2835.8 multi -7.96 import weight 0.00
Epoch 483 Iter 5 subLoss 2689.5 multi 9.96 import weight 0.00
Epoch 483 Iter 6 subLoss 2996.4 multi 6.97 import weight 0.00
Epoch 483 Iter 7 subLoss 2536.1 multi 12.94 import weight 0.00
Epoch 483 Iter 8 subLoss 2926.1 multi 1.00 import weight 0.00
Epoch 483 Iter 9 subLoss 3268.5 multi 3.98 import weight 0.00
Epoch 483 Iter 10 subLoss 2675.8 multi 1.00 import weight 0.00
Epoch 483 Iter 11 subLoss 2684.8 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 483 Acc: 98.58 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 268 train Loss: 2885.1 test Loss: 266.6
Epoch 484 Iter 0 subLoss 3015.2 multi 1.00 import weight 0.00
Epoch 484 Iter 1 subLoss 2579.7 multi 3.99 import weight 0.00
Epoch 484 Iter 2 subLoss 2884.1 multi 12.94 import weight 0.00
Epoch 484 Iter 3 subLoss 2767.7 multi -7.96 import weight 0.00
Epoch 484 Iter 4 subLoss 2731.7 multi 1.00 import weight 0.00
Epoch 484 Iter 5 subLoss 3244.1 multi 1.00 import weight 0.00
Epoch 484 Iter 6 subLoss 2640.9 multi 1.00 import weight 0.00
Epoch 484 Iter 7 subLoss 2747.3 multi -10.94 import weight 0.00
Epoch 484 Iter 8 subLoss 2641.1 multi 3.98 import weight 0.00
Epoch 484 Iter 9 subLoss 2965.5 multi 3.99 import weight 0.00
Epoch 484 Iter 10 subLoss 3080.8 multi -1.99 import weight 0.00
Epoch 484 Iter 11 subLoss 3092.9 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 484 Acc: 98.54 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 309 train Loss: 2842.2 test Loss: 270.8
Epoch 485 Iter 0 subLoss 2563.3 multi 3.98 import weight 0.00
Epoch 485 Iter 1 subLoss 2801.4 multi -7.96 import weight 0.00
Epoch 485 Iter 2 subLoss 2562.2 multi 6.97 import weight 0.00
Epoch 485 Iter 3 subLoss 2533.2 multi 15.93 import weight 0.00
Epoch 485 Iter 4 subLoss 3000.5 multi 6.97 import weight 0.00
Epoch 485 Iter 5 subLoss 2909.7 multi -10.94 import weight 0.00
Epoch 485 Iter 6 subLoss 3020.9 multi 1.00 import weight 0.00
Epoch 485 Iter 7 subLoss 3053.7 multi 6.97 import weight 0.00
Epoch 485 Iter 8 subLoss 2787.9 multi -1.99 import weight 0.00
Epoch 485 Iter 9 subLoss 2855.8 multi -4.97 import weight 0.00
Epoch 485 Iter 10 subLoss 3068.9 multi 3.98 import weight 0.00
Epoch 485 Iter 11 subLoss 2865.7 multi -10.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 485 Acc: 98.42 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -10.94 Pidx 286 train Loss: 2885.7 test Loss: 291.7
Epoch 486 Iter 0 subLoss 2704.8 multi 9.96 import weight 0.00
Epoch 486 Iter 1 subLoss 2859.8 multi -1.99 import weight 0.00
Epoch 486 Iter 2 subLoss 2395.7 multi -1.99 import weight 0.00
Epoch 486 Iter 3 subLoss 2721.5 multi 1.00 import weight 0.00
Epoch 486 Iter 4 subLoss 2889.2 multi 15.93 import weight 0.00
Epoch 486 Iter 5 subLoss 2987.2 multi -19.90 import weight 0.00
Epoch 486 Iter 6 subLoss 3042.5 multi 6.97 import weight 0.00
Epoch 486 Iter 7 subLoss 2751.6 multi 12.94 import weight 0.00
Epoch 486 Iter 8 subLoss 2916.2 multi 3.98 import weight 0.00
Epoch 486 Iter 9 subLoss 2900.1 multi -7.96 import weight 0.00
Epoch 486 Iter 10 subLoss 2657.4 multi -4.97 import weight 0.00
Epoch 486 Iter 11 subLoss 3034.2 multi -13.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 486 Acc: 98.62 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -13.93 Pidx 303 train Loss: 3171.6 test Loss: 256.2
Epoch 487 Iter 0 subLoss 2935.5 multi 1.00 import weight 0.00
Epoch 487 Iter 1 subLoss 3022.3 multi 3.99 import weight 0.00
Epoch 487 Iter 2 subLoss 3079.1 multi -13.93 import weight 0.00
Epoch 487 Iter 3 subLoss 3647.3 multi 1.00 import weight 0.00
Epoch 487 Iter 4 subLoss 2925.7 multi 1.00 import weight 0.00
Epoch 487 Iter 5 subLoss 3407.1 multi -4.97 import weight 0.00
Epoch 487 Iter 6 subLoss 3875.7 multi 1.00 import weight 0.00
Epoch 487 Iter 7 subLoss 3411.1 multi 27.87 import weight 0.00
Epoch 487 Iter 8 subLoss 3461.2 multi 18.91 import weight 0.00
Epoch 487 Iter 9 subLoss 3251.8 multi -4.97 import weight 0.00
Epoch 487 Iter 10 subLoss 3320.8 multi 3.99 import weight 0.00
Epoch 487 Iter 11 subLoss 3382.0 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 487 Acc: 97.92 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 338 train Loss: 3817.7 test Loss: 351.5
Epoch 488 Iter 0 subLoss 3865.7 multi -16.91 import weight 0.00
Epoch 488 Iter 1 subLoss 12702.3 multi 3.99 import weight 0.00
Epoch 488 Iter 2 subLoss 3147.0 multi -7.96 import weight 0.00
Epoch 488 Iter 3 subLoss 3551.4 multi -13.93 import weight 0.00
Epoch 488 Iter 4 subLoss 5543.8 multi 1.00 import weight 0.00
Epoch 488 Iter 5 subLoss 5391.4 multi -1.99 import weight 0.00
Epoch 488 Iter 6 subLoss 5539.5 multi 1.00 import weight 0.00
Epoch 488 Iter 7 subLoss 5096.3 multi -4.97 import weight 0.00
Epoch 488 Iter 8 subLoss 9099.5 multi 1.00 import weight 0.00
Epoch 488 Iter 9 subLoss 7519.0 multi -7.96 import weight 0.00
Epoch 488 Iter 10 subLoss 24772.1 multi 1.00 import weight 0.00
Epoch 488 Iter 11 subLoss 13013.2 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 488 Acc: 98.58 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 1301 train Loss: 3841.7 test Loss: 351.7
Epoch 489 Iter 0 subLoss 3590.9 multi 12.94 import weight 0.00
Epoch 489 Iter 1 subLoss 3375.9 multi -16.91 import weight 0.00
Epoch 489 Iter 2 subLoss 3795.8 multi 9.96 import weight 0.00
Epoch 489 Iter 3 subLoss 3410.1 multi 30.85 import weight 0.00
Epoch 489 Iter 4 subLoss 2677.2 multi 3.99 import weight 0.00
Epoch 489 Iter 5 subLoss 2539.1 multi 18.91 import weight 0.00
Epoch 489 Iter 6 subLoss 2672.0 multi 6.97 import weight 0.00
Epoch 489 Iter 7 subLoss 2344.1 multi 12.94 import weight 0.00
Epoch 489 Iter 8 subLoss 2839.1 multi -4.97 import weight 0.00
Epoch 489 Iter 9 subLoss 3268.6 multi 3.99 import weight 0.00
Epoch 489 Iter 10 subLoss 2827.9 multi 1.00 import weight 0.00
Epoch 489 Iter 11 subLoss 2703.1 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 489 Acc: 98.54 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 270 train Loss: 2645.4 test Loss: 252.0
Epoch 490 Iter 0 subLoss 3193.7 multi 1.00 import weight 0.00
Epoch 490 Iter 1 subLoss 2141.9 multi -4.97 import weight 0.00
Epoch 490 Iter 2 subLoss 2381.4 multi 1.00 import weight 0.00
Epoch 490 Iter 3 subLoss 2399.3 multi -1.98 import weight 0.00
Epoch 490 Iter 4 subLoss 2354.5 multi -7.96 import weight 0.00
Epoch 490 Iter 5 subLoss 2603.7 multi -4.97 import weight 0.00
Epoch 490 Iter 6 subLoss 3079.4 multi -10.94 import weight 0.00
Epoch 490 Iter 7 subLoss 2830.6 multi -4.97 import weight 0.00
Epoch 490 Iter 8 subLoss 3309.7 multi -22.88 import weight 0.00
Epoch 490 Iter 9 subLoss 19232.3 multi -1.99 import weight 0.00
Epoch 490 Iter 10 subLoss 129275.3 multi 1.00 import weight 0.00
Epoch 490 Iter 11 subLoss 5216.3 multi 21.90 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 490 Acc: 97.24 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 21.90 Pidx 521 train Loss: 3948.2 test Loss: 554.3
Epoch 491 Iter 0 subLoss 3819.6 multi -1.98 import weight 0.00
Epoch 491 Iter 1 subLoss 4656.0 multi 6.97 import weight 0.00
Epoch 491 Iter 2 subLoss 3121.1 multi 18.91 import weight 0.00
Epoch 491 Iter 3 subLoss 2888.1 multi 18.91 import weight 0.00
Epoch 491 Iter 4 subLoss 3073.7 multi -7.96 import weight 0.00
Epoch 491 Iter 5 subLoss 2588.9 multi 3.98 import weight 0.00
Epoch 491 Iter 6 subLoss 3293.9 multi 21.90 import weight 0.00
Epoch 491 Iter 7 subLoss 2911.6 multi 3.99 import weight 0.00
Epoch 491 Iter 8 subLoss 2714.9 multi -13.93 import weight 0.00
Epoch 491 Iter 9 subLoss 2974.3 multi 6.97 import weight 0.00
Epoch 491 Iter 10 subLoss 2845.7 multi 1.00 import weight 0.00
Epoch 491 Iter 11 subLoss 3096.1 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 491 Acc: 98.35 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 309 train Loss: 2736.9 test Loss: 292.9
Epoch 492 Iter 0 subLoss 2855.4 multi -1.98 import weight 0.00
Epoch 492 Iter 1 subLoss 2396.7 multi 1.00 import weight 0.00
Epoch 492 Iter 2 subLoss 2774.1 multi 9.96 import weight 0.00
Epoch 492 Iter 3 subLoss 2352.6 multi -4.97 import weight 0.00
Epoch 492 Iter 4 subLoss 2820.9 multi 3.98 import weight 0.00
Epoch 492 Iter 5 subLoss 3233.6 multi -1.99 import weight 0.00
Epoch 492 Iter 6 subLoss 2776.9 multi 12.94 import weight 0.00
Epoch 492 Iter 7 subLoss 2731.2 multi 1.00 import weight 0.00
Epoch 492 Iter 8 subLoss 3081.4 multi -7.96 import weight 0.00
Epoch 492 Iter 9 subLoss 2794.6 multi -1.99 import weight 0.00
Epoch 492 Iter 10 subLoss 3256.3 multi -1.99 import weight 0.00
Epoch 492 Iter 11 subLoss 2983.1 multi -19.90 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 492 Acc: 97.76 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -19.90 Pidx 298 train Loss: 3284.7 test Loss: 365.2
Epoch 493 Iter 0 subLoss 3724.4 multi 6.97 import weight 0.00
Epoch 493 Iter 1 subLoss 2453.0 multi -7.96 import weight 0.00
Epoch 493 Iter 2 subLoss 2913.1 multi 6.97 import weight 0.00
Epoch 493 Iter 3 subLoss 2925.6 multi -1.98 import weight 0.00
Epoch 493 Iter 4 subLoss 2745.1 multi -10.94 import weight 0.00
Epoch 493 Iter 5 subLoss 3048.2 multi 6.97 import weight 0.00
Epoch 493 Iter 6 subLoss 2745.5 multi -7.96 import weight 0.00
Epoch 493 Iter 7 subLoss 3486.0 multi 1.00 import weight 0.00
Epoch 493 Iter 8 subLoss 2620.1 multi 1.00 import weight 0.00
Epoch 493 Iter 9 subLoss 2684.6 multi 6.97 import weight 0.00
Epoch 493 Iter 10 subLoss 3534.3 multi 21.90 import weight 0.00
Epoch 493 Iter 11 subLoss 3195.1 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 493 Acc: 98.46 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 319 train Loss: 2827.5 test Loss: 289.4
Epoch 494 Iter 0 subLoss 2923.6 multi 1.00 import weight 0.00
Epoch 494 Iter 1 subLoss 2973.2 multi 9.96 import weight 0.00
Epoch 494 Iter 2 subLoss 2970.0 multi 12.94 import weight 0.00
Epoch 494 Iter 3 subLoss 2701.2 multi 15.93 import weight 0.00
Epoch 494 Iter 4 subLoss 2684.3 multi 9.96 import weight 0.00
Epoch 494 Iter 5 subLoss 2316.2 multi -4.97 import weight 0.00
Epoch 494 Iter 6 subLoss 2214.6 multi -4.97 import weight 0.00
Epoch 494 Iter 7 subLoss 1932.6 multi 1.00 import weight 0.00
Epoch 494 Iter 8 subLoss 2409.8 multi -1.99 import weight 0.00
Epoch 494 Iter 9 subLoss 2992.2 multi 3.99 import weight 0.00
Epoch 494 Iter 10 subLoss 2570.9 multi 1.00 import weight 0.00
Epoch 494 Iter 11 subLoss 2898.9 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 494 Acc: 98.64 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 289 train Loss: 2687.5 test Loss: 252.4
Epoch 495 Iter 0 subLoss 2835.3 multi -4.97 import weight 0.00
Epoch 495 Iter 1 subLoss 2717.5 multi -13.93 import weight 0.00
Epoch 495 Iter 2 subLoss 3104.1 multi -1.98 import weight 0.00
Epoch 495 Iter 3 subLoss 3790.3 multi 12.94 import weight 0.00
Epoch 495 Iter 4 subLoss 2609.7 multi -1.99 import weight 0.00
Epoch 495 Iter 5 subLoss 2901.9 multi -7.96 import weight 0.00
Epoch 495 Iter 6 subLoss 3131.7 multi -4.97 import weight 0.00
Epoch 495 Iter 7 subLoss 3034.2 multi -13.93 import weight 0.00
Epoch 495 Iter 8 subLoss 4104.4 multi 12.94 import weight 0.00
Epoch 495 Iter 9 subLoss 2507.3 multi -10.94 import weight 0.00
Epoch 495 Iter 10 subLoss 3495.8 multi -16.91 import weight 0.00
Epoch 495 Iter 11 subLoss 4140.0 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 495 Acc: 97.61 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 414 train Loss: 4132.8 test Loss: 475.3
Epoch 496 Iter 0 subLoss 4125.1 multi 15.93 import weight 1.00
Epoch 496 Iter 1 subLoss 3251.4 multi 1.00 import weight 0.00
Epoch 496 Iter 2 subLoss 3133.2 multi -1.99 import weight 0.00
Epoch 496 Iter 3 subLoss 2996.5 multi 6.97 import weight 0.00
Epoch 496 Iter 4 subLoss 2924.6 multi 3.99 import weight 0.00
Epoch 496 Iter 5 subLoss 2333.0 multi -7.96 import weight 0.00
Epoch 496 Iter 6 subLoss 2538.0 multi 21.90 import weight 0.00
Epoch 496 Iter 7 subLoss 2791.8 multi 1.00 import weight 0.00
Epoch 496 Iter 8 subLoss 2449.5 multi 9.96 import weight 0.00
Epoch 496 Iter 9 subLoss 2337.7 multi -4.97 import weight 0.00
Epoch 496 Iter 10 subLoss 3050.8 multi 3.99 import weight 0.00
Epoch 496 Iter 11 subLoss 2294.7 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 496 Acc: 98.54 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 229 train Loss: 2648.7 test Loss: 248.3
Epoch 497 Iter 0 subLoss 2290.2 multi 6.97 import weight 0.00
Epoch 497 Iter 1 subLoss 3028.2 multi 6.97 import weight 0.00
Epoch 497 Iter 2 subLoss 2824.8 multi 6.97 import weight 0.00
Epoch 497 Iter 3 subLoss 2503.0 multi -7.96 import weight 0.00
Epoch 497 Iter 4 subLoss 2864.3 multi -13.93 import weight 0.00
Epoch 497 Iter 5 subLoss 2249.1 multi 1.00 import weight 0.00
Epoch 497 Iter 6 subLoss 2206.5 multi -1.99 import weight 0.00
Epoch 497 Iter 7 subLoss 2388.8 multi 3.98 import weight 0.00
Epoch 497 Iter 8 subLoss 2568.7 multi 9.96 import weight 0.00
Epoch 497 Iter 9 subLoss 2310.5 multi -1.98 import weight 0.00
Epoch 497 Iter 10 subLoss 2668.1 multi -13.93 import weight 0.00
Epoch 497 Iter 11 subLoss 3094.5 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 497 Acc: 98.60 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 309 train Loss: 2715.6 test Loss: 260.6
Epoch 498 Iter 0 subLoss 2781.7 multi -4.97 import weight 0.00
Epoch 498 Iter 1 subLoss 2789.4 multi -1.99 import weight 0.00
Epoch 498 Iter 2 subLoss 2827.2 multi 9.96 import weight 0.00
Epoch 498 Iter 3 subLoss 2945.8 multi 3.98 import weight 0.00
Epoch 498 Iter 4 subLoss 2425.8 multi 1.00 import weight 0.00
Epoch 498 Iter 5 subLoss 2473.7 multi 18.91 import weight 0.00
Epoch 498 Iter 6 subLoss 2650.6 multi -1.99 import weight 0.00
Epoch 498 Iter 7 subLoss 2257.6 multi -4.97 import weight 0.00
Epoch 498 Iter 8 subLoss 3070.6 multi -4.97 import weight 0.00
Epoch 498 Iter 9 subLoss 2653.5 multi 1.00 import weight 0.00
Epoch 498 Iter 10 subLoss 2294.3 multi 9.96 import weight 0.00
Epoch 498 Iter 11 subLoss 2827.8 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 498 Acc: 98.52 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 282 train Loss: 2624.1 test Loss: 252.6
Epoch 499 Iter 0 subLoss 2203.1 multi 1.00 import weight 0.00
Epoch 499 Iter 1 subLoss 2331.7 multi -1.99 import weight 0.00
Epoch 499 Iter 2 subLoss 2752.4 multi 9.96 import weight 0.00
Epoch 499 Iter 3 subLoss 2347.0 multi 6.97 import weight 0.00
Epoch 499 Iter 4 subLoss 2271.4 multi 3.98 import weight 0.00
Epoch 499 Iter 5 subLoss 2577.1 multi 1.00 import weight 0.00
Epoch 499 Iter 6 subLoss 2386.9 multi 6.97 import weight 0.00
Epoch 499 Iter 7 subLoss 2183.4 multi -7.96 import weight 0.00
Epoch 499 Iter 8 subLoss 2847.7 multi 1.00 import weight 0.00
Epoch 499 Iter 9 subLoss 2336.3 multi 1.00 import weight 0.00
Epoch 499 Iter 10 subLoss 2262.5 multi 1.00 import weight 0.00
Epoch 499 Iter 11 subLoss 3000.8 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0071 / 0.10845 / 12.51
Entropy seen (from low to high)
[2818, 290, 155, 121, 157, 171, 147, 163, 124, 98, 61, 65, 68, 79, 65, 41, 45, 55, 37, 27, 29, 32, 24, 34, 41, 28, 26, 22, 25, 14, 17, 16, 10, 7, 11, 3, 1, 4, 2, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 17, 15, 34, 43, 77, 97, 108, 139, 139, 173, 191, 201, 182, 181, 172, 171, 160, 178, 180, 177, 162, 160, 115, 143, 127, 129, 121, 113, 128, 105, 99, 106, 84, 78, 94, 86, 86, 73, 63, 46, 25, 25, 17, 20, 19]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.4, 37.5, 40.1, 44.0, 47.7, 50.3, 54.5, 57.7, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 45.4, 59.9, 55.5, 56.5, 56.6, 73.5, 77.7, 77.1, 87.8]
[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 11, 10, 18, 23, 30, 34, 36, 35, 41]
Epoch 499 Acc: 98.77 BMA: 97.98 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 300 train Loss: 2534.9 test Loss: 235.5
Sampling Time used: 11700.2
Grad mul
