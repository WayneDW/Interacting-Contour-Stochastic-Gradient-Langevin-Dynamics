Namespace(N=50000, T=0.1, batch=5000, c='csghmc', classes=5, div=10, filters=16, gpu=1, hidden=10, ifprint=1.0, ifsave=1.0, lr=1e-06, part=1000000, seed=47008, sn=500, stepsize=0.01, warm=0.5, wdecay=25, zeta=30000.0)
adjust the learning rate 2.000e-06 weight decay 1.200e+01
(16, 1, 5, 5)
(16,)
(32, 16, 5, 5)
(32,)
(10, 1568)
(10,)
(5, 10)
(5,)
Current Theta
tensor([1.0000e-06, 1.0000e-06, 1.0000e-06,  ..., 1.0000e-06, 1.0000e-06,
        1.0000e-06], device='cuda:1')
Epoch 0 Iter 0 subLoss 48978.0 multi 1.00 import weight 1.00
Epoch 0 Iter 1 subLoss 48282.6 multi 1.00 import weight 1.00
Epoch 0 Iter 2 subLoss 48258.1 multi 1.00 import weight 1.00
Epoch 0 Iter 3 subLoss 48073.1 multi 1.00 import weight 1.00
Epoch 0 Iter 4 subLoss 47850.8 multi 1.00 import weight 1.00
Epoch 0 Iter 5 subLoss 47663.3 multi 1.00 import weight 1.00
Epoch 0 Iter 6 subLoss 47614.5 multi 1.00 import weight 1.00
Epoch 0 Iter 7 subLoss 47366.5 multi 1.00 import weight 1.00
Epoch 0 Iter 8 subLoss 47185.9 multi 1.00 import weight 1.00
Epoch 0 Iter 9 subLoss 46881.8 multi 1.00 import weight 1.00
Epoch 0 Iter 10 subLoss 46565.6 multi 1.00 import weight 1.00
Epoch 0 Iter 11 subLoss 46513.9 multi 1.00 import weight 1.00
Epoch 0 Acc: 41.04 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 1.00 Pidx 4651 train Loss: 47044.3 test Loss: 7647.5
Epoch 1 Iter 0 subLoss 46096.1 multi 1.00 import weight 1.00
Epoch 1 Iter 1 subLoss 45800.7 multi 1.00 import weight 1.00
Epoch 1 Iter 2 subLoss 45562.3 multi 1.00 import weight 1.00
Epoch 1 Iter 3 subLoss 45095.7 multi 1.00 import weight 1.00
Epoch 1 Iter 4 subLoss 44731.5 multi 1.00 import weight 1.00
Epoch 1 Iter 5 subLoss 44327.6 multi 1.00 import weight 1.00
Epoch 1 Iter 6 subLoss 43473.2 multi 1.00 import weight 1.00
Epoch 1 Iter 7 subLoss 43122.2 multi 1.00 import weight 1.00
Epoch 1 Iter 8 subLoss 42413.9 multi 1.00 import weight 1.00
Epoch 1 Iter 9 subLoss 41779.1 multi 1.00 import weight 1.00
Epoch 1 Iter 10 subLoss 42031.8 multi 1.00 import weight 1.00
Epoch 1 Iter 11 subLoss 42262.2 multi 1.00 import weight 1.00
Epoch 1 Acc: 48.02 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 1.00 Pidx 4226 train Loss: 45478.3 test Loss: 6779.0
Epoch 2 Iter 0 subLoss 44111.8 multi 1.00 import weight 1.00
Epoch 2 Iter 1 subLoss 42383.0 multi 1.00 import weight 1.00
Epoch 2 Iter 2 subLoss 40791.2 multi 1.00 import weight 1.00
Epoch 2 Iter 3 subLoss 40428.5 multi 1.00 import weight 1.00
Epoch 2 Iter 4 subLoss 40092.1 multi 1.00 import weight 1.00
Epoch 2 Iter 5 subLoss 38520.1 multi 1.00 import weight 1.00
Epoch 2 Iter 6 subLoss 38598.6 multi 1.00 import weight 1.00
Epoch 2 Iter 7 subLoss 37260.9 multi 1.00 import weight 1.00
Epoch 2 Iter 8 subLoss 39043.4 multi 1.00 import weight 1.00
Epoch 2 Iter 9 subLoss 37803.5 multi 1.00 import weight 1.00
Epoch 2 Iter 10 subLoss 36700.5 multi 1.00 import weight 1.00
Epoch 2 Iter 11 subLoss 36906.3 multi 1.00 import weight 1.00
Epoch 2 Acc: 70.97 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 1.00 Pidx 3690 train Loss: 36282.4 test Loss: 4598.7
Epoch 3 Iter 0 subLoss 35459.6 multi 1.00 import weight 1.00
Epoch 3 Iter 1 subLoss 37282.8 multi 1.00 import weight 1.00
Epoch 3 Iter 2 subLoss 36928.9 multi 1.00 import weight 1.00
Epoch 3 Iter 3 subLoss 36973.4 multi 1.00 import weight 1.00
Epoch 3 Iter 4 subLoss 36805.0 multi 1.00 import weight 1.00
Epoch 3 Iter 5 subLoss 33772.5 multi 1.00 import weight 1.00
Epoch 3 Iter 6 subLoss 31117.1 multi 1.00 import weight 1.00
Epoch 3 Iter 7 subLoss 30804.0 multi 1.00 import weight 1.00
Epoch 3 Iter 8 subLoss 31112.7 multi 3.99 import weight 1.00
Epoch 3 Iter 9 subLoss 132784.4 multi 1.00 import weight 0.00
Epoch 3 Iter 10 subLoss 44720.4 multi 1.00 import weight 0.00
Epoch 3 Iter 11 subLoss 43742.4 multi 1.00 import weight 0.00
Epoch 3 Acc: 56.45 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4374 train Loss: 43395.7 test Loss: 6802.7
Epoch 4 Iter 0 subLoss 42420.0 multi -1.99 import weight 0.00
Epoch 4 Iter 1 subLoss 45486.3 multi 1.00 import weight 0.00
Epoch 4 Iter 2 subLoss 44266.3 multi 1.00 import weight 0.00
Epoch 4 Iter 3 subLoss 43250.8 multi 1.00 import weight 0.00
Epoch 4 Iter 4 subLoss 41618.8 multi 1.00 import weight 0.00
Epoch 4 Iter 5 subLoss 40305.7 multi 1.00 import weight 0.00
Epoch 4 Iter 6 subLoss 38937.5 multi 1.00 import weight 0.00
Epoch 4 Iter 7 subLoss 37803.2 multi 3.99 import weight 1.00
Epoch 4 Iter 8 subLoss 34734.2 multi 1.00 import weight 0.00
Epoch 4 Iter 9 subLoss 33176.0 multi 1.00 import weight 0.00
Epoch 4 Iter 10 subLoss 32395.8 multi 1.00 import weight 0.00
Epoch 4 Iter 11 subLoss 31215.0 multi 1.00 import weight 0.00
Epoch 4 Acc: 70.11 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 3121 train Loss: 31347.6 test Loss: 4026.3
Epoch 5 Iter 0 subLoss 30721.1 multi 1.00 import weight 0.00
Epoch 5 Iter 1 subLoss 29651.3 multi 1.00 import weight 0.00
Epoch 5 Iter 2 subLoss 29178.8 multi 1.00 import weight 0.00
Epoch 5 Iter 3 subLoss 28328.7 multi 1.00 import weight 0.00
Epoch 5 Iter 4 subLoss 28044.2 multi 1.00 import weight 0.00
Epoch 5 Iter 5 subLoss 27165.1 multi 1.00 import weight 0.00
Epoch 5 Iter 6 subLoss 29408.6 multi 1.00 import weight 0.00
Epoch 5 Iter 7 subLoss 33689.9 multi 1.00 import weight 0.00
Epoch 5 Iter 8 subLoss 53290.8 multi 1.00 import weight 0.00
Epoch 5 Iter 9 subLoss 35031.7 multi 1.00 import weight 0.00
Epoch 5 Iter 10 subLoss 28380.8 multi 1.00 import weight 0.00
Epoch 5 Iter 11 subLoss 27054.0 multi 1.00 import weight 0.00
Epoch 5 Acc: 82.04 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2705 train Loss: 26451.0 test Loss: 3090.3
Epoch 6 Iter 0 subLoss 25989.9 multi 1.00 import weight 0.00
Epoch 6 Iter 1 subLoss 26142.9 multi 1.00 import weight 0.00
Epoch 6 Iter 2 subLoss 26913.0 multi 1.00 import weight 0.00
Epoch 6 Iter 3 subLoss 29668.3 multi -1.99 import weight 0.00
Epoch 6 Iter 4 subLoss 194549.4 multi 1.00 import weight 0.00
Epoch 6 Iter 5 subLoss 56680.9 multi 1.00 import weight 0.00
Epoch 6 Iter 6 subLoss 44702.2 multi 1.00 import weight 0.00
Epoch 6 Iter 7 subLoss 43381.2 multi 1.00 import weight 0.00
Epoch 6 Iter 8 subLoss 42731.7 multi 1.00 import weight 0.00
Epoch 6 Iter 9 subLoss 41652.9 multi 1.00 import weight 0.00
Epoch 6 Iter 10 subLoss 40942.9 multi 1.00 import weight 0.00
Epoch 6 Iter 11 subLoss 40558.9 multi 1.00 import weight 0.00
Epoch 6 Acc: 37.77 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4055 train Loss: 40512.1 test Loss: 6111.0
Epoch 7 Iter 0 subLoss 39267.6 multi 1.00 import weight 0.00
Epoch 7 Iter 1 subLoss 39209.4 multi 1.00 import weight 0.00
Epoch 7 Iter 2 subLoss 39176.8 multi 1.00 import weight 0.00
Epoch 7 Iter 3 subLoss 37922.0 multi 1.00 import weight 0.00
Epoch 7 Iter 4 subLoss 38051.7 multi 1.00 import weight 0.00
Epoch 7 Iter 5 subLoss 37340.2 multi 1.00 import weight 0.00
Epoch 7 Iter 6 subLoss 36902.8 multi 3.99 import weight 1.00
Epoch 7 Iter 7 subLoss 36097.7 multi 1.00 import weight 0.00
Epoch 7 Iter 8 subLoss 35275.5 multi 1.00 import weight 0.00
Epoch 7 Iter 9 subLoss 35370.8 multi 1.00 import weight 0.00
Epoch 7 Iter 10 subLoss 34814.9 multi 1.00 import weight 0.00
Epoch 7 Iter 11 subLoss 34576.5 multi 1.00 import weight 0.00
Epoch 7 Acc: 71.76 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 3457 train Loss: 34782.0 test Loss: 4817.1
Epoch 8 Iter 0 subLoss 34078.9 multi 1.00 import weight 0.00
Epoch 8 Iter 1 subLoss 34553.6 multi 1.00 import weight 0.00
Epoch 8 Iter 2 subLoss 34404.7 multi 1.00 import weight 0.00
Epoch 8 Iter 3 subLoss 35483.6 multi 1.00 import weight 0.00
Epoch 8 Iter 4 subLoss 34378.2 multi 1.00 import weight 0.00
Epoch 8 Iter 5 subLoss 33830.9 multi 1.00 import weight 0.00
Epoch 8 Iter 6 subLoss 33162.0 multi 1.00 import weight 0.00
Epoch 8 Iter 7 subLoss 32751.1 multi 1.00 import weight 0.00
Epoch 8 Iter 8 subLoss 32651.7 multi 1.00 import weight 0.00
Epoch 8 Iter 9 subLoss 32757.0 multi 3.99 import weight 1.00
Epoch 8 Iter 10 subLoss 98339.8 multi 1.00 import weight 0.00
Epoch 8 Iter 11 subLoss 47034.9 multi 1.00 import weight 0.00
Epoch 8 Acc: 42.15 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4703 train Loss: 47144.2 test Loss: 7689.7
Epoch 9 Iter 0 subLoss 46246.2 multi 1.00 import weight 0.00
Epoch 9 Iter 1 subLoss 44877.6 multi 1.00 import weight 0.00
Epoch 9 Iter 2 subLoss 42149.1 multi 1.00 import weight 0.00
Epoch 9 Iter 3 subLoss 39356.1 multi 1.00 import weight 0.00
Epoch 9 Iter 4 subLoss 36953.8 multi 1.00 import weight 0.00
Epoch 9 Iter 5 subLoss 35144.4 multi 1.00 import weight 0.00
Epoch 9 Iter 6 subLoss 33652.8 multi 1.00 import weight 0.00
Epoch 9 Iter 7 subLoss 32725.5 multi 1.00 import weight 0.00
Epoch 9 Iter 8 subLoss 32170.4 multi 1.00 import weight 0.00
Epoch 9 Iter 9 subLoss 31791.0 multi 1.00 import weight 0.00
Epoch 9 Iter 10 subLoss 30883.6 multi 1.00 import weight 0.00
Epoch 9 Iter 11 subLoss 30123.6 multi 1.00 import weight 0.00
Epoch 9 Acc: 84.92 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 3012 train Loss: 30438.7 test Loss: 3988.5
Epoch 10 Iter 0 subLoss 29648.3 multi 1.00 import weight 0.00
Epoch 10 Iter 1 subLoss 29241.8 multi 1.00 import weight 0.00
Epoch 10 Iter 2 subLoss 28855.6 multi 1.00 import weight 0.00
Epoch 10 Iter 3 subLoss 28572.5 multi 1.00 import weight 0.00
Epoch 10 Iter 4 subLoss 28005.6 multi 1.00 import weight 0.00
Epoch 10 Iter 5 subLoss 28041.3 multi 3.99 import weight 1.00
Epoch 10 Iter 6 subLoss 27314.2 multi 1.00 import weight 0.00
Epoch 10 Iter 7 subLoss 27223.7 multi 1.00 import weight 0.00
Epoch 10 Iter 8 subLoss 26972.6 multi 1.00 import weight 0.00
Epoch 10 Iter 9 subLoss 26838.3 multi 1.00 import weight 0.00
Epoch 10 Iter 10 subLoss 27480.6 multi 1.00 import weight 0.00
Epoch 10 Iter 11 subLoss 26636.3 multi 1.00 import weight 0.00
Epoch 10 Acc: 87.18 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2663 train Loss: 26617.0 test Loss: 3351.1
Epoch 11 Iter 0 subLoss 25219.3 multi 1.00 import weight 0.00
Epoch 11 Iter 1 subLoss 25951.9 multi 1.00 import weight 0.00
Epoch 11 Iter 2 subLoss 27087.6 multi 1.00 import weight 0.00
Epoch 11 Iter 3 subLoss 27131.0 multi 1.00 import weight 0.00
Epoch 11 Iter 4 subLoss 27642.7 multi 1.00 import weight 0.00
Epoch 11 Iter 5 subLoss 25804.7 multi 1.00 import weight 0.00
Epoch 11 Iter 6 subLoss 25538.2 multi 1.00 import weight 0.00
Epoch 11 Iter 7 subLoss 24878.2 multi 1.00 import weight 0.00
Epoch 11 Iter 8 subLoss 24555.2 multi 1.00 import weight 0.00
Epoch 11 Iter 9 subLoss 24474.9 multi 1.00 import weight 0.00
Epoch 11 Iter 10 subLoss 23501.8 multi 1.00 import weight 0.00
Epoch 11 Iter 11 subLoss 24064.4 multi 1.00 import weight 0.00
Epoch 11 Acc: 87.59 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2406 train Loss: 23847.1 test Loss: 2761.7
Epoch 12 Iter 0 subLoss 23267.1 multi 1.00 import weight 0.00
Epoch 12 Iter 1 subLoss 22963.7 multi 1.00 import weight 0.00
Epoch 12 Iter 2 subLoss 23873.3 multi 1.00 import weight 0.00
Epoch 12 Iter 3 subLoss 25407.1 multi 1.00 import weight 0.00
Epoch 12 Iter 4 subLoss 27773.8 multi 1.00 import weight 0.00
Epoch 12 Iter 5 subLoss 24037.8 multi 1.00 import weight 0.00
Epoch 12 Iter 6 subLoss 21706.4 multi 1.00 import weight 0.00
Epoch 12 Iter 7 subLoss 20668.9 multi 1.00 import weight 0.00
Epoch 12 Iter 8 subLoss 20967.9 multi 1.00 import weight 0.00
Epoch 12 Iter 9 subLoss 20435.4 multi 1.00 import weight 0.00
Epoch 12 Iter 10 subLoss 21836.6 multi 1.00 import weight 0.00
Epoch 12 Iter 11 subLoss 21024.6 multi 1.00 import weight 0.00
Epoch 12 Acc: 81.12 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2102 train Loss: 24661.1 test Loss: 2895.8
Epoch 13 Iter 0 subLoss 24227.3 multi 1.00 import weight 0.00
Epoch 13 Iter 1 subLoss 20645.2 multi 1.00 import weight 0.00
Epoch 13 Iter 2 subLoss 20159.1 multi 1.00 import weight 0.00
Epoch 13 Iter 3 subLoss 19178.2 multi 1.00 import weight 0.00
Epoch 13 Iter 4 subLoss 20124.2 multi 1.00 import weight 0.00
Epoch 13 Iter 5 subLoss 18430.4 multi 1.00 import weight 0.00
Epoch 13 Iter 6 subLoss 21099.2 multi 1.00 import weight 0.00
Epoch 13 Iter 7 subLoss 19960.5 multi 1.00 import weight 0.00
Epoch 13 Iter 8 subLoss 21506.1 multi 1.00 import weight 0.00
Epoch 13 Iter 9 subLoss 18981.6 multi 1.00 import weight 0.00
Epoch 13 Iter 10 subLoss 20688.5 multi 1.00 import weight 0.00
Epoch 13 Iter 11 subLoss 19027.8 multi 1.00 import weight 0.00
Epoch 13 Acc: 85.54 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1902 train Loss: 19942.6 test Loss: 2275.8
Epoch 14 Iter 0 subLoss 20039.6 multi 1.00 import weight 0.00
Epoch 14 Iter 1 subLoss 18321.4 multi 1.00 import weight 0.00
Epoch 14 Iter 2 subLoss 19039.6 multi -1.99 import weight 0.00
Epoch 14 Iter 3 subLoss 58953.5 multi 1.00 import weight 0.00
Epoch 14 Iter 4 subLoss 43200.0 multi 1.00 import weight 0.00
Epoch 14 Iter 5 subLoss 28310.8 multi 1.00 import weight 0.00
Epoch 14 Iter 6 subLoss 22840.1 multi 1.00 import weight 0.00
Epoch 14 Iter 7 subLoss 19596.0 multi 1.00 import weight 0.00
Epoch 14 Iter 8 subLoss 18269.5 multi 1.00 import weight 0.00
Epoch 14 Iter 9 subLoss 16746.4 multi 1.00 import weight 0.00
Epoch 14 Iter 10 subLoss 16620.2 multi 1.00 import weight 0.00
Epoch 14 Iter 11 subLoss 14943.3 multi 1.00 import weight 0.00
Epoch 14 Acc: 92.84 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1494 train Loss: 15560.1 test Loss: 1465.8
Epoch 15 Iter 0 subLoss 15327.3 multi 1.00 import weight 0.00
Epoch 15 Iter 1 subLoss 14925.7 multi 1.00 import weight 0.00
Epoch 15 Iter 2 subLoss 15077.2 multi 1.00 import weight 0.00
Epoch 15 Iter 3 subLoss 13959.3 multi 1.00 import weight 0.00
Epoch 15 Iter 4 subLoss 14359.6 multi 1.00 import weight 0.00
Epoch 15 Iter 5 subLoss 16366.1 multi 1.00 import weight 0.00
Epoch 15 Iter 6 subLoss 16349.3 multi 1.00 import weight 0.00
Epoch 15 Iter 7 subLoss 19981.4 multi 1.00 import weight 0.00
Epoch 15 Iter 8 subLoss 18064.8 multi 1.00 import weight 0.00
Epoch 15 Iter 9 subLoss 20897.6 multi 1.00 import weight 0.00
Epoch 15 Iter 10 subLoss 16903.0 multi 1.00 import weight 0.00
Epoch 15 Iter 11 subLoss 16697.8 multi 1.00 import weight 0.00
Epoch 15 Acc: 93.31 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1669 train Loss: 14953.6 test Loss: 1312.9
Epoch 16 Iter 0 subLoss 15174.7 multi 1.00 import weight 0.00
Epoch 16 Iter 1 subLoss 15277.0 multi 1.00 import weight 0.00
Epoch 16 Iter 2 subLoss 13288.6 multi 1.00 import weight 0.00
Epoch 16 Iter 3 subLoss 13777.1 multi 1.00 import weight 0.00
Epoch 16 Iter 4 subLoss 13496.8 multi 1.00 import weight 0.00
Epoch 16 Iter 5 subLoss 15281.1 multi -1.99 import weight 0.00
Epoch 16 Iter 6 subLoss 49774.4 multi 1.00 import weight 0.00
Epoch 16 Iter 7 subLoss 22366.7 multi 1.00 import weight 0.00
Epoch 16 Iter 8 subLoss 19840.2 multi 1.00 import weight 0.00
Epoch 16 Iter 9 subLoss 16327.7 multi 1.00 import weight 0.00
Epoch 16 Iter 10 subLoss 13286.2 multi 3.99 import weight 1.00
Epoch 16 Iter 11 subLoss 18268.9 multi 3.99 import weight 1.00
Epoch 16 Acc: 20.35 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 3.99 Pidx 1826 train Loss: 242591.8 test Loss: 41843.8
Epoch 17 Iter 0 subLoss 236863.8 multi 1.00 import weight 0.00
Epoch 17 Iter 1 subLoss 41849.8 multi 1.00 import weight 0.00
Epoch 17 Iter 2 subLoss 40700.5 multi 1.00 import weight 0.00
Epoch 17 Iter 3 subLoss 39247.6 multi 1.00 import weight 0.00
Epoch 17 Iter 4 subLoss 37836.5 multi 1.00 import weight 0.00
Epoch 17 Iter 5 subLoss 37130.8 multi 1.00 import weight 0.00
Epoch 17 Iter 6 subLoss 36102.6 multi -1.99 import weight 0.00
Epoch 17 Iter 7 subLoss 38555.8 multi 1.00 import weight 0.00
Epoch 17 Iter 8 subLoss 37455.2 multi 1.00 import weight 0.00
Epoch 17 Iter 9 subLoss 35860.1 multi 1.00 import weight 0.00
Epoch 17 Iter 10 subLoss 35345.0 multi 1.00 import weight 0.00
Epoch 17 Iter 11 subLoss 34910.8 multi 1.00 import weight 0.00
Epoch 17 Acc: 58.98 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 3491 train Loss: 34226.1 test Loss: 5151.1
Epoch 18 Iter 0 subLoss 33845.8 multi -1.99 import weight 0.00
Epoch 18 Iter 1 subLoss 35466.6 multi -1.99 import weight 0.00
Epoch 18 Iter 2 subLoss 38129.4 multi 1.00 import weight 0.00
Epoch 18 Iter 3 subLoss 36122.1 multi 1.00 import weight 0.00
Epoch 18 Iter 4 subLoss 35590.2 multi 1.00 import weight 0.00
Epoch 18 Iter 5 subLoss 34717.6 multi 1.00 import weight 0.00
Epoch 18 Iter 6 subLoss 34505.0 multi 1.00 import weight 0.00
Epoch 18 Iter 7 subLoss 33567.9 multi 1.00 import weight 0.00
Epoch 18 Iter 8 subLoss 32706.9 multi 1.00 import weight 0.00
Epoch 18 Iter 9 subLoss 31845.4 multi 1.00 import weight 0.00
Epoch 18 Iter 10 subLoss 31827.0 multi 1.00 import weight 0.00
Epoch 18 Iter 11 subLoss 29222.8 multi 1.00 import weight 0.00
Epoch 18 Acc: 67.23 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2922 train Loss: 29879.4 test Loss: 4224.5
Epoch 19 Iter 0 subLoss 30105.7 multi 1.00 import weight 0.00
Epoch 19 Iter 1 subLoss 27446.6 multi 1.00 import weight 0.00
Epoch 19 Iter 2 subLoss 27472.5 multi 1.00 import weight 0.00
Epoch 19 Iter 3 subLoss 26368.3 multi 1.00 import weight 0.00
Epoch 19 Iter 4 subLoss 24849.0 multi 1.00 import weight 0.00
Epoch 19 Iter 5 subLoss 24420.5 multi 1.00 import weight 0.00
Epoch 19 Iter 6 subLoss 22851.1 multi -1.99 import weight 0.00
Epoch 19 Iter 7 subLoss 26657.4 multi 1.00 import weight 0.00
Epoch 19 Iter 8 subLoss 27714.8 multi 1.00 import weight 0.00
Epoch 19 Iter 9 subLoss 26023.9 multi 1.00 import weight 0.00
Epoch 19 Iter 10 subLoss 29105.6 multi 1.00 import weight 0.00
Epoch 19 Iter 11 subLoss 25165.0 multi 1.00 import weight 0.00
Epoch 19 Acc: 88.50 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2516 train Loss: 22662.1 test Loss: 2545.6
Epoch 20 Iter 0 subLoss 21668.2 multi 1.00 import weight 0.00
Epoch 20 Iter 1 subLoss 21246.9 multi 1.00 import weight 0.00
Epoch 20 Iter 2 subLoss 22202.9 multi 1.00 import weight 0.00
Epoch 20 Iter 3 subLoss 23089.3 multi 1.00 import weight 0.00
Epoch 20 Iter 4 subLoss 26161.3 multi 1.00 import weight 0.00
Epoch 20 Iter 5 subLoss 22006.6 multi 1.00 import weight 0.00
Epoch 20 Iter 6 subLoss 19245.2 multi 1.00 import weight 0.00
Epoch 20 Iter 7 subLoss 17710.1 multi 1.00 import weight 0.00
Epoch 20 Iter 8 subLoss 16754.4 multi -1.99 import weight 0.00
Epoch 20 Iter 9 subLoss 24336.0 multi 1.00 import weight 0.00
Epoch 20 Iter 10 subLoss 20086.4 multi 1.00 import weight 0.00
Epoch 20 Iter 11 subLoss 17171.3 multi 1.00 import weight 0.00
Epoch 20 Acc: 92.90 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1717 train Loss: 16341.6 test Loss: 1472.4
Epoch 21 Iter 0 subLoss 16074.6 multi 1.00 import weight 0.00
Epoch 21 Iter 1 subLoss 15021.4 multi 1.00 import weight 0.00
Epoch 21 Iter 2 subLoss 14839.9 multi 1.00 import weight 0.00
Epoch 21 Iter 3 subLoss 14138.5 multi 1.00 import weight 0.00
Epoch 21 Iter 4 subLoss 13736.4 multi 1.00 import weight 0.00
Epoch 21 Iter 5 subLoss 13655.0 multi 1.00 import weight 0.00
Epoch 21 Iter 6 subLoss 14284.2 multi 1.00 import weight 0.00
Epoch 21 Iter 7 subLoss 15572.1 multi 1.00 import weight 0.00
Epoch 21 Iter 8 subLoss 21483.3 multi 1.00 import weight 0.00
Epoch 21 Iter 9 subLoss 24123.1 multi 1.00 import weight 0.00
Epoch 21 Iter 10 subLoss 16987.6 multi 1.00 import weight 0.00
Epoch 21 Iter 11 subLoss 13096.9 multi 1.00 import weight 0.00
Epoch 21 Acc: 94.10 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1309 train Loss: 13121.2 test Loss: 1114.1
Epoch 22 Iter 0 subLoss 12717.5 multi 1.00 import weight 0.00
Epoch 22 Iter 1 subLoss 12585.2 multi 1.00 import weight 0.00
Epoch 22 Iter 2 subLoss 12578.8 multi 1.00 import weight 0.00
Epoch 22 Iter 3 subLoss 12318.4 multi 1.00 import weight 0.00
Epoch 22 Iter 4 subLoss 12073.1 multi 1.00 import weight 0.00
Epoch 22 Iter 5 subLoss 12801.4 multi 1.00 import weight 0.00
Epoch 22 Iter 6 subLoss 14441.5 multi 1.00 import weight 0.00
Epoch 22 Iter 7 subLoss 15201.0 multi 1.00 import weight 0.00
Epoch 22 Iter 8 subLoss 23797.2 multi 1.00 import weight 0.00
Epoch 22 Iter 9 subLoss 19054.2 multi 1.00 import weight 0.00
Epoch 22 Iter 10 subLoss 17709.0 multi 1.00 import weight 0.00
Epoch 22 Iter 11 subLoss 11965.0 multi 1.00 import weight 0.00
Epoch 22 Acc: 94.73 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1196 train Loss: 11291.7 test Loss: 986.3
Epoch 23 Iter 0 subLoss 10805.2 multi 1.00 import weight 0.00
Epoch 23 Iter 1 subLoss 10171.8 multi 1.00 import weight 0.00
Epoch 23 Iter 2 subLoss 9918.7 multi 1.00 import weight 0.00
Epoch 23 Iter 3 subLoss 10774.2 multi 1.00 import weight 0.00
Epoch 23 Iter 4 subLoss 10831.6 multi 1.00 import weight 0.00
Epoch 23 Iter 5 subLoss 11063.9 multi 1.00 import weight 0.00
Epoch 23 Iter 6 subLoss 12502.6 multi 1.00 import weight 0.00
Epoch 23 Iter 7 subLoss 15374.1 multi 1.00 import weight 0.00
Epoch 23 Iter 8 subLoss 18299.1 multi 1.00 import weight 0.00
Epoch 23 Iter 9 subLoss 15245.3 multi 1.00 import weight 0.00
Epoch 23 Iter 10 subLoss 11549.0 multi 1.00 import weight 0.00
Epoch 23 Iter 11 subLoss 9695.3 multi 1.00 import weight 0.00
Epoch 23 Acc: 95.17 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 969 train Loss: 9743.6 test Loss: 894.8
Epoch 24 Iter 0 subLoss 9879.7 multi 1.00 import weight 0.00
Epoch 24 Iter 1 subLoss 9904.3 multi 1.00 import weight 0.00
Epoch 24 Iter 2 subLoss 9235.2 multi 1.00 import weight 0.00
Epoch 24 Iter 3 subLoss 9210.4 multi 1.00 import weight 0.00
Epoch 24 Iter 4 subLoss 8952.1 multi 1.00 import weight 0.00
Epoch 24 Iter 5 subLoss 8821.4 multi 1.00 import weight 0.00
Epoch 24 Iter 6 subLoss 8727.1 multi 1.00 import weight 0.00
Epoch 24 Iter 7 subLoss 9665.8 multi 1.00 import weight 0.00
Epoch 24 Iter 8 subLoss 9097.0 multi 1.00 import weight 0.00
Epoch 24 Iter 9 subLoss 9716.6 multi 1.00 import weight 0.00
Epoch 24 Iter 10 subLoss 10326.1 multi 1.00 import weight 0.00
Epoch 24 Iter 11 subLoss 11428.9 multi 1.00 import weight 0.00
Epoch 24 Acc: 93.71 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1142 train Loss: 9777.4 test Loss: 1020.8
Epoch 25 Iter 0 subLoss 8737.2 multi -1.99 import weight 0.00
Epoch 25 Iter 1 subLoss 58079.5 multi 1.00 import weight 0.00
Epoch 25 Iter 2 subLoss 62194.6 multi 1.00 import weight 0.00
Epoch 25 Iter 3 subLoss 27374.5 multi 1.00 import weight 0.00
Epoch 25 Iter 4 subLoss 22405.0 multi 1.00 import weight 0.00
Epoch 25 Iter 5 subLoss 19467.8 multi 1.00 import weight 0.00
Epoch 25 Iter 6 subLoss 19798.0 multi 1.00 import weight 0.00
Epoch 25 Iter 7 subLoss 18397.7 multi 1.00 import weight 0.00
Epoch 25 Iter 8 subLoss 18896.8 multi 1.00 import weight 0.00
Epoch 25 Iter 9 subLoss 16022.0 multi 1.00 import weight 0.00
Epoch 25 Iter 10 subLoss 14889.6 multi 1.00 import weight 0.00
Epoch 25 Iter 11 subLoss 14314.3 multi 1.00 import weight 0.00
Epoch 25 Acc: 93.48 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1431 train Loss: 12475.0 test Loss: 1245.0
Epoch 26 Iter 0 subLoss 12477.9 multi 1.00 import weight 0.00
Epoch 26 Iter 1 subLoss 11128.7 multi 1.00 import weight 0.00
Epoch 26 Iter 2 subLoss 10915.4 multi 1.00 import weight 0.00
Epoch 26 Iter 3 subLoss 10235.7 multi 1.00 import weight 0.00
Epoch 26 Iter 4 subLoss 9902.7 multi 3.99 import weight 1.00
Epoch 26 Iter 5 subLoss 13836.9 multi 1.00 import weight 0.00
Epoch 26 Iter 6 subLoss 11768.8 multi 1.00 import weight 0.00
Epoch 26 Iter 7 subLoss 12557.8 multi 1.00 import weight 0.00
Epoch 26 Iter 8 subLoss 9452.0 multi 1.00 import weight 0.00
Epoch 26 Iter 9 subLoss 8873.5 multi 1.00 import weight 0.00
Epoch 26 Iter 10 subLoss 8709.6 multi 1.00 import weight 0.00
Epoch 26 Iter 11 subLoss 8244.9 multi 1.00 import weight 0.00
Epoch 26 Acc: 95.39 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 824 train Loss: 8394.5 test Loss: 778.6
Epoch 27 Iter 0 subLoss 8139.5 multi 1.00 import weight 0.00
Epoch 27 Iter 1 subLoss 7876.2 multi 1.00 import weight 0.00
Epoch 27 Iter 2 subLoss 8454.3 multi 1.00 import weight 0.00
Epoch 27 Iter 3 subLoss 7097.5 multi 1.00 import weight 0.00
Epoch 27 Iter 4 subLoss 7476.0 multi 1.00 import weight 0.00
Epoch 27 Iter 5 subLoss 7173.1 multi 1.00 import weight 0.00
Epoch 27 Iter 6 subLoss 7638.6 multi 1.00 import weight 0.00
Epoch 27 Iter 7 subLoss 7421.1 multi 1.00 import weight 0.00
Epoch 27 Iter 8 subLoss 7857.1 multi 1.00 import weight 0.00
Epoch 27 Iter 9 subLoss 6620.5 multi 1.00 import weight 0.00
Epoch 27 Iter 10 subLoss 7390.6 multi 1.00 import weight 0.00
Epoch 27 Iter 11 subLoss 7496.6 multi 1.00 import weight 0.00
Epoch 27 Acc: 96.19 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 749 train Loss: 7050.3 test Loss: 639.5
Epoch 28 Iter 0 subLoss 6837.9 multi 1.00 import weight 0.00
Epoch 28 Iter 1 subLoss 6904.0 multi 1.00 import weight 0.00
Epoch 28 Iter 2 subLoss 6715.8 multi 1.00 import weight 0.00
Epoch 28 Iter 3 subLoss 6751.6 multi 1.00 import weight 0.00
Epoch 28 Iter 4 subLoss 6808.1 multi 1.00 import weight 0.00
Epoch 28 Iter 5 subLoss 7223.5 multi 1.00 import weight 0.00
Epoch 28 Iter 6 subLoss 6491.1 multi 1.00 import weight 0.00
Epoch 28 Iter 7 subLoss 6379.9 multi 1.00 import weight 0.00
Epoch 28 Iter 8 subLoss 7062.1 multi 1.00 import weight 0.00
Epoch 28 Iter 9 subLoss 6107.2 multi 1.00 import weight 0.00
Epoch 28 Iter 10 subLoss 6144.4 multi 1.00 import weight 0.00
Epoch 28 Iter 11 subLoss 6386.3 multi -1.99 import weight 0.00
Epoch 28 Acc: 95.72 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 638 train Loss: 7296.5 test Loss: 689.1
Epoch 29 Iter 0 subLoss 7625.9 multi 1.00 import weight 0.00
Epoch 29 Iter 1 subLoss 6840.9 multi -1.99 import weight 0.00
Epoch 29 Iter 2 subLoss 13693.0 multi 1.00 import weight 0.00
Epoch 29 Iter 3 subLoss 12396.5 multi 1.00 import weight 0.00
Epoch 29 Iter 4 subLoss 7490.9 multi 3.99 import weight 1.00
Epoch 29 Iter 5 subLoss 21429.3 multi 1.00 import weight 0.00
Epoch 29 Iter 6 subLoss 9762.0 multi 1.00 import weight 0.00
Epoch 29 Iter 7 subLoss 8056.9 multi 1.00 import weight 0.00
Epoch 29 Iter 8 subLoss 6107.4 multi 3.99 import weight 1.00
Epoch 29 Iter 9 subLoss 11122.3 multi 3.99 import weight 1.00
Epoch 29 Iter 10 subLoss 213714.9 multi 1.00 import weight 0.00
Epoch 29 Iter 11 subLoss 49873.4 multi 1.00 import weight 0.00
Epoch 29 Acc: 60.52 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4987 train Loss: 30923.5 test Loss: 4941.1
Epoch 30 Iter 0 subLoss 30238.0 multi 1.00 import weight 0.00
Epoch 30 Iter 1 subLoss 26218.1 multi 1.00 import weight 0.00
Epoch 30 Iter 2 subLoss 24506.6 multi 1.00 import weight 0.00
Epoch 30 Iter 3 subLoss 25257.1 multi 1.00 import weight 0.00
Epoch 30 Iter 4 subLoss 23506.8 multi 3.99 import weight 1.00
Epoch 30 Iter 5 subLoss 21535.2 multi 1.00 import weight 0.00
Epoch 30 Iter 6 subLoss 21733.9 multi 1.00 import weight 0.00
Epoch 30 Iter 7 subLoss 20864.4 multi 1.00 import weight 0.00
Epoch 30 Iter 8 subLoss 20416.2 multi 1.00 import weight 0.00
Epoch 30 Iter 9 subLoss 20353.6 multi 1.00 import weight 0.00
Epoch 30 Iter 10 subLoss 20287.4 multi 1.00 import weight 0.00
Epoch 30 Iter 11 subLoss 19467.6 multi 3.99 import weight 1.00
Epoch 30 Acc: 78.79 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 3.99 Pidx 1946 train Loss: 20768.7 test Loss: 3008.4
Epoch 31 Iter 0 subLoss 19615.8 multi 1.00 import weight 0.00
Epoch 31 Iter 1 subLoss 18924.9 multi 1.00 import weight 0.00
Epoch 31 Iter 2 subLoss 17561.6 multi 1.00 import weight 0.00
Epoch 31 Iter 3 subLoss 17758.8 multi 1.00 import weight 0.00
Epoch 31 Iter 4 subLoss 17969.1 multi 1.00 import weight 0.00
Epoch 31 Iter 5 subLoss 16563.2 multi 1.00 import weight 0.00
Epoch 31 Iter 6 subLoss 17261.4 multi 1.00 import weight 0.00
Epoch 31 Iter 7 subLoss 16391.0 multi 1.00 import weight 0.00
Epoch 31 Iter 8 subLoss 16694.0 multi 3.99 import weight 1.00
Epoch 31 Iter 9 subLoss 17305.7 multi 1.00 import weight 0.00
Epoch 31 Iter 10 subLoss 16893.1 multi 1.00 import weight 0.00
Epoch 31 Iter 11 subLoss 16791.3 multi 1.00 import weight 0.00
Epoch 31 Acc: 80.04 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1679 train Loss: 15896.9 test Loss: 2320.1
Epoch 32 Iter 0 subLoss 15484.8 multi 1.00 import weight 0.00
Epoch 32 Iter 1 subLoss 15254.2 multi -1.99 import weight 0.00
Epoch 32 Iter 2 subLoss 21263.3 multi 1.00 import weight 0.00
Epoch 32 Iter 3 subLoss 16825.4 multi 1.00 import weight 0.00
Epoch 32 Iter 4 subLoss 15546.2 multi 1.00 import weight 0.00
Epoch 32 Iter 5 subLoss 14710.7 multi 1.00 import weight 0.00
Epoch 32 Iter 6 subLoss 14390.9 multi 1.00 import weight 0.00
Epoch 32 Iter 7 subLoss 14364.1 multi -1.99 import weight 0.00
Epoch 32 Iter 8 subLoss 14667.7 multi 1.00 import weight 0.00
Epoch 32 Iter 9 subLoss 14640.8 multi 1.00 import weight 0.00
Epoch 32 Iter 10 subLoss 14724.0 multi -1.99 import weight 0.00
Epoch 32 Iter 11 subLoss 15241.8 multi 3.99 import weight 1.00
Epoch 32 Acc: 79.20 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 3.99 Pidx 1524 train Loss: 14672.2 test Loss: 2131.0
Epoch 33 Iter 0 subLoss 14164.1 multi 1.00 import weight 0.00
Epoch 33 Iter 1 subLoss 13725.1 multi 1.00 import weight 0.00
Epoch 33 Iter 2 subLoss 14024.7 multi 1.00 import weight 0.00
Epoch 33 Iter 3 subLoss 12846.8 multi 1.00 import weight 0.00
Epoch 33 Iter 4 subLoss 13647.2 multi 1.00 import weight 0.00
Epoch 33 Iter 5 subLoss 12775.3 multi 1.00 import weight 0.00
Epoch 33 Iter 6 subLoss 12996.4 multi 1.00 import weight 0.00
Epoch 33 Iter 7 subLoss 11922.9 multi 1.00 import weight 0.00
Epoch 33 Iter 8 subLoss 12353.3 multi 1.00 import weight 0.00
Epoch 33 Iter 9 subLoss 12585.7 multi 1.00 import weight 1.00
Epoch 33 Iter 10 subLoss 13134.0 multi 1.00 import weight 0.00
Epoch 33 Iter 11 subLoss 14468.6 multi 1.00 import weight 0.00
Epoch 33 Acc: 79.53 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1446 train Loss: 16719.4 test Loss: 2255.3
Epoch 34 Iter 0 subLoss 16758.7 multi 1.00 import weight 1.00
Epoch 34 Iter 1 subLoss 15347.6 multi 1.00 import weight 0.00
Epoch 34 Iter 2 subLoss 16324.5 multi 3.99 import weight 1.00
Epoch 34 Iter 3 subLoss 199967.0 multi 1.00 import weight 0.00
Epoch 34 Iter 4 subLoss 33330.0 multi 1.00 import weight 0.00
Epoch 34 Iter 5 subLoss 29570.9 multi 1.00 import weight 0.00
Epoch 34 Iter 6 subLoss 27465.5 multi 1.00 import weight 0.00
Epoch 34 Iter 7 subLoss 25279.1 multi 1.00 import weight 0.00
Epoch 34 Iter 8 subLoss 24506.7 multi 3.99 import weight 1.00
Epoch 34 Iter 9 subLoss 23248.5 multi 1.00 import weight 0.00
Epoch 34 Iter 10 subLoss 22338.3 multi 1.00 import weight 0.00
Epoch 34 Iter 11 subLoss 20719.7 multi 1.00 import weight 0.00
Epoch 34 Acc: 85.58 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2071 train Loss: 20486.4 test Loss: 2742.4
Epoch 35 Iter 0 subLoss 19724.2 multi 1.00 import weight 0.00
Epoch 35 Iter 1 subLoss 20009.2 multi 1.00 import weight 0.00
Epoch 35 Iter 2 subLoss 18487.5 multi 1.00 import weight 0.00
Epoch 35 Iter 3 subLoss 16851.1 multi 1.00 import weight 0.00
Epoch 35 Iter 4 subLoss 16092.8 multi 1.00 import weight 0.00
Epoch 35 Iter 5 subLoss 15166.7 multi 1.00 import weight 0.00
Epoch 35 Iter 6 subLoss 14175.0 multi -1.99 import weight 0.00
Epoch 35 Iter 7 subLoss 15493.7 multi -1.99 import weight 0.00
Epoch 35 Iter 8 subLoss 17735.8 multi 1.00 import weight 0.00
Epoch 35 Iter 9 subLoss 16368.4 multi 3.99 import weight 1.00
Epoch 35 Iter 10 subLoss 13716.7 multi 1.00 import weight 0.00
Epoch 35 Iter 11 subLoss 12645.7 multi 1.00 import weight 0.00
Epoch 35 Acc: 90.62 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1264 train Loss: 12893.0 test Loss: 1505.0
Epoch 36 Iter 0 subLoss 13006.0 multi -1.99 import weight 0.00
Epoch 36 Iter 1 subLoss 14044.3 multi 1.00 import weight 0.00
Epoch 36 Iter 2 subLoss 13158.0 multi 1.00 import weight 0.00
Epoch 36 Iter 3 subLoss 12762.3 multi 1.00 import weight 0.00
Epoch 36 Iter 4 subLoss 12272.9 multi 1.00 import weight 0.00
Epoch 36 Iter 5 subLoss 11959.3 multi 1.00 import weight 0.00
Epoch 36 Iter 6 subLoss 11577.1 multi 1.00 import weight 0.00
Epoch 36 Iter 7 subLoss 11489.7 multi 1.00 import weight 0.00
Epoch 36 Iter 8 subLoss 10626.6 multi 1.00 import weight 0.00
Epoch 36 Iter 9 subLoss 10782.8 multi -1.99 import weight 0.00
Epoch 36 Iter 10 subLoss 12454.6 multi 1.00 import weight 0.00
Epoch 36 Iter 11 subLoss 11271.8 multi 1.00 import weight 0.00
Epoch 36 Acc: 94.06 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1127 train Loss: 10823.5 test Loss: 1074.5
Epoch 37 Iter 0 subLoss 10167.6 multi 1.00 import weight 0.00
Epoch 37 Iter 1 subLoss 10562.7 multi 1.00 import weight 0.00
Epoch 37 Iter 2 subLoss 10247.0 multi -1.99 import weight 0.00
Epoch 37 Iter 3 subLoss 10434.2 multi 1.00 import weight 0.00
Epoch 37 Iter 4 subLoss 10180.1 multi -1.99 import weight 0.00
Epoch 37 Iter 5 subLoss 10897.5 multi 1.00 import weight 0.00
Epoch 37 Iter 6 subLoss 10482.6 multi 1.00 import weight 0.00
Epoch 37 Iter 7 subLoss 10437.3 multi 3.99 import weight 1.00
Epoch 37 Iter 8 subLoss 9582.1 multi 1.00 import weight 0.00
Epoch 37 Iter 9 subLoss 9292.1 multi 1.00 import weight 0.00
Epoch 37 Iter 10 subLoss 8945.4 multi 1.00 import weight 0.00
Epoch 37 Iter 11 subLoss 8669.2 multi 1.00 import weight 0.00
Epoch 37 Acc: 95.70 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 866 train Loss: 8840.6 test Loss: 790.9
Epoch 38 Iter 0 subLoss 8457.3 multi 3.99 import weight 1.00
Epoch 38 Iter 1 subLoss 8166.9 multi 1.00 import weight 0.00
Epoch 38 Iter 2 subLoss 8303.7 multi 1.00 import weight 0.00
Epoch 38 Iter 3 subLoss 8225.0 multi 1.00 import weight 0.00
Epoch 38 Iter 4 subLoss 7801.0 multi 1.00 import weight 0.00
Epoch 38 Iter 5 subLoss 8159.9 multi 1.00 import weight 0.00
Epoch 38 Iter 6 subLoss 8823.5 multi 3.99 import weight 1.00
Epoch 38 Iter 7 subLoss 43524.6 multi 1.00 import weight 0.00
Epoch 38 Iter 8 subLoss 42609.7 multi 1.00 import weight 0.00
Epoch 38 Iter 9 subLoss 17141.7 multi 1.00 import weight 0.00
Epoch 38 Iter 10 subLoss 14456.3 multi -1.99 import weight 0.00
Epoch 38 Iter 11 subLoss 17669.1 multi 1.00 import weight 0.00
Epoch 38 Acc: 85.44 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1766 train Loss: 16245.0 test Loss: 1989.7
Epoch 39 Iter 0 subLoss 15292.5 multi -1.99 import weight 0.00
Epoch 39 Iter 1 subLoss 18905.8 multi -1.99 import weight 0.00
Epoch 39 Iter 2 subLoss 22543.3 multi 1.00 import weight 0.00
Epoch 39 Iter 3 subLoss 20470.7 multi 1.00 import weight 0.00
Epoch 39 Iter 4 subLoss 18461.9 multi 1.00 import weight 0.00
Epoch 39 Iter 5 subLoss 17324.7 multi 1.00 import weight 0.00
Epoch 39 Iter 6 subLoss 16328.8 multi 6.97 import weight 1.00
Epoch 39 Iter 7 subLoss 10834.5 multi 3.99 import weight 0.00
Epoch 39 Iter 8 subLoss 9416.3 multi 1.00 import weight 0.00
Epoch 39 Iter 9 subLoss 7985.4 multi 1.00 import weight 0.00
Epoch 39 Iter 10 subLoss 9003.5 multi 1.00 import weight 0.00
Epoch 39 Iter 11 subLoss 8366.9 multi 1.00 import weight 0.00
Epoch 39 Acc: 96.21 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 836 train Loss: 7956.6 test Loss: 677.0
Epoch 40 Iter 0 subLoss 7569.3 multi 1.00 import weight 0.00
Epoch 40 Iter 1 subLoss 7115.6 multi 1.00 import weight 0.00
Epoch 40 Iter 2 subLoss 7056.8 multi 1.00 import weight 0.00
Epoch 40 Iter 3 subLoss 7340.2 multi 1.00 import weight 0.00
Epoch 40 Iter 4 subLoss 7227.1 multi 3.99 import weight 0.00
Epoch 40 Iter 5 subLoss 7480.0 multi -1.99 import weight 0.00
Epoch 40 Iter 6 subLoss 9514.9 multi 1.00 import weight 0.00
Epoch 40 Iter 7 subLoss 7990.7 multi -1.99 import weight 0.00
Epoch 40 Iter 8 subLoss 17188.2 multi -1.99 import weight 0.00
Epoch 40 Iter 9 subLoss 313832.3 multi 1.00 import weight 0.00
Epoch 40 Iter 10 subLoss 43230.2 multi 1.00 import weight 0.00
Epoch 40 Iter 11 subLoss 41089.0 multi 1.00 import weight 0.00
Epoch 40 Acc: 46.51 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4108 train Loss: 40474.9 test Loss: 6671.9
Epoch 41 Iter 0 subLoss 40323.8 multi 1.00 import weight 0.00
Epoch 41 Iter 1 subLoss 37009.8 multi 1.00 import weight 0.00
Epoch 41 Iter 2 subLoss 34250.2 multi 1.00 import weight 0.00
Epoch 41 Iter 3 subLoss 32043.7 multi 1.00 import weight 0.00
Epoch 41 Iter 4 subLoss 29258.2 multi -1.99 import weight 0.00
Epoch 41 Iter 5 subLoss 33955.5 multi 1.00 import weight 0.00
Epoch 41 Iter 6 subLoss 31100.8 multi 1.00 import weight 0.00
Epoch 41 Iter 7 subLoss 29934.4 multi 1.00 import weight 0.00
Epoch 41 Iter 8 subLoss 27524.2 multi 1.00 import weight 0.00
Epoch 41 Iter 9 subLoss 26805.9 multi 1.00 import weight 0.00
Epoch 41 Iter 10 subLoss 26165.0 multi 3.99 import weight 0.00
Epoch 41 Iter 11 subLoss 21839.6 multi 3.99 import weight 0.00
Epoch 41 Acc: 58.73 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 2183 train Loss: 35834.1 test Loss: 5484.8
Epoch 42 Iter 0 subLoss 34893.1 multi 1.00 import weight 0.00
Epoch 42 Iter 1 subLoss 22912.5 multi 1.00 import weight 0.00
Epoch 42 Iter 2 subLoss 18745.9 multi 1.00 import weight 0.00
Epoch 42 Iter 3 subLoss 16848.0 multi 1.00 import weight 0.00
Epoch 42 Iter 4 subLoss 15772.2 multi 1.00 import weight 0.00
Epoch 42 Iter 5 subLoss 15214.4 multi -1.99 import weight 0.00
Epoch 42 Iter 6 subLoss 16817.7 multi 1.00 import weight 0.00
Epoch 42 Iter 7 subLoss 16913.4 multi -1.99 import weight 0.00
Epoch 42 Iter 8 subLoss 17811.5 multi 1.00 import weight 0.00
Epoch 42 Iter 9 subLoss 16116.8 multi 1.00 import weight 0.00
Epoch 42 Iter 10 subLoss 15649.2 multi 1.00 import weight 0.00
Epoch 42 Iter 11 subLoss 15713.5 multi 1.00 import weight 0.00
Epoch 42 Acc: 91.69 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1571 train Loss: 15194.4 test Loss: 1734.9
Epoch 43 Iter 0 subLoss 14463.8 multi 1.00 import weight 0.00
Epoch 43 Iter 1 subLoss 14503.5 multi 1.00 import weight 0.00
Epoch 43 Iter 2 subLoss 13913.5 multi 1.00 import weight 0.00
Epoch 43 Iter 3 subLoss 13229.3 multi 1.00 import weight 0.00
Epoch 43 Iter 4 subLoss 13836.4 multi 3.99 import weight 0.00
Epoch 43 Iter 5 subLoss 12206.7 multi 1.00 import weight 0.00
Epoch 43 Iter 6 subLoss 11412.8 multi 1.00 import weight 0.00
Epoch 43 Iter 7 subLoss 11424.0 multi 1.00 import weight 0.00
Epoch 43 Iter 8 subLoss 11579.8 multi 3.99 import weight 0.00
Epoch 43 Iter 9 subLoss 10765.3 multi 1.00 import weight 0.00
Epoch 43 Iter 10 subLoss 10578.3 multi -1.99 import weight 0.00
Epoch 43 Iter 11 subLoss 18620.9 multi 1.00 import weight 0.00
Epoch 43 Acc: 85.81 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1862 train Loss: 14961.5 test Loss: 2099.5
Epoch 44 Iter 0 subLoss 14556.7 multi 1.00 import weight 0.00
Epoch 44 Iter 1 subLoss 10562.3 multi 3.99 import weight 0.00
Epoch 44 Iter 2 subLoss 14499.0 multi 1.00 import weight 0.00
Epoch 44 Iter 3 subLoss 11292.7 multi 1.00 import weight 0.00
Epoch 44 Iter 4 subLoss 9067.1 multi 1.00 import weight 0.00
Epoch 44 Iter 5 subLoss 8783.9 multi 1.00 import weight 0.00
Epoch 44 Iter 6 subLoss 8827.3 multi 6.97 import weight 1.00
Epoch 44 Iter 7 subLoss 9965.8 multi 1.00 import weight 0.00
Epoch 44 Iter 8 subLoss 8102.9 multi 1.00 import weight 0.00
Epoch 44 Iter 9 subLoss 8043.7 multi 1.00 import weight 0.00
Epoch 44 Iter 10 subLoss 7447.3 multi 1.00 import weight 0.00
Epoch 44 Iter 11 subLoss 7128.4 multi -1.99 import weight 0.00
Epoch 44 Acc: 95.10 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 712 train Loss: 8711.5 test Loss: 844.8
Epoch 45 Iter 0 subLoss 8807.8 multi 1.00 import weight 0.00
Epoch 45 Iter 1 subLoss 7494.7 multi 3.98 import weight 1.00
Epoch 45 Iter 2 subLoss 11354.2 multi 1.00 import weight 0.00
Epoch 45 Iter 3 subLoss 8478.6 multi 1.00 import weight 0.00
Epoch 45 Iter 4 subLoss 6855.7 multi -1.99 import weight 0.00
Epoch 45 Iter 5 subLoss 8264.5 multi 1.00 import weight 0.00
Epoch 45 Iter 6 subLoss 7293.0 multi 1.00 import weight 0.00
Epoch 45 Iter 7 subLoss 7129.0 multi 1.00 import weight 0.00
Epoch 45 Iter 8 subLoss 6913.8 multi -1.99 import weight 0.00
Epoch 45 Iter 9 subLoss 8202.4 multi 1.00 import weight 0.00
Epoch 45 Iter 10 subLoss 7346.8 multi 3.99 import weight 0.00
Epoch 45 Iter 11 subLoss 13490.7 multi 3.99 import weight 0.00
Epoch 45 Acc: 31.89 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 1349 train Loss: 179042.0 test Loss: 35846.6
Epoch 46 Iter 0 subLoss 179747.1 multi 1.00 import weight 0.00
Epoch 46 Iter 1 subLoss 119105.1 multi 1.00 import weight 0.00
Epoch 46 Iter 2 subLoss 44392.2 multi 1.00 import weight 0.00
Epoch 46 Iter 3 subLoss 38717.2 multi 1.00 import weight 0.00
Epoch 46 Iter 4 subLoss 35999.5 multi 1.00 import weight 0.00
Epoch 46 Iter 5 subLoss 34231.4 multi 1.00 import weight 0.00
Epoch 46 Iter 6 subLoss 32070.7 multi 1.00 import weight 0.00
Epoch 46 Iter 7 subLoss 29690.6 multi 1.00 import weight 0.00
Epoch 46 Iter 8 subLoss 27873.2 multi 1.00 import weight 0.00
Epoch 46 Iter 9 subLoss 25277.0 multi 3.99 import weight 0.00
Epoch 46 Iter 10 subLoss 18185.8 multi 1.00 import weight 0.00
Epoch 46 Iter 11 subLoss 15983.5 multi 1.00 import weight 0.00
Epoch 46 Acc: 92.45 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1598 train Loss: 15812.6 test Loss: 1703.2
Epoch 47 Iter 0 subLoss 16180.6 multi 1.00 import weight 0.00
Epoch 47 Iter 1 subLoss 14317.7 multi 3.99 import weight 0.00
Epoch 47 Iter 2 subLoss 12498.7 multi 1.00 import weight 0.00
Epoch 47 Iter 3 subLoss 11197.4 multi 1.00 import weight 0.00
Epoch 47 Iter 4 subLoss 11232.9 multi 1.00 import weight 0.00
Epoch 47 Iter 5 subLoss 10795.7 multi -1.99 import weight 0.00
Epoch 47 Iter 6 subLoss 10628.9 multi 3.99 import weight 0.00
Epoch 47 Iter 7 subLoss 10289.6 multi 1.00 import weight 0.00
Epoch 47 Iter 8 subLoss 9455.9 multi 3.99 import weight 0.00
Epoch 47 Iter 9 subLoss 9998.7 multi 1.00 import weight 0.00
Epoch 47 Iter 10 subLoss 8533.7 multi 1.00 import weight 0.00
Epoch 47 Iter 11 subLoss 9356.7 multi 1.00 import weight 0.00
Epoch 47 Acc: 95.68 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 935 train Loss: 8718.4 test Loss: 791.8
Epoch 48 Iter 0 subLoss 8515.4 multi 1.00 import weight 0.00
Epoch 48 Iter 1 subLoss 8017.6 multi 1.00 import weight 0.00
Epoch 48 Iter 2 subLoss 9301.5 multi -1.99 import weight 0.00
Epoch 48 Iter 3 subLoss 9774.5 multi -1.99 import weight 0.00
Epoch 48 Iter 4 subLoss 13011.7 multi -1.99 import weight 0.00
Epoch 48 Iter 5 subLoss 72888.8 multi 1.00 import weight 0.00
Epoch 48 Iter 6 subLoss 21278.1 multi -1.99 import weight 0.00
Epoch 48 Iter 7 subLoss 84977.4 multi 1.00 import weight 0.00
Epoch 48 Iter 8 subLoss 31802.1 multi -1.99 import weight 0.00
Epoch 48 Iter 9 subLoss 95556.7 multi 1.00 import weight 0.00
Epoch 48 Iter 10 subLoss 34367.0 multi 1.00 import weight 0.00
Epoch 48 Iter 11 subLoss 28019.2 multi -1.99 import weight 0.00
Epoch 48 Acc: 58.05 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 2801 train Loss: 34237.8 test Loss: 5662.7
Epoch 49 Iter 0 subLoss 33739.0 multi 1.00 import weight 0.00
Epoch 49 Iter 1 subLoss 32220.6 multi 1.00 import weight 0.00
Epoch 49 Iter 2 subLoss 29211.9 multi 1.00 import weight 0.00
Epoch 49 Iter 3 subLoss 26387.2 multi 1.00 import weight 0.00
Epoch 49 Iter 4 subLoss 23477.6 multi 1.00 import weight 0.00
Epoch 49 Iter 5 subLoss 21684.4 multi 1.00 import weight 0.00
Epoch 49 Iter 6 subLoss 19046.6 multi -1.99 import weight 0.00
Epoch 49 Iter 7 subLoss 22894.3 multi 1.00 import weight 0.00
Epoch 49 Iter 8 subLoss 20872.1 multi -1.99 import weight 0.00
Epoch 49 Iter 9 subLoss 24895.0 multi 1.00 import weight 0.00
Epoch 49 Iter 10 subLoss 22549.4 multi 3.99 import weight 0.00
Epoch 49 Iter 11 subLoss 15870.9 multi 1.00 import weight 0.00
Epoch 49 Acc: 92.63 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1587 train Loss: 14975.8 test Loss: 1597.8
Epoch 50 Iter 0 subLoss 14975.2 multi 1.00 import weight 0.00
Epoch 50 Iter 1 subLoss 14162.9 multi 3.99 import weight 0.00
Epoch 50 Iter 2 subLoss 11312.9 multi 1.00 import weight 0.00
Epoch 50 Iter 3 subLoss 10447.2 multi -4.97 import weight 0.00
Epoch 50 Iter 4 subLoss 12534.2 multi 1.00 import weight 0.00
Epoch 50 Iter 5 subLoss 12560.1 multi -1.99 import weight 0.00
Epoch 50 Iter 6 subLoss 13650.7 multi 1.00 import weight 0.00
Epoch 50 Iter 7 subLoss 12093.7 multi 1.00 import weight 0.00
Epoch 50 Iter 8 subLoss 11127.1 multi 6.97 import weight 1.00
Epoch 50 Iter 9 subLoss 9296.2 multi 3.99 import weight 0.00
Epoch 50 Iter 10 subLoss 9638.0 multi 1.00 import weight 0.00
Epoch 50 Iter 11 subLoss 9527.5 multi -1.99 import weight 0.00
Epoch 50 Acc: 94.82 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 952 train Loss: 9567.1 test Loss: 896.3
Epoch 51 Iter 0 subLoss 9274.0 multi 1.00 import weight 0.00
Epoch 51 Iter 1 subLoss 9462.5 multi -4.97 import weight 0.00
Epoch 51 Iter 2 subLoss 10719.4 multi 1.00 import weight 0.00
Epoch 51 Iter 3 subLoss 9701.9 multi -1.99 import weight 0.00
Epoch 51 Iter 4 subLoss 11723.1 multi 1.00 import weight 0.00
Epoch 51 Iter 5 subLoss 9605.3 multi 1.00 import weight 0.00
Epoch 51 Iter 6 subLoss 9922.3 multi -1.99 import weight 0.00
Epoch 51 Iter 7 subLoss 10482.5 multi 3.99 import weight 0.00
Epoch 51 Iter 8 subLoss 9556.3 multi 1.00 import weight 0.00
Epoch 51 Iter 9 subLoss 9707.8 multi 1.00 import weight 0.00
Epoch 51 Iter 10 subLoss 8907.5 multi 1.00 import weight 0.00
Epoch 51 Iter 11 subLoss 8473.1 multi 3.99 import weight 0.00
Epoch 51 Acc: 94.96 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 847 train Loss: 8668.0 test Loss: 834.8
Epoch 52 Iter 0 subLoss 8534.0 multi 3.99 import weight 0.00
Epoch 52 Iter 1 subLoss 8562.7 multi 1.00 import weight 0.00
Epoch 52 Iter 2 subLoss 8143.8 multi -1.99 import weight 0.00
Epoch 52 Iter 3 subLoss 8725.6 multi 3.99 import weight 0.00
Epoch 52 Iter 4 subLoss 9404.4 multi 1.00 import weight 0.00
Epoch 52 Iter 5 subLoss 7444.5 multi 3.99 import weight 0.00
Epoch 52 Iter 6 subLoss 8032.6 multi 1.00 import weight 0.00
Epoch 52 Iter 7 subLoss 6885.3 multi 1.00 import weight 0.00
Epoch 52 Iter 8 subLoss 7481.7 multi 1.00 import weight 0.00
Epoch 52 Iter 9 subLoss 7158.0 multi 1.00 import weight 0.00
Epoch 52 Iter 10 subLoss 7020.9 multi 1.00 import weight 0.00
Epoch 52 Iter 11 subLoss 7170.3 multi 3.99 import weight 0.00
Epoch 52 Acc: 96.11 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 717 train Loss: 7089.1 test Loss: 630.0
Epoch 53 Iter 0 subLoss 7075.3 multi -1.99 import weight 0.00
Epoch 53 Iter 1 subLoss 7068.8 multi 1.00 import weight 0.00
Epoch 53 Iter 2 subLoss 6819.0 multi -1.99 import weight 0.00
Epoch 53 Iter 3 subLoss 7343.0 multi 6.97 import weight 1.00
Epoch 53 Iter 4 subLoss 12680.5 multi 1.00 import weight 0.00
Epoch 53 Iter 5 subLoss 7185.9 multi -4.97 import weight 0.00
Epoch 53 Iter 6 subLoss 11140.5 multi 1.00 import weight 0.00
Epoch 53 Iter 7 subLoss 6780.1 multi 1.00 import weight 0.00
Epoch 53 Iter 8 subLoss 7740.7 multi 1.00 import weight 0.00
Epoch 53 Iter 9 subLoss 6732.7 multi 1.00 import weight 0.00
Epoch 53 Iter 10 subLoss 7259.1 multi 1.00 import weight 0.00
Epoch 53 Iter 11 subLoss 6272.8 multi 1.00 import weight 0.00
Epoch 53 Acc: 96.56 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 627 train Loss: 6749.8 test Loss: 604.5
Epoch 54 Iter 0 subLoss 6685.7 multi 1.00 import weight 0.00
Epoch 54 Iter 1 subLoss 6647.8 multi 1.00 import weight 0.00
Epoch 54 Iter 2 subLoss 6459.7 multi 1.00 import weight 0.00
Epoch 54 Iter 3 subLoss 6499.8 multi 3.99 import weight 0.00
Epoch 54 Iter 4 subLoss 6497.0 multi 6.97 import weight 1.00
Epoch 54 Iter 5 subLoss 6629.7 multi 3.99 import weight 0.00
Epoch 54 Iter 6 subLoss 14197.2 multi 1.00 import weight 0.00
Epoch 54 Iter 7 subLoss 7385.4 multi 1.00 import weight 0.00
Epoch 54 Iter 8 subLoss 5820.3 multi 1.00 import weight 0.00
Epoch 54 Iter 9 subLoss 6563.9 multi 1.00 import weight 0.00
Epoch 54 Iter 10 subLoss 5703.2 multi 1.00 import weight 0.00
Epoch 54 Iter 11 subLoss 5499.6 multi 1.00 import weight 0.00
Epoch 54 Acc: 96.79 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 549 train Loss: 5967.4 test Loss: 547.4
Epoch 55 Iter 0 subLoss 5695.6 multi 1.00 import weight 0.00
Epoch 55 Iter 1 subLoss 6192.2 multi 1.00 import weight 0.00
Epoch 55 Iter 2 subLoss 5806.7 multi 1.00 import weight 0.00
Epoch 55 Iter 3 subLoss 6089.6 multi 1.00 import weight 0.00
Epoch 55 Iter 4 subLoss 6015.5 multi 1.00 import weight 0.00
Epoch 55 Iter 5 subLoss 6322.2 multi 1.00 import weight 0.00
Epoch 55 Iter 6 subLoss 5103.7 multi 1.00 import weight 0.00
Epoch 55 Iter 7 subLoss 5533.5 multi 1.00 import weight 0.00
Epoch 55 Iter 8 subLoss 5791.4 multi 1.00 import weight 0.00
Epoch 55 Iter 9 subLoss 5618.5 multi 1.00 import weight 0.00
Epoch 55 Iter 10 subLoss 5470.5 multi 1.00 import weight 0.00
Epoch 55 Iter 11 subLoss 5174.9 multi 1.00 import weight 0.00
Epoch 55 Acc: 96.91 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 517 train Loss: 5627.2 test Loss: 521.5
Epoch 56 Iter 0 subLoss 5377.5 multi 1.00 import weight 0.00
Epoch 56 Iter 1 subLoss 5312.6 multi 1.00 import weight 0.00
Epoch 56 Iter 2 subLoss 5711.3 multi -1.99 import weight 0.00
Epoch 56 Iter 3 subLoss 5422.1 multi 1.00 import weight 0.00
Epoch 56 Iter 4 subLoss 5031.3 multi 1.00 import weight 0.00
Epoch 56 Iter 5 subLoss 5627.5 multi -1.99 import weight 0.00
Epoch 56 Iter 6 subLoss 6319.9 multi 1.00 import weight 0.00
Epoch 56 Iter 7 subLoss 5668.0 multi 1.00 import weight 0.00
Epoch 56 Iter 8 subLoss 5487.9 multi -1.99 import weight 0.00
Epoch 56 Iter 9 subLoss 6013.2 multi 3.99 import weight 0.00
Epoch 56 Iter 10 subLoss 6256.4 multi 1.00 import weight 0.00
Epoch 56 Iter 11 subLoss 5252.4 multi 1.00 import weight 0.00
Epoch 56 Acc: 97.08 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 525 train Loss: 5450.0 test Loss: 498.0
Epoch 57 Iter 0 subLoss 5753.5 multi 1.00 import weight 0.00
Epoch 57 Iter 1 subLoss 5875.9 multi 1.00 import weight 0.00
Epoch 57 Iter 2 subLoss 5370.6 multi 3.99 import weight 0.00
Epoch 57 Iter 3 subLoss 5010.9 multi 1.00 import weight 0.00
Epoch 57 Iter 4 subLoss 5403.3 multi 1.00 import weight 0.00
Epoch 57 Iter 5 subLoss 5121.8 multi 1.00 import weight 0.00
Epoch 57 Iter 6 subLoss 5159.3 multi 1.00 import weight 0.00
Epoch 57 Iter 7 subLoss 5304.3 multi 1.00 import weight 0.00
Epoch 57 Iter 8 subLoss 5127.0 multi 3.99 import weight 0.00
Epoch 57 Iter 9 subLoss 4743.9 multi 1.00 import weight 0.00
Epoch 57 Iter 10 subLoss 5176.9 multi 3.99 import weight 0.00
Epoch 57 Iter 11 subLoss 5372.4 multi 6.97 import weight 1.00
Epoch 57 Acc: 81.18 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 6.97 Pidx 537 train Loss: 18776.0 test Loss: 3623.1
Epoch 58 Iter 0 subLoss 17827.4 multi -1.99 import weight 0.00
Epoch 58 Iter 1 subLoss 331891.0 multi 1.00 import weight 0.00
Epoch 58 Iter 2 subLoss 99153.9 multi 1.00 import weight 0.00
Epoch 58 Iter 3 subLoss 40805.2 multi -1.99 import weight 0.00
Epoch 58 Iter 4 subLoss 107079.0 multi 1.00 import weight 0.00
Epoch 58 Iter 5 subLoss 48360.3 multi 1.00 import weight 0.00
Epoch 58 Iter 6 subLoss 47304.0 multi 1.00 import weight 0.00
Epoch 58 Iter 7 subLoss 45005.5 multi 1.00 import weight 0.00
Epoch 58 Iter 8 subLoss 40757.6 multi 1.00 import weight 0.00
Epoch 58 Iter 9 subLoss 35484.4 multi 3.99 import weight 0.00
Epoch 58 Iter 10 subLoss 35891.3 multi 1.00 import weight 0.00
Epoch 58 Iter 11 subLoss 24794.1 multi 1.00 import weight 0.00
Epoch 58 Acc: 79.55 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2479 train Loss: 22663.4 test Loss: 3153.9
Epoch 59 Iter 0 subLoss 21831.2 multi 6.97 import weight 1.00
Epoch 59 Iter 1 subLoss 17758.6 multi 3.99 import weight 0.00
Epoch 59 Iter 2 subLoss 22512.4 multi 1.00 import weight 0.00
Epoch 59 Iter 3 subLoss 15186.3 multi -1.99 import weight 0.00
Epoch 59 Iter 4 subLoss 18868.3 multi 1.00 import weight 0.00
Epoch 59 Iter 5 subLoss 15830.6 multi 1.00 import weight 0.00
Epoch 59 Iter 6 subLoss 15004.7 multi 1.00 import weight 0.00
Epoch 59 Iter 7 subLoss 13889.4 multi 1.00 import weight 0.00
Epoch 59 Iter 8 subLoss 13528.0 multi 1.00 import weight 0.00
Epoch 59 Iter 9 subLoss 11334.6 multi 1.00 import weight 0.00
Epoch 59 Iter 10 subLoss 11108.7 multi 1.00 import weight 0.00
Epoch 59 Iter 11 subLoss 10855.3 multi 1.00 import weight 0.00
Epoch 59 Acc: 93.66 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1085 train Loss: 10849.0 test Loss: 1190.7
Epoch 60 Iter 0 subLoss 10359.1 multi 1.00 import weight 0.00
Epoch 60 Iter 1 subLoss 9814.2 multi 1.00 import weight 0.00
Epoch 60 Iter 2 subLoss 9984.0 multi 1.00 import weight 0.00
Epoch 60 Iter 3 subLoss 10048.2 multi 1.00 import weight 0.00
Epoch 60 Iter 4 subLoss 9175.5 multi 1.00 import weight 0.00
Epoch 60 Iter 5 subLoss 9186.5 multi -1.99 import weight 0.00
Epoch 60 Iter 6 subLoss 9612.4 multi -1.99 import weight 0.00
Epoch 60 Iter 7 subLoss 9986.2 multi 3.99 import weight 0.00
Epoch 60 Iter 8 subLoss 12006.0 multi 1.00 import weight 0.00
Epoch 60 Iter 9 subLoss 8956.5 multi 1.00 import weight 0.00
Epoch 60 Iter 10 subLoss 8647.6 multi 1.00 import weight 0.00
Epoch 60 Iter 11 subLoss 8485.9 multi -4.97 import weight 0.00
Epoch 60 Acc: 93.70 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 848 train Loss: 11049.8 test Loss: 1173.9
Epoch 61 Iter 0 subLoss 11101.6 multi 3.99 import weight 0.00
Epoch 61 Iter 1 subLoss 30299.8 multi 1.00 import weight 0.00
Epoch 61 Iter 2 subLoss 11145.8 multi 3.99 import weight 0.00
Epoch 61 Iter 3 subLoss 14705.6 multi 1.00 import weight 0.00
Epoch 61 Iter 4 subLoss 8278.8 multi -1.99 import weight 0.00
Epoch 61 Iter 5 subLoss 11951.7 multi 3.99 import weight 0.00
Epoch 61 Iter 6 subLoss 15635.9 multi 1.00 import weight 0.00
Epoch 61 Iter 7 subLoss 8724.1 multi 6.97 import weight 1.00
Epoch 61 Iter 8 subLoss 8695.7 multi 1.00 import weight 0.00
Epoch 61 Iter 9 subLoss 6821.2 multi -1.99 import weight 0.00
Epoch 61 Iter 10 subLoss 7622.3 multi 3.99 import weight 0.00
Epoch 61 Iter 11 subLoss 9331.0 multi 1.00 import weight 0.00
Epoch 61 Acc: 96.69 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 933 train Loss: 6832.9 test Loss: 640.8
Epoch 62 Iter 0 subLoss 6158.9 multi -1.99 import weight 0.00
Epoch 62 Iter 1 subLoss 6899.2 multi -1.99 import weight 0.00
Epoch 62 Iter 2 subLoss 12433.8 multi 1.00 import weight 0.00
Epoch 62 Iter 3 subLoss 7908.2 multi 1.00 import weight 0.00
Epoch 62 Iter 4 subLoss 6970.9 multi 1.00 import weight 0.00
Epoch 62 Iter 5 subLoss 6244.6 multi 1.00 import weight 0.00
Epoch 62 Iter 6 subLoss 6254.8 multi 1.00 import weight 0.00
Epoch 62 Iter 7 subLoss 6198.5 multi 3.99 import weight 0.00
Epoch 62 Iter 8 subLoss 6478.8 multi 1.00 import weight 0.00
Epoch 62 Iter 9 subLoss 6775.3 multi 1.00 import weight 0.00
Epoch 62 Iter 10 subLoss 6660.0 multi -1.99 import weight 0.00
Epoch 62 Iter 11 subLoss 6232.8 multi 1.00 import weight 0.00
Epoch 62 Acc: 96.83 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 623 train Loss: 6312.4 test Loss: 592.1
Epoch 63 Iter 0 subLoss 5771.7 multi 1.00 import weight 0.00
Epoch 63 Iter 1 subLoss 6472.5 multi 3.99 import weight 0.00
Epoch 63 Iter 2 subLoss 6973.8 multi 3.99 import weight 0.00
Epoch 63 Iter 3 subLoss 12483.5 multi -1.99 import weight 0.00
Epoch 63 Iter 4 subLoss 345240.6 multi 1.00 import weight 0.00
Epoch 63 Iter 5 subLoss 48927.6 multi 1.00 import weight 0.00
Epoch 63 Iter 6 subLoss 35192.4 multi 1.00 import weight 0.00
Epoch 63 Iter 7 subLoss 27784.8 multi -1.99 import weight 0.00
Epoch 63 Iter 8 subLoss 29996.7 multi 1.00 import weight 0.00
Epoch 63 Iter 9 subLoss 27768.9 multi 1.00 import weight 0.00
Epoch 63 Iter 10 subLoss 27273.0 multi 1.00 import weight 0.00
Epoch 63 Iter 11 subLoss 28056.1 multi -4.97 import weight 0.00
Epoch 63 Acc: 56.82 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 2805 train Loss: 30235.8 test Loss: 4834.2
Epoch 64 Iter 0 subLoss 29272.5 multi 1.00 import weight 0.00
Epoch 64 Iter 1 subLoss 29225.6 multi 1.00 import weight 0.00
Epoch 64 Iter 2 subLoss 28637.7 multi 1.00 import weight 0.00
Epoch 64 Iter 3 subLoss 27579.7 multi 1.00 import weight 0.00
Epoch 64 Iter 4 subLoss 26747.0 multi 1.00 import weight 0.00
Epoch 64 Iter 5 subLoss 26906.7 multi 1.00 import weight 0.00
Epoch 64 Iter 6 subLoss 26448.8 multi 1.00 import weight 0.00
Epoch 64 Iter 7 subLoss 24940.2 multi 1.00 import weight 0.00
Epoch 64 Iter 8 subLoss 25973.2 multi 1.00 import weight 0.00
Epoch 64 Iter 9 subLoss 24516.4 multi -4.97 import weight 0.00
Epoch 64 Iter 10 subLoss 26804.0 multi 3.99 import weight 0.00
Epoch 64 Iter 11 subLoss 28087.5 multi 1.00 import weight 0.00
Epoch 64 Acc: 65.07 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2808 train Loss: 25622.8 test Loss: 3899.3
Epoch 65 Iter 0 subLoss 25630.1 multi 1.00 import weight 0.00
Epoch 65 Iter 1 subLoss 24762.1 multi 1.00 import weight 0.00
Epoch 65 Iter 2 subLoss 24408.4 multi 1.00 import weight 0.00
Epoch 65 Iter 3 subLoss 23214.2 multi 1.00 import weight 0.00
Epoch 65 Iter 4 subLoss 24114.9 multi 1.00 import weight 0.00
Epoch 65 Iter 5 subLoss 23450.8 multi 1.00 import weight 0.00
Epoch 65 Iter 6 subLoss 22655.0 multi 1.00 import weight 0.00
Epoch 65 Iter 7 subLoss 21856.0 multi 1.00 import weight 0.00
Epoch 65 Iter 8 subLoss 21071.7 multi 1.00 import weight 0.00
Epoch 65 Iter 9 subLoss 22019.9 multi -1.99 import weight 0.00
Epoch 65 Iter 10 subLoss 21887.3 multi 1.00 import weight 0.00
Epoch 65 Iter 11 subLoss 21836.2 multi 9.96 import weight 1.00
Epoch 65 Acc: 77.93 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 9.96 Pidx 2183 train Loss: 20017.3 test Loss: 2767.7
Epoch 66 Iter 0 subLoss 20136.4 multi -1.99 import weight 0.00
Epoch 66 Iter 1 subLoss 21674.3 multi -1.99 import weight 0.00
Epoch 66 Iter 2 subLoss 29053.2 multi 1.00 import weight 0.00
Epoch 66 Iter 3 subLoss 21379.2 multi 1.00 import weight 0.00
Epoch 66 Iter 4 subLoss 19923.6 multi 1.00 import weight 0.00
Epoch 66 Iter 5 subLoss 19429.1 multi 1.00 import weight 0.00
Epoch 66 Iter 6 subLoss 19011.5 multi 1.00 import weight 0.00
Epoch 66 Iter 7 subLoss 18965.5 multi 1.00 import weight 0.00
Epoch 66 Iter 8 subLoss 18244.4 multi 1.00 import weight 0.00
Epoch 66 Iter 9 subLoss 18755.9 multi -1.99 import weight 0.00
Epoch 66 Iter 10 subLoss 18568.5 multi 1.00 import weight 0.00
Epoch 66 Iter 11 subLoss 19001.4 multi 1.00 import weight 0.00
Epoch 66 Acc: 77.64 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1900 train Loss: 18763.2 test Loss: 2624.8
Epoch 67 Iter 0 subLoss 18243.8 multi 3.99 import weight 0.00
Epoch 67 Iter 1 subLoss 17665.9 multi 3.99 import weight 0.00
Epoch 67 Iter 2 subLoss 16679.0 multi 1.00 import weight 0.00
Epoch 67 Iter 3 subLoss 17190.7 multi -1.99 import weight 0.00
Epoch 67 Iter 4 subLoss 16774.3 multi 1.00 import weight 0.00
Epoch 67 Iter 5 subLoss 17596.6 multi 1.00 import weight 0.00
Epoch 67 Iter 6 subLoss 17328.4 multi 3.99 import weight 0.00
Epoch 67 Iter 7 subLoss 16284.6 multi 1.00 import weight 0.00
Epoch 67 Iter 8 subLoss 16927.3 multi -1.99 import weight 0.00
Epoch 67 Iter 9 subLoss 16565.3 multi 3.99 import weight 0.00
Epoch 67 Iter 10 subLoss 16117.0 multi 3.99 import weight 0.00
Epoch 67 Iter 11 subLoss 15069.5 multi 1.00 import weight 0.00
Epoch 67 Acc: 83.58 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1506 train Loss: 16013.1 test Loss: 2138.3
Epoch 68 Iter 0 subLoss 15655.5 multi -1.99 import weight 0.00
Epoch 68 Iter 1 subLoss 15969.8 multi 1.00 import weight 0.00
Epoch 68 Iter 2 subLoss 16021.2 multi 3.99 import weight 0.00
Epoch 68 Iter 3 subLoss 15043.8 multi 1.00 import weight 0.00
Epoch 68 Iter 4 subLoss 15241.0 multi 6.97 import weight 0.00
Epoch 68 Iter 5 subLoss 13835.6 multi 6.97 import weight 0.00
Epoch 68 Iter 6 subLoss 14884.0 multi 3.99 import weight 0.00
Epoch 68 Iter 7 subLoss 14490.9 multi 3.99 import weight 0.00
Epoch 68 Iter 8 subLoss 15175.3 multi 1.00 import weight 0.00
Epoch 68 Iter 9 subLoss 13076.2 multi 1.00 import weight 0.00
Epoch 68 Iter 10 subLoss 13297.2 multi -4.97 import weight 0.00
Epoch 68 Iter 11 subLoss 13978.2 multi 1.00 import weight 0.00
Epoch 68 Acc: 87.86 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1397 train Loss: 13919.8 test Loss: 1851.5
Epoch 69 Iter 0 subLoss 13375.4 multi 1.00 import weight 0.00
Epoch 69 Iter 1 subLoss 13325.4 multi 1.00 import weight 0.00
Epoch 69 Iter 2 subLoss 13797.3 multi 1.00 import weight 0.00
Epoch 69 Iter 3 subLoss 13151.4 multi 3.99 import weight 0.00
Epoch 69 Iter 4 subLoss 13209.5 multi 1.00 import weight 0.00
Epoch 69 Iter 5 subLoss 12558.0 multi 3.99 import weight 0.00
Epoch 69 Iter 6 subLoss 12915.7 multi 1.00 import weight 0.00
Epoch 69 Iter 7 subLoss 12297.1 multi 1.00 import weight 0.00
Epoch 69 Iter 8 subLoss 12813.5 multi -1.99 import weight 0.00
Epoch 69 Iter 9 subLoss 12635.2 multi 1.00 import weight 0.00
Epoch 69 Iter 10 subLoss 12551.0 multi 6.97 import weight 0.00
Epoch 69 Iter 11 subLoss 11816.8 multi 1.00 import weight 0.00
Epoch 69 Acc: 91.38 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1181 train Loss: 12258.2 test Loss: 1546.0
Epoch 70 Iter 0 subLoss 11979.1 multi -1.99 import weight 0.00
Epoch 70 Iter 1 subLoss 11908.2 multi 1.00 import weight 0.00
Epoch 70 Iter 2 subLoss 11556.4 multi -1.99 import weight 0.00
Epoch 70 Iter 3 subLoss 12508.5 multi 1.00 import weight 0.00
Epoch 70 Iter 4 subLoss 12108.8 multi -1.99 import weight 0.00
Epoch 70 Iter 5 subLoss 12357.9 multi 3.99 import weight 0.00
Epoch 70 Iter 6 subLoss 12121.7 multi 1.00 import weight 0.00
Epoch 70 Iter 7 subLoss 12230.2 multi 1.00 import weight 0.00
Epoch 70 Iter 8 subLoss 11924.8 multi 3.99 import weight 0.00
Epoch 70 Iter 9 subLoss 11994.5 multi 1.00 import weight 0.00
Epoch 70 Iter 10 subLoss 11038.4 multi 1.00 import weight 0.00
Epoch 70 Iter 11 subLoss 10862.1 multi -1.99 import weight 0.00
Epoch 70 Acc: 92.70 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 1086 train Loss: 11586.3 test Loss: 1455.8
Epoch 71 Iter 0 subLoss 11017.7 multi 1.00 import weight 0.00
Epoch 71 Iter 1 subLoss 11088.7 multi 1.00 import weight 0.00
Epoch 71 Iter 2 subLoss 11295.5 multi 3.99 import weight 0.00
Epoch 71 Iter 3 subLoss 10606.7 multi 1.00 import weight 0.00
Epoch 71 Iter 4 subLoss 10485.8 multi 6.97 import weight 0.00
Epoch 71 Iter 5 subLoss 9735.0 multi 1.00 import weight 0.00
Epoch 71 Iter 6 subLoss 8493.8 multi -1.99 import weight 0.00
Epoch 71 Iter 7 subLoss 9087.7 multi 1.00 import weight 0.00
Epoch 71 Iter 8 subLoss 9480.5 multi 1.00 import weight 0.00
Epoch 71 Iter 9 subLoss 8774.8 multi 1.00 import weight 0.00
Epoch 71 Iter 10 subLoss 8139.2 multi 3.99 import weight 0.00
Epoch 71 Iter 11 subLoss 7629.9 multi 6.97 import weight 0.00
Epoch 71 Acc: 96.61 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 762 train Loss: 7189.6 test Loss: 669.4
Epoch 72 Iter 0 subLoss 6733.5 multi 3.99 import weight 0.00
Epoch 72 Iter 1 subLoss 6570.9 multi -1.99 import weight 0.00
Epoch 72 Iter 2 subLoss 7945.5 multi 1.00 import weight 0.00
Epoch 72 Iter 3 subLoss 7413.3 multi 1.00 import weight 0.00
Epoch 72 Iter 4 subLoss 6253.6 multi 3.98 import weight 0.00
Epoch 72 Iter 5 subLoss 6756.9 multi 3.99 import weight 0.00
Epoch 72 Iter 6 subLoss 6676.6 multi 1.00 import weight 0.00
Epoch 72 Iter 7 subLoss 5777.2 multi 3.99 import weight 0.00
Epoch 72 Iter 8 subLoss 5622.2 multi 1.00 import weight 0.00
Epoch 72 Iter 9 subLoss 5340.6 multi 1.00 import weight 0.00
Epoch 72 Iter 10 subLoss 5288.1 multi 1.00 import weight 0.00
Epoch 72 Iter 11 subLoss 5764.7 multi -1.99 import weight 0.00
Epoch 72 Acc: 97.22 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 576 train Loss: 5748.6 test Loss: 529.5
Epoch 73 Iter 0 subLoss 6233.6 multi 3.99 import weight 0.00
Epoch 73 Iter 1 subLoss 5706.9 multi 1.00 import weight 0.00
Epoch 73 Iter 2 subLoss 5761.4 multi 1.00 import weight 0.00
Epoch 73 Iter 3 subLoss 5684.9 multi 1.00 import weight 0.00
Epoch 73 Iter 4 subLoss 4753.5 multi -1.99 import weight 0.00
Epoch 73 Iter 5 subLoss 5489.3 multi 1.00 import weight 0.00
Epoch 73 Iter 6 subLoss 5102.7 multi 3.99 import weight 0.00
Epoch 73 Iter 7 subLoss 4810.0 multi 1.00 import weight 0.00
Epoch 73 Iter 8 subLoss 5109.8 multi 6.97 import weight 0.00
Epoch 73 Iter 9 subLoss 5581.2 multi 1.00 import weight 0.00
Epoch 73 Iter 10 subLoss 5292.9 multi -1.99 import weight 0.00
Epoch 73 Iter 11 subLoss 5812.8 multi -1.99 import weight 0.00
Epoch 73 Acc: 95.43 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 581 train Loss: 7531.0 test Loss: 737.3
Epoch 74 Iter 0 subLoss 7177.8 multi 6.97 import weight 0.00
Epoch 74 Iter 1 subLoss 45696.9 multi 1.00 import weight 0.00
Epoch 74 Iter 2 subLoss 9275.4 multi 3.99 import weight 0.00
Epoch 74 Iter 3 subLoss 9093.0 multi 1.00 import weight 0.00
Epoch 74 Iter 4 subLoss 6059.3 multi 1.00 import weight 0.00
Epoch 74 Iter 5 subLoss 6302.5 multi 1.00 import weight 0.00
Epoch 74 Iter 6 subLoss 5804.1 multi 1.00 import weight 0.00
Epoch 74 Iter 7 subLoss 6247.5 multi -1.98 import weight 0.00
Epoch 74 Iter 8 subLoss 6273.8 multi 3.99 import weight 0.00
Epoch 74 Iter 9 subLoss 5657.8 multi 1.00 import weight 0.00
Epoch 74 Iter 10 subLoss 5600.2 multi 1.00 import weight 0.00
Epoch 74 Iter 11 subLoss 5511.4 multi 1.00 import weight 0.00
Epoch 74 Acc: 97.12 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 551 train Loss: 5325.9 test Loss: 534.7
Epoch 75 Iter 0 subLoss 5250.8 multi 3.99 import weight 0.00
Epoch 75 Iter 1 subLoss 5226.5 multi 1.00 import weight 0.00
Epoch 75 Iter 2 subLoss 4815.7 multi -1.99 import weight 0.00
Epoch 75 Iter 3 subLoss 5080.1 multi 1.00 import weight 0.00
Epoch 75 Iter 4 subLoss 5348.2 multi 3.99 import weight 0.00
Epoch 75 Iter 5 subLoss 5944.6 multi 1.00 import weight 0.00
Epoch 75 Iter 6 subLoss 5065.5 multi 1.00 import weight 0.00
Epoch 75 Iter 7 subLoss 4486.6 multi 1.00 import weight 0.00
Epoch 75 Iter 8 subLoss 4556.7 multi 1.00 import weight 0.00
Epoch 75 Iter 9 subLoss 4985.0 multi 1.00 import weight 0.00
Epoch 75 Iter 10 subLoss 5290.3 multi 1.00 import weight 0.00
Epoch 75 Iter 11 subLoss 4515.6 multi 1.00 import weight 0.00
Epoch 75 Acc: 97.14 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 451 train Loss: 5030.5 test Loss: 483.1
Epoch 76 Iter 0 subLoss 5158.2 multi 3.99 import weight 0.00
Epoch 76 Iter 1 subLoss 4903.3 multi 1.00 import weight 0.00
Epoch 76 Iter 2 subLoss 4910.9 multi -1.99 import weight 0.00
Epoch 76 Iter 3 subLoss 5011.6 multi 3.99 import weight 0.00
Epoch 76 Iter 4 subLoss 5564.3 multi 1.00 import weight 0.00
Epoch 76 Iter 5 subLoss 5096.7 multi -1.99 import weight 0.00
Epoch 76 Iter 6 subLoss 5151.8 multi 6.97 import weight 0.00
Epoch 76 Iter 7 subLoss 7520.3 multi 1.00 import weight 0.00
Epoch 76 Iter 8 subLoss 5157.3 multi 9.96 import weight 1.00
Epoch 76 Iter 9 subLoss 7186.0 multi -4.97 import weight 0.00
Epoch 76 Iter 10 subLoss 254803.5 multi 1.00 import weight 0.00
Epoch 76 Iter 11 subLoss 63734.4 multi 1.00 import weight 0.00
Epoch 76 Acc: 33.57 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 6373 train Loss: 42478.4 test Loss: 7442.3
Epoch 77 Iter 0 subLoss 42530.6 multi 1.00 import weight 0.00
Epoch 77 Iter 1 subLoss 32029.8 multi 1.00 import weight 0.00
Epoch 77 Iter 2 subLoss 28173.0 multi 1.00 import weight 0.00
Epoch 77 Iter 3 subLoss 25742.7 multi 1.00 import weight 0.00
Epoch 77 Iter 4 subLoss 25957.4 multi 3.99 import weight 0.00
Epoch 77 Iter 5 subLoss 22508.5 multi 1.00 import weight 0.00
Epoch 77 Iter 6 subLoss 22316.3 multi 1.00 import weight 0.00
Epoch 77 Iter 7 subLoss 21411.0 multi 1.00 import weight 0.00
Epoch 77 Iter 8 subLoss 21207.2 multi 1.00 import weight 0.00
Epoch 77 Iter 9 subLoss 20095.0 multi -1.99 import weight 0.00
Epoch 77 Iter 10 subLoss 20938.1 multi 1.00 import weight 0.00
Epoch 77 Iter 11 subLoss 20405.2 multi 1.00 import weight 0.00
Epoch 77 Acc: 75.89 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2040 train Loss: 20737.7 test Loss: 3417.1
Epoch 78 Iter 0 subLoss 19578.1 multi 1.00 import weight 0.00
Epoch 78 Iter 1 subLoss 19837.4 multi 1.00 import weight 0.00
Epoch 78 Iter 2 subLoss 20554.6 multi 1.00 import weight 0.00
Epoch 78 Iter 3 subLoss 19212.3 multi 1.00 import weight 0.00
Epoch 78 Iter 4 subLoss 18523.4 multi 1.00 import weight 0.00
Epoch 78 Iter 5 subLoss 18751.2 multi 1.00 import weight 0.00
Epoch 78 Iter 6 subLoss 17470.7 multi 1.00 import weight 0.00
Epoch 78 Iter 7 subLoss 17095.1 multi 1.00 import weight 0.00
Epoch 78 Iter 8 subLoss 16479.4 multi 1.00 import weight 0.00
Epoch 78 Iter 9 subLoss 16383.3 multi 1.00 import weight 0.00
Epoch 78 Iter 10 subLoss 15544.8 multi 3.99 import weight 0.00
Epoch 78 Iter 11 subLoss 14644.1 multi 3.99 import weight 0.00
Epoch 78 Acc: 76.42 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 1464 train Loss: 16770.0 test Loss: 2942.3
Epoch 79 Iter 0 subLoss 15983.0 multi 3.99 import weight 0.00
Epoch 79 Iter 1 subLoss 107082.7 multi -1.99 import weight 0.00
Epoch 79 Iter 2 subLoss 4159554.2 multi 1.00 import weight 0.00
Epoch 79 Iter 3 subLoss 52635.3 multi 1.00 import weight 0.00
Epoch 79 Iter 4 subLoss 52096.0 multi 1.00 import weight 0.00
Epoch 79 Iter 5 subLoss 51900.4 multi 1.00 import weight 0.00
Epoch 79 Iter 6 subLoss 51589.4 multi 1.00 import weight 0.00
Epoch 79 Iter 7 subLoss 51226.6 multi 1.00 import weight 0.00
Epoch 79 Iter 8 subLoss 50701.5 multi 1.00 import weight 0.00
Epoch 79 Iter 9 subLoss 50879.3 multi 1.00 import weight 0.00
Epoch 79 Iter 10 subLoss 50080.8 multi 1.00 import weight 0.00
Epoch 79 Iter 11 subLoss 50200.8 multi 1.00 import weight 0.00
Epoch 79 Acc: 19.65 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 5020 train Loss: 51139.8 test Loss: 8472.9
Epoch 80 Iter 0 subLoss 49566.8 multi 1.00 import weight 0.00
Epoch 80 Iter 1 subLoss 49862.3 multi 1.00 import weight 0.00
Epoch 80 Iter 2 subLoss 50568.1 multi 1.00 import weight 0.00
Epoch 80 Iter 3 subLoss 49230.2 multi 1.00 import weight 0.00
Epoch 80 Iter 4 subLoss 49470.6 multi 1.00 import weight 0.00
Epoch 80 Iter 5 subLoss 48875.9 multi 1.00 import weight 0.00
Epoch 80 Iter 6 subLoss 49298.6 multi 1.00 import weight 0.00
Epoch 80 Iter 7 subLoss 49700.1 multi 1.00 import weight 0.00
Epoch 80 Iter 8 subLoss 49484.2 multi -1.99 import weight 0.00
Epoch 80 Iter 9 subLoss 50504.1 multi 1.00 import weight 0.00
Epoch 80 Iter 10 subLoss 50312.9 multi 1.00 import weight 0.00
Epoch 80 Iter 11 subLoss 49550.6 multi 1.00 import weight 0.00
Epoch 80 Acc: 19.65 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4955 train Loss: 50471.8 test Loss: 8379.7
Epoch 81 Iter 0 subLoss 49479.8 multi 3.99 import weight 0.00
Epoch 81 Iter 1 subLoss 48930.9 multi -1.99 import weight 0.00
Epoch 81 Iter 2 subLoss 49710.0 multi 3.99 import weight 0.00
Epoch 81 Iter 3 subLoss 49689.9 multi 1.00 import weight 0.00
Epoch 81 Iter 4 subLoss 49196.5 multi 1.00 import weight 0.00
Epoch 81 Iter 5 subLoss 49292.2 multi 3.99 import weight 0.00
Epoch 81 Iter 6 subLoss 47192.5 multi -1.99 import weight 0.00
Epoch 81 Iter 7 subLoss 50078.1 multi 1.00 import weight 0.00
Epoch 81 Iter 8 subLoss 49022.2 multi 1.00 import weight 0.00
Epoch 81 Iter 9 subLoss 48358.9 multi 1.00 import weight 0.00
Epoch 81 Iter 10 subLoss 48484.1 multi 1.00 import weight 0.00
Epoch 81 Iter 11 subLoss 47135.4 multi 1.00 import weight 0.00
Epoch 81 Acc: 19.65 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4713 train Loss: 48235.7 test Loss: 7896.8
Epoch 82 Iter 0 subLoss 47329.3 multi 1.00 import weight 0.00
Epoch 82 Iter 1 subLoss 46703.2 multi 1.00 import weight 0.00
Epoch 82 Iter 2 subLoss 46508.8 multi 1.00 import weight 0.00
Epoch 82 Iter 3 subLoss 45688.1 multi 1.00 import weight 0.00
Epoch 82 Iter 4 subLoss 45167.8 multi 1.00 import weight 0.00
Epoch 82 Iter 5 subLoss 46014.5 multi 1.00 import weight 0.00
Epoch 82 Iter 6 subLoss 45616.9 multi 1.00 import weight 0.00
Epoch 82 Iter 7 subLoss 47242.7 multi 1.00 import weight 0.00
Epoch 82 Iter 8 subLoss 46619.9 multi 1.00 import weight 0.00
Epoch 82 Iter 9 subLoss 45291.9 multi 1.00 import weight 0.00
Epoch 82 Iter 10 subLoss 43673.9 multi 1.00 import weight 0.00
Epoch 82 Iter 11 subLoss 43933.8 multi 1.00 import weight 0.00
Epoch 82 Acc: 19.67 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4393 train Loss: 45742.0 test Loss: 7261.1
Epoch 83 Iter 0 subLoss 44836.0 multi 1.00 import weight 0.00
Epoch 83 Iter 1 subLoss 42654.7 multi 1.00 import weight 0.00
Epoch 83 Iter 2 subLoss 43221.1 multi 1.00 import weight 0.00
Epoch 83 Iter 3 subLoss 44737.0 multi 1.00 import weight 0.00
Epoch 83 Iter 4 subLoss 42210.9 multi 1.00 import weight 0.00
Epoch 83 Iter 5 subLoss 43538.7 multi -1.99 import weight 0.00
Epoch 83 Iter 6 subLoss 853260.3 multi 1.00 import weight 0.00
Epoch 83 Iter 7 subLoss 48885.0 multi -1.99 import weight 0.00
Epoch 83 Iter 8 subLoss 49770.6 multi 3.99 import weight 0.00
Epoch 83 Iter 9 subLoss 48822.9 multi 1.00 import weight 0.00
Epoch 83 Iter 10 subLoss 48542.9 multi 1.00 import weight 0.00
Epoch 83 Iter 11 subLoss 48463.3 multi 1.00 import weight 0.00
Epoch 83 Acc: 19.58 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4846 train Loss: 48945.6 test Loss: 8150.8
Epoch 84 Iter 0 subLoss 48314.4 multi 1.00 import weight 0.00
Epoch 84 Iter 1 subLoss 47458.8 multi 1.00 import weight 0.00
Epoch 84 Iter 2 subLoss 47378.9 multi -1.99 import weight 0.00
Epoch 84 Iter 3 subLoss 47992.1 multi 1.00 import weight 0.00
Epoch 84 Iter 4 subLoss 47671.3 multi -1.99 import weight 0.00
Epoch 84 Iter 5 subLoss 47940.7 multi 1.00 import weight 0.00
Epoch 84 Iter 6 subLoss 48068.9 multi 1.00 import weight 0.00
Epoch 84 Iter 7 subLoss 47730.9 multi 1.00 import weight 0.00
Epoch 84 Iter 8 subLoss 47420.4 multi 1.00 import weight 0.00
Epoch 84 Iter 9 subLoss 47414.9 multi 1.00 import weight 0.00
Epoch 84 Iter 10 subLoss 47006.7 multi 1.00 import weight 0.00
Epoch 84 Iter 11 subLoss 47394.0 multi 1.00 import weight 0.00
Epoch 84 Acc: 22.38 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4739 train Loss: 47715.1 test Loss: 7817.7
Epoch 85 Iter 0 subLoss 46849.9 multi 1.00 import weight 0.00
Epoch 85 Iter 1 subLoss 46909.5 multi 1.00 import weight 0.00
Epoch 85 Iter 2 subLoss 46416.9 multi 1.00 import weight 0.00
Epoch 85 Iter 3 subLoss 46602.1 multi 1.00 import weight 0.00
Epoch 85 Iter 4 subLoss 45981.5 multi 1.00 import weight 0.00
Epoch 85 Iter 5 subLoss 45777.4 multi 1.00 import weight 0.00
Epoch 85 Iter 6 subLoss 45341.8 multi 1.00 import weight 0.00
Epoch 85 Iter 7 subLoss 45620.7 multi -1.99 import weight 0.00
Epoch 85 Iter 8 subLoss 46351.6 multi 1.00 import weight 0.00
Epoch 85 Iter 9 subLoss 45723.5 multi 1.00 import weight 0.00
Epoch 85 Iter 10 subLoss 45779.9 multi 3.99 import weight 0.00
Epoch 85 Iter 11 subLoss 44567.3 multi 1.00 import weight 0.00
Epoch 85 Acc: 37.98 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4456 train Loss: 45161.4 test Loss: 7326.6
Epoch 86 Iter 0 subLoss 43919.8 multi 1.00 import weight 0.00
Epoch 86 Iter 1 subLoss 43577.2 multi 1.00 import weight 0.00
Epoch 86 Iter 2 subLoss 43574.8 multi 3.99 import weight 0.00
Epoch 86 Iter 3 subLoss 42954.3 multi 1.00 import weight 0.00
Epoch 86 Iter 4 subLoss 43431.9 multi 1.00 import weight 0.00
Epoch 86 Iter 5 subLoss 40982.1 multi 1.00 import weight 0.00
Epoch 86 Iter 6 subLoss 40340.8 multi 1.00 import weight 0.00
Epoch 86 Iter 7 subLoss 39677.6 multi 1.00 import weight 0.00
Epoch 86 Iter 8 subLoss 40027.9 multi 1.00 import weight 0.00
Epoch 86 Iter 9 subLoss 40172.3 multi 1.00 import weight 0.00
Epoch 86 Iter 10 subLoss 41645.2 multi 1.00 import weight 0.00
Epoch 86 Iter 11 subLoss 39130.4 multi 1.00 import weight 0.00
Epoch 86 Acc: 60.17 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 3913 train Loss: 38792.0 test Loss: 5814.7
Epoch 87 Iter 0 subLoss 37379.1 multi 1.00 import weight 0.00
Epoch 87 Iter 1 subLoss 37038.9 multi 1.00 import weight 0.00
Epoch 87 Iter 2 subLoss 35998.0 multi 3.99 import weight 0.00
Epoch 87 Iter 3 subLoss 34227.2 multi 1.00 import weight 0.00
Epoch 87 Iter 4 subLoss 38718.0 multi 3.99 import weight 0.00
Epoch 87 Iter 5 subLoss 115592.3 multi 1.00 import weight 0.00
Epoch 87 Iter 6 subLoss 47529.5 multi 1.00 import weight 0.00
Epoch 87 Iter 7 subLoss 46273.0 multi 1.00 import weight 0.00
Epoch 87 Iter 8 subLoss 45102.5 multi -1.99 import weight 0.00
Epoch 87 Iter 9 subLoss 46846.8 multi 3.99 import weight 0.00
Epoch 87 Iter 10 subLoss 44351.6 multi 1.00 import weight 0.00
Epoch 87 Iter 11 subLoss 43292.0 multi 1.00 import weight 0.00
Epoch 87 Acc: 47.19 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4329 train Loss: 43596.9 test Loss: 7180.9
Epoch 88 Iter 0 subLoss 42440.6 multi 1.00 import weight 0.00
Epoch 88 Iter 1 subLoss 41904.4 multi 1.00 import weight 0.00
Epoch 88 Iter 2 subLoss 41047.5 multi 1.00 import weight 0.00
Epoch 88 Iter 3 subLoss 40208.4 multi 1.00 import weight 0.00
Epoch 88 Iter 4 subLoss 40100.3 multi -1.99 import weight 0.00
Epoch 88 Iter 5 subLoss 45177.2 multi -1.99 import weight 0.00
Epoch 88 Iter 6 subLoss 439010.9 multi 1.00 import weight 0.00
Epoch 88 Iter 7 subLoss 48621.6 multi 1.00 import weight 0.00
Epoch 88 Iter 8 subLoss 47911.0 multi 1.00 import weight 0.00
Epoch 88 Iter 9 subLoss 47685.1 multi -1.99 import weight 0.00
Epoch 88 Iter 10 subLoss 48465.6 multi 3.99 import weight 0.00
Epoch 88 Iter 11 subLoss 46440.7 multi 1.00 import weight 0.00
Epoch 88 Acc: 30.53 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4644 train Loss: 47315.3 test Loss: 7775.8
Epoch 89 Iter 0 subLoss 46504.8 multi 3.99 import weight 0.00
Epoch 89 Iter 1 subLoss 44864.3 multi 1.00 import weight 0.00
Epoch 89 Iter 2 subLoss 44422.1 multi 1.00 import weight 0.00
Epoch 89 Iter 3 subLoss 43655.8 multi 1.00 import weight 0.00
Epoch 89 Iter 4 subLoss 43131.4 multi -1.99 import weight 0.00
Epoch 89 Iter 5 subLoss 43677.8 multi 3.99 import weight 0.00
Epoch 89 Iter 6 subLoss 42499.6 multi 1.00 import weight 0.00
Epoch 89 Iter 7 subLoss 42395.8 multi -1.99 import weight 0.00
Epoch 89 Iter 8 subLoss 43246.2 multi -1.99 import weight 0.00
Epoch 89 Iter 9 subLoss 44102.1 multi 1.00 import weight 0.00
Epoch 89 Iter 10 subLoss 43655.7 multi 3.99 import weight 0.00
Epoch 89 Iter 11 subLoss 42199.4 multi 1.00 import weight 0.00
Epoch 89 Acc: 47.27 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4219 train Loss: 42642.4 test Loss: 6705.3
Epoch 90 Iter 0 subLoss 41663.6 multi -1.99 import weight 0.00
Epoch 90 Iter 1 subLoss 42648.9 multi 1.00 import weight 0.00
Epoch 90 Iter 2 subLoss 42202.4 multi -1.99 import weight 0.00
Epoch 90 Iter 3 subLoss 43017.6 multi 1.00 import weight 0.00
Epoch 90 Iter 4 subLoss 42442.8 multi 3.99 import weight 0.00
Epoch 90 Iter 5 subLoss 41455.1 multi 1.00 import weight 0.00
Epoch 90 Iter 6 subLoss 41310.5 multi 1.00 import weight 0.00
Epoch 90 Iter 7 subLoss 40549.0 multi 1.00 import weight 0.00
Epoch 90 Iter 8 subLoss 40213.1 multi -1.99 import weight 0.00
Epoch 90 Iter 9 subLoss 40947.1 multi 3.99 import weight 0.00
Epoch 90 Iter 10 subLoss 39410.3 multi 1.00 import weight 0.00
Epoch 90 Iter 11 subLoss 39365.0 multi -1.99 import weight 0.00
Epoch 90 Acc: 52.46 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 3936 train Loss: 40883.4 test Loss: 6411.6
Epoch 91 Iter 0 subLoss 40794.1 multi 3.99 import weight 0.00
Epoch 91 Iter 1 subLoss 39513.8 multi 1.00 import weight 0.00
Epoch 91 Iter 2 subLoss 38980.2 multi 1.00 import weight 0.00
Epoch 91 Iter 3 subLoss 37915.0 multi 1.00 import weight 0.00
Epoch 91 Iter 4 subLoss 37653.8 multi 1.00 import weight 0.00
Epoch 91 Iter 5 subLoss 37374.7 multi 3.99 import weight 0.00
Epoch 91 Iter 6 subLoss 36210.1 multi 1.00 import weight 0.00
Epoch 91 Iter 7 subLoss 35314.2 multi 1.00 import weight 0.00
Epoch 91 Iter 8 subLoss 35050.4 multi 1.00 import weight 0.00
Epoch 91 Iter 9 subLoss 34561.9 multi -1.99 import weight 0.00
Epoch 91 Iter 10 subLoss 35500.9 multi 1.00 import weight 0.00
Epoch 91 Iter 11 subLoss 35046.9 multi -1.99 import weight 0.00
Epoch 91 Acc: 69.84 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 3504 train Loss: 36587.5 test Loss: 5348.5
Epoch 92 Iter 0 subLoss 35787.3 multi 1.00 import weight 0.00
Epoch 92 Iter 1 subLoss 35750.9 multi 1.00 import weight 0.00
Epoch 92 Iter 2 subLoss 35182.8 multi 1.00 import weight 0.00
Epoch 92 Iter 3 subLoss 34506.4 multi 3.99 import weight 0.00
Epoch 92 Iter 4 subLoss 33589.6 multi 1.00 import weight 0.00
Epoch 92 Iter 5 subLoss 32827.5 multi 1.00 import weight 0.00
Epoch 92 Iter 6 subLoss 32635.5 multi 1.00 import weight 0.00
Epoch 92 Iter 7 subLoss 31836.9 multi -1.99 import weight 0.00
Epoch 92 Iter 8 subLoss 33209.4 multi 1.00 import weight 0.00
Epoch 92 Iter 9 subLoss 32398.6 multi 3.99 import weight 0.00
Epoch 92 Iter 10 subLoss 31098.5 multi 1.00 import weight 0.00
Epoch 92 Iter 11 subLoss 30744.3 multi 1.00 import weight 0.00
Epoch 92 Acc: 83.17 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 3074 train Loss: 30680.9 test Loss: 3982.9
Epoch 93 Iter 0 subLoss 30611.9 multi 1.00 import weight 0.00
Epoch 93 Iter 1 subLoss 29793.9 multi 1.00 import weight 0.00
Epoch 93 Iter 2 subLoss 29026.3 multi 1.00 import weight 0.00
Epoch 93 Iter 3 subLoss 28760.6 multi 1.00 import weight 0.00
Epoch 93 Iter 4 subLoss 27822.8 multi 1.00 import weight 0.00
Epoch 93 Iter 5 subLoss 28028.3 multi -1.99 import weight 0.00
Epoch 93 Iter 6 subLoss 29389.7 multi 1.00 import weight 0.00
Epoch 93 Iter 7 subLoss 29012.1 multi 1.00 import weight 0.00
Epoch 93 Iter 8 subLoss 29044.6 multi 1.00 import weight 0.00
Epoch 93 Iter 9 subLoss 27573.7 multi 3.99 import weight 0.00
Epoch 93 Iter 10 subLoss 36373.2 multi 1.00 import weight 0.00
Epoch 93 Iter 11 subLoss 30613.2 multi 3.99 import weight 0.00
Epoch 93 Acc: 78.58 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 3061 train Loss: 31519.8 test Loss: 4212.6
Epoch 94 Iter 0 subLoss 29636.3 multi 1.00 import weight 0.00
Epoch 94 Iter 1 subLoss 26501.3 multi 1.00 import weight 0.00
Epoch 94 Iter 2 subLoss 25334.3 multi 1.00 import weight 0.00
Epoch 94 Iter 3 subLoss 24491.0 multi 1.00 import weight 0.00
Epoch 94 Iter 4 subLoss 23805.6 multi -1.99 import weight 0.00
Epoch 94 Iter 5 subLoss 25049.0 multi 1.00 import weight 0.00
Epoch 94 Iter 6 subLoss 23671.9 multi 1.00 import weight 0.00
Epoch 94 Iter 7 subLoss 23300.3 multi 1.00 import weight 0.00
Epoch 94 Iter 8 subLoss 24097.4 multi 1.00 import weight 0.00
Epoch 94 Iter 9 subLoss 23350.1 multi 1.00 import weight 0.00
Epoch 94 Iter 10 subLoss 22543.1 multi 6.97 import weight 0.00
Epoch 94 Iter 11 subLoss 29318.2 multi 1.00 import weight 0.00
Epoch 94 Acc: 65.19 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2931 train Loss: 34122.7 test Loss: 5123.5
Epoch 95 Iter 0 subLoss 33254.6 multi 1.00 import weight 0.00
Epoch 95 Iter 1 subLoss 23378.5 multi 1.00 import weight 0.00
Epoch 95 Iter 2 subLoss 21537.0 multi 3.99 import weight 0.00
Epoch 95 Iter 3 subLoss 26128.6 multi 1.00 import weight 0.00
Epoch 95 Iter 4 subLoss 33369.7 multi 1.00 import weight 0.00
Epoch 95 Iter 5 subLoss 26040.0 multi 1.00 import weight 0.00
Epoch 95 Iter 6 subLoss 21432.9 multi -1.99 import weight 0.00
Epoch 95 Iter 7 subLoss 27299.1 multi 1.00 import weight 0.00
Epoch 95 Iter 8 subLoss 22215.2 multi -1.99 import weight 0.00
Epoch 95 Iter 9 subLoss 28512.2 multi 1.00 import weight 0.00
Epoch 95 Iter 10 subLoss 24889.7 multi -1.99 import weight 0.00
Epoch 95 Iter 11 subLoss 29309.6 multi 1.00 import weight 0.00
Epoch 95 Acc: 71.75 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2930 train Loss: 27560.7 test Loss: 3908.9
Epoch 96 Iter 0 subLoss 27026.0 multi 1.00 import weight 0.00
Epoch 96 Iter 1 subLoss 24864.6 multi 1.00 import weight 0.00
Epoch 96 Iter 2 subLoss 23134.6 multi 1.00 import weight 0.00
Epoch 96 Iter 3 subLoss 21613.2 multi 1.00 import weight 0.00
Epoch 96 Iter 4 subLoss 21478.4 multi 1.00 import weight 0.00
Epoch 96 Iter 5 subLoss 19440.6 multi 1.00 import weight 0.00
Epoch 96 Iter 6 subLoss 19193.8 multi 1.00 import weight 0.00
Epoch 96 Iter 7 subLoss 19246.6 multi 3.99 import weight 0.00
Epoch 96 Iter 8 subLoss 18137.5 multi 1.00 import weight 0.00
Epoch 96 Iter 9 subLoss 19525.7 multi 1.00 import weight 0.00
Epoch 96 Iter 10 subLoss 24421.2 multi 3.99 import weight 0.00
Epoch 96 Iter 11 subLoss 141514.8 multi 1.00 import weight 0.00
Epoch 96 Acc: 22.12 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 14151 train Loss: 64097.7 test Loss: 10961.0
Epoch 97 Iter 0 subLoss 62725.5 multi 1.00 import weight 0.00
Epoch 97 Iter 1 subLoss 52319.6 multi 1.00 import weight 0.00
Epoch 97 Iter 2 subLoss 40533.2 multi 1.00 import weight 0.00
Epoch 97 Iter 3 subLoss 34247.9 multi -1.99 import weight 0.00
Epoch 97 Iter 4 subLoss 39315.1 multi 1.00 import weight 0.00
Epoch 97 Iter 5 subLoss 36626.4 multi 1.00 import weight 0.00
Epoch 97 Iter 6 subLoss 35476.3 multi -1.99 import weight 0.00
Epoch 97 Iter 7 subLoss 39882.3 multi 1.00 import weight 0.00
Epoch 97 Iter 8 subLoss 36668.9 multi 1.00 import weight 0.00
Epoch 97 Iter 9 subLoss 34907.5 multi -1.99 import weight 0.00
Epoch 97 Iter 10 subLoss 38255.5 multi 1.00 import weight 0.00
Epoch 97 Iter 11 subLoss 37640.0 multi 1.00 import weight 0.00
Epoch 97 Acc: 58.32 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 3764 train Loss: 36927.5 test Loss: 5293.0
Epoch 98 Iter 0 subLoss 35935.6 multi 1.00 import weight 0.00
Epoch 98 Iter 1 subLoss 35672.5 multi 1.00 import weight 0.00
Epoch 98 Iter 2 subLoss 33545.5 multi 1.00 import weight 0.00
Epoch 98 Iter 3 subLoss 32351.3 multi 1.00 import weight 0.00
Epoch 98 Iter 4 subLoss 31021.8 multi 1.00 import weight 0.00
Epoch 98 Iter 5 subLoss 29395.8 multi -1.99 import weight 0.00
Epoch 98 Iter 6 subLoss 32265.2 multi 1.00 import weight 0.00
Epoch 98 Iter 7 subLoss 30916.8 multi 1.00 import weight 0.00
Epoch 98 Iter 8 subLoss 29348.1 multi 1.00 import weight 0.00
Epoch 98 Iter 9 subLoss 27982.4 multi 1.00 import weight 0.00
Epoch 98 Iter 10 subLoss 27048.6 multi 1.00 import weight 0.00
Epoch 98 Iter 11 subLoss 26057.0 multi -1.99 import weight 0.00
Epoch 98 Acc: 81.73 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 2605 train Loss: 28521.0 test Loss: 3703.2
Epoch 99 Iter 0 subLoss 28100.4 multi 1.00 import weight 0.00
Epoch 99 Iter 1 subLoss 27009.5 multi 1.00 import weight 0.00
Epoch 99 Iter 2 subLoss 26034.7 multi -1.99 import weight 0.00
Epoch 99 Iter 3 subLoss 27453.1 multi -1.99 import weight 0.00
Epoch 99 Iter 4 subLoss 29875.7 multi 1.00 import weight 0.00
Epoch 99 Iter 5 subLoss 27974.8 multi 1.00 import weight 0.00
Epoch 99 Iter 6 subLoss 28398.4 multi -1.99 import weight 0.00
Epoch 99 Iter 7 subLoss 29818.4 multi 1.00 import weight 0.00
Epoch 99 Iter 8 subLoss 28354.1 multi 1.00 import weight 0.00
Epoch 99 Iter 9 subLoss 27611.6 multi 1.00 import weight 0.00
Epoch 99 Iter 10 subLoss 26589.1 multi 1.00 import weight 0.00
Epoch 99 Iter 11 subLoss 26109.6 multi 1.00 import weight 0.00
Epoch 99 Acc: 84.45 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2610 train Loss: 26010.1 test Loss: 3216.7
Epoch 100 Iter 0 subLoss 25496.8 multi 1.00 import weight 0.00
Epoch 100 Iter 1 subLoss 25368.7 multi 1.00 import weight 0.00
Epoch 100 Iter 2 subLoss 24538.3 multi 1.00 import weight 0.00
Epoch 100 Iter 3 subLoss 24293.5 multi 1.00 import weight 0.00
Epoch 100 Iter 4 subLoss 24222.9 multi 3.99 import weight 0.00
Epoch 100 Iter 5 subLoss 21491.2 multi -1.99 import weight 0.00
Epoch 100 Iter 6 subLoss 26903.5 multi 3.99 import weight 0.00
Epoch 100 Iter 7 subLoss 50998.1 multi 1.00 import weight 0.00
Epoch 100 Iter 8 subLoss 36398.1 multi 1.00 import weight 0.00
Epoch 100 Iter 9 subLoss 32436.3 multi 1.00 import weight 0.00
Epoch 100 Iter 10 subLoss 31179.6 multi 1.00 import weight 0.00
Epoch 100 Iter 11 subLoss 26867.4 multi 1.00 import weight 0.00
Epoch 100 Acc: 86.48 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2686 train Loss: 26506.7 test Loss: 3215.6
Epoch 101 Iter 0 subLoss 25826.1 multi 1.00 import weight 0.00
Epoch 101 Iter 1 subLoss 24250.7 multi 1.00 import weight 0.00
Epoch 101 Iter 2 subLoss 24323.1 multi 1.00 import weight 0.00
Epoch 101 Iter 3 subLoss 23040.4 multi 1.00 import weight 0.00
Epoch 101 Iter 4 subLoss 22818.0 multi 1.00 import weight 0.00
Epoch 101 Iter 5 subLoss 21472.2 multi 3.99 import weight 0.00
Epoch 101 Iter 6 subLoss 20398.9 multi 1.00 import weight 0.00
Epoch 101 Iter 7 subLoss 19501.9 multi 1.00 import weight 0.00
Epoch 101 Iter 8 subLoss 19051.7 multi 1.00 import weight 0.00
Epoch 101 Iter 9 subLoss 18247.4 multi 6.97 import weight 0.00
Epoch 101 Iter 10 subLoss 18991.3 multi -1.99 import weight 0.00
Epoch 101 Iter 11 subLoss 121951.3 multi 1.00 import weight 0.00
Epoch 101 Acc: 47.44 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 12195 train Loss: 45937.4 test Loss: 8252.8
Epoch 102 Iter 0 subLoss 44448.0 multi 1.00 import weight 0.00
Epoch 102 Iter 1 subLoss 32381.0 multi 1.00 import weight 0.00
Epoch 102 Iter 2 subLoss 28996.0 multi 1.00 import weight 0.00
Epoch 102 Iter 3 subLoss 27581.9 multi -4.97 import weight 0.00
Epoch 102 Iter 4 subLoss 131949.9 multi 1.00 import weight 0.00
Epoch 102 Iter 5 subLoss 44215.2 multi 1.00 import weight 0.00
Epoch 102 Iter 6 subLoss 34080.8 multi -1.99 import weight 0.00
Epoch 102 Iter 7 subLoss 43365.5 multi 1.00 import weight 0.00
Epoch 102 Iter 8 subLoss 36805.5 multi 3.99 import weight 0.00
Epoch 102 Iter 9 subLoss 29866.7 multi 1.00 import weight 0.00
Epoch 102 Iter 10 subLoss 28596.5 multi 1.00 import weight 0.00
Epoch 102 Iter 11 subLoss 27759.3 multi 1.00 import weight 0.00
Epoch 102 Acc: 77.45 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2775 train Loss: 27495.4 test Loss: 3822.1
Epoch 103 Iter 0 subLoss 27229.6 multi 3.99 import weight 0.00
Epoch 103 Iter 1 subLoss 23878.4 multi 3.99 import weight 0.00
Epoch 103 Iter 2 subLoss 22772.9 multi 1.00 import weight 0.00
Epoch 103 Iter 3 subLoss 22246.0 multi 1.00 import weight 0.00
Epoch 103 Iter 4 subLoss 21935.2 multi 1.00 import weight 0.00
Epoch 103 Iter 5 subLoss 21501.1 multi 1.00 import weight 0.00
Epoch 103 Iter 6 subLoss 21240.0 multi 3.99 import weight 0.00
Epoch 103 Iter 7 subLoss 19927.5 multi 3.99 import weight 0.00
Epoch 103 Iter 8 subLoss 22866.6 multi -1.99 import weight 0.00
Epoch 103 Iter 9 subLoss 31354.7 multi 1.00 import weight 0.00
Epoch 103 Iter 10 subLoss 24845.6 multi 3.99 import weight 0.00
Epoch 103 Iter 11 subLoss 22146.3 multi 1.00 import weight 0.00
Epoch 103 Acc: 88.21 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2214 train Loss: 20068.7 test Loss: 2313.0
Epoch 104 Iter 0 subLoss 19099.5 multi 1.00 import weight 0.00
Epoch 104 Iter 1 subLoss 19037.1 multi 1.00 import weight 0.00
Epoch 104 Iter 2 subLoss 18835.4 multi 1.00 import weight 0.00
Epoch 104 Iter 3 subLoss 17696.9 multi 1.00 import weight 0.00
Epoch 104 Iter 4 subLoss 19097.5 multi 3.99 import weight 0.00
Epoch 104 Iter 5 subLoss 18462.2 multi 3.99 import weight 0.00
Epoch 104 Iter 6 subLoss 21971.9 multi 1.00 import weight 0.00
Epoch 104 Iter 7 subLoss 17675.6 multi -4.97 import weight 0.00
Epoch 104 Iter 8 subLoss 26934.5 multi 1.00 import weight 0.00
Epoch 104 Iter 9 subLoss 20490.8 multi 1.00 import weight 0.00
Epoch 104 Iter 10 subLoss 18926.8 multi 3.99 import weight 0.00
Epoch 104 Iter 11 subLoss 19962.9 multi 3.99 import weight 0.00
Epoch 104 Acc: 66.08 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 1996 train Loss: 32042.5 test Loss: 4822.1
Epoch 105 Iter 0 subLoss 32152.9 multi 1.00 import weight 0.00
Epoch 105 Iter 1 subLoss 26292.1 multi 1.00 import weight 0.00
Epoch 105 Iter 2 subLoss 23814.3 multi -1.99 import weight 0.00
Epoch 105 Iter 3 subLoss 26487.4 multi 1.00 import weight 0.00
Epoch 105 Iter 4 subLoss 25211.8 multi 3.99 import weight 0.00
Epoch 105 Iter 5 subLoss 20032.1 multi 3.99 import weight 0.00
Epoch 105 Iter 6 subLoss 17130.2 multi 1.00 import weight 0.00
Epoch 105 Iter 7 subLoss 16065.2 multi 1.00 import weight 0.00
Epoch 105 Iter 8 subLoss 16154.6 multi 1.00 import weight 0.00
Epoch 105 Iter 9 subLoss 15211.4 multi 1.00 import weight 0.00
Epoch 105 Iter 10 subLoss 15374.9 multi 3.99 import weight 0.00
Epoch 105 Iter 11 subLoss 14336.9 multi 1.00 import weight 0.00
Epoch 105 Acc: 91.22 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1433 train Loss: 14584.2 test Loss: 1652.4
Epoch 106 Iter 0 subLoss 14666.8 multi 3.99 import weight 0.00
Epoch 106 Iter 1 subLoss 13600.5 multi 1.00 import weight 0.00
Epoch 106 Iter 2 subLoss 13920.5 multi -1.99 import weight 0.00
Epoch 106 Iter 3 subLoss 14216.0 multi 1.00 import weight 0.00
Epoch 106 Iter 4 subLoss 13737.0 multi 1.00 import weight 0.00
Epoch 106 Iter 5 subLoss 13640.4 multi 3.99 import weight 0.00
Epoch 106 Iter 6 subLoss 13912.3 multi 3.99 import weight 0.00
Epoch 106 Iter 7 subLoss 21605.2 multi 1.00 import weight 0.00
Epoch 106 Iter 8 subLoss 14087.0 multi 1.00 import weight 0.00
Epoch 106 Iter 9 subLoss 13261.6 multi 1.00 import weight 0.00
Epoch 106 Iter 10 subLoss 12734.9 multi 1.00 import weight 0.00
Epoch 106 Iter 11 subLoss 12383.5 multi 1.00 import weight 0.00
Epoch 106 Acc: 92.22 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1238 train Loss: 12804.0 test Loss: 1453.4
Epoch 107 Iter 0 subLoss 12386.2 multi 3.99 import weight 0.00
Epoch 107 Iter 1 subLoss 11948.2 multi 1.00 import weight 0.00
Epoch 107 Iter 2 subLoss 12670.4 multi 1.00 import weight 0.00
Epoch 107 Iter 3 subLoss 12312.3 multi 3.99 import weight 0.00
Epoch 107 Iter 4 subLoss 11667.8 multi 1.00 import weight 0.00
Epoch 107 Iter 5 subLoss 11972.5 multi 1.00 import weight 0.00
Epoch 107 Iter 6 subLoss 11302.9 multi -4.97 import weight 0.00
Epoch 107 Iter 7 subLoss 32725.4 multi 3.99 import weight 0.00
Epoch 107 Iter 8 subLoss 75421.4 multi 1.00 import weight 0.00
Epoch 107 Iter 9 subLoss 40897.9 multi 1.00 import weight 0.00
Epoch 107 Iter 10 subLoss 32102.6 multi 1.00 import weight 0.00
Epoch 107 Iter 11 subLoss 26572.9 multi 1.00 import weight 0.00
Epoch 107 Acc: 75.89 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2657 train Loss: 22980.5 test Loss: 3240.4
Epoch 108 Iter 0 subLoss 23219.4 multi 3.99 import weight 0.00
Epoch 108 Iter 1 subLoss 17277.6 multi -1.99 import weight 0.00
Epoch 108 Iter 2 subLoss 20128.0 multi 3.99 import weight 0.00
Epoch 108 Iter 3 subLoss 26309.8 multi -1.99 import weight 0.00
Epoch 108 Iter 4 subLoss 43067.1 multi 1.00 import weight 0.00
Epoch 108 Iter 5 subLoss 27898.2 multi 1.00 import weight 0.00
Epoch 108 Iter 6 subLoss 23423.0 multi 1.00 import weight 0.00
Epoch 108 Iter 7 subLoss 20898.1 multi 3.99 import weight 0.00
Epoch 108 Iter 8 subLoss 15690.3 multi 1.00 import weight 0.00
Epoch 108 Iter 9 subLoss 16157.5 multi 3.99 import weight 0.00
Epoch 108 Iter 10 subLoss 14603.7 multi 1.00 import weight 0.00
Epoch 108 Iter 11 subLoss 14441.9 multi 3.99 import weight 0.00
Epoch 108 Acc: 89.96 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 1444 train Loss: 14703.1 test Loss: 1757.0
Epoch 109 Iter 0 subLoss 15127.5 multi 1.00 import weight 0.00
Epoch 109 Iter 1 subLoss 14225.0 multi -1.99 import weight 0.00
Epoch 109 Iter 2 subLoss 13490.1 multi 6.97 import weight 0.00
Epoch 109 Iter 3 subLoss 15875.7 multi 3.99 import weight 0.00
Epoch 109 Iter 4 subLoss 20225.7 multi 1.00 import weight 0.00
Epoch 109 Iter 5 subLoss 12891.6 multi 1.00 import weight 0.00
Epoch 109 Iter 6 subLoss 13466.5 multi 1.00 import weight 0.00
Epoch 109 Iter 7 subLoss 13182.6 multi 1.00 import weight 0.00
Epoch 109 Iter 8 subLoss 12440.1 multi -1.99 import weight 0.00
Epoch 109 Iter 9 subLoss 13612.4 multi -1.99 import weight 0.00
Epoch 109 Iter 10 subLoss 13100.6 multi -1.99 import weight 0.00
Epoch 109 Iter 11 subLoss 15431.7 multi 1.00 import weight 0.00
Epoch 109 Acc: 90.89 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1543 train Loss: 14168.7 test Loss: 1736.4
Epoch 110 Iter 0 subLoss 13959.3 multi 3.99 import weight 0.00
Epoch 110 Iter 1 subLoss 14631.9 multi 1.00 import weight 0.00
Epoch 110 Iter 2 subLoss 12640.6 multi 1.00 import weight 0.00
Epoch 110 Iter 3 subLoss 12145.1 multi 1.00 import weight 0.00
Epoch 110 Iter 4 subLoss 13244.5 multi 1.00 import weight 0.00
Epoch 110 Iter 5 subLoss 12852.4 multi -1.99 import weight 0.00
Epoch 110 Iter 6 subLoss 12864.0 multi -1.99 import weight 0.00
Epoch 110 Iter 7 subLoss 14306.9 multi 1.00 import weight 0.00
Epoch 110 Iter 8 subLoss 13961.6 multi -4.97 import weight 0.00
Epoch 110 Iter 9 subLoss 16366.8 multi 6.97 import weight 0.00
Epoch 110 Iter 10 subLoss 30158.7 multi 1.00 import weight 0.00
Epoch 110 Iter 11 subLoss 25819.8 multi -1.99 import weight 0.00
Epoch 110 Acc: 65.62 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 2581 train Loss: 31590.9 test Loss: 5011.7
Epoch 111 Iter 0 subLoss 30216.0 multi 1.00 import weight 0.00
Epoch 111 Iter 1 subLoss 26843.2 multi -1.99 import weight 0.00
Epoch 111 Iter 2 subLoss 32700.1 multi 3.99 import weight 0.00
Epoch 111 Iter 3 subLoss 23178.9 multi 1.00 import weight 0.00
Epoch 111 Iter 4 subLoss 22181.6 multi 1.00 import weight 0.00
Epoch 111 Iter 5 subLoss 20943.5 multi -1.99 import weight 0.00
Epoch 111 Iter 6 subLoss 23335.2 multi 1.00 import weight 0.00
Epoch 111 Iter 7 subLoss 21188.1 multi 1.00 import weight 0.00
Epoch 111 Iter 8 subLoss 19566.7 multi 1.00 import weight 0.00
Epoch 111 Iter 9 subLoss 18782.8 multi 1.00 import weight 0.00
Epoch 111 Iter 10 subLoss 17434.6 multi 1.00 import weight 0.00
Epoch 111 Iter 11 subLoss 16383.2 multi 3.99 import weight 0.00
Epoch 111 Acc: 91.36 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 1638 train Loss: 14023.3 test Loss: 1617.5
Epoch 112 Iter 0 subLoss 13561.5 multi 1.00 import weight 0.00
Epoch 112 Iter 1 subLoss 13391.4 multi 1.00 import weight 0.00
Epoch 112 Iter 2 subLoss 13247.9 multi 3.99 import weight 0.00
Epoch 112 Iter 3 subLoss 13843.1 multi -7.96 import weight 0.00
Epoch 112 Iter 4 subLoss 16381.8 multi 6.97 import weight 0.00
Epoch 112 Iter 5 subLoss 34908.5 multi 1.00 import weight 0.00
Epoch 112 Iter 6 subLoss 15139.9 multi -1.99 import weight 0.00
Epoch 112 Iter 7 subLoss 16442.2 multi 1.00 import weight 0.00
Epoch 112 Iter 8 subLoss 14726.7 multi 1.00 import weight 0.00
Epoch 112 Iter 9 subLoss 14117.3 multi 1.00 import weight 0.00
Epoch 112 Iter 10 subLoss 14532.9 multi 1.00 import weight 0.00
Epoch 112 Iter 11 subLoss 13150.7 multi 6.97 import weight 0.00
Epoch 112 Acc: 91.63 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 1315 train Loss: 13563.5 test Loss: 1491.8
Epoch 113 Iter 0 subLoss 13542.6 multi 1.00 import weight 0.00
Epoch 113 Iter 1 subLoss 11892.1 multi 1.00 import weight 0.00
Epoch 113 Iter 2 subLoss 12508.9 multi 3.98 import weight 0.00
Epoch 113 Iter 3 subLoss 13060.0 multi 1.00 import weight 0.00
Epoch 113 Iter 4 subLoss 11593.8 multi 1.00 import weight 0.00
Epoch 113 Iter 5 subLoss 13455.1 multi 1.00 import weight 0.00
Epoch 113 Iter 6 subLoss 12427.3 multi 1.00 import weight 0.00
Epoch 113 Iter 7 subLoss 10671.1 multi 1.00 import weight 0.00
Epoch 113 Iter 8 subLoss 11942.4 multi 3.99 import weight 0.00
Epoch 113 Iter 9 subLoss 11212.4 multi 1.00 import weight 0.00
Epoch 113 Iter 10 subLoss 11043.8 multi -1.99 import weight 0.00
Epoch 113 Iter 11 subLoss 12116.5 multi -1.99 import weight 0.00
Epoch 113 Acc: 92.04 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 1211 train Loss: 11936.7 test Loss: 1421.7
Epoch 114 Iter 0 subLoss 10592.3 multi 1.00 import weight 0.00
Epoch 114 Iter 1 subLoss 12151.9 multi -1.99 import weight 0.00
Epoch 114 Iter 2 subLoss 11981.5 multi -4.97 import weight 0.00
Epoch 114 Iter 3 subLoss 14689.8 multi 1.00 import weight 0.00
Epoch 114 Iter 4 subLoss 12566.2 multi -4.97 import weight 0.00
Epoch 114 Iter 5 subLoss 18023.8 multi 1.00 import weight 0.00
Epoch 114 Iter 6 subLoss 13237.4 multi -1.99 import weight 0.00
Epoch 114 Iter 7 subLoss 15084.3 multi -1.99 import weight 0.00
Epoch 114 Iter 8 subLoss 22419.4 multi -1.99 import weight 0.00
Epoch 114 Iter 9 subLoss 67149.6 multi 1.00 import weight 0.00
Epoch 114 Iter 10 subLoss 20628.6 multi 1.00 import weight 0.00
Epoch 114 Iter 11 subLoss 19367.3 multi 1.00 import weight 0.00
Epoch 114 Acc: 84.18 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1936 train Loss: 17704.5 test Loss: 2301.6
Epoch 115 Iter 0 subLoss 16683.6 multi -1.99 import weight 0.00
Epoch 115 Iter 1 subLoss 21091.8 multi 3.99 import weight 0.00
Epoch 115 Iter 2 subLoss 14162.5 multi 6.97 import weight 0.00
Epoch 115 Iter 3 subLoss 14453.4 multi -1.98 import weight 0.00
Epoch 115 Iter 4 subLoss 16119.1 multi 6.97 import weight 0.00
Epoch 115 Iter 5 subLoss 23628.0 multi 1.00 import weight 0.00
Epoch 115 Iter 6 subLoss 13797.1 multi 3.99 import weight 0.00
Epoch 115 Iter 7 subLoss 12743.9 multi -1.99 import weight 0.00
Epoch 115 Iter 8 subLoss 12687.9 multi 1.00 import weight 0.00
Epoch 115 Iter 9 subLoss 13156.9 multi 9.96 import weight 1.00
Epoch 115 Iter 10 subLoss 15092.9 multi -1.99 import weight 0.00
Epoch 115 Iter 11 subLoss 38982.1 multi 3.99 import weight 0.00
Epoch 115 Acc: 58.88 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 3898 train Loss: 42165.0 test Loss: 6842.0
Epoch 116 Iter 0 subLoss 42190.8 multi 3.99 import weight 0.00
Epoch 116 Iter 1 subLoss 43005.1 multi 1.00 import weight 0.00
Epoch 116 Iter 2 subLoss 33394.2 multi 1.00 import weight 0.00
Epoch 116 Iter 3 subLoss 28520.3 multi -1.99 import weight 0.00
Epoch 116 Iter 4 subLoss 35571.0 multi 1.00 import weight 0.00
Epoch 116 Iter 5 subLoss 29188.6 multi -1.99 import weight 0.00
Epoch 116 Iter 6 subLoss 37574.6 multi 1.00 import weight 0.00
Epoch 116 Iter 7 subLoss 32035.6 multi -1.99 import weight 0.00
Epoch 116 Iter 8 subLoss 41728.2 multi 1.00 import weight 0.00
Epoch 116 Iter 9 subLoss 32951.8 multi 1.00 import weight 0.00
Epoch 116 Iter 10 subLoss 28528.5 multi 1.00 import weight 0.00
Epoch 116 Iter 11 subLoss 27470.0 multi 1.00 import weight 0.00
Epoch 116 Acc: 69.97 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2746 train Loss: 25955.5 test Loss: 4054.5
Epoch 117 Iter 0 subLoss 25603.9 multi 1.00 import weight 0.00
Epoch 117 Iter 1 subLoss 23820.0 multi 1.00 import weight 0.00
Epoch 117 Iter 2 subLoss 23702.4 multi 1.00 import weight 0.00
Epoch 117 Iter 3 subLoss 23890.1 multi 1.00 import weight 0.00
Epoch 117 Iter 4 subLoss 22817.3 multi 3.99 import weight 0.00
Epoch 117 Iter 5 subLoss 20654.1 multi -1.99 import weight 0.00
Epoch 117 Iter 6 subLoss 21091.8 multi 6.97 import weight 0.00
Epoch 117 Iter 7 subLoss 19351.8 multi 1.00 import weight 0.00
Epoch 117 Iter 8 subLoss 18610.5 multi 1.00 import weight 0.00
Epoch 117 Iter 9 subLoss 18682.4 multi 1.00 import weight 0.00
Epoch 117 Iter 10 subLoss 18355.2 multi 1.00 import weight 0.00
Epoch 117 Iter 11 subLoss 18185.8 multi 3.99 import weight 0.00
Epoch 117 Acc: 82.49 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 1818 train Loss: 17699.3 test Loss: 2454.1
Epoch 118 Iter 0 subLoss 18166.0 multi 1.00 import weight 0.00
Epoch 118 Iter 1 subLoss 17461.4 multi 1.00 import weight 0.00
Epoch 118 Iter 2 subLoss 17515.4 multi 1.00 import weight 0.00
Epoch 118 Iter 3 subLoss 16330.4 multi -7.96 import weight 0.00
Epoch 118 Iter 4 subLoss 18271.9 multi -4.97 import weight 0.00
Epoch 118 Iter 5 subLoss 21452.2 multi 1.00 import weight 0.00
Epoch 118 Iter 6 subLoss 19649.2 multi 1.00 import weight 0.00
Epoch 118 Iter 7 subLoss 19529.6 multi 3.99 import weight 0.00
Epoch 118 Iter 8 subLoss 17529.5 multi -1.99 import weight 0.00
Epoch 118 Iter 9 subLoss 18853.7 multi 1.00 import weight 0.00
Epoch 118 Iter 10 subLoss 19354.4 multi 3.99 import weight 0.00
Epoch 118 Iter 11 subLoss 18312.4 multi 1.00 import weight 0.00
Epoch 118 Acc: 82.93 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1831 train Loss: 17826.0 test Loss: 2452.8
Epoch 119 Iter 0 subLoss 18241.0 multi 9.96 import weight 1.00
Epoch 119 Iter 1 subLoss 15965.5 multi 3.99 import weight 0.00
Epoch 119 Iter 2 subLoss 14639.6 multi 3.99 import weight 0.00
Epoch 119 Iter 3 subLoss 15364.9 multi 1.00 import weight 0.00
Epoch 119 Iter 4 subLoss 14717.6 multi 1.00 import weight 0.00
Epoch 119 Iter 5 subLoss 14653.5 multi -4.97 import weight 0.00
Epoch 119 Iter 6 subLoss 15091.5 multi 1.00 import weight 0.00
Epoch 119 Iter 7 subLoss 14682.6 multi 3.99 import weight 0.00
Epoch 119 Iter 8 subLoss 15128.5 multi 3.99 import weight 0.00
Epoch 119 Iter 9 subLoss 14065.6 multi 1.00 import weight 0.00
Epoch 119 Iter 10 subLoss 13874.3 multi 1.00 import weight 0.00
Epoch 119 Iter 11 subLoss 14193.6 multi 3.99 import weight 0.00
Epoch 119 Acc: 90.29 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 1419 train Loss: 13471.4 test Loss: 1612.4
Epoch 120 Iter 0 subLoss 13567.3 multi 3.99 import weight 0.00
Epoch 120 Iter 1 subLoss 13269.9 multi 3.99 import weight 0.00
Epoch 120 Iter 2 subLoss 13034.0 multi 1.00 import weight 0.00
Epoch 120 Iter 3 subLoss 12539.9 multi 3.99 import weight 0.00
Epoch 120 Iter 4 subLoss 11632.6 multi 1.00 import weight 0.00
Epoch 120 Iter 5 subLoss 11383.3 multi 1.00 import weight 0.00
Epoch 120 Iter 6 subLoss 11645.3 multi -1.99 import weight 0.00
Epoch 120 Iter 7 subLoss 10861.4 multi 1.00 import weight 0.00
Epoch 120 Iter 8 subLoss 12091.4 multi 3.99 import weight 0.00
Epoch 120 Iter 9 subLoss 11004.3 multi 1.00 import weight 0.00
Epoch 120 Iter 10 subLoss 10810.8 multi -1.99 import weight 0.00
Epoch 120 Iter 11 subLoss 11548.5 multi 3.99 import weight 0.00
Epoch 120 Acc: 89.06 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 1154 train Loss: 12062.7 test Loss: 1653.3
Epoch 121 Iter 0 subLoss 11699.6 multi 1.00 import weight 0.00
Epoch 121 Iter 1 subLoss 10869.1 multi 3.98 import weight 0.00
Epoch 121 Iter 2 subLoss 12602.3 multi 1.00 import weight 0.00
Epoch 121 Iter 3 subLoss 10673.1 multi 3.99 import weight 0.00
Epoch 121 Iter 4 subLoss 11902.1 multi 1.00 import weight 0.00
Epoch 121 Iter 5 subLoss 10313.3 multi 1.00 import weight 0.00
Epoch 121 Iter 6 subLoss 10100.4 multi 1.00 import weight 0.00
Epoch 121 Iter 7 subLoss 9655.5 multi 1.00 import weight 0.00
Epoch 121 Iter 8 subLoss 10542.3 multi 1.00 import weight 0.00
Epoch 121 Iter 9 subLoss 9612.5 multi 1.00 import weight 0.00
Epoch 121 Iter 10 subLoss 9276.2 multi 6.97 import weight 0.00
Epoch 121 Iter 11 subLoss 9134.3 multi 1.00 import weight 0.00
Epoch 121 Acc: 92.96 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 913 train Loss: 9613.4 test Loss: 1138.4
Epoch 122 Iter 0 subLoss 8943.4 multi 3.99 import weight 0.00
Epoch 122 Iter 1 subLoss 9328.2 multi 1.00 import weight 0.00
Epoch 122 Iter 2 subLoss 9201.0 multi 1.00 import weight 0.00
Epoch 122 Iter 3 subLoss 8840.4 multi 1.00 import weight 0.00
Epoch 122 Iter 4 subLoss 8741.1 multi -1.99 import weight 0.00
Epoch 122 Iter 5 subLoss 9120.4 multi 1.00 import weight 0.00
Epoch 122 Iter 6 subLoss 9313.0 multi -1.99 import weight 0.00
Epoch 122 Iter 7 subLoss 8909.3 multi 3.99 import weight 0.00
Epoch 122 Iter 8 subLoss 10834.0 multi 6.97 import weight 0.00
Epoch 122 Iter 9 subLoss 36512.8 multi 1.00 import weight 0.00
Epoch 122 Iter 10 subLoss 22365.4 multi 3.99 import weight 0.00
Epoch 122 Iter 11 subLoss 17212.3 multi 1.00 import weight 0.00
Epoch 122 Acc: 76.65 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1721 train Loss: 17843.3 test Loss: 2986.0
Epoch 123 Iter 0 subLoss 17458.3 multi 1.00 import weight 0.00
Epoch 123 Iter 1 subLoss 17043.4 multi 1.00 import weight 0.00
Epoch 123 Iter 2 subLoss 16387.6 multi 9.96 import weight 1.00
Epoch 123 Iter 3 subLoss 14046.7 multi 3.99 import weight 0.00
Epoch 123 Iter 4 subLoss 13214.7 multi -1.99 import weight 0.00
Epoch 123 Iter 5 subLoss 14125.6 multi -1.99 import weight 0.00
Epoch 123 Iter 6 subLoss 18665.0 multi 1.00 import weight 0.00
Epoch 123 Iter 7 subLoss 14287.5 multi 3.99 import weight 0.00
Epoch 123 Iter 8 subLoss 13894.0 multi -1.99 import weight 0.00
Epoch 123 Iter 9 subLoss 15496.5 multi 1.00 import weight 0.00
Epoch 123 Iter 10 subLoss 13608.8 multi 3.99 import weight 0.00
Epoch 123 Iter 11 subLoss 13218.5 multi 1.00 import weight 0.00
Epoch 123 Acc: 87.90 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1321 train Loss: 12506.5 test Loss: 1899.8
Epoch 124 Iter 0 subLoss 12504.2 multi 6.97 import weight 1.00
Epoch 124 Iter 1 subLoss 13583.8 multi 1.00 import weight 0.00
Epoch 124 Iter 2 subLoss 10739.2 multi 1.00 import weight 0.00
Epoch 124 Iter 3 subLoss 10540.8 multi 3.99 import weight 0.00
Epoch 124 Iter 4 subLoss 10213.2 multi 1.00 import weight 0.00
Epoch 124 Iter 5 subLoss 9819.7 multi 3.99 import weight 0.00
Epoch 124 Iter 6 subLoss 9952.2 multi 1.00 import weight 0.00
Epoch 124 Iter 7 subLoss 9612.2 multi 3.98 import weight 0.00
Epoch 124 Iter 8 subLoss 9472.5 multi -1.99 import weight 0.00
Epoch 124 Iter 9 subLoss 9998.8 multi -1.98 import weight 0.00
Epoch 124 Iter 10 subLoss 75928.5 multi 1.00 import weight 0.00
Epoch 124 Iter 11 subLoss 13091.4 multi 3.99 import weight 0.00
Epoch 124 Acc: 87.64 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 1309 train Loss: 13898.6 test Loss: 1926.9
Epoch 125 Iter 0 subLoss 13201.0 multi 3.99 import weight 0.00
Epoch 125 Iter 1 subLoss 13953.8 multi 6.97 import weight 0.00
Epoch 125 Iter 2 subLoss 18744.5 multi 3.99 import weight 0.00
Epoch 125 Iter 3 subLoss 13325.0 multi 3.99 import weight 0.00
Epoch 125 Iter 4 subLoss 11387.3 multi 3.99 import weight 0.00
Epoch 125 Iter 5 subLoss 9313.6 multi 1.00 import weight 0.00
Epoch 125 Iter 6 subLoss 8935.8 multi 1.00 import weight 0.00
Epoch 125 Iter 7 subLoss 9393.5 multi 1.00 import weight 0.00
Epoch 125 Iter 8 subLoss 9486.8 multi 1.00 import weight 0.00
Epoch 125 Iter 9 subLoss 8555.4 multi 1.00 import weight 0.00
Epoch 125 Iter 10 subLoss 8714.7 multi -1.99 import weight 0.00
Epoch 125 Iter 11 subLoss 9148.1 multi -1.99 import weight 0.00
Epoch 125 Acc: 92.96 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 914 train Loss: 9465.1 test Loss: 1195.3
Epoch 126 Iter 0 subLoss 9509.0 multi 1.00 import weight 0.00
Epoch 126 Iter 1 subLoss 9082.2 multi 3.99 import weight 0.00
Epoch 126 Iter 2 subLoss 9280.8 multi -7.96 import weight 0.00
Epoch 126 Iter 3 subLoss 11069.5 multi 3.99 import weight 0.00
Epoch 126 Iter 4 subLoss 9400.9 multi 1.00 import weight 0.00
Epoch 126 Iter 5 subLoss 9294.2 multi 3.98 import weight 0.00
Epoch 126 Iter 6 subLoss 8813.7 multi -1.99 import weight 0.00
Epoch 126 Iter 7 subLoss 8575.4 multi -1.99 import weight 0.00
Epoch 126 Iter 8 subLoss 9221.1 multi -1.99 import weight 0.00
Epoch 126 Iter 9 subLoss 9225.6 multi 1.00 import weight 0.00
Epoch 126 Iter 10 subLoss 8717.3 multi 1.00 import weight 0.00
Epoch 126 Iter 11 subLoss 8725.4 multi 3.99 import weight 1.00
Epoch 126 Acc: 94.03 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 3.99 Pidx 872 train Loss: 8625.6 test Loss: 1041.7
Epoch 127 Iter 0 subLoss 8799.1 multi -1.99 import weight 0.00
Epoch 127 Iter 1 subLoss 8609.3 multi 1.00 import weight 0.00
Epoch 127 Iter 2 subLoss 8359.6 multi 1.00 import weight 0.00
Epoch 127 Iter 3 subLoss 8513.1 multi 3.99 import weight 0.00
Epoch 127 Iter 4 subLoss 8226.4 multi 3.99 import weight 0.00
Epoch 127 Iter 5 subLoss 7997.5 multi 1.00 import weight 0.00
Epoch 127 Iter 6 subLoss 8680.2 multi 1.00 import weight 0.00
Epoch 127 Iter 7 subLoss 7372.9 multi 1.00 import weight 0.00
Epoch 127 Iter 8 subLoss 7783.3 multi 1.00 import weight 0.00
Epoch 127 Iter 9 subLoss 7701.6 multi 1.00 import weight 0.00
Epoch 127 Iter 10 subLoss 7458.2 multi -4.97 import weight 0.00
Epoch 127 Iter 11 subLoss 7955.4 multi -1.99 import weight 0.00
Epoch 127 Acc: 94.05 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 795 train Loss: 8431.0 test Loss: 1009.0
Epoch 128 Iter 0 subLoss 8519.9 multi 6.97 import weight 0.00
Epoch 128 Iter 1 subLoss 10039.9 multi 1.00 import weight 0.00
Epoch 128 Iter 2 subLoss 8549.7 multi -4.97 import weight 0.00
Epoch 128 Iter 3 subLoss 12955.1 multi 1.00 import weight 0.00
Epoch 128 Iter 4 subLoss 11054.7 multi -1.99 import weight 0.00
Epoch 128 Iter 5 subLoss 15565.0 multi 1.00 import weight 0.00
Epoch 128 Iter 6 subLoss 11094.4 multi -1.99 import weight 0.00
Epoch 128 Iter 7 subLoss 14756.0 multi 1.00 import weight 0.00
Epoch 128 Iter 8 subLoss 12399.3 multi -1.98 import weight 0.00
Epoch 128 Iter 9 subLoss 15910.8 multi 1.00 import weight 0.00
Epoch 128 Iter 10 subLoss 12686.1 multi 3.98 import weight 0.00
Epoch 128 Iter 11 subLoss 8949.0 multi 3.98 import weight 0.00
Epoch 128 Acc: 94.10 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 894 train Loss: 8529.7 test Loss: 1006.2
Epoch 129 Iter 0 subLoss 8341.6 multi 1.00 import weight 0.00
Epoch 129 Iter 1 subLoss 8207.0 multi 3.99 import weight 0.00
Epoch 129 Iter 2 subLoss 7341.7 multi 9.96 import weight 1.00
Epoch 129 Iter 3 subLoss 8147.9 multi -1.98 import weight 0.00
Epoch 129 Iter 4 subLoss 7802.3 multi 3.99 import weight 0.00
Epoch 129 Iter 5 subLoss 7016.9 multi 1.00 import weight 0.00
Epoch 129 Iter 6 subLoss 7527.8 multi 3.99 import weight 0.00
Epoch 129 Iter 7 subLoss 7146.9 multi 1.00 import weight 0.00
Epoch 129 Iter 8 subLoss 8045.8 multi 1.00 import weight 0.00
Epoch 129 Iter 9 subLoss 7856.6 multi 3.99 import weight 0.00
Epoch 129 Iter 10 subLoss 7167.6 multi -1.99 import weight 0.00
Epoch 129 Iter 11 subLoss 7119.3 multi 3.99 import weight 0.00
Epoch 129 Acc: 93.56 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 711 train Loss: 7546.8 test Loss: 986.1
Epoch 130 Iter 0 subLoss 7921.9 multi 1.00 import weight 0.00
Epoch 130 Iter 1 subLoss 7154.1 multi 1.00 import weight 0.00
Epoch 130 Iter 2 subLoss 6312.7 multi 1.00 import weight 0.00
Epoch 130 Iter 3 subLoss 6465.5 multi -1.99 import weight 0.00
Epoch 130 Iter 4 subLoss 7281.7 multi 1.00 import weight 0.00
Epoch 130 Iter 5 subLoss 7738.3 multi 1.00 import weight 0.00
Epoch 130 Iter 6 subLoss 7527.3 multi 6.97 import weight 0.00
Epoch 130 Iter 7 subLoss 7076.4 multi -1.98 import weight 0.00
Epoch 130 Iter 8 subLoss 7735.2 multi 3.99 import weight 0.00
Epoch 130 Iter 9 subLoss 8797.4 multi 1.00 import weight 0.00
Epoch 130 Iter 10 subLoss 6538.2 multi 1.00 import weight 0.00
Epoch 130 Iter 11 subLoss 6617.7 multi 1.00 import weight 0.00
Epoch 130 Acc: 94.73 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 661 train Loss: 7009.8 test Loss: 844.5
Epoch 131 Iter 0 subLoss 5963.3 multi 1.00 import weight 0.00
Epoch 131 Iter 1 subLoss 6409.7 multi 1.00 import weight 0.00
Epoch 131 Iter 2 subLoss 6994.8 multi 1.00 import weight 0.00
Epoch 131 Iter 3 subLoss 6740.4 multi -4.97 import weight 0.00
Epoch 131 Iter 4 subLoss 7200.0 multi 1.00 import weight 0.00
Epoch 131 Iter 5 subLoss 6629.8 multi 3.98 import weight 0.00
Epoch 131 Iter 6 subLoss 6497.8 multi 9.96 import weight 1.00
Epoch 131 Iter 7 subLoss 11164.7 multi 1.00 import weight 0.00
Epoch 131 Iter 8 subLoss 8165.7 multi 1.00 import weight 0.00
Epoch 131 Iter 9 subLoss 6934.6 multi 1.00 import weight 0.00
Epoch 131 Iter 10 subLoss 6438.0 multi 1.00 import weight 0.00
Epoch 131 Iter 11 subLoss 6288.1 multi -4.97 import weight 0.00
Epoch 131 Acc: 94.78 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 628 train Loss: 6806.5 test Loss: 805.5
Epoch 132 Iter 0 subLoss 6708.4 multi 1.00 import weight 0.00
Epoch 132 Iter 1 subLoss 6445.3 multi -1.99 import weight 0.00
Epoch 132 Iter 2 subLoss 7022.5 multi 1.00 import weight 0.00
Epoch 132 Iter 3 subLoss 7313.2 multi 1.00 import weight 0.00
Epoch 132 Iter 4 subLoss 6747.1 multi -1.98 import weight 0.00
Epoch 132 Iter 5 subLoss 6623.0 multi 6.97 import weight 1.00
Epoch 132 Iter 6 subLoss 7317.1 multi 3.99 import weight 0.00
Epoch 132 Iter 7 subLoss 8169.6 multi 3.98 import weight 0.00
Epoch 132 Iter 8 subLoss 9906.1 multi 6.97 import weight 0.00
Epoch 132 Iter 9 subLoss 40425.2 multi 3.99 import weight 0.00
Epoch 132 Iter 10 subLoss 26331.3 multi 1.00 import weight 0.00
Epoch 132 Iter 11 subLoss 19003.6 multi 1.00 import weight 0.00
Epoch 132 Acc: 75.56 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1900 train Loss: 18017.4 test Loss: 3058.0
Epoch 133 Iter 0 subLoss 17422.0 multi 1.00 import weight 0.00
Epoch 133 Iter 1 subLoss 16655.3 multi 1.00 import weight 0.00
Epoch 133 Iter 2 subLoss 15744.5 multi 1.00 import weight 0.00
Epoch 133 Iter 3 subLoss 14227.6 multi 1.00 import weight 0.00
Epoch 133 Iter 4 subLoss 13432.2 multi 1.00 import weight 0.00
Epoch 133 Iter 5 subLoss 13114.4 multi -1.99 import weight 0.00
Epoch 133 Iter 6 subLoss 14263.5 multi 1.00 import weight 0.00
Epoch 133 Iter 7 subLoss 14626.1 multi 1.00 import weight 0.00
Epoch 133 Iter 8 subLoss 13380.1 multi -1.99 import weight 0.00
Epoch 133 Iter 9 subLoss 14815.1 multi 1.00 import weight 0.00
Epoch 133 Iter 10 subLoss 13345.7 multi 1.00 import weight 0.00
Epoch 133 Iter 11 subLoss 13577.7 multi -4.97 import weight 0.00
Epoch 133 Acc: 82.93 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 1357 train Loss: 16521.5 test Loss: 2524.4
Epoch 134 Iter 0 subLoss 16090.2 multi 3.99 import weight 0.00
Epoch 134 Iter 1 subLoss 13864.2 multi 1.00 import weight 0.00
Epoch 134 Iter 2 subLoss 13323.4 multi 6.97 import weight 0.00
Epoch 134 Iter 3 subLoss 11326.5 multi -1.99 import weight 0.00
Epoch 134 Iter 4 subLoss 10424.0 multi 1.00 import weight 0.00
Epoch 134 Iter 5 subLoss 10913.1 multi 3.99 import weight 0.00
Epoch 134 Iter 6 subLoss 9804.1 multi 1.00 import weight 0.00
Epoch 134 Iter 7 subLoss 9681.0 multi 1.00 import weight 0.00
Epoch 134 Iter 8 subLoss 10449.8 multi -1.98 import weight 0.00
Epoch 134 Iter 9 subLoss 10518.2 multi 1.00 import weight 0.00
Epoch 134 Iter 10 subLoss 9952.3 multi 3.99 import weight 0.00
Epoch 134 Iter 11 subLoss 9129.1 multi 3.99 import weight 0.00
Epoch 134 Acc: 94.47 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 912 train Loss: 9227.0 test Loss: 1055.8
Epoch 135 Iter 0 subLoss 8539.8 multi 6.97 import weight 0.00
Epoch 135 Iter 1 subLoss 8792.3 multi 3.98 import weight 0.00
Epoch 135 Iter 2 subLoss 8018.8 multi 3.99 import weight 0.00
Epoch 135 Iter 3 subLoss 7339.0 multi 1.00 import weight 0.00
Epoch 135 Iter 4 subLoss 8057.6 multi -1.98 import weight 0.00
Epoch 135 Iter 5 subLoss 8740.2 multi 1.00 import weight 0.00
Epoch 135 Iter 6 subLoss 7715.0 multi -1.99 import weight 0.00
Epoch 135 Iter 7 subLoss 7596.5 multi 1.00 import weight 0.00
Epoch 135 Iter 8 subLoss 7952.5 multi 1.00 import weight 0.00
Epoch 135 Iter 9 subLoss 7375.5 multi 3.99 import weight 0.00
Epoch 135 Iter 10 subLoss 7343.8 multi 9.96 import weight 1.00
Epoch 135 Iter 11 subLoss 7005.8 multi -1.99 import weight 0.00
Epoch 135 Acc: 93.21 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 700 train Loss: 8966.6 test Loss: 1145.6
Epoch 136 Iter 0 subLoss 8465.4 multi -4.97 import weight 0.00
Epoch 136 Iter 1 subLoss 22320.9 multi -1.99 import weight 0.00
Epoch 136 Iter 2 subLoss 163308.3 multi 1.00 import weight 0.00
Epoch 136 Iter 3 subLoss 19807.0 multi -1.99 import weight 0.00
Epoch 136 Iter 4 subLoss 74395.1 multi 1.00 import weight 0.00
Epoch 136 Iter 5 subLoss 14199.5 multi 6.97 import weight 0.00
Epoch 136 Iter 6 subLoss 19184.6 multi -1.99 import weight 0.00
Epoch 136 Iter 7 subLoss 40962.7 multi 1.00 import weight 0.00
Epoch 136 Iter 8 subLoss 22125.5 multi 1.00 import weight 0.00
Epoch 136 Iter 9 subLoss 15324.3 multi 3.99 import weight 0.00
Epoch 136 Iter 10 subLoss 9490.9 multi -4.97 import weight 0.00
Epoch 136 Iter 11 subLoss 10306.7 multi 1.00 import weight 0.00
Epoch 136 Acc: 93.38 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1030 train Loss: 10166.3 test Loss: 1287.7
Epoch 137 Iter 0 subLoss 10162.1 multi 3.99 import weight 0.00
Epoch 137 Iter 1 subLoss 9470.6 multi 1.00 import weight 0.00
Epoch 137 Iter 2 subLoss 8646.1 multi 3.99 import weight 0.00
Epoch 137 Iter 3 subLoss 8842.9 multi 3.99 import weight 0.00
Epoch 137 Iter 4 subLoss 8475.1 multi 3.98 import weight 0.00
Epoch 137 Iter 5 subLoss 7838.2 multi 1.00 import weight 0.00
Epoch 137 Iter 6 subLoss 8901.0 multi 6.97 import weight 0.00
Epoch 137 Iter 7 subLoss 8678.8 multi -1.99 import weight 0.00
Epoch 137 Iter 8 subLoss 8200.5 multi 6.97 import weight 0.00
Epoch 137 Iter 9 subLoss 7709.4 multi 3.99 import weight 0.00
Epoch 137 Iter 10 subLoss 7744.0 multi -1.98 import weight 0.00
Epoch 137 Iter 11 subLoss 7052.1 multi 3.99 import weight 0.00
Epoch 137 Acc: 94.77 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 705 train Loss: 7570.2 test Loss: 929.7
Epoch 138 Iter 0 subLoss 7799.0 multi -1.99 import weight 0.00
Epoch 138 Iter 1 subLoss 7844.6 multi -1.99 import weight 0.00
Epoch 138 Iter 2 subLoss 7805.7 multi 3.98 import weight 0.00
Epoch 138 Iter 3 subLoss 7271.6 multi 1.00 import weight 0.00
Epoch 138 Iter 4 subLoss 7231.4 multi -4.97 import weight 0.00
Epoch 138 Iter 5 subLoss 7635.2 multi -4.97 import weight 0.00
Epoch 138 Iter 6 subLoss 8454.8 multi 6.97 import weight 0.00
Epoch 138 Iter 7 subLoss 9694.3 multi 1.00 import weight 0.00
Epoch 138 Iter 8 subLoss 8133.4 multi 6.97 import weight 0.00
Epoch 138 Iter 9 subLoss 7857.1 multi 3.98 import weight 0.00
Epoch 138 Iter 10 subLoss 7100.7 multi -1.99 import weight 0.00
Epoch 138 Iter 11 subLoss 7237.4 multi -1.98 import weight 0.00
Epoch 138 Acc: 93.66 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 723 train Loss: 8194.7 test Loss: 1061.7
Epoch 139 Iter 0 subLoss 8058.4 multi 1.00 import weight 0.00
Epoch 139 Iter 1 subLoss 7736.9 multi 6.97 import weight 0.00
Epoch 139 Iter 2 subLoss 7819.7 multi -7.96 import weight 0.00
Epoch 139 Iter 3 subLoss 24000.1 multi 1.00 import weight 0.00
Epoch 139 Iter 4 subLoss 11704.3 multi -1.99 import weight 0.00
Epoch 139 Iter 5 subLoss 16881.2 multi 1.00 import weight 0.00
Epoch 139 Iter 6 subLoss 12723.9 multi -1.99 import weight 0.00
Epoch 139 Iter 7 subLoss 20516.2 multi 1.00 import weight 0.00
Epoch 139 Iter 8 subLoss 13077.2 multi 3.99 import weight 0.00
Epoch 139 Iter 9 subLoss 7942.9 multi 3.99 import weight 0.00
Epoch 139 Iter 10 subLoss 7933.7 multi -1.99 import weight 0.00
Epoch 139 Iter 11 subLoss 7578.2 multi -1.99 import weight 0.00
Epoch 139 Acc: 94.16 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 757 train Loss: 8195.9 test Loss: 1086.2
Epoch 140 Iter 0 subLoss 8732.8 multi -7.96 import weight 0.00
Epoch 140 Iter 1 subLoss 9345.8 multi -1.99 import weight 0.00
Epoch 140 Iter 2 subLoss 11113.2 multi -4.97 import weight 0.00
Epoch 140 Iter 3 subLoss 15397.6 multi 1.00 import weight 0.00
Epoch 140 Iter 4 subLoss 13540.5 multi 3.99 import weight 0.00
Epoch 140 Iter 5 subLoss 9865.4 multi 1.00 import weight 0.00
Epoch 140 Iter 6 subLoss 10044.6 multi 1.00 import weight 0.00
Epoch 140 Iter 7 subLoss 9904.0 multi 9.96 import weight 0.00
Epoch 140 Iter 8 subLoss 7575.7 multi 1.00 import weight 0.00
Epoch 140 Iter 9 subLoss 7218.4 multi -1.99 import weight 0.00
Epoch 140 Iter 10 subLoss 8214.4 multi -7.96 import weight 0.00
Epoch 140 Iter 11 subLoss 12318.9 multi 6.97 import weight 0.00
Epoch 140 Acc: 85.11 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 1231 train Loss: 14457.8 test Loss: 2362.0
Epoch 141 Iter 0 subLoss 14220.2 multi 3.98 import weight 0.00
Epoch 141 Iter 1 subLoss 7930.7 multi 1.00 import weight 0.00
Epoch 141 Iter 2 subLoss 7953.4 multi 1.00 import weight 0.00
Epoch 141 Iter 3 subLoss 7868.7 multi -7.96 import weight 0.00
Epoch 141 Iter 4 subLoss 9437.7 multi 1.00 import weight 0.00
Epoch 141 Iter 5 subLoss 8930.2 multi 3.99 import weight 0.00
Epoch 141 Iter 6 subLoss 8946.6 multi 3.99 import weight 0.00
Epoch 141 Iter 7 subLoss 7701.3 multi 6.97 import weight 0.00
Epoch 141 Iter 8 subLoss 8358.0 multi 1.00 import weight 0.00
Epoch 141 Iter 9 subLoss 7386.4 multi -1.98 import weight 0.00
Epoch 141 Iter 10 subLoss 7124.5 multi 1.00 import weight 0.00
Epoch 141 Iter 11 subLoss 7499.4 multi 3.99 import weight 0.00
Epoch 141 Acc: 95.08 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 749 train Loss: 7445.8 test Loss: 899.3
Epoch 142 Iter 0 subLoss 7096.8 multi 3.99 import weight 0.00
Epoch 142 Iter 1 subLoss 7286.0 multi 1.00 import weight 0.00
Epoch 142 Iter 2 subLoss 7409.2 multi -1.99 import weight 0.00
Epoch 142 Iter 3 subLoss 6961.8 multi 1.00 import weight 0.00
Epoch 142 Iter 4 subLoss 7007.4 multi 1.00 import weight 0.00
Epoch 142 Iter 5 subLoss 7719.9 multi -4.97 import weight 0.00
Epoch 142 Iter 6 subLoss 6400.6 multi 3.99 import weight 0.00
Epoch 142 Iter 7 subLoss 7056.0 multi 6.97 import weight 0.00
Epoch 142 Iter 8 subLoss 6452.5 multi 1.00 import weight 0.00
Epoch 142 Iter 9 subLoss 6800.7 multi 3.99 import weight 0.00
Epoch 142 Iter 10 subLoss 6899.2 multi 1.00 import weight 0.00
Epoch 142 Iter 11 subLoss 7313.3 multi 6.97 import weight 0.00
Epoch 142 Acc: 94.73 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 731 train Loss: 6920.5 test Loss: 876.2
Epoch 143 Iter 0 subLoss 6734.7 multi 6.97 import weight 0.00
Epoch 143 Iter 1 subLoss 6834.8 multi 1.00 import weight 0.00
Epoch 143 Iter 2 subLoss 7271.6 multi 3.99 import weight 0.00
Epoch 143 Iter 3 subLoss 6490.0 multi 12.94 import weight 1.00
Epoch 143 Iter 4 subLoss 6956.8 multi 1.00 import weight 0.00
Epoch 143 Iter 5 subLoss 7057.8 multi 9.96 import weight 0.00
Epoch 143 Iter 6 subLoss 6939.0 multi 3.99 import weight 0.00
Epoch 143 Iter 7 subLoss 6625.7 multi 9.96 import weight 1.00
Epoch 143 Iter 8 subLoss 10520.6 multi -1.99 import weight 0.00
Epoch 143 Iter 9 subLoss 17919.6 multi 1.00 import weight 0.00
Epoch 143 Iter 10 subLoss 11541.5 multi 6.97 import weight 0.00
Epoch 143 Iter 11 subLoss 10456.9 multi -4.97 import weight 0.00
Epoch 143 Acc: 52.62 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 1045 train Loss: 61379.2 test Loss: 13563.6
Epoch 144 Iter 0 subLoss 57805.1 multi 1.00 import weight 0.00
Epoch 144 Iter 1 subLoss 9987.2 multi 6.97 import weight 0.00
Epoch 144 Iter 2 subLoss 7477.9 multi 3.99 import weight 0.00
Epoch 144 Iter 3 subLoss 6768.6 multi -4.97 import weight 0.00
Epoch 144 Iter 4 subLoss 7319.4 multi 9.96 import weight 0.00
Epoch 144 Iter 5 subLoss 6385.3 multi 1.00 import weight 0.00
Epoch 144 Iter 6 subLoss 6678.2 multi 3.99 import weight 0.00
Epoch 144 Iter 7 subLoss 6699.0 multi -1.99 import weight 0.00
Epoch 144 Iter 8 subLoss 6210.7 multi 1.00 import weight 0.00
Epoch 144 Iter 9 subLoss 6616.7 multi 3.99 import weight 0.00
Epoch 144 Iter 10 subLoss 6437.6 multi 3.99 import weight 0.00
Epoch 144 Iter 11 subLoss 6294.0 multi -1.99 import weight 0.00
Epoch 144 Acc: 95.12 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 629 train Loss: 6463.8 test Loss: 800.1
Epoch 145 Iter 0 subLoss 6108.8 multi 6.97 import weight 0.00
Epoch 145 Iter 1 subLoss 6704.5 multi 1.00 import weight 0.00
Epoch 145 Iter 2 subLoss 6574.1 multi 1.00 import weight 0.00
Epoch 145 Iter 3 subLoss 5938.4 multi 1.00 import weight 0.00
Epoch 145 Iter 4 subLoss 5757.9 multi 3.99 import weight 0.00
Epoch 145 Iter 5 subLoss 6101.5 multi 9.96 import weight 0.00
Epoch 145 Iter 6 subLoss 6209.4 multi -4.97 import weight 0.00
Epoch 145 Iter 7 subLoss 6281.7 multi -1.98 import weight 0.00
Epoch 145 Iter 8 subLoss 8189.6 multi 1.00 import weight 0.00
Epoch 145 Iter 9 subLoss 6541.7 multi -1.99 import weight 0.00
Epoch 145 Iter 10 subLoss 8109.0 multi 3.99 import weight 0.00
Epoch 145 Iter 11 subLoss 5910.9 multi 1.00 import weight 0.00
Epoch 145 Acc: 95.08 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 591 train Loss: 6107.0 test Loss: 779.9
Epoch 146 Iter 0 subLoss 6291.2 multi -1.98 import weight 0.00
Epoch 146 Iter 1 subLoss 6094.5 multi -1.99 import weight 0.00
Epoch 146 Iter 2 subLoss 6482.2 multi -4.97 import weight 0.00
Epoch 146 Iter 3 subLoss 9278.1 multi 9.96 import weight 0.00
Epoch 146 Iter 4 subLoss 20728.5 multi -1.99 import weight 0.00
Epoch 146 Iter 5 subLoss 121043.7 multi 1.00 import weight 0.00
Epoch 146 Iter 6 subLoss 11024.3 multi -1.99 import weight 0.00
Epoch 146 Iter 7 subLoss 14319.2 multi 3.98 import weight 0.00
Epoch 146 Iter 8 subLoss 8734.9 multi -4.97 import weight 0.00
Epoch 146 Iter 9 subLoss 10917.4 multi 6.97 import weight 0.00
Epoch 146 Iter 10 subLoss 7640.3 multi -4.97 import weight 0.00
Epoch 146 Iter 11 subLoss 8056.0 multi 3.99 import weight 0.00
Epoch 146 Acc: 94.12 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 805 train Loss: 7806.0 test Loss: 986.8
Epoch 147 Iter 0 subLoss 8113.7 multi -4.97 import weight 0.00
Epoch 147 Iter 1 subLoss 7434.5 multi -1.99 import weight 0.00
Epoch 147 Iter 2 subLoss 8862.6 multi 1.00 import weight 0.00
Epoch 147 Iter 3 subLoss 8489.8 multi -4.97 import weight 0.00
Epoch 147 Iter 4 subLoss 10147.7 multi 1.00 import weight 0.00
Epoch 147 Iter 5 subLoss 8716.4 multi 3.98 import weight 0.00
Epoch 147 Iter 6 subLoss 8197.4 multi -1.99 import weight 0.00
Epoch 147 Iter 7 subLoss 8384.8 multi 1.00 import weight 0.00
Epoch 147 Iter 8 subLoss 8352.8 multi 3.98 import weight 0.00
Epoch 147 Iter 9 subLoss 7363.8 multi 1.00 import weight 0.00
Epoch 147 Iter 10 subLoss 8239.5 multi -4.97 import weight 0.00
Epoch 147 Iter 11 subLoss 7593.9 multi 3.99 import weight 0.00
Epoch 147 Acc: 94.24 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 759 train Loss: 7849.5 test Loss: 959.4
Epoch 148 Iter 0 subLoss 8198.4 multi 1.00 import weight 0.00
Epoch 148 Iter 1 subLoss 7255.4 multi 3.99 import weight 0.00
Epoch 148 Iter 2 subLoss 7771.1 multi 1.00 import weight 0.00
Epoch 148 Iter 3 subLoss 7189.4 multi -1.99 import weight 0.00
Epoch 148 Iter 4 subLoss 7583.9 multi -4.97 import weight 0.00
Epoch 148 Iter 5 subLoss 8598.4 multi 1.00 import weight 0.00
Epoch 148 Iter 6 subLoss 7186.9 multi 1.00 import weight 0.00
Epoch 148 Iter 7 subLoss 7993.5 multi 3.98 import weight 0.00
Epoch 148 Iter 8 subLoss 7251.6 multi 6.97 import weight 0.00
Epoch 148 Iter 9 subLoss 7032.1 multi -4.97 import weight 0.00
Epoch 148 Iter 10 subLoss 8561.0 multi 1.00 import weight 0.00
Epoch 148 Iter 11 subLoss 7568.2 multi 3.99 import weight 0.00
Epoch 148 Acc: 94.57 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 756 train Loss: 7046.2 test Loss: 921.3
Epoch 149 Iter 0 subLoss 7057.2 multi 12.94 import weight 1.00
Epoch 149 Iter 1 subLoss 6918.7 multi 1.00 import weight 0.00
Epoch 149 Iter 2 subLoss 6679.7 multi 6.97 import weight 0.00
Epoch 149 Iter 3 subLoss 6256.7 multi 3.99 import weight 0.00
Epoch 149 Iter 4 subLoss 6336.0 multi -1.99 import weight 0.00
Epoch 149 Iter 5 subLoss 6258.3 multi 6.97 import weight 1.00
Epoch 149 Iter 6 subLoss 6977.8 multi 3.98 import weight 0.00
Epoch 149 Iter 7 subLoss 6421.9 multi 1.00 import weight 0.00
Epoch 149 Iter 8 subLoss 5895.0 multi 1.00 import weight 0.00
Epoch 149 Iter 9 subLoss 5747.4 multi 1.00 import weight 0.00
Epoch 149 Iter 10 subLoss 5757.6 multi 3.98 import weight 0.00
Epoch 149 Iter 11 subLoss 5911.8 multi 3.99 import weight 0.00
Epoch 149 Acc: 95.17 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 591 train Loss: 6103.4 test Loss: 786.0
Epoch 150 Iter 0 subLoss 5910.9 multi 6.97 import weight 0.00
Epoch 150 Iter 1 subLoss 6258.4 multi 9.96 import weight 1.00
Epoch 150 Iter 2 subLoss 6417.0 multi -4.97 import weight 0.00
Epoch 150 Iter 3 subLoss 13234.5 multi 1.00 import weight 0.00
Epoch 150 Iter 4 subLoss 7013.6 multi -1.98 import weight 0.00
Epoch 150 Iter 5 subLoss 8047.2 multi 3.98 import weight 0.00
Epoch 150 Iter 6 subLoss 7528.8 multi 9.96 import weight 0.00
Epoch 150 Iter 7 subLoss 8526.0 multi -7.96 import weight 0.00
Epoch 150 Iter 8 subLoss 103577.3 multi 1.00 import weight 0.00
Epoch 150 Iter 9 subLoss 15497.7 multi 3.98 import weight 0.00
Epoch 150 Iter 10 subLoss 7550.5 multi 1.00 import weight 0.00
Epoch 150 Iter 11 subLoss 7184.0 multi 3.99 import weight 0.00
Epoch 150 Acc: 94.55 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 718 train Loss: 6830.0 test Loss: 876.0
Epoch 151 Iter 0 subLoss 7142.9 multi 3.99 import weight 0.00
Epoch 151 Iter 1 subLoss 6195.2 multi 6.97 import weight 0.00
Epoch 151 Iter 2 subLoss 7346.2 multi 12.94 import weight 1.00
Epoch 151 Iter 3 subLoss 6569.0 multi 3.99 import weight 0.00
Epoch 151 Iter 4 subLoss 5349.1 multi 6.97 import weight 0.00
Epoch 151 Iter 5 subLoss 6017.5 multi 6.97 import weight 0.00
Epoch 151 Iter 6 subLoss 5513.3 multi 3.99 import weight 0.00
Epoch 151 Iter 7 subLoss 5181.2 multi -4.97 import weight 0.00
Epoch 151 Iter 8 subLoss 5425.7 multi 3.99 import weight 0.00
Epoch 151 Iter 9 subLoss 5742.5 multi 3.99 import weight 0.00
Epoch 151 Iter 10 subLoss 5245.7 multi 1.00 import weight 0.00
Epoch 151 Iter 11 subLoss 6015.3 multi 9.96 import weight 0.00
Epoch 151 Acc: 95.15 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 601 train Loss: 5742.0 test Loss: 724.7
Epoch 152 Iter 0 subLoss 5757.9 multi 3.99 import weight 0.00
Epoch 152 Iter 1 subLoss 5263.0 multi -4.97 import weight 0.00
Epoch 152 Iter 2 subLoss 5248.7 multi 3.99 import weight 0.00
Epoch 152 Iter 3 subLoss 5436.1 multi -4.97 import weight 0.00
Epoch 152 Iter 4 subLoss 6152.8 multi 1.00 import weight 0.00
Epoch 152 Iter 5 subLoss 6649.5 multi 3.99 import weight 0.00
Epoch 152 Iter 6 subLoss 6106.9 multi 9.96 import weight 0.00
Epoch 152 Iter 7 subLoss 5257.5 multi 1.00 import weight 0.00
Epoch 152 Iter 8 subLoss 5354.1 multi -7.96 import weight 0.00
Epoch 152 Iter 9 subLoss 7788.3 multi 1.00 import weight 0.00
Epoch 152 Iter 10 subLoss 6347.7 multi -1.99 import weight 0.00
Epoch 152 Iter 11 subLoss 7232.8 multi 1.00 import weight 0.00
Epoch 152 Acc: 93.13 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 723 train Loss: 6538.3 test Loss: 984.1
Epoch 153 Iter 0 subLoss 6213.6 multi 1.00 import weight 0.00
Epoch 153 Iter 1 subLoss 5767.9 multi -4.97 import weight 0.00
Epoch 153 Iter 2 subLoss 7920.8 multi 3.99 import weight 0.00
Epoch 153 Iter 3 subLoss 6020.0 multi -10.94 import weight 0.00
Epoch 153 Iter 4 subLoss 7316.3 multi 12.94 import weight 0.00
Epoch 153 Iter 5 subLoss 7677.8 multi 1.00 import weight 0.00
Epoch 153 Iter 6 subLoss 5992.8 multi 1.00 import weight 0.00
Epoch 153 Iter 7 subLoss 6018.3 multi 12.94 import weight 0.00
Epoch 153 Iter 8 subLoss 8494.7 multi -1.98 import weight 0.00
Epoch 153 Iter 9 subLoss 13617.2 multi -1.98 import weight 0.00
Epoch 153 Iter 10 subLoss 28825.7 multi 1.00 import weight 0.00
Epoch 153 Iter 11 subLoss 10909.8 multi -1.99 import weight 0.00
Epoch 153 Acc: 77.97 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 1090 train Loss: 18871.6 test Loss: 3215.0
Epoch 154 Iter 0 subLoss 19658.4 multi -1.99 import weight 0.00
Epoch 154 Iter 1 subLoss 45366.6 multi 1.00 import weight 0.00
Epoch 154 Iter 2 subLoss 17925.3 multi -1.99 import weight 0.00
Epoch 154 Iter 3 subLoss 35479.7 multi 1.00 import weight 0.00
Epoch 154 Iter 4 subLoss 19367.0 multi -1.98 import weight 0.00
Epoch 154 Iter 5 subLoss 31173.9 multi 3.99 import weight 0.00
Epoch 154 Iter 6 subLoss 11524.1 multi 1.00 import weight 0.00
Epoch 154 Iter 7 subLoss 10809.3 multi 1.00 import weight 0.00
Epoch 154 Iter 8 subLoss 9721.6 multi -1.99 import weight 0.00
Epoch 154 Iter 9 subLoss 10936.1 multi 1.00 import weight 0.00
Epoch 154 Iter 10 subLoss 10346.3 multi 1.00 import weight 0.00
Epoch 154 Iter 11 subLoss 10548.7 multi 6.97 import weight 0.00
Epoch 154 Acc: 95.10 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 1054 train Loss: 6331.9 test Loss: 846.0
Epoch 155 Iter 0 subLoss 6118.2 multi -13.93 import weight 0.00
Epoch 155 Iter 1 subLoss 8609.1 multi 1.00 import weight 0.00
Epoch 155 Iter 2 subLoss 8045.4 multi 6.97 import weight 0.00
Epoch 155 Iter 3 subLoss 6630.0 multi -13.93 import weight 0.00
Epoch 155 Iter 4 subLoss 7565.7 multi 3.98 import weight 0.00
Epoch 155 Iter 5 subLoss 6627.1 multi 9.96 import weight 1.00
Epoch 155 Iter 6 subLoss 6567.2 multi 6.97 import weight 0.00
Epoch 155 Iter 7 subLoss 5416.5 multi -1.99 import weight 0.00
Epoch 155 Iter 8 subLoss 6234.0 multi 6.97 import weight 0.00
Epoch 155 Iter 9 subLoss 5234.4 multi -1.99 import weight 0.00
Epoch 155 Iter 10 subLoss 6260.6 multi -16.91 import weight 0.00
Epoch 155 Iter 11 subLoss 15588.0 multi -1.99 import weight 0.00
Epoch 155 Acc: 63.30 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 1558 train Loss: 44689.9 test Loss: 7753.7
Epoch 156 Iter 0 subLoss 46220.9 multi 1.00 import weight 0.00
Epoch 156 Iter 1 subLoss 11958.5 multi 1.00 import weight 0.00
Epoch 156 Iter 2 subLoss 10224.9 multi -1.99 import weight 0.00
Epoch 156 Iter 3 subLoss 13704.7 multi -1.99 import weight 0.00
Epoch 156 Iter 4 subLoss 20111.8 multi 1.00 import weight 0.00
Epoch 156 Iter 5 subLoss 15280.3 multi 1.00 import weight 0.00
Epoch 156 Iter 6 subLoss 11438.7 multi -4.97 import weight 0.00
Epoch 156 Iter 7 subLoss 25074.7 multi 1.00 import weight 0.00
Epoch 156 Iter 8 subLoss 18922.5 multi 6.97 import weight 0.00
Epoch 156 Iter 9 subLoss 11012.2 multi 1.00 import weight 0.00
Epoch 156 Iter 10 subLoss 9642.6 multi -1.99 import weight 0.00
Epoch 156 Iter 11 subLoss 10637.0 multi -4.97 import weight 0.00
Epoch 156 Acc: 78.15 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 1063 train Loss: 17724.0 test Loss: 3315.0
Epoch 157 Iter 0 subLoss 17954.2 multi 1.00 import weight 0.00
Epoch 157 Iter 1 subLoss 14802.4 multi 1.00 import weight 0.00
Epoch 157 Iter 2 subLoss 12902.2 multi -1.99 import weight 0.00
Epoch 157 Iter 3 subLoss 16427.6 multi 1.00 import weight 0.00
Epoch 157 Iter 4 subLoss 13932.7 multi -1.99 import weight 0.00
Epoch 157 Iter 5 subLoss 17543.8 multi 1.00 import weight 0.00
Epoch 157 Iter 6 subLoss 15260.0 multi -4.97 import weight 0.00
Epoch 157 Iter 7 subLoss 29145.1 multi 1.00 import weight 0.00
Epoch 157 Iter 8 subLoss 22971.7 multi -1.99 import weight 0.00
Epoch 157 Iter 9 subLoss 30810.6 multi -1.99 import weight 0.00
Epoch 157 Iter 10 subLoss 46840.7 multi 6.97 import weight 0.00
Epoch 157 Iter 11 subLoss 12752.3 multi -1.99 import weight 0.00
Epoch 157 Acc: 87.59 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 1275 train Loss: 14368.5 test Loss: 2446.7
Epoch 158 Iter 0 subLoss 14543.9 multi -1.99 import weight 0.00
Epoch 158 Iter 1 subLoss 16270.2 multi 1.00 import weight 0.00
Epoch 158 Iter 2 subLoss 15320.6 multi 6.97 import weight 0.00
Epoch 158 Iter 3 subLoss 10312.2 multi 1.00 import weight 0.00
Epoch 158 Iter 4 subLoss 9746.8 multi -1.99 import weight 0.00
Epoch 158 Iter 5 subLoss 10405.5 multi 1.00 import weight 0.00
Epoch 158 Iter 6 subLoss 9979.5 multi -1.99 import weight 0.00
Epoch 158 Iter 7 subLoss 10818.0 multi -1.98 import weight 0.00
Epoch 158 Iter 8 subLoss 11473.8 multi 1.00 import weight 0.00
Epoch 158 Iter 9 subLoss 10716.6 multi 3.99 import weight 0.00
Epoch 158 Iter 10 subLoss 9011.6 multi -1.99 import weight 0.00
Epoch 158 Iter 11 subLoss 9945.9 multi 1.00 import weight 0.00
Epoch 158 Acc: 93.01 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 994 train Loss: 9846.5 test Loss: 1441.2
Epoch 159 Iter 0 subLoss 9598.1 multi -1.99 import weight 0.00
Epoch 159 Iter 1 subLoss 10110.7 multi -1.99 import weight 0.00
Epoch 159 Iter 2 subLoss 10649.4 multi -1.99 import weight 0.00
Epoch 159 Iter 3 subLoss 12066.8 multi 1.00 import weight 0.00
Epoch 159 Iter 4 subLoss 11275.4 multi 3.99 import weight 0.00
Epoch 159 Iter 5 subLoss 9839.3 multi 1.00 import weight 0.00
Epoch 159 Iter 6 subLoss 9772.4 multi 1.00 import weight 0.00
Epoch 159 Iter 7 subLoss 9279.1 multi 12.94 import weight 0.00
Epoch 159 Iter 8 subLoss 8217.6 multi -4.97 import weight 0.00
Epoch 159 Iter 9 subLoss 9090.4 multi 1.00 import weight 0.00
Epoch 159 Iter 10 subLoss 7765.6 multi 1.00 import weight 0.00
Epoch 159 Iter 11 subLoss 7761.0 multi 3.99 import weight 0.00
Epoch 159 Acc: 94.90 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 776 train Loss: 7215.3 test Loss: 895.7
Epoch 160 Iter 0 subLoss 7313.0 multi 15.93 import weight 1.00
Epoch 160 Iter 1 subLoss 6458.3 multi 3.98 import weight 0.00
Epoch 160 Iter 2 subLoss 6441.5 multi -1.98 import weight 0.00
Epoch 160 Iter 3 subLoss 6589.2 multi -4.97 import weight 0.00
Epoch 160 Iter 4 subLoss 6948.3 multi -4.97 import weight 0.00
Epoch 160 Iter 5 subLoss 7381.0 multi 1.00 import weight 0.00
Epoch 160 Iter 6 subLoss 6694.9 multi 1.00 import weight 0.00
Epoch 160 Iter 7 subLoss 6506.9 multi -13.93 import weight 0.00
Epoch 160 Iter 8 subLoss 9656.8 multi 1.00 import weight 0.00
Epoch 160 Iter 9 subLoss 9195.1 multi -1.99 import weight 0.00
Epoch 160 Iter 10 subLoss 11252.4 multi 1.00 import weight 0.00
Epoch 160 Iter 11 subLoss 8687.3 multi 1.00 import weight 0.00
Epoch 160 Acc: 92.29 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 868 train Loss: 8283.9 test Loss: 1170.9
Epoch 161 Iter 0 subLoss 7917.6 multi -1.99 import weight 0.00
Epoch 161 Iter 1 subLoss 9132.5 multi -1.98 import weight 0.00
Epoch 161 Iter 2 subLoss 12081.7 multi -1.99 import weight 0.00
Epoch 161 Iter 3 subLoss 20396.4 multi 3.99 import weight 0.00
Epoch 161 Iter 4 subLoss 9315.2 multi 3.98 import weight 0.00
Epoch 161 Iter 5 subLoss 8313.5 multi -1.99 import weight 0.00
Epoch 161 Iter 6 subLoss 8328.4 multi -1.99 import weight 0.00
Epoch 161 Iter 7 subLoss 8741.2 multi -1.99 import weight 0.00
Epoch 161 Iter 8 subLoss 9205.5 multi 1.00 import weight 0.00
Epoch 161 Iter 9 subLoss 8877.2 multi 1.00 import weight 0.00
Epoch 161 Iter 10 subLoss 8080.6 multi 1.00 import weight 0.00
Epoch 161 Iter 11 subLoss 7869.4 multi -4.97 import weight 0.00
Epoch 161 Acc: 93.19 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 786 train Loss: 9415.3 test Loss: 1388.9
Epoch 162 Iter 0 subLoss 9636.0 multi 3.99 import weight 0.00
Epoch 162 Iter 1 subLoss 8077.5 multi 1.00 import weight 0.00
Epoch 162 Iter 2 subLoss 7717.5 multi -1.99 import weight 0.00
Epoch 162 Iter 3 subLoss 8056.8 multi 1.00 import weight 0.00
Epoch 162 Iter 4 subLoss 7659.3 multi -1.99 import weight 0.00
Epoch 162 Iter 5 subLoss 8773.6 multi 3.99 import weight 0.00
Epoch 162 Iter 6 subLoss 7971.2 multi 1.00 import weight 0.00
Epoch 162 Iter 7 subLoss 6890.7 multi 3.98 import weight 0.00
Epoch 162 Iter 8 subLoss 7061.5 multi -7.96 import weight 0.00
Epoch 162 Iter 9 subLoss 8636.2 multi 1.00 import weight 0.00
Epoch 162 Iter 10 subLoss 8529.4 multi -4.97 import weight 0.00
Epoch 162 Iter 11 subLoss 8877.3 multi 3.98 import weight 0.00
Epoch 162 Acc: 94.51 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 887 train Loss: 8106.4 test Loss: 1112.7
Epoch 163 Iter 0 subLoss 7436.5 multi 1.00 import weight 0.00
Epoch 163 Iter 1 subLoss 8243.0 multi 1.00 import weight 0.00
Epoch 163 Iter 2 subLoss 8763.8 multi 1.00 import weight 0.00
Epoch 163 Iter 3 subLoss 6882.5 multi 3.99 import weight 0.00
Epoch 163 Iter 4 subLoss 6731.1 multi 9.96 import weight 0.00
Epoch 163 Iter 5 subLoss 6157.5 multi 3.98 import weight 0.00
Epoch 163 Iter 6 subLoss 7454.5 multi -1.98 import weight 0.00
Epoch 163 Iter 7 subLoss 6726.5 multi -1.99 import weight 0.00
Epoch 163 Iter 8 subLoss 6482.8 multi -1.98 import weight 0.00
Epoch 163 Iter 9 subLoss 6955.2 multi 1.00 import weight 0.00
Epoch 163 Iter 10 subLoss 7421.8 multi 1.00 import weight 0.00
Epoch 163 Iter 11 subLoss 6616.5 multi 6.97 import weight 0.00
Epoch 163 Acc: 95.25 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 661 train Loss: 6572.7 test Loss: 848.9
Epoch 164 Iter 0 subLoss 6496.2 multi 9.96 import weight 1.00
Epoch 164 Iter 1 subLoss 6992.0 multi 3.99 import weight 0.00
Epoch 164 Iter 2 subLoss 6080.9 multi 3.99 import weight 0.00
Epoch 164 Iter 3 subLoss 6327.9 multi -1.98 import weight 0.00
Epoch 164 Iter 4 subLoss 5938.1 multi 3.99 import weight 0.00
Epoch 164 Iter 5 subLoss 6429.3 multi 1.00 import weight 0.00
Epoch 164 Iter 6 subLoss 5332.4 multi 1.00 import weight 0.00
Epoch 164 Iter 7 subLoss 6981.0 multi -7.96 import weight 0.00
Epoch 164 Iter 8 subLoss 6134.5 multi 1.00 import weight 0.00
Epoch 164 Iter 9 subLoss 6284.9 multi 1.00 import weight 0.00
Epoch 164 Iter 10 subLoss 6294.1 multi -1.99 import weight 0.00
Epoch 164 Iter 11 subLoss 6069.5 multi -1.99 import weight 0.00
Epoch 164 Acc: 94.80 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 606 train Loss: 6755.6 test Loss: 852.5
Epoch 165 Iter 0 subLoss 6727.6 multi 1.00 import weight 0.00
Epoch 165 Iter 1 subLoss 6374.1 multi 3.99 import weight 0.00
Epoch 165 Iter 2 subLoss 5908.0 multi -1.99 import weight 0.00
Epoch 165 Iter 3 subLoss 6094.4 multi -1.98 import weight 0.00
Epoch 165 Iter 4 subLoss 6699.4 multi 3.98 import weight 0.00
Epoch 165 Iter 5 subLoss 6872.1 multi 1.00 import weight 0.00
Epoch 165 Iter 6 subLoss 6330.5 multi -1.98 import weight 0.00
Epoch 165 Iter 7 subLoss 6245.9 multi -1.99 import weight 0.00
Epoch 165 Iter 8 subLoss 5805.3 multi 3.98 import weight 0.00
Epoch 165 Iter 9 subLoss 5600.6 multi 3.99 import weight 0.00
Epoch 165 Iter 10 subLoss 5768.8 multi -1.99 import weight 0.00
Epoch 165 Iter 11 subLoss 6013.4 multi 15.93 import weight 1.00
Epoch 165 Acc: 94.82 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 15.93 Pidx 601 train Loss: 6789.1 test Loss: 867.4
Epoch 166 Iter 0 subLoss 6599.4 multi -1.99 import weight 0.00
Epoch 166 Iter 1 subLoss 7314.5 multi 18.91 import weight 1.00
Epoch 166 Iter 2 subLoss 29248.4 multi 3.99 import weight 0.00
Epoch 166 Iter 3 subLoss 13304.8 multi -1.99 import weight 0.00
Epoch 166 Iter 4 subLoss 19781.4 multi 1.00 import weight 0.00
Epoch 166 Iter 5 subLoss 13851.6 multi -1.99 import weight 0.00
Epoch 166 Iter 6 subLoss 18592.5 multi 1.00 import weight 0.00
Epoch 166 Iter 7 subLoss 13845.2 multi -4.97 import weight 0.00
Epoch 166 Iter 8 subLoss 33100.1 multi 1.00 import weight 0.00
Epoch 166 Iter 9 subLoss 19011.6 multi -1.98 import weight 0.00
Epoch 166 Iter 10 subLoss 25570.6 multi 1.00 import weight 0.00
Epoch 166 Iter 11 subLoss 19358.7 multi 6.97 import weight 0.00
Epoch 166 Acc: 90.23 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 1935 train Loss: 11114.5 test Loss: 1649.3
Epoch 167 Iter 0 subLoss 11333.0 multi 1.00 import weight 0.00
Epoch 167 Iter 1 subLoss 10468.2 multi -1.99 import weight 0.00
Epoch 167 Iter 2 subLoss 10733.4 multi 3.99 import weight 0.00
Epoch 167 Iter 3 subLoss 10068.9 multi 1.00 import weight 0.00
Epoch 167 Iter 4 subLoss 8693.3 multi -1.98 import weight 0.00
Epoch 167 Iter 5 subLoss 9491.2 multi -1.98 import weight 0.00
Epoch 167 Iter 6 subLoss 10273.5 multi 1.00 import weight 0.00
Epoch 167 Iter 7 subLoss 9586.4 multi 3.99 import weight 0.00
Epoch 167 Iter 8 subLoss 8582.1 multi -1.99 import weight 0.00
Epoch 167 Iter 9 subLoss 8480.8 multi -1.99 import weight 0.00
Epoch 167 Iter 10 subLoss 10119.8 multi 1.00 import weight 0.00
Epoch 167 Iter 11 subLoss 8750.7 multi -7.96 import weight 0.00
Epoch 167 Acc: 88.73 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 875 train Loss: 12434.4 test Loss: 1870.0
Epoch 168 Iter 0 subLoss 12339.4 multi 1.00 import weight 0.00
Epoch 168 Iter 1 subLoss 11784.6 multi 1.00 import weight 0.00
Epoch 168 Iter 2 subLoss 10469.1 multi 1.00 import weight 0.00
Epoch 168 Iter 3 subLoss 10635.5 multi -1.98 import weight 0.00
Epoch 168 Iter 4 subLoss 11028.8 multi -1.98 import weight 0.00
Epoch 168 Iter 5 subLoss 12336.9 multi 3.99 import weight 0.00
Epoch 168 Iter 6 subLoss 11207.8 multi -1.99 import weight 0.00
Epoch 168 Iter 7 subLoss 12134.9 multi -1.99 import weight 0.00
Epoch 168 Iter 8 subLoss 13464.5 multi 1.00 import weight 0.00
Epoch 168 Iter 9 subLoss 12211.0 multi -1.99 import weight 0.00
Epoch 168 Iter 10 subLoss 12671.0 multi 3.99 import weight 0.00
Epoch 168 Iter 11 subLoss 10536.6 multi -1.99 import weight 0.00
Epoch 168 Acc: 89.57 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 1053 train Loss: 11820.1 test Loss: 1714.0
Epoch 169 Iter 0 subLoss 11940.5 multi 6.97 import weight 0.00
Epoch 169 Iter 1 subLoss 8640.5 multi 3.98 import weight 0.00
Epoch 169 Iter 2 subLoss 8678.9 multi 1.00 import weight 0.00
Epoch 169 Iter 3 subLoss 8012.2 multi 6.97 import weight 0.00
Epoch 169 Iter 4 subLoss 6934.8 multi 6.97 import weight 0.00
Epoch 169 Iter 5 subLoss 7020.2 multi 1.00 import weight 0.00
Epoch 169 Iter 6 subLoss 6136.7 multi 3.99 import weight 0.00
Epoch 169 Iter 7 subLoss 6569.5 multi 9.96 import weight 0.00
Epoch 169 Iter 8 subLoss 6238.6 multi 9.96 import weight 0.00
Epoch 169 Iter 9 subLoss 6287.5 multi 3.99 import weight 0.00
Epoch 169 Iter 10 subLoss 6331.5 multi 1.00 import weight 0.00
Epoch 169 Iter 11 subLoss 5484.2 multi 3.98 import weight 0.00
Epoch 169 Acc: 95.37 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 548 train Loss: 5965.5 test Loss: 757.4
Epoch 170 Iter 0 subLoss 5784.4 multi -4.97 import weight 0.00
Epoch 170 Iter 1 subLoss 5881.1 multi -1.99 import weight 0.00
Epoch 170 Iter 2 subLoss 6685.4 multi -4.97 import weight 0.00
Epoch 170 Iter 3 subLoss 8208.8 multi 3.99 import weight 0.00
Epoch 170 Iter 4 subLoss 5770.0 multi 1.00 import weight 0.00
Epoch 170 Iter 5 subLoss 5893.4 multi 1.00 import weight 0.00
Epoch 170 Iter 6 subLoss 5922.2 multi -7.96 import weight 0.00
Epoch 170 Iter 7 subLoss 6142.2 multi -1.98 import weight 0.00
Epoch 170 Iter 8 subLoss 6068.4 multi 1.00 import weight 0.00
Epoch 170 Iter 9 subLoss 6095.7 multi 1.00 import weight 0.00
Epoch 170 Iter 10 subLoss 6510.1 multi -1.99 import weight 0.00
Epoch 170 Iter 11 subLoss 6328.6 multi 1.00 import weight 0.00
Epoch 170 Acc: 95.29 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 632 train Loss: 6470.7 test Loss: 800.4
Epoch 171 Iter 0 subLoss 7189.4 multi 6.97 import weight 0.00
Epoch 171 Iter 1 subLoss 5898.3 multi 3.98 import weight 0.00
Epoch 171 Iter 2 subLoss 5772.6 multi -7.96 import weight 0.00
Epoch 171 Iter 3 subLoss 5926.0 multi -4.97 import weight 0.00
Epoch 171 Iter 4 subLoss 6822.7 multi 1.00 import weight 0.00
Epoch 171 Iter 5 subLoss 5993.8 multi 3.99 import weight 0.00
Epoch 171 Iter 6 subLoss 5263.7 multi -4.97 import weight 0.00
Epoch 171 Iter 7 subLoss 6209.4 multi -4.97 import weight 0.00
Epoch 171 Iter 8 subLoss 6576.6 multi -4.97 import weight 0.00
Epoch 171 Iter 9 subLoss 8636.4 multi 3.99 import weight 0.00
Epoch 171 Iter 10 subLoss 7010.5 multi 1.00 import weight 0.00
Epoch 171 Iter 11 subLoss 6145.1 multi 1.00 import weight 0.00
Epoch 171 Acc: 94.86 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 614 train Loss: 6519.3 test Loss: 853.1
Epoch 172 Iter 0 subLoss 6425.2 multi 3.98 import weight 0.00
Epoch 172 Iter 1 subLoss 5996.1 multi 6.97 import weight 0.00
Epoch 172 Iter 2 subLoss 6512.4 multi 1.00 import weight 0.00
Epoch 172 Iter 3 subLoss 6250.6 multi 9.96 import weight 1.00
Epoch 172 Iter 4 subLoss 5579.2 multi -1.99 import weight 0.00
Epoch 172 Iter 5 subLoss 5072.6 multi -1.99 import weight 0.00
Epoch 172 Iter 6 subLoss 5936.5 multi 1.00 import weight 0.00
Epoch 172 Iter 7 subLoss 5484.6 multi 6.97 import weight 0.00
Epoch 172 Iter 8 subLoss 6111.3 multi -10.94 import weight 0.00
Epoch 172 Iter 9 subLoss 6221.3 multi -4.97 import weight 0.00
Epoch 172 Iter 10 subLoss 7479.6 multi 6.97 import weight 0.00
Epoch 172 Iter 11 subLoss 6843.3 multi -1.98 import weight 0.00
Epoch 172 Acc: 94.38 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 684 train Loss: 6880.0 test Loss: 899.3
Epoch 173 Iter 0 subLoss 7382.8 multi 3.99 import weight 0.00
Epoch 173 Iter 1 subLoss 5698.3 multi 1.00 import weight 0.00
Epoch 173 Iter 2 subLoss 5865.3 multi 1.00 import weight 0.00
Epoch 173 Iter 3 subLoss 5667.4 multi 1.00 import weight 0.00
Epoch 173 Iter 4 subLoss 5918.2 multi 6.97 import weight 0.00
Epoch 173 Iter 5 subLoss 5539.9 multi 3.99 import weight 0.00
Epoch 173 Iter 6 subLoss 5666.3 multi 3.98 import weight 0.00
Epoch 173 Iter 7 subLoss 6315.2 multi 3.98 import weight 0.00
Epoch 173 Iter 8 subLoss 5506.4 multi -1.99 import weight 0.00
Epoch 173 Iter 9 subLoss 6151.0 multi 1.00 import weight 0.00
Epoch 173 Iter 10 subLoss 5468.7 multi 1.00 import weight 0.00
Epoch 173 Iter 11 subLoss 5623.7 multi 3.98 import weight 0.00
Epoch 173 Acc: 95.64 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 562 train Loss: 5578.3 test Loss: 717.4
Epoch 174 Iter 0 subLoss 5250.4 multi 3.99 import weight 0.00
Epoch 174 Iter 1 subLoss 5610.0 multi -1.98 import weight 0.00
Epoch 174 Iter 2 subLoss 5134.5 multi -4.97 import weight 0.00
Epoch 174 Iter 3 subLoss 5389.1 multi -7.96 import weight 0.00
Epoch 174 Iter 4 subLoss 7615.1 multi 1.00 import weight 0.00
Epoch 174 Iter 5 subLoss 6528.7 multi -4.97 import weight 0.00
Epoch 174 Iter 6 subLoss 9080.9 multi 6.97 import weight 0.00
Epoch 174 Iter 7 subLoss 6434.5 multi -1.99 import weight 0.00
Epoch 174 Iter 8 subLoss 7891.5 multi 1.00 import weight 0.00
Epoch 174 Iter 9 subLoss 7071.8 multi -1.99 import weight 0.00
Epoch 174 Iter 10 subLoss 8186.3 multi 3.99 import weight 0.00
Epoch 174 Iter 11 subLoss 6083.6 multi 6.97 import weight 0.00
Epoch 174 Acc: 95.33 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 608 train Loss: 5836.7 test Loss: 727.7
Epoch 175 Iter 0 subLoss 5835.7 multi -1.99 import weight 0.00
Epoch 175 Iter 1 subLoss 5349.3 multi 6.97 import weight 0.00
Epoch 175 Iter 2 subLoss 5350.2 multi -7.96 import weight 0.00
Epoch 175 Iter 3 subLoss 5616.0 multi 1.00 import weight 0.00
Epoch 175 Iter 4 subLoss 6282.9 multi 6.97 import weight 0.00
Epoch 175 Iter 5 subLoss 5717.5 multi -1.98 import weight 0.00
Epoch 175 Iter 6 subLoss 5777.0 multi -4.97 import weight 0.00
Epoch 175 Iter 7 subLoss 6366.1 multi 1.00 import weight 0.00
Epoch 175 Iter 8 subLoss 5781.0 multi -7.96 import weight 0.00
Epoch 175 Iter 9 subLoss 8493.1 multi -1.99 import weight 0.00
Epoch 175 Iter 10 subLoss 10946.8 multi -1.99 import weight 0.00
Epoch 175 Iter 11 subLoss 14984.0 multi -1.99 import weight 0.00
Epoch 175 Acc: 79.30 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 1498 train Loss: 29351.4 test Loss: 5185.5
Epoch 176 Iter 0 subLoss 28790.6 multi 1.00 import weight 0.00
Epoch 176 Iter 1 subLoss 16327.8 multi 9.96 import weight 0.00
Epoch 176 Iter 2 subLoss 11433.0 multi -1.98 import weight 0.00
Epoch 176 Iter 3 subLoss 16042.0 multi 1.00 import weight 0.00
Epoch 176 Iter 4 subLoss 12564.0 multi -1.99 import weight 0.00
Epoch 176 Iter 5 subLoss 17319.6 multi -1.99 import weight 0.00
Epoch 176 Iter 6 subLoss 32623.7 multi 1.00 import weight 0.00
Epoch 176 Iter 7 subLoss 14191.7 multi 9.96 import weight 0.00
Epoch 176 Iter 8 subLoss 8400.9 multi 1.00 import weight 0.00
Epoch 176 Iter 9 subLoss 8842.7 multi 6.97 import weight 0.00
Epoch 176 Iter 10 subLoss 6643.2 multi 3.98 import weight 0.00
Epoch 176 Iter 11 subLoss 6461.7 multi -4.97 import weight 0.00
Epoch 176 Acc: 94.63 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 646 train Loss: 6592.9 test Loss: 890.1
Epoch 177 Iter 0 subLoss 6722.2 multi 3.98 import weight 0.00
Epoch 177 Iter 1 subLoss 6156.6 multi 3.99 import weight 0.00
Epoch 177 Iter 2 subLoss 5524.5 multi -4.97 import weight 0.00
Epoch 177 Iter 3 subLoss 6347.3 multi -4.97 import weight 0.00
Epoch 177 Iter 4 subLoss 6429.0 multi 6.97 import weight 0.00
Epoch 177 Iter 5 subLoss 5452.3 multi 1.00 import weight 0.00
Epoch 177 Iter 6 subLoss 6269.5 multi -16.91 import weight 0.00
Epoch 177 Iter 7 subLoss 6356.5 multi -4.97 import weight 0.00
Epoch 177 Iter 8 subLoss 7824.6 multi -1.99 import weight 0.00
Epoch 177 Iter 9 subLoss 8753.0 multi -4.97 import weight 0.00
Epoch 177 Iter 10 subLoss 18337.0 multi -1.99 import weight 0.00
Epoch 177 Iter 11 subLoss 146846.5 multi 1.00 import weight 0.00
Epoch 177 Acc: 90.47 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 14684 train Loss: 10801.3 test Loss: 1545.9
Epoch 178 Iter 0 subLoss 10162.4 multi 6.97 import weight 0.00
Epoch 178 Iter 1 subLoss 7321.4 multi -19.90 import weight 0.00
Epoch 178 Iter 2 subLoss 12808.3 multi 3.99 import weight 0.00
Epoch 178 Iter 3 subLoss 9787.2 multi -4.97 import weight 0.00
Epoch 178 Iter 4 subLoss 12266.1 multi 1.00 import weight 0.00
Epoch 178 Iter 5 subLoss 10947.2 multi 1.00 import weight 0.00
Epoch 178 Iter 6 subLoss 10525.7 multi 1.00 import weight 0.00
Epoch 178 Iter 7 subLoss 9957.0 multi 3.98 import weight 0.00
Epoch 178 Iter 8 subLoss 8928.8 multi 1.00 import weight 0.00
Epoch 178 Iter 9 subLoss 8528.1 multi -1.99 import weight 0.00
Epoch 178 Iter 10 subLoss 8964.6 multi -4.97 import weight 0.00
Epoch 178 Iter 11 subLoss 10627.0 multi 6.97 import weight 0.00
Epoch 178 Acc: 93.05 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 1062 train Loss: 8363.2 test Loss: 1127.0
Epoch 179 Iter 0 subLoss 7667.1 multi -1.99 import weight 0.00
Epoch 179 Iter 1 subLoss 8672.1 multi 3.98 import weight 0.00
Epoch 179 Iter 2 subLoss 7381.9 multi 6.97 import weight 0.00
Epoch 179 Iter 3 subLoss 7360.4 multi 3.99 import weight 0.00
Epoch 179 Iter 4 subLoss 6789.9 multi 1.00 import weight 0.00
Epoch 179 Iter 5 subLoss 7168.9 multi -1.98 import weight 0.00
Epoch 179 Iter 6 subLoss 7017.0 multi 3.99 import weight 0.00
Epoch 179 Iter 7 subLoss 7108.1 multi -1.98 import weight 0.00
Epoch 179 Iter 8 subLoss 6905.6 multi -4.97 import weight 0.00
Epoch 179 Iter 9 subLoss 6547.0 multi 1.00 import weight 0.00
Epoch 179 Iter 10 subLoss 7201.2 multi 3.99 import weight 0.00
Epoch 179 Iter 11 subLoss 7406.7 multi 1.00 import weight 0.00
Epoch 179 Acc: 94.30 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 740 train Loss: 7011.0 test Loss: 900.6
Epoch 180 Iter 0 subLoss 6790.0 multi 3.98 import weight 0.00
Epoch 180 Iter 1 subLoss 6642.3 multi 6.97 import weight 0.00
Epoch 180 Iter 2 subLoss 6878.4 multi 3.99 import weight 0.00
Epoch 180 Iter 3 subLoss 5949.3 multi -4.97 import weight 0.00
Epoch 180 Iter 4 subLoss 6656.8 multi -7.96 import weight 0.00
Epoch 180 Iter 5 subLoss 6458.4 multi 3.99 import weight 0.00
Epoch 180 Iter 6 subLoss 6730.8 multi 3.99 import weight 0.00
Epoch 180 Iter 7 subLoss 6642.7 multi 9.96 import weight 0.00
Epoch 180 Iter 8 subLoss 6620.4 multi 9.96 import weight 1.00
Epoch 180 Iter 9 subLoss 5813.0 multi -4.97 import weight 0.00
Epoch 180 Iter 10 subLoss 6813.9 multi -1.98 import weight 0.00
Epoch 180 Iter 11 subLoss 6382.2 multi 1.00 import weight 0.00
Epoch 180 Acc: 94.32 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 638 train Loss: 6563.0 test Loss: 896.8
Epoch 181 Iter 0 subLoss 6506.3 multi -13.93 import weight 0.00
Epoch 181 Iter 1 subLoss 11371.5 multi 1.00 import weight 0.00
Epoch 181 Iter 2 subLoss 9069.1 multi 3.99 import weight 0.00
Epoch 181 Iter 3 subLoss 6742.9 multi -7.96 import weight 0.00
Epoch 181 Iter 4 subLoss 8272.8 multi 1.00 import weight 0.00
Epoch 181 Iter 5 subLoss 7869.8 multi -1.99 import weight 0.00
Epoch 181 Iter 6 subLoss 8246.1 multi 3.98 import weight 0.00
Epoch 181 Iter 7 subLoss 6574.3 multi -1.99 import weight 0.00
Epoch 181 Iter 8 subLoss 7932.2 multi 1.00 import weight 0.00
Epoch 181 Iter 9 subLoss 7200.5 multi 6.97 import weight 0.00
Epoch 181 Iter 10 subLoss 6892.1 multi 3.99 import weight 0.00
Epoch 181 Iter 11 subLoss 6707.4 multi -1.99 import weight 0.00
Epoch 181 Acc: 94.32 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 670 train Loss: 6495.3 test Loss: 904.0
Epoch 182 Iter 0 subLoss 6562.5 multi 12.94 import weight 0.00
Epoch 182 Iter 1 subLoss 5912.6 multi 9.96 import weight 0.00
Epoch 182 Iter 2 subLoss 6263.9 multi -13.93 import weight 0.00
Epoch 182 Iter 3 subLoss 7214.9 multi -4.97 import weight 0.00
Epoch 182 Iter 4 subLoss 9952.8 multi 6.97 import weight 0.00
Epoch 182 Iter 5 subLoss 7067.0 multi -4.97 import weight 0.00
Epoch 182 Iter 6 subLoss 7972.6 multi 3.99 import weight 0.00
Epoch 182 Iter 7 subLoss 5458.2 multi 3.99 import weight 0.00
Epoch 182 Iter 8 subLoss 6697.1 multi 3.99 import weight 0.00
Epoch 182 Iter 9 subLoss 6143.4 multi 3.99 import weight 0.00
Epoch 182 Iter 10 subLoss 5597.0 multi -1.99 import weight 0.00
Epoch 182 Iter 11 subLoss 5878.1 multi 1.00 import weight 0.00
Epoch 182 Acc: 94.69 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 587 train Loss: 6026.0 test Loss: 802.2
Epoch 183 Iter 0 subLoss 6140.4 multi 6.97 import weight 0.00
Epoch 183 Iter 1 subLoss 5695.8 multi 3.98 import weight 0.00
Epoch 183 Iter 2 subLoss 5756.5 multi 6.97 import weight 0.00
Epoch 183 Iter 3 subLoss 5367.1 multi -4.97 import weight 0.00
Epoch 183 Iter 4 subLoss 6184.8 multi 1.00 import weight 0.00
Epoch 183 Iter 5 subLoss 5605.4 multi 3.98 import weight 0.00
Epoch 183 Iter 6 subLoss 5491.7 multi -7.96 import weight 0.00
Epoch 183 Iter 7 subLoss 6029.3 multi -13.93 import weight 0.00
Epoch 183 Iter 8 subLoss 6665.6 multi -4.97 import weight 0.00
Epoch 183 Iter 9 subLoss 7140.2 multi 6.97 import weight 0.00
Epoch 183 Iter 10 subLoss 5943.9 multi -1.99 import weight 0.00
Epoch 183 Iter 11 subLoss 6840.1 multi 1.00 import weight 0.00
Epoch 183 Acc: 94.73 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 684 train Loss: 6502.0 test Loss: 847.5
Epoch 184 Iter 0 subLoss 6823.2 multi 1.00 import weight 0.00
Epoch 184 Iter 1 subLoss 6403.5 multi 6.97 import weight 0.00
Epoch 184 Iter 2 subLoss 6461.6 multi -4.97 import weight 0.00
Epoch 184 Iter 3 subLoss 6158.3 multi 1.00 import weight 0.00
Epoch 184 Iter 4 subLoss 6309.9 multi -4.97 import weight 0.00
Epoch 184 Iter 5 subLoss 6611.1 multi 9.96 import weight 0.00
Epoch 184 Iter 6 subLoss 6115.3 multi -7.96 import weight 0.00
Epoch 184 Iter 7 subLoss 6712.3 multi -4.97 import weight 0.00
Epoch 184 Iter 8 subLoss 6722.2 multi 3.99 import weight 0.00
Epoch 184 Iter 9 subLoss 6683.7 multi -1.99 import weight 0.00
Epoch 184 Iter 10 subLoss 6077.1 multi -4.97 import weight 0.00
Epoch 184 Iter 11 subLoss 6996.1 multi 3.98 import weight 0.00
Epoch 184 Acc: 94.61 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 699 train Loss: 6349.8 test Loss: 817.4
Epoch 185 Iter 0 subLoss 6162.2 multi -16.91 import weight 0.00
Epoch 185 Iter 1 subLoss 8729.8 multi 3.99 import weight 0.00
Epoch 185 Iter 2 subLoss 6252.0 multi 12.94 import weight 1.00
Epoch 185 Iter 3 subLoss 6929.9 multi -4.97 import weight 0.00
Epoch 185 Iter 4 subLoss 5978.7 multi -1.99 import weight 0.00
Epoch 185 Iter 5 subLoss 6876.5 multi 6.97 import weight 0.00
Epoch 185 Iter 6 subLoss 6754.4 multi -1.99 import weight 0.00
Epoch 185 Iter 7 subLoss 5940.8 multi 1.00 import weight 0.00
Epoch 185 Iter 8 subLoss 6271.5 multi -1.99 import weight 0.00
Epoch 185 Iter 9 subLoss 6510.7 multi 1.00 import weight 0.00
Epoch 185 Iter 10 subLoss 6473.4 multi -1.99 import weight 0.00
Epoch 185 Iter 11 subLoss 6925.8 multi -1.98 import weight 0.00
Epoch 185 Acc: 94.18 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 692 train Loss: 6878.7 test Loss: 885.3
Epoch 186 Iter 0 subLoss 6930.5 multi 3.99 import weight 0.00
Epoch 186 Iter 1 subLoss 5873.5 multi 3.98 import weight 0.00
Epoch 186 Iter 2 subLoss 6590.2 multi 1.00 import weight 0.00
Epoch 186 Iter 3 subLoss 5872.3 multi 6.97 import weight 0.00
Epoch 186 Iter 4 subLoss 5530.4 multi 3.98 import weight 0.00
Epoch 186 Iter 5 subLoss 5793.3 multi -1.98 import weight 0.00
Epoch 186 Iter 6 subLoss 5841.9 multi -1.99 import weight 0.00
Epoch 186 Iter 7 subLoss 5509.7 multi -1.98 import weight 0.00
Epoch 186 Iter 8 subLoss 6481.7 multi -1.99 import weight 0.00
Epoch 186 Iter 9 subLoss 5734.7 multi 1.00 import weight 0.00
Epoch 186 Iter 10 subLoss 6427.4 multi 9.96 import weight 0.00
Epoch 186 Iter 11 subLoss 6236.7 multi 9.96 import weight 0.00
Epoch 186 Acc: 94.77 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 623 train Loss: 6347.8 test Loss: 794.0
Epoch 187 Iter 0 subLoss 5773.0 multi -1.98 import weight 0.00
Epoch 187 Iter 1 subLoss 6889.5 multi -1.99 import weight 0.00
Epoch 187 Iter 2 subLoss 7861.6 multi 1.00 import weight 0.00
Epoch 187 Iter 3 subLoss 7273.3 multi 6.97 import weight 0.00
Epoch 187 Iter 4 subLoss 5829.6 multi -1.98 import weight 0.00
Epoch 187 Iter 5 subLoss 6840.3 multi 3.99 import weight 0.00
Epoch 187 Iter 6 subLoss 6024.4 multi -10.94 import weight 0.00
Epoch 187 Iter 7 subLoss 6981.9 multi -4.97 import weight 0.00
Epoch 187 Iter 8 subLoss 8290.2 multi 1.00 import weight 0.00
Epoch 187 Iter 9 subLoss 7220.2 multi 1.00 import weight 0.00
Epoch 187 Iter 10 subLoss 6724.6 multi 6.97 import weight 0.00
Epoch 187 Iter 11 subLoss 5599.2 multi 1.00 import weight 0.00
Epoch 187 Acc: 94.65 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 559 train Loss: 6125.9 test Loss: 802.2
Epoch 188 Iter 0 subLoss 6283.8 multi 6.97 import weight 0.00
Epoch 188 Iter 1 subLoss 5886.5 multi -7.96 import weight 0.00
Epoch 188 Iter 2 subLoss 6132.6 multi 6.97 import weight 0.00
Epoch 188 Iter 3 subLoss 6382.1 multi 3.99 import weight 0.00
Epoch 188 Iter 4 subLoss 5241.7 multi 3.98 import weight 0.00
Epoch 188 Iter 5 subLoss 5627.8 multi 1.00 import weight 0.00
Epoch 188 Iter 6 subLoss 5733.3 multi 3.99 import weight 0.00
Epoch 188 Iter 7 subLoss 5947.7 multi 3.99 import weight 0.00
Epoch 188 Iter 8 subLoss 5532.2 multi 6.97 import weight 0.00
Epoch 188 Iter 9 subLoss 5562.9 multi 3.99 import weight 0.00
Epoch 188 Iter 10 subLoss 5615.5 multi 1.00 import weight 0.00
Epoch 188 Iter 11 subLoss 5325.4 multi -1.99 import weight 0.00
Epoch 188 Acc: 95.27 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 532 train Loss: 5582.7 test Loss: 723.4
Epoch 189 Iter 0 subLoss 4902.1 multi 3.99 import weight 0.00
Epoch 189 Iter 1 subLoss 5466.9 multi -1.98 import weight 0.00
Epoch 189 Iter 2 subLoss 5659.2 multi 3.99 import weight 0.00
Epoch 189 Iter 3 subLoss 5487.9 multi 9.96 import weight 0.00
Epoch 189 Iter 4 subLoss 5898.5 multi 3.99 import weight 0.00
Epoch 189 Iter 5 subLoss 5064.6 multi 3.99 import weight 0.00
Epoch 189 Iter 6 subLoss 4747.0 multi 3.99 import weight 0.00
Epoch 189 Iter 7 subLoss 4801.5 multi 3.99 import weight 0.00
Epoch 189 Iter 8 subLoss 5281.0 multi 3.99 import weight 0.00
Epoch 189 Iter 9 subLoss 5372.8 multi 6.97 import weight 0.00
Epoch 189 Iter 10 subLoss 5133.6 multi -1.98 import weight 0.00
Epoch 189 Iter 11 subLoss 5255.7 multi 3.99 import weight 0.00
Epoch 189 Acc: 95.37 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 525 train Loss: 5270.6 test Loss: 689.2
Epoch 190 Iter 0 subLoss 5833.5 multi -1.98 import weight 0.00
Epoch 190 Iter 1 subLoss 4803.6 multi 6.97 import weight 0.00
Epoch 190 Iter 2 subLoss 4806.4 multi 9.96 import weight 0.00
Epoch 190 Iter 3 subLoss 5050.0 multi -1.99 import weight 0.00
Epoch 190 Iter 4 subLoss 5427.3 multi 3.98 import weight 0.00
Epoch 190 Iter 5 subLoss 5626.2 multi 1.00 import weight 0.00
Epoch 190 Iter 6 subLoss 4973.4 multi 1.00 import weight 0.00
Epoch 190 Iter 7 subLoss 4666.4 multi 1.00 import weight 0.00
Epoch 190 Iter 8 subLoss 4680.2 multi 1.00 import weight 0.00
Epoch 190 Iter 9 subLoss 4845.9 multi 1.00 import weight 0.00
Epoch 190 Iter 10 subLoss 4594.5 multi 1.00 import weight 0.00
Epoch 190 Iter 11 subLoss 4781.7 multi 1.00 import weight 0.00
Epoch 190 Acc: 96.01 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 478 train Loss: 5074.7 test Loss: 619.8
Epoch 191 Iter 0 subLoss 5161.9 multi -10.94 import weight 0.00
Epoch 191 Iter 1 subLoss 4185.0 multi 1.00 import weight 0.00
Epoch 191 Iter 2 subLoss 4985.8 multi 1.00 import weight 0.00
Epoch 191 Iter 3 subLoss 5375.8 multi 9.96 import weight 0.00
Epoch 191 Iter 4 subLoss 5665.0 multi 3.99 import weight 0.00
Epoch 191 Iter 5 subLoss 4803.9 multi 12.94 import weight 0.00
Epoch 191 Iter 6 subLoss 5790.5 multi 1.00 import weight 0.00
Epoch 191 Iter 7 subLoss 5191.4 multi -1.99 import weight 0.00
Epoch 191 Iter 8 subLoss 5302.2 multi -1.98 import weight 0.00
Epoch 191 Iter 9 subLoss 6979.7 multi 6.97 import weight 0.00
Epoch 191 Iter 10 subLoss 5583.1 multi 1.00 import weight 0.00
Epoch 191 Iter 11 subLoss 4518.6 multi 3.99 import weight 0.00
Epoch 191 Acc: 96.07 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 451 train Loss: 5080.5 test Loss: 606.3
Epoch 192 Iter 0 subLoss 4882.5 multi 1.00 import weight 0.00
Epoch 192 Iter 1 subLoss 4815.9 multi -10.94 import weight 0.00
Epoch 192 Iter 2 subLoss 4978.1 multi 3.99 import weight 0.00
Epoch 192 Iter 3 subLoss 4832.3 multi 1.00 import weight 0.00
Epoch 192 Iter 4 subLoss 5101.7 multi 6.97 import weight 0.00
Epoch 192 Iter 5 subLoss 5618.2 multi 3.99 import weight 0.00
Epoch 192 Iter 6 subLoss 4263.9 multi 1.00 import weight 0.00
Epoch 192 Iter 7 subLoss 5069.6 multi 6.97 import weight 0.00
Epoch 192 Iter 8 subLoss 4199.7 multi -1.99 import weight 0.00
Epoch 192 Iter 9 subLoss 4778.4 multi 1.00 import weight 0.00
Epoch 192 Iter 10 subLoss 4807.0 multi 15.93 import weight 0.00
Epoch 192 Iter 11 subLoss 5341.2 multi 9.96 import weight 0.00
Epoch 192 Acc: 95.45 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 534 train Loss: 5116.5 test Loss: 680.1
Epoch 193 Iter 0 subLoss 5501.2 multi 1.00 import weight 0.00
Epoch 193 Iter 1 subLoss 4906.9 multi 6.97 import weight 0.00
Epoch 193 Iter 2 subLoss 5471.8 multi -1.98 import weight 0.00
Epoch 193 Iter 3 subLoss 5547.4 multi -10.94 import weight 0.00
Epoch 193 Iter 4 subLoss 8005.9 multi -7.96 import weight 0.00
Epoch 193 Iter 5 subLoss 134262.4 multi 1.00 import weight 0.00
Epoch 193 Iter 6 subLoss 10434.8 multi 3.98 import weight 0.00
Epoch 193 Iter 7 subLoss 6285.5 multi 9.96 import weight 0.00
Epoch 193 Iter 8 subLoss 5335.3 multi 1.00 import weight 0.00
Epoch 193 Iter 9 subLoss 4760.9 multi -1.99 import weight 0.00
Epoch 193 Iter 10 subLoss 5678.2 multi -10.94 import weight 0.00
Epoch 193 Iter 11 subLoss 7815.1 multi -4.97 import weight 0.00
Epoch 193 Acc: 75.44 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 781 train Loss: 22668.3 test Loss: 5021.0
Epoch 194 Iter 0 subLoss 21745.0 multi -1.99 import weight 0.00
Epoch 194 Iter 1 subLoss 193399.3 multi 1.00 import weight 0.00
Epoch 194 Iter 2 subLoss 15363.4 multi 3.99 import weight 0.00
Epoch 194 Iter 3 subLoss 8146.6 multi -1.99 import weight 0.00
Epoch 194 Iter 4 subLoss 8616.9 multi -4.97 import weight 0.00
Epoch 194 Iter 5 subLoss 12663.2 multi 1.00 import weight 0.00
Epoch 194 Iter 6 subLoss 11458.5 multi 1.00 import weight 0.00
Epoch 194 Iter 7 subLoss 10506.0 multi 1.00 import weight 0.00
Epoch 194 Iter 8 subLoss 9502.3 multi -1.98 import weight 0.00
Epoch 194 Iter 9 subLoss 12206.1 multi 3.99 import weight 0.00
Epoch 194 Iter 10 subLoss 7484.5 multi -1.99 import weight 0.00
Epoch 194 Iter 11 subLoss 7635.4 multi -1.99 import weight 0.00
Epoch 194 Acc: 91.87 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 763 train Loss: 9314.2 test Loss: 1418.2
Epoch 195 Iter 0 subLoss 9177.9 multi 3.99 import weight 0.00
Epoch 195 Iter 1 subLoss 6942.3 multi -7.96 import weight 0.00
Epoch 195 Iter 2 subLoss 8378.4 multi -1.99 import weight 0.00
Epoch 195 Iter 3 subLoss 11137.4 multi -7.96 import weight 0.00
Epoch 195 Iter 4 subLoss 21834.1 multi 12.94 import weight 0.00
Epoch 195 Iter 5 subLoss 10787.0 multi 1.00 import weight 0.00
Epoch 195 Iter 6 subLoss 8742.4 multi 1.00 import weight 0.00
Epoch 195 Iter 7 subLoss 7681.6 multi -1.99 import weight 0.00
Epoch 195 Iter 8 subLoss 9023.3 multi -1.99 import weight 0.00
Epoch 195 Iter 9 subLoss 12002.0 multi 1.00 import weight 0.00
Epoch 195 Iter 10 subLoss 8611.2 multi -1.98 import weight 0.00
Epoch 195 Iter 11 subLoss 11898.6 multi 3.99 import weight 0.00
Epoch 195 Acc: 93.64 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 1189 train Loss: 7281.9 test Loss: 983.8
Epoch 196 Iter 0 subLoss 7608.0 multi -4.97 import weight 0.00
Epoch 196 Iter 1 subLoss 9967.1 multi -7.96 import weight 0.00
Epoch 196 Iter 2 subLoss 107229.0 multi 1.00 import weight 0.00
Epoch 196 Iter 3 subLoss 8642.1 multi 3.99 import weight 0.00
Epoch 196 Iter 4 subLoss 6732.3 multi 1.00 import weight 0.00
Epoch 196 Iter 5 subLoss 8395.3 multi -1.99 import weight 0.00
Epoch 196 Iter 6 subLoss 7478.8 multi 9.96 import weight 0.00
Epoch 196 Iter 7 subLoss 6957.3 multi 1.00 import weight 0.00
Epoch 196 Iter 8 subLoss 6754.9 multi 1.00 import weight 0.00
Epoch 196 Iter 9 subLoss 5771.0 multi 1.00 import weight 0.00
Epoch 196 Iter 10 subLoss 6509.1 multi -10.94 import weight 0.00
Epoch 196 Iter 11 subLoss 7520.4 multi 12.94 import weight 0.00
Epoch 196 Acc: 93.36 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 752 train Loss: 7213.7 test Loss: 1002.0
Epoch 197 Iter 0 subLoss 7090.0 multi 6.97 import weight 0.00
Epoch 197 Iter 1 subLoss 6021.7 multi -7.96 import weight 0.00
Epoch 197 Iter 2 subLoss 6747.6 multi -7.96 import weight 0.00
Epoch 197 Iter 3 subLoss 10826.3 multi -4.97 import weight 0.00
Epoch 197 Iter 4 subLoss 26462.5 multi 1.00 import weight 0.00
Epoch 197 Iter 5 subLoss 15654.0 multi 1.00 import weight 0.00
Epoch 197 Iter 6 subLoss 11292.5 multi 6.97 import weight 0.00
Epoch 197 Iter 7 subLoss 6493.8 multi 9.96 import weight 0.00
Epoch 197 Iter 8 subLoss 6000.7 multi -7.96 import weight 0.00
Epoch 197 Iter 9 subLoss 7669.8 multi 1.00 import weight 0.00
Epoch 197 Iter 10 subLoss 6520.7 multi -4.97 import weight 0.00
Epoch 197 Iter 11 subLoss 7561.6 multi 6.97 import weight 0.00
Epoch 197 Acc: 95.02 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 756 train Loss: 6385.2 test Loss: 830.8
Epoch 198 Iter 0 subLoss 6691.6 multi 3.99 import weight 0.00
Epoch 198 Iter 1 subLoss 6273.7 multi 1.00 import weight 0.00
Epoch 198 Iter 2 subLoss 6411.4 multi -4.97 import weight 0.00
Epoch 198 Iter 3 subLoss 5983.6 multi -1.99 import weight 0.00
Epoch 198 Iter 4 subLoss 6900.3 multi -4.97 import weight 0.00
Epoch 198 Iter 5 subLoss 6744.3 multi -4.97 import weight 0.00
Epoch 198 Iter 6 subLoss 6962.6 multi -4.97 import weight 0.00
Epoch 198 Iter 7 subLoss 7751.3 multi -4.97 import weight 0.00
Epoch 198 Iter 8 subLoss 7730.9 multi 9.96 import weight 0.00
Epoch 198 Iter 9 subLoss 6724.8 multi 9.96 import weight 0.00
Epoch 198 Iter 10 subLoss 6169.8 multi -13.93 import weight 0.00
Epoch 198 Iter 11 subLoss 8056.2 multi 3.98 import weight 0.00
Epoch 198 Acc: 93.93 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 805 train Loss: 6881.1 test Loss: 942.0
Epoch 199 Iter 0 subLoss 5987.0 multi 1.00 import weight 0.00
Epoch 199 Iter 1 subLoss 6616.6 multi 12.94 import weight 0.00
Epoch 199 Iter 2 subLoss 6106.0 multi 6.97 import weight 0.00
Epoch 199 Iter 3 subLoss 6045.2 multi 1.00 import weight 0.00
Epoch 199 Iter 4 subLoss 5470.8 multi 1.00 import weight 0.00
Epoch 199 Iter 5 subLoss 6042.0 multi 3.99 import weight 0.00
Epoch 199 Iter 6 subLoss 5961.8 multi 3.99 import weight 0.00
Epoch 199 Iter 7 subLoss 5700.4 multi -1.99 import weight 0.00
Epoch 199 Iter 8 subLoss 5110.6 multi -10.94 import weight 0.00
Epoch 199 Iter 9 subLoss 5919.3 multi 12.94 import weight 0.00
Epoch 199 Iter 10 subLoss 6009.8 multi -4.97 import weight 0.00
Epoch 199 Iter 11 subLoss 6256.2 multi 15.93 import weight 1.00
Epoch 199 Acc: 95.21 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 15.93 Pidx 625 train Loss: 5768.0 test Loss: 728.4
Epoch 200 Iter 0 subLoss 5844.5 multi -1.98 import weight 0.00
Epoch 200 Iter 1 subLoss 5887.6 multi -4.97 import weight 0.00
Epoch 200 Iter 2 subLoss 7448.3 multi 1.00 import weight 0.00
Epoch 200 Iter 3 subLoss 6396.7 multi -10.94 import weight 0.00
Epoch 200 Iter 4 subLoss 16283.7 multi 1.00 import weight 0.00
Epoch 200 Iter 5 subLoss 9746.6 multi 1.00 import weight 0.00
Epoch 200 Iter 6 subLoss 8571.8 multi -1.98 import weight 0.00
Epoch 200 Iter 7 subLoss 10906.5 multi 1.00 import weight 0.00
Epoch 200 Iter 8 subLoss 8289.3 multi -4.97 import weight 0.00
Epoch 200 Iter 9 subLoss 19100.2 multi -4.97 import weight 0.00
Epoch 200 Iter 10 subLoss 304501.1 multi 1.00 import weight 0.00
Epoch 200 Iter 11 subLoss 14490.1 multi 6.97 import weight 0.00
Epoch 200 Acc: 92.47 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 1449 train Loss: 10128.1 test Loss: 1301.9
Epoch 201 Iter 0 subLoss 9850.8 multi 1.00 import weight 0.00
Epoch 201 Iter 1 subLoss 10431.6 multi 6.97 import weight 0.00
Epoch 201 Iter 2 subLoss 8562.1 multi 3.98 import weight 0.00
Epoch 201 Iter 3 subLoss 7834.0 multi 1.00 import weight 0.00
Epoch 201 Iter 4 subLoss 7745.8 multi -4.97 import weight 0.00
Epoch 201 Iter 5 subLoss 8208.7 multi 6.97 import weight 0.00
Epoch 201 Iter 6 subLoss 7999.4 multi 6.97 import weight 0.00
Epoch 201 Iter 7 subLoss 7787.4 multi 3.98 import weight 0.00
Epoch 201 Iter 8 subLoss 6982.9 multi -4.97 import weight 0.00
Epoch 201 Iter 9 subLoss 6801.1 multi 6.97 import weight 0.00
Epoch 201 Iter 10 subLoss 6627.8 multi 6.97 import weight 0.00
Epoch 201 Iter 11 subLoss 6397.1 multi -7.96 import weight 0.00
Epoch 201 Acc: 94.05 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 639 train Loss: 7542.6 test Loss: 891.6
Epoch 202 Iter 0 subLoss 6864.3 multi -1.99 import weight 0.00
Epoch 202 Iter 1 subLoss 7993.4 multi 9.96 import weight 0.00
Epoch 202 Iter 2 subLoss 6644.1 multi 12.94 import weight 0.00
Epoch 202 Iter 3 subLoss 6580.5 multi -7.96 import weight 0.00
Epoch 202 Iter 4 subLoss 12331.3 multi 6.97 import weight 0.00
Epoch 202 Iter 5 subLoss 9591.8 multi -1.98 import weight 0.00
Epoch 202 Iter 6 subLoss 9371.6 multi 1.00 import weight 0.00
Epoch 202 Iter 7 subLoss 10389.9 multi 1.00 import weight 0.00
Epoch 202 Iter 8 subLoss 8759.6 multi -4.97 import weight 0.00
Epoch 202 Iter 9 subLoss 12057.4 multi 1.00 import weight 0.00
Epoch 202 Iter 10 subLoss 11482.0 multi 1.00 import weight 0.00
Epoch 202 Iter 11 subLoss 10478.5 multi -4.97 import weight 0.00
Epoch 202 Acc: 81.12 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 1047 train Loss: 16198.7 test Loss: 3327.6
Epoch 203 Iter 0 subLoss 15630.0 multi 1.00 import weight 0.00
Epoch 203 Iter 1 subLoss 13499.2 multi 9.96 import weight 0.00
Epoch 203 Iter 2 subLoss 7998.6 multi 12.94 import weight 0.00
Epoch 203 Iter 3 subLoss 7461.7 multi -4.97 import weight 0.00
Epoch 203 Iter 4 subLoss 8340.7 multi 3.99 import weight 0.00
Epoch 203 Iter 5 subLoss 6654.0 multi -10.94 import weight 0.00
Epoch 203 Iter 6 subLoss 7653.8 multi 1.00 import weight 0.00
Epoch 203 Iter 7 subLoss 7771.8 multi -1.98 import weight 0.00
Epoch 203 Iter 8 subLoss 7425.0 multi 3.98 import weight 0.00
Epoch 203 Iter 9 subLoss 7064.4 multi -1.98 import weight 0.00
Epoch 203 Iter 10 subLoss 7402.5 multi 3.98 import weight 0.00
Epoch 203 Iter 11 subLoss 7331.5 multi 1.00 import weight 0.00
Epoch 203 Acc: 94.01 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 733 train Loss: 6687.4 test Loss: 924.8
Epoch 204 Iter 0 subLoss 6420.2 multi 9.96 import weight 0.00
Epoch 204 Iter 1 subLoss 6247.3 multi -4.97 import weight 0.00
Epoch 204 Iter 2 subLoss 6410.2 multi -1.99 import weight 0.00
Epoch 204 Iter 3 subLoss 7373.9 multi 1.00 import weight 0.00
Epoch 204 Iter 4 subLoss 6251.5 multi 15.93 import weight 1.00
Epoch 204 Iter 5 subLoss 7353.9 multi -16.91 import weight 0.00
Epoch 204 Iter 6 subLoss 15142.2 multi -1.99 import weight 0.00
Epoch 204 Iter 7 subLoss 24383.0 multi 1.00 import weight 0.00
Epoch 204 Iter 8 subLoss 17038.6 multi 1.00 import weight 0.00
Epoch 204 Iter 9 subLoss 14403.3 multi -1.99 import weight 0.00
Epoch 204 Iter 10 subLoss 20984.8 multi 1.00 import weight 0.00
Epoch 204 Iter 11 subLoss 15086.9 multi 1.00 import weight 0.00
Epoch 204 Acc: 86.77 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1508 train Loss: 13250.8 test Loss: 1915.8
Epoch 205 Iter 0 subLoss 12851.0 multi 1.00 import weight 0.00
Epoch 205 Iter 1 subLoss 12265.6 multi 3.99 import weight 0.00
Epoch 205 Iter 2 subLoss 7859.9 multi 6.97 import weight 0.00
Epoch 205 Iter 3 subLoss 5855.9 multi -4.97 import weight 0.00
Epoch 205 Iter 4 subLoss 5778.1 multi 3.99 import weight 0.00
Epoch 205 Iter 5 subLoss 6104.4 multi 9.96 import weight 0.00
Epoch 205 Iter 6 subLoss 5718.1 multi -1.99 import weight 0.00
Epoch 205 Iter 7 subLoss 6189.9 multi 3.99 import weight 0.00
Epoch 205 Iter 8 subLoss 5950.5 multi -13.93 import weight 0.00
Epoch 205 Iter 9 subLoss 7090.2 multi 9.96 import weight 0.00
Epoch 205 Iter 10 subLoss 6541.4 multi 3.98 import weight 0.00
Epoch 205 Iter 11 subLoss 5756.2 multi 9.96 import weight 0.00
Epoch 205 Acc: 94.36 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 575 train Loss: 5929.5 test Loss: 821.2
Epoch 206 Iter 0 subLoss 6241.2 multi -1.98 import weight 0.00
Epoch 206 Iter 1 subLoss 6251.2 multi 15.93 import weight 1.00
Epoch 206 Iter 2 subLoss 5332.7 multi 3.98 import weight 0.00
Epoch 206 Iter 3 subLoss 5933.4 multi 3.99 import weight 0.00
Epoch 206 Iter 4 subLoss 5141.4 multi -4.97 import weight 0.00
Epoch 206 Iter 5 subLoss 5604.9 multi 3.99 import weight 0.00
Epoch 206 Iter 6 subLoss 4501.3 multi 1.00 import weight 0.00
Epoch 206 Iter 7 subLoss 6249.3 multi 1.00 import weight 0.00
Epoch 206 Iter 8 subLoss 5216.6 multi 1.00 import weight 0.00
Epoch 206 Iter 9 subLoss 5364.1 multi -1.98 import weight 0.00
Epoch 206 Iter 10 subLoss 5247.5 multi 6.97 import weight 0.00
Epoch 206 Iter 11 subLoss 5616.0 multi 3.98 import weight 0.00
Epoch 206 Acc: 95.14 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 561 train Loss: 5596.5 test Loss: 709.1
Epoch 207 Iter 0 subLoss 5489.8 multi 6.97 import weight 0.00
Epoch 207 Iter 1 subLoss 5769.9 multi -1.99 import weight 0.00
Epoch 207 Iter 2 subLoss 5488.9 multi 9.96 import weight 0.00
Epoch 207 Iter 3 subLoss 4343.2 multi 1.00 import weight 0.00
Epoch 207 Iter 4 subLoss 4583.6 multi 1.00 import weight 0.00
Epoch 207 Iter 5 subLoss 5475.7 multi 3.99 import weight 0.00
Epoch 207 Iter 6 subLoss 5298.4 multi 1.00 import weight 0.00
Epoch 207 Iter 7 subLoss 5160.7 multi -7.96 import weight 0.00
Epoch 207 Iter 8 subLoss 5277.6 multi -4.97 import weight 0.00
Epoch 207 Iter 9 subLoss 6293.2 multi -10.94 import weight 0.00
Epoch 207 Iter 10 subLoss 6996.0 multi 1.00 import weight 0.00
Epoch 207 Iter 11 subLoss 6561.9 multi 15.93 import weight 0.00
Epoch 207 Acc: 93.23 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 15.93 Pidx 656 train Loss: 7853.2 test Loss: 1202.0
Epoch 208 Iter 0 subLoss 6764.5 multi -7.96 import weight 0.00
Epoch 208 Iter 1 subLoss 26302.0 multi 1.00 import weight 0.00
Epoch 208 Iter 2 subLoss 12568.3 multi 1.00 import weight 0.00
Epoch 208 Iter 3 subLoss 9492.1 multi 1.00 import weight 0.00
Epoch 208 Iter 4 subLoss 7186.3 multi 9.96 import weight 0.00
Epoch 208 Iter 5 subLoss 5863.6 multi 1.00 import weight 0.00
Epoch 208 Iter 6 subLoss 5674.8 multi -7.96 import weight 0.00
Epoch 208 Iter 7 subLoss 8533.1 multi 1.00 import weight 0.00
Epoch 208 Iter 8 subLoss 7543.2 multi 1.00 import weight 0.00
Epoch 208 Iter 9 subLoss 6912.0 multi -1.99 import weight 0.00
Epoch 208 Iter 10 subLoss 7147.6 multi 9.96 import weight 0.00
Epoch 208 Iter 11 subLoss 7845.3 multi -1.98 import weight 0.00
Epoch 208 Acc: 90.68 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 784 train Loss: 9766.5 test Loss: 1510.0
Epoch 209 Iter 0 subLoss 9262.9 multi 1.00 import weight 0.00
Epoch 209 Iter 1 subLoss 8459.7 multi 9.96 import weight 0.00
Epoch 209 Iter 2 subLoss 5986.5 multi 3.98 import weight 0.00
Epoch 209 Iter 3 subLoss 5481.7 multi 9.96 import weight 0.00
Epoch 209 Iter 4 subLoss 5165.0 multi -4.97 import weight 0.00
Epoch 209 Iter 5 subLoss 5530.8 multi 9.96 import weight 0.00
Epoch 209 Iter 6 subLoss 5100.3 multi 9.96 import weight 0.00
Epoch 209 Iter 7 subLoss 5368.4 multi 1.00 import weight 0.00
Epoch 209 Iter 8 subLoss 5088.3 multi 1.00 import weight 0.00
Epoch 209 Iter 9 subLoss 5007.7 multi 1.00 import weight 0.00
Epoch 209 Iter 10 subLoss 4958.9 multi 1.00 import weight 0.00
Epoch 209 Iter 11 subLoss 5329.5 multi 1.00 import weight 0.00
Epoch 209 Acc: 95.68 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 532 train Loss: 5141.5 test Loss: 652.3
Epoch 210 Iter 0 subLoss 4658.0 multi 1.00 import weight 0.00
Epoch 210 Iter 1 subLoss 4908.9 multi 9.96 import weight 0.00
Epoch 210 Iter 2 subLoss 5655.0 multi 6.97 import weight 0.00
Epoch 210 Iter 3 subLoss 4821.1 multi -4.97 import weight 0.00
Epoch 210 Iter 4 subLoss 5646.8 multi 1.00 import weight 0.00
Epoch 210 Iter 5 subLoss 4929.7 multi -1.99 import weight 0.00
Epoch 210 Iter 6 subLoss 4634.4 multi 1.00 import weight 0.00
Epoch 210 Iter 7 subLoss 4885.3 multi 3.99 import weight 0.00
Epoch 210 Iter 8 subLoss 4303.5 multi 1.00 import weight 0.00
Epoch 210 Iter 9 subLoss 4802.0 multi 18.91 import weight 0.00
Epoch 210 Iter 10 subLoss 5022.9 multi -4.97 import weight 0.00
Epoch 210 Iter 11 subLoss 4770.9 multi 1.00 import weight 0.00
Epoch 210 Acc: 95.68 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 477 train Loss: 4984.2 test Loss: 656.4
Epoch 211 Iter 0 subLoss 5457.3 multi 6.97 import weight 0.00
Epoch 211 Iter 1 subLoss 4714.2 multi 1.00 import weight 0.00
Epoch 211 Iter 2 subLoss 4868.6 multi 1.00 import weight 0.00
Epoch 211 Iter 3 subLoss 4357.9 multi -1.99 import weight 0.00
Epoch 211 Iter 4 subLoss 4462.6 multi 1.00 import weight 0.00
Epoch 211 Iter 5 subLoss 4699.9 multi -1.99 import weight 0.00
Epoch 211 Iter 6 subLoss 4783.8 multi -1.98 import weight 0.00
Epoch 211 Iter 7 subLoss 4940.3 multi 1.00 import weight 0.00
Epoch 211 Iter 8 subLoss 4409.7 multi 1.00 import weight 0.00
Epoch 211 Iter 9 subLoss 5547.0 multi -10.94 import weight 0.00
Epoch 211 Iter 10 subLoss 5671.6 multi -4.97 import weight 0.00
Epoch 211 Iter 11 subLoss 5603.6 multi 6.97 import weight 0.00
Epoch 211 Acc: 95.70 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 560 train Loss: 5149.5 test Loss: 637.8
Epoch 212 Iter 0 subLoss 5290.2 multi 3.99 import weight 0.00
Epoch 212 Iter 1 subLoss 4603.7 multi -1.99 import weight 0.00
Epoch 212 Iter 2 subLoss 4870.7 multi -1.99 import weight 0.00
Epoch 212 Iter 3 subLoss 4421.1 multi 1.00 import weight 0.00
Epoch 212 Iter 4 subLoss 5332.0 multi 3.99 import weight 0.00
Epoch 212 Iter 5 subLoss 5080.9 multi 3.98 import weight 0.00
Epoch 212 Iter 6 subLoss 5397.9 multi -1.99 import weight 0.00
Epoch 212 Iter 7 subLoss 5003.3 multi 3.99 import weight 0.00
Epoch 212 Iter 8 subLoss 4858.6 multi -1.99 import weight 0.00
Epoch 212 Iter 9 subLoss 4356.3 multi 1.00 import weight 0.00
Epoch 212 Iter 10 subLoss 5639.5 multi -13.93 import weight 0.00
Epoch 212 Iter 11 subLoss 5630.9 multi -10.94 import weight 0.00
Epoch 212 Acc: 94.49 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -10.94 Pidx 563 train Loss: 6342.0 test Loss: 890.3
Epoch 213 Iter 0 subLoss 6226.6 multi -1.98 import weight 0.00
Epoch 213 Iter 1 subLoss 6244.3 multi 3.99 import weight 0.00
Epoch 213 Iter 2 subLoss 5050.7 multi -1.99 import weight 0.00
Epoch 213 Iter 3 subLoss 5460.7 multi -1.99 import weight 0.00
Epoch 213 Iter 4 subLoss 5671.5 multi -1.99 import weight 0.00
Epoch 213 Iter 5 subLoss 6962.1 multi -1.99 import weight 0.00
Epoch 213 Iter 6 subLoss 8023.2 multi -7.96 import weight 0.00
Epoch 213 Iter 7 subLoss 17108.1 multi -1.99 import weight 0.00
Epoch 213 Iter 8 subLoss 34705.4 multi 1.00 import weight 0.00
Epoch 213 Iter 9 subLoss 17291.3 multi 1.00 import weight 0.00
Epoch 213 Iter 10 subLoss 11612.0 multi 1.00 import weight 0.00
Epoch 213 Iter 11 subLoss 10452.2 multi -1.98 import weight 0.00
Epoch 213 Acc: 86.42 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 1045 train Loss: 13923.9 test Loss: 2216.2
Epoch 214 Iter 0 subLoss 14374.7 multi -1.99 import weight 0.00
Epoch 214 Iter 1 subLoss 21797.7 multi 1.00 import weight 0.00
Epoch 214 Iter 2 subLoss 14157.3 multi 1.00 import weight 0.00
Epoch 214 Iter 3 subLoss 11826.6 multi -1.99 import weight 0.00
Epoch 214 Iter 4 subLoss 18395.0 multi 3.99 import weight 0.00
Epoch 214 Iter 5 subLoss 7355.8 multi -13.93 import weight 0.00
Epoch 214 Iter 6 subLoss 18072.2 multi -1.99 import weight 0.00
Epoch 214 Iter 7 subLoss 31520.5 multi 1.00 import weight 0.00
Epoch 214 Iter 8 subLoss 17217.7 multi 3.99 import weight 0.00
Epoch 214 Iter 9 subLoss 10358.8 multi 1.00 import weight 0.00
Epoch 214 Iter 10 subLoss 11578.6 multi 6.97 import weight 0.00
Epoch 214 Iter 11 subLoss 7383.8 multi 6.97 import weight 0.00
Epoch 214 Acc: 93.42 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 738 train Loss: 6302.8 test Loss: 974.5
Epoch 215 Iter 0 subLoss 6396.2 multi -4.97 import weight 0.00
Epoch 215 Iter 1 subLoss 6646.2 multi 15.93 import weight 0.00
Epoch 215 Iter 2 subLoss 5446.7 multi -1.99 import weight 0.00
Epoch 215 Iter 3 subLoss 5620.1 multi -1.99 import weight 0.00
Epoch 215 Iter 4 subLoss 5145.4 multi -1.98 import weight 0.00
Epoch 215 Iter 5 subLoss 6022.7 multi -4.97 import weight 0.00
Epoch 215 Iter 6 subLoss 6395.1 multi -1.99 import weight 0.00
Epoch 215 Iter 7 subLoss 6728.4 multi 12.94 import weight 0.00
Epoch 215 Iter 8 subLoss 6875.0 multi 6.97 import weight 0.00
Epoch 215 Iter 9 subLoss 5678.9 multi 1.00 import weight 0.00
Epoch 215 Iter 10 subLoss 5274.8 multi -1.98 import weight 0.00
Epoch 215 Iter 11 subLoss 5436.2 multi -4.97 import weight 0.00
Epoch 215 Acc: 94.65 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 543 train Loss: 5595.9 test Loss: 820.7
Epoch 216 Iter 0 subLoss 5797.6 multi 3.99 import weight 0.00
Epoch 216 Iter 1 subLoss 5438.8 multi -1.99 import weight 0.00
Epoch 216 Iter 2 subLoss 4900.0 multi -4.97 import weight 0.00
Epoch 216 Iter 3 subLoss 5495.3 multi -16.91 import weight 0.00
Epoch 216 Iter 4 subLoss 6204.4 multi -1.99 import weight 0.00
Epoch 216 Iter 5 subLoss 6640.2 multi 18.91 import weight 0.00
Epoch 216 Iter 6 subLoss 7266.1 multi -7.96 import weight 0.00
Epoch 216 Iter 7 subLoss 13520.3 multi 3.99 import weight 0.00
Epoch 216 Iter 8 subLoss 6154.0 multi 3.99 import weight 0.00
Epoch 216 Iter 9 subLoss 5765.0 multi 1.00 import weight 0.00
Epoch 216 Iter 10 subLoss 5394.5 multi 1.00 import weight 0.00
Epoch 216 Iter 11 subLoss 5895.2 multi 3.99 import weight 0.00
Epoch 216 Acc: 94.67 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 589 train Loss: 5524.2 test Loss: 797.4
Epoch 217 Iter 0 subLoss 5619.2 multi 3.99 import weight 0.00
Epoch 217 Iter 1 subLoss 5634.6 multi -10.94 import weight 0.00
Epoch 217 Iter 2 subLoss 6556.8 multi -7.96 import weight 0.00
Epoch 217 Iter 3 subLoss 6921.2 multi -1.99 import weight 0.00
Epoch 217 Iter 4 subLoss 9009.6 multi 3.99 import weight 0.00
Epoch 217 Iter 5 subLoss 5906.5 multi -10.94 import weight 0.00
Epoch 217 Iter 6 subLoss 8762.5 multi -4.97 import weight 0.00
Epoch 217 Iter 7 subLoss 10718.4 multi 6.97 import weight 0.00
Epoch 217 Iter 8 subLoss 7398.3 multi -13.93 import weight 0.00
Epoch 217 Iter 9 subLoss 11502.2 multi 1.00 import weight 0.00
Epoch 217 Iter 10 subLoss 10797.1 multi -1.98 import weight 0.00
Epoch 217 Iter 11 subLoss 12217.3 multi -1.98 import weight 0.00
Epoch 217 Acc: 82.91 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 1221 train Loss: 14116.7 test Loss: 2313.3
Epoch 218 Iter 0 subLoss 13969.5 multi -4.97 import weight 0.00
Epoch 218 Iter 1 subLoss 20232.2 multi -1.99 import weight 0.00
Epoch 218 Iter 2 subLoss 27632.6 multi 1.00 import weight 0.00
Epoch 218 Iter 3 subLoss 20015.4 multi -1.99 import weight 0.00
Epoch 218 Iter 4 subLoss 26622.5 multi 1.00 import weight 0.00
Epoch 218 Iter 5 subLoss 20867.3 multi 3.99 import weight 0.00
Epoch 218 Iter 6 subLoss 13811.9 multi 1.00 import weight 0.00
Epoch 218 Iter 7 subLoss 13881.6 multi 1.00 import weight 0.00
Epoch 218 Iter 8 subLoss 12887.2 multi 1.00 import weight 0.00
Epoch 218 Iter 9 subLoss 12810.4 multi -1.98 import weight 0.00
Epoch 218 Iter 10 subLoss 13918.3 multi 6.97 import weight 0.00
Epoch 218 Iter 11 subLoss 9862.4 multi 1.00 import weight 0.00
Epoch 218 Acc: 86.88 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 986 train Loss: 10137.9 test Loss: 1788.9
Epoch 219 Iter 0 subLoss 10470.3 multi -1.98 import weight 0.00
Epoch 219 Iter 1 subLoss 10499.4 multi -7.96 import weight 0.00
Epoch 219 Iter 2 subLoss 12839.4 multi 1.00 import weight 0.00
Epoch 219 Iter 3 subLoss 13283.5 multi 6.97 import weight 0.00
Epoch 219 Iter 4 subLoss 10880.2 multi 1.00 import weight 0.00
Epoch 219 Iter 5 subLoss 9582.4 multi 6.97 import weight 0.00
Epoch 219 Iter 6 subLoss 8173.7 multi -7.96 import weight 0.00
Epoch 219 Iter 7 subLoss 10248.4 multi 1.00 import weight 0.00
Epoch 219 Iter 8 subLoss 9815.7 multi 3.98 import weight 0.00
Epoch 219 Iter 9 subLoss 8589.0 multi -1.98 import weight 0.00
Epoch 219 Iter 10 subLoss 9185.9 multi -1.98 import weight 0.00
Epoch 219 Iter 11 subLoss 9967.5 multi -4.97 import weight 0.00
Epoch 219 Acc: 85.78 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 996 train Loss: 11440.5 test Loss: 1945.8
Epoch 220 Iter 0 subLoss 10915.2 multi 3.99 import weight 0.00
Epoch 220 Iter 1 subLoss 10244.8 multi 3.98 import weight 0.00
Epoch 220 Iter 2 subLoss 7925.7 multi 3.98 import weight 0.00
Epoch 220 Iter 3 subLoss 7820.7 multi -1.98 import weight 0.00
Epoch 220 Iter 4 subLoss 8871.8 multi 6.97 import weight 0.00
Epoch 220 Iter 5 subLoss 6913.9 multi 1.00 import weight 0.00
Epoch 220 Iter 6 subLoss 6682.5 multi 1.00 import weight 0.00
Epoch 220 Iter 7 subLoss 6942.7 multi -4.97 import weight 0.00
Epoch 220 Iter 8 subLoss 7061.0 multi 1.00 import weight 0.00
Epoch 220 Iter 9 subLoss 7249.8 multi -7.96 import weight 0.00
Epoch 220 Iter 10 subLoss 7976.0 multi 6.97 import weight 0.00
Epoch 220 Iter 11 subLoss 7106.0 multi -4.97 import weight 0.00
Epoch 220 Acc: 92.14 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 710 train Loss: 7933.8 test Loss: 1287.9
Epoch 221 Iter 0 subLoss 7454.9 multi -1.99 import weight 0.00
Epoch 221 Iter 1 subLoss 7817.9 multi -1.99 import weight 0.00
Epoch 221 Iter 2 subLoss 8459.5 multi 12.94 import weight 0.00
Epoch 221 Iter 3 subLoss 6898.8 multi 3.99 import weight 0.00
Epoch 221 Iter 4 subLoss 5976.1 multi -1.98 import weight 0.00
Epoch 221 Iter 5 subLoss 6825.7 multi 3.99 import weight 0.00
Epoch 221 Iter 6 subLoss 5735.9 multi 6.97 import weight 0.00
Epoch 221 Iter 7 subLoss 5943.8 multi 3.98 import weight 0.00
Epoch 221 Iter 8 subLoss 5799.2 multi 6.97 import weight 0.00
Epoch 221 Iter 9 subLoss 5417.4 multi 1.00 import weight 0.00
Epoch 221 Iter 10 subLoss 5925.8 multi -10.94 import weight 0.00
Epoch 221 Iter 11 subLoss 6250.4 multi 12.94 import weight 1.00
Epoch 221 Acc: 94.65 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 12.94 Pidx 625 train Loss: 5979.0 test Loss: 816.8
Epoch 222 Iter 0 subLoss 5790.2 multi 9.96 import weight 0.00
Epoch 222 Iter 1 subLoss 5812.7 multi -1.99 import weight 0.00
Epoch 222 Iter 2 subLoss 5665.6 multi 3.99 import weight 0.00
Epoch 222 Iter 3 subLoss 5308.6 multi -4.97 import weight 0.00
Epoch 222 Iter 4 subLoss 5980.1 multi 3.99 import weight 0.00
Epoch 222 Iter 5 subLoss 5196.2 multi 1.00 import weight 0.00
Epoch 222 Iter 6 subLoss 4673.4 multi -1.99 import weight 0.00
Epoch 222 Iter 7 subLoss 5889.6 multi -1.99 import weight 0.00
Epoch 222 Iter 8 subLoss 5878.4 multi 6.97 import weight 0.00
Epoch 222 Iter 9 subLoss 4891.2 multi -1.98 import weight 0.00
Epoch 222 Iter 10 subLoss 5218.2 multi 3.99 import weight 0.00
Epoch 222 Iter 11 subLoss 5220.9 multi -1.98 import weight 0.00
Epoch 222 Acc: 94.94 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 522 train Loss: 5486.5 test Loss: 762.7
Epoch 223 Iter 0 subLoss 6029.8 multi -1.99 import weight 0.00
Epoch 223 Iter 1 subLoss 4959.3 multi 1.00 import weight 0.00
Epoch 223 Iter 2 subLoss 5369.5 multi 3.99 import weight 0.00
Epoch 223 Iter 3 subLoss 5544.0 multi -7.96 import weight 0.00
Epoch 223 Iter 4 subLoss 5753.5 multi 12.94 import weight 0.00
Epoch 223 Iter 5 subLoss 6070.1 multi -1.98 import weight 0.00
Epoch 223 Iter 6 subLoss 5691.6 multi 6.97 import weight 0.00
Epoch 223 Iter 7 subLoss 4611.9 multi -1.99 import weight 0.00
Epoch 223 Iter 8 subLoss 5440.9 multi -4.97 import weight 0.00
Epoch 223 Iter 9 subLoss 5701.3 multi -1.99 import weight 0.00
Epoch 223 Iter 10 subLoss 5165.0 multi -1.99 import weight 0.00
Epoch 223 Iter 11 subLoss 5431.6 multi 1.00 import weight 0.00
Epoch 223 Acc: 95.04 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 543 train Loss: 5423.5 test Loss: 735.6
Epoch 224 Iter 0 subLoss 5137.0 multi 1.00 import weight 0.00
Epoch 224 Iter 1 subLoss 5117.2 multi -10.94 import weight 0.00
Epoch 224 Iter 2 subLoss 6294.1 multi -7.96 import weight 0.00
Epoch 224 Iter 3 subLoss 6826.5 multi 6.97 import weight 0.00
Epoch 224 Iter 4 subLoss 6153.9 multi 6.97 import weight 0.00
Epoch 224 Iter 5 subLoss 5083.5 multi 6.97 import weight 0.00
Epoch 224 Iter 6 subLoss 4886.0 multi 3.98 import weight 0.00
Epoch 224 Iter 7 subLoss 5145.5 multi -1.99 import weight 0.00
Epoch 224 Iter 8 subLoss 5622.3 multi -1.99 import weight 0.00
Epoch 224 Iter 9 subLoss 5285.0 multi 1.00 import weight 0.00
Epoch 224 Iter 10 subLoss 4773.3 multi 3.98 import weight 0.00
Epoch 224 Iter 11 subLoss 5202.4 multi -4.97 import weight 0.00
Epoch 224 Acc: 95.50 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 520 train Loss: 5475.1 test Loss: 690.6
Epoch 225 Iter 0 subLoss 5551.9 multi -7.96 import weight 0.00
Epoch 225 Iter 1 subLoss 5796.3 multi 12.94 import weight 0.00
Epoch 225 Iter 2 subLoss 5048.6 multi 1.00 import weight 0.00
Epoch 225 Iter 3 subLoss 5372.9 multi 3.98 import weight 0.00
Epoch 225 Iter 4 subLoss 5625.7 multi 1.00 import weight 0.00
Epoch 225 Iter 5 subLoss 5367.2 multi 6.97 import weight 0.00
Epoch 225 Iter 6 subLoss 5082.0 multi 9.96 import weight 0.00
Epoch 225 Iter 7 subLoss 5474.1 multi 3.99 import weight 0.00
Epoch 225 Iter 8 subLoss 4538.4 multi 1.00 import weight 0.00
Epoch 225 Iter 9 subLoss 5057.8 multi -1.98 import weight 0.00
Epoch 225 Iter 10 subLoss 4611.5 multi 1.00 import weight 0.00
Epoch 225 Iter 11 subLoss 4688.6 multi 1.00 import weight 0.00
Epoch 225 Acc: 95.78 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 468 train Loss: 5048.8 test Loss: 634.8
Epoch 226 Iter 0 subLoss 5474.0 multi 6.97 import weight 0.00
Epoch 226 Iter 1 subLoss 5029.3 multi -1.98 import weight 0.00
Epoch 226 Iter 2 subLoss 5099.3 multi -10.94 import weight 0.00
Epoch 226 Iter 3 subLoss 5360.9 multi 9.96 import weight 0.00
Epoch 226 Iter 4 subLoss 4902.4 multi 6.97 import weight 0.00
Epoch 226 Iter 5 subLoss 5074.5 multi -4.97 import weight 0.00
Epoch 226 Iter 6 subLoss 4991.1 multi -4.97 import weight 0.00
Epoch 226 Iter 7 subLoss 4514.4 multi 3.98 import weight 0.00
Epoch 226 Iter 8 subLoss 4408.9 multi 3.99 import weight 0.00
Epoch 226 Iter 9 subLoss 4648.6 multi -1.99 import weight 0.00
Epoch 226 Iter 10 subLoss 5553.5 multi -4.97 import weight 0.00
Epoch 226 Iter 11 subLoss 4847.7 multi 1.00 import weight 0.00
Epoch 226 Acc: 96.05 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 484 train Loss: 5139.9 test Loss: 617.4
Epoch 227 Iter 0 subLoss 6173.1 multi -4.97 import weight 0.00
Epoch 227 Iter 1 subLoss 5092.8 multi -7.96 import weight 0.00
Epoch 227 Iter 2 subLoss 6074.5 multi 1.00 import weight 0.00
Epoch 227 Iter 3 subLoss 4390.0 multi 1.00 import weight 0.00
Epoch 227 Iter 4 subLoss 5093.6 multi -4.97 import weight 0.00
Epoch 227 Iter 5 subLoss 5516.1 multi -1.99 import weight 0.00
Epoch 227 Iter 6 subLoss 7721.8 multi -7.96 import weight 0.00
Epoch 227 Iter 7 subLoss 13393.4 multi 1.00 import weight 0.00
Epoch 227 Iter 8 subLoss 10500.4 multi 1.00 import weight 0.00
Epoch 227 Iter 9 subLoss 9640.8 multi -1.98 import weight 0.00
Epoch 227 Iter 10 subLoss 12305.3 multi -1.99 import weight 0.00
Epoch 227 Iter 11 subLoss 20366.7 multi -1.99 import weight 0.00
Epoch 227 Acc: 76.01 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 2036 train Loss: 46406.8 test Loss: 6072.2
Epoch 228 Iter 0 subLoss 44086.7 multi 1.00 import weight 0.00
Epoch 228 Iter 1 subLoss 20325.6 multi 1.00 import weight 0.00
Epoch 228 Iter 2 subLoss 15283.0 multi 3.98 import weight 0.00
Epoch 228 Iter 3 subLoss 6894.8 multi 6.97 import weight 0.00
Epoch 228 Iter 4 subLoss 5625.5 multi 3.98 import weight 0.00
Epoch 228 Iter 5 subLoss 5121.8 multi 1.00 import weight 0.00
Epoch 228 Iter 6 subLoss 5740.5 multi -1.99 import weight 0.00
Epoch 228 Iter 7 subLoss 5833.6 multi 1.00 import weight 0.00
Epoch 228 Iter 8 subLoss 5745.1 multi 1.00 import weight 0.00
Epoch 228 Iter 9 subLoss 5088.1 multi 9.96 import weight 0.00
Epoch 228 Iter 10 subLoss 6018.8 multi 12.94 import weight 0.00
Epoch 228 Iter 11 subLoss 5055.9 multi 1.00 import weight 0.00
Epoch 228 Acc: 95.50 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 505 train Loss: 5288.6 test Loss: 688.1
Epoch 229 Iter 0 subLoss 4648.3 multi 1.00 import weight 0.00
Epoch 229 Iter 1 subLoss 4247.5 multi 1.00 import weight 0.00
Epoch 229 Iter 2 subLoss 5105.3 multi 3.98 import weight 0.00
Epoch 229 Iter 3 subLoss 5184.6 multi -1.98 import weight 0.00
Epoch 229 Iter 4 subLoss 4731.5 multi 1.00 import weight 0.00
Epoch 229 Iter 5 subLoss 4833.4 multi 1.00 import weight 0.00
Epoch 229 Iter 6 subLoss 5072.7 multi -1.99 import weight 0.00
Epoch 229 Iter 7 subLoss 5674.0 multi 1.00 import weight 0.00
Epoch 229 Iter 8 subLoss 5092.3 multi -4.97 import weight 0.00
Epoch 229 Iter 9 subLoss 5165.8 multi 1.00 import weight 0.00
Epoch 229 Iter 10 subLoss 4763.7 multi 1.00 import weight 0.00
Epoch 229 Iter 11 subLoss 5689.7 multi -13.93 import weight 0.00
Epoch 229 Acc: 95.27 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -13.93 Pidx 568 train Loss: 5505.2 test Loss: 729.9
Epoch 230 Iter 0 subLoss 5490.6 multi -13.93 import weight 0.00
Epoch 230 Iter 1 subLoss 5752.4 multi 9.96 import weight 0.00
Epoch 230 Iter 2 subLoss 5619.2 multi 6.97 import weight 0.00
Epoch 230 Iter 3 subLoss 5662.3 multi 6.97 import weight 0.00
Epoch 230 Iter 4 subLoss 5338.5 multi 6.97 import weight 0.00
Epoch 230 Iter 5 subLoss 5041.7 multi 3.98 import weight 0.00
Epoch 230 Iter 6 subLoss 5535.6 multi 12.94 import weight 0.00
Epoch 230 Iter 7 subLoss 5260.2 multi -7.96 import weight 0.00
Epoch 230 Iter 8 subLoss 5167.4 multi 3.98 import weight 0.00
Epoch 230 Iter 9 subLoss 4920.8 multi 1.00 import weight 0.00
Epoch 230 Iter 10 subLoss 5129.4 multi 3.99 import weight 0.00
Epoch 230 Iter 11 subLoss 4965.3 multi -4.97 import weight 0.00
Epoch 230 Acc: 95.47 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 496 train Loss: 5203.2 test Loss: 686.9
Epoch 231 Iter 0 subLoss 6080.8 multi 1.00 import weight 0.00
Epoch 231 Iter 1 subLoss 5061.7 multi 1.00 import weight 0.00
Epoch 231 Iter 2 subLoss 5834.3 multi 3.99 import weight 0.00
Epoch 231 Iter 3 subLoss 4937.4 multi -4.97 import weight 0.00
Epoch 231 Iter 4 subLoss 5036.8 multi -1.98 import weight 0.00
Epoch 231 Iter 5 subLoss 4818.0 multi -13.93 import weight 0.00
Epoch 231 Iter 6 subLoss 6890.2 multi 9.96 import weight 0.00
Epoch 231 Iter 7 subLoss 4579.2 multi 1.00 import weight 0.00
Epoch 231 Iter 8 subLoss 5227.6 multi 1.00 import weight 0.00
Epoch 231 Iter 9 subLoss 5186.9 multi 1.00 import weight 0.00
Epoch 231 Iter 10 subLoss 4859.2 multi -1.98 import weight 0.00
Epoch 231 Iter 11 subLoss 5782.7 multi -13.93 import weight 0.00
Epoch 231 Acc: 92.64 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -13.93 Pidx 578 train Loss: 7451.0 test Loss: 1146.0
Epoch 232 Iter 0 subLoss 7099.7 multi 12.94 import weight 0.00
Epoch 232 Iter 1 subLoss 9593.4 multi -1.99 import weight 0.00
Epoch 232 Iter 2 subLoss 13407.2 multi -4.97 import weight 0.00
Epoch 232 Iter 3 subLoss 48028.4 multi 1.00 import weight 0.00
Epoch 232 Iter 4 subLoss 19509.6 multi 3.99 import weight 0.00
Epoch 232 Iter 5 subLoss 7248.7 multi -4.97 import weight 0.00
Epoch 232 Iter 6 subLoss 9645.3 multi 1.00 import weight 0.00
Epoch 232 Iter 7 subLoss 8951.6 multi -4.97 import weight 0.00
Epoch 232 Iter 8 subLoss 12465.9 multi -1.99 import weight 0.00
Epoch 232 Iter 9 subLoss 15704.1 multi -1.99 import weight 0.00
Epoch 232 Iter 10 subLoss 32787.1 multi 1.00 import weight 0.00
Epoch 232 Iter 11 subLoss 17395.9 multi 1.00 import weight 0.00
Epoch 232 Acc: 83.79 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1739 train Loss: 14830.8 test Loss: 2550.4
Epoch 233 Iter 0 subLoss 14932.9 multi -1.99 import weight 0.00
Epoch 233 Iter 1 subLoss 18436.9 multi 3.99 import weight 0.00
Epoch 233 Iter 2 subLoss 9716.2 multi -1.98 import weight 0.00
Epoch 233 Iter 3 subLoss 12637.3 multi 3.99 import weight 0.00
Epoch 233 Iter 4 subLoss 8723.6 multi 6.97 import weight 0.00
Epoch 233 Iter 5 subLoss 7408.8 multi 3.99 import weight 0.00
Epoch 233 Iter 6 subLoss 6864.9 multi 1.00 import weight 0.00
Epoch 233 Iter 7 subLoss 6144.7 multi 6.97 import weight 0.00
Epoch 233 Iter 8 subLoss 5650.6 multi 6.97 import weight 0.00
Epoch 233 Iter 9 subLoss 6284.5 multi 9.96 import weight 0.00
Epoch 233 Iter 10 subLoss 5358.9 multi -7.96 import weight 0.00
Epoch 233 Iter 11 subLoss 5440.9 multi -4.97 import weight 0.00
Epoch 233 Acc: 94.96 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 544 train Loss: 6009.6 test Loss: 798.8
Epoch 234 Iter 0 subLoss 5827.0 multi -1.99 import weight 0.00
Epoch 234 Iter 1 subLoss 6150.6 multi 6.97 import weight 0.00
Epoch 234 Iter 2 subLoss 5184.7 multi 3.99 import weight 0.00
Epoch 234 Iter 3 subLoss 5315.6 multi -4.97 import weight 0.00
Epoch 234 Iter 4 subLoss 5314.0 multi -1.99 import weight 0.00
Epoch 234 Iter 5 subLoss 4799.4 multi -4.97 import weight 0.00
Epoch 234 Iter 6 subLoss 5816.3 multi 1.00 import weight 0.00
Epoch 234 Iter 7 subLoss 5612.3 multi 9.96 import weight 0.00
Epoch 234 Iter 8 subLoss 5822.6 multi -1.99 import weight 0.00
Epoch 234 Iter 9 subLoss 5592.6 multi 1.00 import weight 0.00
Epoch 234 Iter 10 subLoss 5535.7 multi 15.93 import weight 0.00
Epoch 234 Iter 11 subLoss 5930.5 multi 3.99 import weight 0.00
Epoch 234 Acc: 95.35 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 593 train Loss: 5187.9 test Loss: 698.3
Epoch 235 Iter 0 subLoss 5511.4 multi 1.00 import weight 0.00
Epoch 235 Iter 1 subLoss 5125.4 multi 6.97 import weight 0.00
Epoch 235 Iter 2 subLoss 5239.5 multi -4.97 import weight 0.00
Epoch 235 Iter 3 subLoss 4529.2 multi -7.96 import weight 0.00
Epoch 235 Iter 4 subLoss 6035.9 multi -16.91 import weight 0.00
Epoch 235 Iter 5 subLoss 6725.6 multi 15.93 import weight 0.00
Epoch 235 Iter 6 subLoss 5853.3 multi -1.98 import weight 0.00
Epoch 235 Iter 7 subLoss 7675.2 multi -1.98 import weight 0.00
Epoch 235 Iter 8 subLoss 8929.6 multi 3.99 import weight 0.00
Epoch 235 Iter 9 subLoss 5844.5 multi -4.97 import weight 0.00
Epoch 235 Iter 10 subLoss 6962.4 multi 1.00 import weight 0.00
Epoch 235 Iter 11 subLoss 5924.3 multi -7.96 import weight 0.00
Epoch 235 Acc: 88.89 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 592 train Loss: 10192.0 test Loss: 1674.8
Epoch 236 Iter 0 subLoss 8966.7 multi -4.97 import weight 0.00
Epoch 236 Iter 1 subLoss 18311.6 multi 3.99 import weight 0.00
Epoch 236 Iter 2 subLoss 6315.1 multi 3.99 import weight 0.00
Epoch 236 Iter 3 subLoss 6291.8 multi -7.96 import weight 0.00
Epoch 236 Iter 4 subLoss 7889.1 multi -1.99 import weight 0.00
Epoch 236 Iter 5 subLoss 8881.6 multi -10.94 import weight 0.00
Epoch 236 Iter 6 subLoss 17721.5 multi -1.99 import weight 0.00
Epoch 236 Iter 7 subLoss 27174.7 multi -1.99 import weight 0.00
Epoch 236 Iter 8 subLoss 99551.8 multi 1.00 import weight 0.00
Epoch 236 Iter 9 subLoss 18564.9 multi 3.99 import weight 0.00
Epoch 236 Iter 10 subLoss 11997.3 multi 1.00 import weight 0.00
Epoch 236 Iter 11 subLoss 12270.3 multi -1.98 import weight 0.00
Epoch 236 Acc: 83.30 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 1227 train Loss: 13035.9 test Loss: 2385.8
Epoch 237 Iter 0 subLoss 12838.1 multi 3.99 import weight 0.00
Epoch 237 Iter 1 subLoss 11009.4 multi 3.99 import weight 0.00
Epoch 237 Iter 2 subLoss 7540.2 multi 3.99 import weight 0.00
Epoch 237 Iter 3 subLoss 6925.3 multi -1.99 import weight 0.00
Epoch 237 Iter 4 subLoss 7130.9 multi -7.96 import weight 0.00
Epoch 237 Iter 5 subLoss 8476.8 multi 6.97 import weight 0.00
Epoch 237 Iter 6 subLoss 7104.8 multi -4.97 import weight 0.00
Epoch 237 Iter 7 subLoss 8412.3 multi -1.99 import weight 0.00
Epoch 237 Iter 8 subLoss 9240.0 multi -1.99 import weight 0.00
Epoch 237 Iter 9 subLoss 9212.8 multi -1.98 import weight 0.00
Epoch 237 Iter 10 subLoss 11025.5 multi 1.00 import weight 0.00
Epoch 237 Iter 11 subLoss 9772.7 multi 3.98 import weight 0.00
Epoch 237 Acc: 90.00 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 977 train Loss: 8631.3 test Loss: 1504.3
Epoch 238 Iter 0 subLoss 8676.8 multi 6.97 import weight 0.00
Epoch 238 Iter 1 subLoss 6734.7 multi -4.97 import weight 0.00
Epoch 238 Iter 2 subLoss 7494.9 multi 3.99 import weight 0.00
Epoch 238 Iter 3 subLoss 6587.0 multi -4.97 import weight 0.00
Epoch 238 Iter 4 subLoss 7294.6 multi -1.98 import weight 0.00
Epoch 238 Iter 5 subLoss 8210.9 multi -7.96 import weight 0.00
Epoch 238 Iter 6 subLoss 10234.4 multi 1.00 import weight 0.00
Epoch 238 Iter 7 subLoss 9177.3 multi 6.97 import weight 0.00
Epoch 238 Iter 8 subLoss 6508.0 multi -10.94 import weight 0.00
Epoch 238 Iter 9 subLoss 9982.0 multi 6.97 import weight 0.00
Epoch 238 Iter 10 subLoss 7916.8 multi 1.00 import weight 0.00
Epoch 238 Iter 11 subLoss 6716.1 multi -1.99 import weight 0.00
Epoch 238 Acc: 91.48 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 671 train Loss: 7730.0 test Loss: 1322.8
Epoch 239 Iter 0 subLoss 7766.9 multi 3.98 import weight 0.00
Epoch 239 Iter 1 subLoss 7308.5 multi -4.97 import weight 0.00
Epoch 239 Iter 2 subLoss 7746.5 multi -1.99 import weight 0.00
Epoch 239 Iter 3 subLoss 8546.9 multi -7.96 import weight 0.00
Epoch 239 Iter 4 subLoss 11434.7 multi 1.00 import weight 0.00
Epoch 239 Iter 5 subLoss 10378.5 multi 1.00 import weight 0.00
Epoch 239 Iter 6 subLoss 10611.4 multi -1.99 import weight 0.00
Epoch 239 Iter 7 subLoss 11402.5 multi 1.00 import weight 0.00
Epoch 239 Iter 8 subLoss 9893.7 multi 1.00 import weight 0.00
Epoch 239 Iter 9 subLoss 9466.9 multi -1.98 import weight 0.00
Epoch 239 Iter 10 subLoss 10231.4 multi 3.98 import weight 0.00
Epoch 239 Iter 11 subLoss 9016.8 multi -1.98 import weight 0.00
Epoch 239 Acc: 87.74 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 901 train Loss: 9864.8 test Loss: 1782.0
Epoch 240 Iter 0 subLoss 10018.5 multi 1.00 import weight 0.00
Epoch 240 Iter 1 subLoss 9239.0 multi -1.98 import weight 0.00
Epoch 240 Iter 2 subLoss 10265.5 multi 1.00 import weight 0.00
Epoch 240 Iter 3 subLoss 9662.1 multi -1.98 import weight 0.00
Epoch 240 Iter 4 subLoss 10556.5 multi -7.96 import weight 0.00
Epoch 240 Iter 5 subLoss 13899.7 multi -1.98 import weight 0.00
Epoch 240 Iter 6 subLoss 15220.1 multi -4.97 import weight 0.00
Epoch 240 Iter 7 subLoss 19334.5 multi 1.00 import weight 0.00
Epoch 240 Iter 8 subLoss 18172.6 multi -1.99 import weight 0.00
Epoch 240 Iter 9 subLoss 19169.8 multi 1.00 import weight 0.00
Epoch 240 Iter 10 subLoss 17644.8 multi 1.00 import weight 0.00
Epoch 240 Iter 11 subLoss 17366.6 multi 1.00 import weight 0.00
Epoch 240 Acc: 78.23 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1736 train Loss: 16952.1 test Loss: 3072.9
Epoch 241 Iter 0 subLoss 16871.3 multi 1.00 import weight 0.00
Epoch 241 Iter 1 subLoss 15728.4 multi -1.99 import weight 0.00
Epoch 241 Iter 2 subLoss 17454.1 multi 3.99 import weight 0.00
Epoch 241 Iter 3 subLoss 14602.6 multi 3.99 import weight 0.00
Epoch 241 Iter 4 subLoss 12797.3 multi 1.00 import weight 0.00
Epoch 241 Iter 5 subLoss 12041.0 multi 1.00 import weight 0.00
Epoch 241 Iter 6 subLoss 11807.4 multi 1.00 import weight 0.00
Epoch 241 Iter 7 subLoss 11276.0 multi 6.97 import weight 0.00
Epoch 241 Iter 8 subLoss 8980.5 multi 1.00 import weight 0.00
Epoch 241 Iter 9 subLoss 9221.9 multi 1.00 import weight 0.00
Epoch 241 Iter 10 subLoss 8275.5 multi 3.98 import weight 0.00
Epoch 241 Iter 11 subLoss 7576.7 multi -4.97 import weight 0.00
Epoch 241 Acc: 90.29 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 757 train Loss: 8688.8 test Loss: 1477.9
Epoch 242 Iter 0 subLoss 8893.4 multi -1.99 import weight 0.00
Epoch 242 Iter 1 subLoss 9023.1 multi -1.98 import weight 0.00
Epoch 242 Iter 2 subLoss 10257.6 multi -7.96 import weight 0.00
Epoch 242 Iter 3 subLoss 11690.1 multi 3.99 import weight 0.00
Epoch 242 Iter 4 subLoss 10173.4 multi -4.97 import weight 0.00
Epoch 242 Iter 5 subLoss 12817.6 multi 1.00 import weight 0.00
Epoch 242 Iter 6 subLoss 12148.1 multi 1.00 import weight 0.00
Epoch 242 Iter 7 subLoss 11415.9 multi 1.00 import weight 0.00
Epoch 242 Iter 8 subLoss 11119.7 multi -1.98 import weight 0.00
Epoch 242 Iter 9 subLoss 12503.2 multi 9.96 import weight 0.00
Epoch 242 Iter 10 subLoss 8867.5 multi 3.99 import weight 0.00
Epoch 242 Iter 11 subLoss 7872.5 multi -7.96 import weight 0.00
Epoch 242 Acc: 88.81 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 787 train Loss: 9629.2 test Loss: 1668.8
Epoch 243 Iter 0 subLoss 9982.7 multi 9.96 import weight 0.00
Epoch 243 Iter 1 subLoss 7830.8 multi 1.00 import weight 0.00
Epoch 243 Iter 2 subLoss 7289.4 multi -1.99 import weight 0.00
Epoch 243 Iter 3 subLoss 7482.8 multi -1.99 import weight 0.00
Epoch 243 Iter 4 subLoss 8380.2 multi 1.00 import weight 0.00
Epoch 243 Iter 5 subLoss 7410.5 multi -7.96 import weight 0.00
Epoch 243 Iter 6 subLoss 8761.2 multi -1.99 import weight 0.00
Epoch 243 Iter 7 subLoss 9631.8 multi 6.97 import weight 0.00
Epoch 243 Iter 8 subLoss 8200.6 multi 9.96 import weight 0.00
Epoch 243 Iter 9 subLoss 6851.1 multi -7.96 import weight 0.00
Epoch 243 Iter 10 subLoss 7667.1 multi 1.00 import weight 0.00
Epoch 243 Iter 11 subLoss 7594.7 multi 3.98 import weight 0.00
Epoch 243 Acc: 92.82 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 759 train Loss: 7106.1 test Loss: 1121.1
Epoch 244 Iter 0 subLoss 7160.2 multi 1.00 import weight 0.00
Epoch 244 Iter 1 subLoss 7090.9 multi 15.93 import weight 0.00
Epoch 244 Iter 2 subLoss 6103.6 multi 12.94 import weight 0.00
Epoch 244 Iter 3 subLoss 5396.8 multi 3.98 import weight 0.00
Epoch 244 Iter 4 subLoss 6241.1 multi 6.97 import weight 0.00
Epoch 244 Iter 5 subLoss 5135.7 multi -4.97 import weight 0.00
Epoch 244 Iter 6 subLoss 6257.7 multi 12.94 import weight 1.00
Epoch 244 Iter 7 subLoss 5550.3 multi -1.99 import weight 0.00
Epoch 244 Iter 8 subLoss 5407.3 multi -4.97 import weight 0.00
Epoch 244 Iter 9 subLoss 5381.8 multi -13.93 import weight 0.00
Epoch 244 Iter 10 subLoss 5828.3 multi 1.00 import weight 0.00
Epoch 244 Iter 11 subLoss 5951.7 multi -13.93 import weight 0.00
Epoch 244 Acc: 90.21 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -13.93 Pidx 595 train Loss: 8649.3 test Loss: 1444.9
Epoch 245 Iter 0 subLoss 8850.7 multi -7.96 import weight 0.00
Epoch 245 Iter 1 subLoss 14827.1 multi -1.99 import weight 0.00
Epoch 245 Iter 2 subLoss 36645.0 multi 1.00 import weight 0.00
Epoch 245 Iter 3 subLoss 13662.7 multi -4.97 import weight 0.00
Epoch 245 Iter 4 subLoss 26545.0 multi 1.00 import weight 0.00
Epoch 245 Iter 5 subLoss 18638.1 multi -1.99 import weight 0.00
Epoch 245 Iter 6 subLoss 28101.3 multi 3.99 import weight 0.00
Epoch 245 Iter 7 subLoss 12117.6 multi 1.00 import weight 0.00
Epoch 245 Iter 8 subLoss 10652.5 multi -1.99 import weight 0.00
Epoch 245 Iter 9 subLoss 12413.3 multi 1.00 import weight 0.00
Epoch 245 Iter 10 subLoss 11335.4 multi 3.98 import weight 0.00
Epoch 245 Iter 11 subLoss 9735.3 multi 1.00 import weight 0.00
Epoch 245 Acc: 88.48 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 973 train Loss: 9292.2 test Loss: 1670.5
Epoch 246 Iter 0 subLoss 9556.4 multi 3.99 import weight 0.00
Epoch 246 Iter 1 subLoss 8231.3 multi -1.98 import weight 0.00
Epoch 246 Iter 2 subLoss 8917.3 multi -7.96 import weight 0.00
Epoch 246 Iter 3 subLoss 10813.0 multi 1.00 import weight 0.00
Epoch 246 Iter 4 subLoss 10111.5 multi 3.98 import weight 0.00
Epoch 246 Iter 5 subLoss 8583.9 multi 1.00 import weight 0.00
Epoch 246 Iter 6 subLoss 7973.1 multi 9.96 import weight 0.00
Epoch 246 Iter 7 subLoss 7080.8 multi -7.96 import weight 0.00
Epoch 246 Iter 8 subLoss 7975.4 multi 12.94 import weight 0.00
Epoch 246 Iter 9 subLoss 5671.9 multi 1.00 import weight 0.00
Epoch 246 Iter 10 subLoss 6072.5 multi 3.99 import weight 0.00
Epoch 246 Iter 11 subLoss 6239.0 multi 9.96 import weight 0.00
Epoch 246 Acc: 94.34 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 623 train Loss: 5927.4 test Loss: 865.4
Epoch 247 Iter 0 subLoss 5168.6 multi 6.97 import weight 0.00
Epoch 247 Iter 1 subLoss 6405.6 multi -1.99 import weight 0.00
Epoch 247 Iter 2 subLoss 5913.7 multi 12.94 import weight 0.00
Epoch 247 Iter 3 subLoss 5448.8 multi -1.99 import weight 0.00
Epoch 247 Iter 4 subLoss 5159.8 multi 3.99 import weight 0.00
Epoch 247 Iter 5 subLoss 5556.4 multi 1.00 import weight 0.00
Epoch 247 Iter 6 subLoss 4725.7 multi -1.99 import weight 0.00
Epoch 247 Iter 7 subLoss 6024.0 multi -1.99 import weight 0.00
Epoch 247 Iter 8 subLoss 5389.9 multi -10.94 import weight 0.00
Epoch 247 Iter 9 subLoss 6079.7 multi 6.97 import weight 0.00
Epoch 247 Iter 10 subLoss 4880.8 multi 6.97 import weight 0.00
Epoch 247 Iter 11 subLoss 5773.2 multi 1.00 import weight 0.00
Epoch 247 Acc: 94.82 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 577 train Loss: 5553.5 test Loss: 783.1
Epoch 248 Iter 0 subLoss 5623.2 multi 1.00 import weight 0.00
Epoch 248 Iter 1 subLoss 5020.7 multi 1.00 import weight 0.00
Epoch 248 Iter 2 subLoss 5500.4 multi -1.99 import weight 0.00
Epoch 248 Iter 3 subLoss 5986.2 multi 6.97 import weight 0.00
Epoch 248 Iter 4 subLoss 5846.8 multi -1.99 import weight 0.00
Epoch 248 Iter 5 subLoss 4801.6 multi 18.91 import weight 0.00
Epoch 248 Iter 6 subLoss 5136.9 multi -1.98 import weight 0.00
Epoch 248 Iter 7 subLoss 5278.4 multi -1.99 import weight 0.00
Epoch 248 Iter 8 subLoss 5362.0 multi 9.96 import weight 0.00
Epoch 248 Iter 9 subLoss 4754.1 multi -1.98 import weight 0.00
Epoch 248 Iter 10 subLoss 5335.4 multi 9.96 import weight 0.00
Epoch 248 Iter 11 subLoss 5067.0 multi 3.99 import weight 0.00
Epoch 248 Acc: 95.45 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 506 train Loss: 5106.3 test Loss: 686.7
Epoch 249 Iter 0 subLoss 5077.7 multi -4.97 import weight 0.00
Epoch 249 Iter 1 subLoss 4912.7 multi -10.94 import weight 0.00
Epoch 249 Iter 2 subLoss 4894.2 multi -4.97 import weight 0.00
Epoch 249 Iter 3 subLoss 6121.1 multi -7.96 import weight 0.00
Epoch 249 Iter 4 subLoss 6118.9 multi -13.93 import weight 0.00
Epoch 249 Iter 5 subLoss 46311.2 multi 1.00 import weight 0.00
Epoch 249 Iter 6 subLoss 8552.3 multi -1.98 import weight 0.00
Epoch 249 Iter 7 subLoss 11512.7 multi -1.99 import weight 0.00
Epoch 249 Iter 8 subLoss 15893.9 multi 1.00 import weight 0.00
Epoch 249 Iter 9 subLoss 11702.3 multi -1.98 import weight 0.00
Epoch 249 Iter 10 subLoss 19727.8 multi 3.99 import weight 0.00
Epoch 249 Iter 11 subLoss 5719.6 multi -1.99 import weight 0.00
Epoch 249 Acc: 93.13 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 571 train Loss: 6870.4 test Loss: 1075.9
Epoch 250 Iter 0 subLoss 6377.7 multi 3.98 import weight 0.00
Epoch 250 Iter 1 subLoss 5966.2 multi 1.00 import weight 0.00
Epoch 250 Iter 2 subLoss 5827.8 multi 3.98 import weight 0.00
Epoch 250 Iter 3 subLoss 5143.2 multi -4.97 import weight 0.00
Epoch 250 Iter 4 subLoss 6556.9 multi -4.97 import weight 0.00
Epoch 250 Iter 5 subLoss 6802.4 multi 9.96 import weight 0.00
Epoch 250 Iter 6 subLoss 5456.0 multi -1.99 import weight 0.00
Epoch 250 Iter 7 subLoss 5905.0 multi -7.96 import weight 0.00
Epoch 250 Iter 8 subLoss 6532.6 multi -1.98 import weight 0.00
Epoch 250 Iter 9 subLoss 6142.6 multi 9.96 import weight 0.00
Epoch 250 Iter 10 subLoss 6074.8 multi 9.96 import weight 0.00
Epoch 250 Iter 11 subLoss 5953.4 multi -10.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0175 / 0.11714 / 9.07
Entropy seen (from low to high)
[1869, 473, 255, 485, 513, 331, 125, 88, 72, 68, 63, 42, 43, 42, 44, 44, 38, 42, 51, 44, 43, 40, 33, 24, 30, 27, 25, 26, 17, 19, 17, 21, 10, 15, 7, 7, 9, 5, 10, 6, 3, 3, 3, 2, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 7, 33, 69, 89, 113, 143, 136, 155, 165, 146, 136, 155, 159, 130, 161, 130, 137, 112, 121, 105, 119, 110, 99, 112, 98, 105, 88, 90, 73, 82, 73, 72, 102, 84, 101, 85, 101, 100, 90, 93, 118, 114, 101, 118, 129]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.5, 30.0, 33.2, 37.1, 40.3, 43.6, 46.8, 50.7, 54.1, 57.8, 61.3, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 74.9, 39.9, 49.9, 58.3, 49.9, 42.3, 56.7, 57.4, 91.4, 72.4, 67.5, 70.4]
[0, 0, 0, 0, 0, 0, 0, 1, 4, 5, 10, 12, 26, 26, 37, 47, 35, 40, 37, 61]
Epoch 250 Acc: 94.42 BMA: 94.42 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -10.94 Pidx 595 train Loss: 5973.7 test Loss: 866.4
Epoch 251 Iter 0 subLoss 6441.4 multi -1.99 import weight 0.00
Epoch 251 Iter 1 subLoss 5684.7 multi -13.93 import weight 0.00
Epoch 251 Iter 2 subLoss 6583.5 multi -1.99 import weight 0.00
Epoch 251 Iter 3 subLoss 8030.6 multi 1.00 import weight 0.00
Epoch 251 Iter 4 subLoss 7051.5 multi 15.93 import weight 0.00
Epoch 251 Iter 5 subLoss 7299.1 multi -1.99 import weight 0.00
Epoch 251 Iter 6 subLoss 7143.6 multi 9.96 import weight 0.00
Epoch 251 Iter 7 subLoss 5577.9 multi -1.98 import weight 0.00
Epoch 251 Iter 8 subLoss 5430.3 multi 3.99 import weight 0.00
Epoch 251 Iter 9 subLoss 5431.7 multi 6.97 import weight 0.00
Epoch 251 Iter 10 subLoss 5165.9 multi 6.97 import weight 0.00
Epoch 251 Iter 11 subLoss 4983.3 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0158 / 0.11767 / 10.26
Entropy seen (from low to high)
[1882, 471, 323, 546, 463, 282, 121, 83, 78, 56, 54, 53, 36, 43, 45, 48, 42, 39, 48, 42, 41, 47, 23, 34, 26, 32, 18, 21, 20, 17, 19, 10, 16, 4, 5, 8, 6, 8, 10, 4, 2, 1, 6, 3, 3, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 10, 33, 54, 80, 109, 101, 139, 178, 142, 143, 142, 157, 145, 156, 136, 142, 129, 119, 119, 130, 125, 108, 125, 104, 110, 104, 82, 88, 65, 76, 92, 70, 109, 80, 100, 99, 90, 94, 95, 122, 108, 116, 90, 117, 128]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.0, 33.0, 36.9, 40.2, 43.8, 47.4, 51.0, 53.8, 57.7, 61.2, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 66.6, 62.4, 49.9, 37.4, 46.1, 60.8, 61.3, 39.9, 63.1, 49.9, 71.1, 81.3]
[0, 0, 0, 0, 0, 0, 0, 0, 3, 8, 8, 16, 13, 23, 44, 30, 38, 48, 52, 43]
Epoch 251 Acc: 95.21 BMA: 94.75 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 498 train Loss: 5323.6 test Loss: 742.9
Epoch 252 Iter 0 subLoss 5803.4 multi -10.94 import weight 0.00
Epoch 252 Iter 1 subLoss 5769.7 multi -1.98 import weight 0.00
Epoch 252 Iter 2 subLoss 5710.2 multi 1.00 import weight 0.00
Epoch 252 Iter 3 subLoss 5768.2 multi 1.00 import weight 0.00
Epoch 252 Iter 4 subLoss 5275.7 multi 1.00 import weight 0.00
Epoch 252 Iter 5 subLoss 5803.7 multi -7.96 import weight 0.00
Epoch 252 Iter 6 subLoss 4960.7 multi -1.98 import weight 0.00
Epoch 252 Iter 7 subLoss 6054.0 multi -1.98 import weight 0.00
Epoch 252 Iter 8 subLoss 5697.7 multi 3.99 import weight 0.00
Epoch 252 Iter 9 subLoss 5683.3 multi -10.94 import weight 0.00
Epoch 252 Iter 10 subLoss 5825.4 multi 6.97 import weight 0.00
Epoch 252 Iter 11 subLoss 5812.6 multi -1.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0155 / 0.11684 / 6.56
Entropy seen (from low to high)
[1822, 464, 323, 538, 484, 313, 130, 92, 72, 56, 65, 48, 50, 39, 37, 38, 45, 46, 42, 46, 37, 39, 32, 31, 26, 30, 23, 25, 19, 14, 19, 18, 14, 5, 6, 5, 8, 8, 11, 3, 3, 1, 6, 3, 3, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 11, 34, 67, 80, 97, 135, 137, 155, 139, 147, 158, 148, 147, 159, 137, 128, 132, 133, 124, 133, 121, 112, 115, 116, 105, 102, 79, 74, 86, 84, 86, 100, 73, 92, 96, 81, 92, 103, 101, 123, 109, 90, 99, 108, 113]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.8, 30.3, 32.5, 36.6, 39.8, 43.3, 47.4, 50.6, 54.2, 57.8, 61.2, 64.7, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 74.9, 59.9, 33.3, 39.9, 36.8, 52.1, 52.2, 62.4, 49.9, 66.6, 72.3, 62.7]
[0, 0, 0, 0, 0, 0, 0, 1, 4, 5, 9, 10, 19, 23, 44, 40, 44, 36, 47, 51]
Epoch 252 Acc: 94.92 BMA: 94.73 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 581 train Loss: 5869.4 test Loss: 787.9
Epoch 253 Iter 0 subLoss 6148.9 multi 12.94 import weight 0.00
Epoch 253 Iter 1 subLoss 5644.9 multi -4.97 import weight 0.00
Epoch 253 Iter 2 subLoss 4733.9 multi 1.00 import weight 0.00
Epoch 253 Iter 3 subLoss 5777.6 multi -1.99 import weight 0.00
Epoch 253 Iter 4 subLoss 5648.9 multi -1.99 import weight 0.00
Epoch 253 Iter 5 subLoss 6049.9 multi 3.98 import weight 0.00
Epoch 253 Iter 6 subLoss 5204.0 multi -1.98 import weight 0.00
Epoch 253 Iter 7 subLoss 5780.9 multi -16.91 import weight 0.00
Epoch 253 Iter 8 subLoss 7617.0 multi 1.00 import weight 0.00
Epoch 253 Iter 9 subLoss 7025.0 multi -1.99 import weight 0.00
Epoch 253 Iter 10 subLoss 7730.9 multi 9.96 import weight 0.00
Epoch 253 Iter 11 subLoss 5909.3 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0154 / 0.11303 / 4.85
Entropy seen (from low to high)
[1689, 456, 328, 499, 547, 344, 147, 93, 77, 64, 57, 52, 47, 55, 45, 42, 44, 44, 45, 52, 40, 41, 28, 25, 34, 28, 28, 20, 22, 25, 25, 17, 11, 6, 9, 8, 7, 8, 6, 9, 4, 1, 3, 5, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 16, 34, 74, 85, 125, 140, 138, 145, 149, 169, 157, 194, 143, 148, 143, 129, 148, 127, 131, 122, 127, 120, 124, 107, 116, 125, 89, 76, 91, 88, 102, 85, 82, 77, 93, 87, 89, 100, 79, 90, 98, 81, 73, 80, 64]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.3, 33.1, 37.0, 40.4, 44.1, 47.5, 50.8, 54.4, 57.8, 61.1, 64.8, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 44.4, 59.9, 59.9, 42.8, 47.8, 57.4, 59.6, 58.9, 60.7, 71.0, 69.4]
[0, 0, 0, 0, 0, 0, 0, 0, 2, 9, 10, 15, 14, 23, 47, 52, 39, 51, 38, 59]
Epoch 253 Acc: 94.59 BMA: 95.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 590 train Loss: 6659.6 test Loss: 877.3
Epoch 254 Iter 0 subLoss 6474.4 multi 1.00 import weight 0.00
Epoch 254 Iter 1 subLoss 6645.1 multi 21.90 import weight 0.00
Epoch 254 Iter 2 subLoss 7407.7 multi 6.97 import weight 0.00
Epoch 254 Iter 3 subLoss 5040.9 multi 3.99 import weight 0.00
Epoch 254 Iter 4 subLoss 4917.2 multi -7.96 import weight 0.00
Epoch 254 Iter 5 subLoss 5150.2 multi 3.98 import weight 0.00
Epoch 254 Iter 6 subLoss 6385.9 multi 3.99 import weight 0.00
Epoch 254 Iter 7 subLoss 5178.3 multi -16.91 import weight 0.00
Epoch 254 Iter 8 subLoss 5741.2 multi 3.99 import weight 0.00
Epoch 254 Iter 9 subLoss 5581.8 multi 1.00 import weight 0.00
Epoch 254 Iter 10 subLoss 5793.2 multi 9.96 import weight 0.00
Epoch 254 Iter 11 subLoss 5550.3 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0152 / 0.11323 / 5.19
Entropy seen (from low to high)
[1693, 473, 358, 576, 474, 305, 136, 101, 73, 61, 63, 56, 58, 43, 37, 44, 41, 42, 50, 48, 47, 37, 22, 28, 34, 33, 22, 24, 22, 27, 17, 16, 9, 8, 9, 11, 4, 9, 7, 7, 3, 1, 4, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 20, 33, 74, 86, 103, 153, 137, 151, 149, 149, 166, 183, 159, 150, 139, 148, 141, 136, 125, 120, 132, 132, 99, 107, 125, 110, 80, 79, 97, 88, 80, 100, 89, 69, 91, 83, 104, 92, 90, 88, 98, 80, 70, 87, 69]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.8, 33.0, 36.8, 39.9, 43.9, 47.5, 50.6, 54.5, 57.6, 61.1, 64.7, 68.5]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 33.3, 49.9, 46.1, 64.7, 44.4, 53.0, 64.2, 55.5, 65.3, 69.2, 68.4]
[0, 0, 0, 0, 0, 0, 0, 0, 3, 6, 8, 13, 17, 27, 49, 42, 45, 49, 39, 57]
Epoch 254 Acc: 95.08 BMA: 95.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 555 train Loss: 5558.7 test Loss: 757.5
Epoch 255 Iter 0 subLoss 5399.9 multi 1.00 import weight 0.00
Epoch 255 Iter 1 subLoss 4807.9 multi 21.90 import weight 0.00
Epoch 255 Iter 2 subLoss 5728.0 multi -13.93 import weight 0.00
Epoch 255 Iter 3 subLoss 6300.9 multi -10.94 import weight 0.00
Epoch 255 Iter 4 subLoss 7817.5 multi 1.00 import weight 0.00
Epoch 255 Iter 5 subLoss 6604.3 multi -4.97 import weight 0.00
Epoch 255 Iter 6 subLoss 9960.1 multi -1.99 import weight 0.00
Epoch 255 Iter 7 subLoss 16438.8 multi -1.99 import weight 0.00
Epoch 255 Iter 8 subLoss 33499.4 multi 1.00 import weight 0.00
Epoch 255 Iter 9 subLoss 16459.2 multi -1.99 import weight 0.00
Epoch 255 Iter 10 subLoss 29947.5 multi -1.99 import weight 0.00
Epoch 255 Iter 11 subLoss 92035.4 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0159 / 0.09919 / 9.10
Entropy seen (from low to high)
[1112, 419, 342, 568, 484, 290, 150, 144, 119, 98, 96, 126, 94, 116, 76, 86, 85, 78, 61, 57, 68, 43, 53, 35, 46, 40, 31, 37, 18, 31, 21, 20, 16, 12, 5, 14, 9, 6, 5, 8, 5, 6, 4, 1, 2, 2, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 7, 24, 59, 98, 125, 156, 141, 158, 172, 198, 193, 182, 173, 172, 180, 165, 147, 180, 132, 149, 140, 143, 124, 146, 157, 146, 152, 132, 123, 127, 106, 83, 77, 49, 52, 38, 39, 29, 42, 28, 30, 30, 20, 16, 15, 6]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.2, 29.3, 33.4, 37.1, 40.1, 43.5, 47.5, 50.5, 53.9, 57.7, 61.3, 64.6, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 63.6, 41.1, 54.9, 59.9, 59.9, 56.0, 61.4, 77.9, 67.6, 78.6]
[0, 0, 0, 0, 0, 0, 0, 1, 4, 8, 11, 17, 20, 45, 40, 41, 57, 59, 65, 61]
Epoch 255 Acc: 83.11 BMA: 95.14 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 9203 train Loss: 22124.3 test Loss: 2936.7
Epoch 256 Iter 0 subLoss 22658.4 multi 3.99 import weight 0.00
Epoch 256 Iter 1 subLoss 6862.8 multi 1.00 import weight 0.00
Epoch 256 Iter 2 subLoss 6892.2 multi 12.94 import weight 0.00
Epoch 256 Iter 3 subLoss 5044.8 multi 6.97 import weight 0.00
Epoch 256 Iter 4 subLoss 5157.3 multi 6.97 import weight 0.00
Epoch 256 Iter 5 subLoss 5685.0 multi -7.96 import weight 0.00
Epoch 256 Iter 6 subLoss 5234.5 multi -1.99 import weight 0.00
Epoch 256 Iter 7 subLoss 5193.6 multi -4.97 import weight 0.00
Epoch 256 Iter 8 subLoss 5155.4 multi 9.96 import weight 0.00
Epoch 256 Iter 9 subLoss 5533.6 multi 18.91 import weight 0.00
Epoch 256 Iter 10 subLoss 5318.7 multi 1.00 import weight 0.00
Epoch 256 Iter 11 subLoss 5105.4 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0151 / 0.10139 / 10.76
Entropy seen (from low to high)
[1142, 427, 405, 586, 462, 249, 162, 153, 108, 101, 128, 112, 113, 87, 75, 74, 82, 54, 53, 69, 55, 44, 37, 47, 49, 38, 29, 20, 26, 22, 23, 19, 17, 8, 6, 14, 6, 3, 10, 5, 5, 5, 4, 1, 2, 2, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 6, 27, 52, 100, 113, 149, 136, 159, 159, 183, 203, 167, 179, 154, 173, 160, 155, 163, 146, 143, 137, 129, 135, 128, 152, 140, 139, 145, 118, 134, 100, 111, 100, 79, 52, 63, 33, 37, 42, 36, 22, 37, 24, 17, 18, 6]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.0, 29.2, 33.5, 36.9, 40.3, 43.5, 47.2, 50.7, 54.3, 57.7, 61.0, 64.6, 68.4]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 0.0, 57.1, 44.4, 79.9, 55.9, 66.6, 48.8, 59.9, 56.8, 75.8, 73.3, 80.5]
[0, 0, 0, 0, 0, 0, 0, 2, 3, 7, 9, 15, 25, 30, 43, 50, 44, 58, 60, 67]
Epoch 256 Acc: 95.78 BMA: 95.39 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 510 train Loss: 5346.3 test Loss: 641.8
Epoch 257 Iter 0 subLoss 5419.4 multi 1.00 import weight 0.00
Epoch 257 Iter 1 subLoss 4557.7 multi 3.99 import weight 0.00
Epoch 257 Iter 2 subLoss 5295.0 multi 3.99 import weight 0.00
Epoch 257 Iter 3 subLoss 4820.8 multi -4.97 import weight 0.00
Epoch 257 Iter 4 subLoss 5485.6 multi 6.97 import weight 0.00
Epoch 257 Iter 5 subLoss 4972.8 multi 1.00 import weight 0.00
Epoch 257 Iter 6 subLoss 5207.9 multi -1.99 import weight 0.00
Epoch 257 Iter 7 subLoss 5166.3 multi 1.00 import weight 0.00
Epoch 257 Iter 8 subLoss 4580.9 multi 1.00 import weight 0.00
Epoch 257 Iter 9 subLoss 4488.2 multi 3.99 import weight 0.00
Epoch 257 Iter 10 subLoss 4784.3 multi -1.99 import weight 0.00
Epoch 257 Iter 11 subLoss 4331.4 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0146 / 0.10342 / 10.32
Entropy seen (from low to high)
[1163, 452, 489, 597, 415, 208, 182, 136, 123, 119, 118, 119, 94, 79, 82, 69, 59, 51, 56, 55, 49, 53, 36, 45, 37, 41, 21, 31, 22, 16, 20, 18, 17, 5, 8, 11, 8, 6, 7, 4, 4, 5, 4, 1, 2, 2, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 5, 26, 49, 91, 106, 148, 133, 158, 144, 167, 204, 168, 185, 151, 155, 145, 163, 161, 150, 142, 138, 131, 129, 133, 112, 152, 123, 147, 125, 113, 139, 110, 104, 104, 79, 54, 63, 36, 37, 49, 25, 34, 28, 19, 19, 7]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.0, 29.8, 33.7, 36.6, 40.1, 43.9, 47.4, 50.7, 54.3, 57.6, 61.5, 64.7, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 59.9, 39.9, 55.5, 81.8, 69.5, 63.3, 54.5, 57.7, 65.2, 65.4, 79.1, 75.3]
[0, 0, 0, 0, 0, 0, 0, 1, 5, 5, 9, 11, 23, 30, 44, 45, 46, 55, 48, 65]
Epoch 257 Acc: 95.82 BMA: 95.60 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 433 train Loss: 5172.3 test Loss: 639.1
Epoch 258 Iter 0 subLoss 5427.9 multi 1.00 import weight 0.00
Epoch 258 Iter 1 subLoss 5045.5 multi 9.96 import weight 0.00
Epoch 258 Iter 2 subLoss 4929.2 multi -1.99 import weight 0.00
Epoch 258 Iter 3 subLoss 5530.8 multi 21.90 import weight 0.00
Epoch 258 Iter 4 subLoss 5927.2 multi -7.96 import weight 0.00
Epoch 258 Iter 5 subLoss 5788.0 multi -13.93 import weight 0.00
Epoch 258 Iter 6 subLoss 27373.3 multi 3.99 import weight 0.00
Epoch 258 Iter 7 subLoss 10630.5 multi -1.99 import weight 0.00
Epoch 258 Iter 8 subLoss 14110.7 multi 3.99 import weight 0.00
Epoch 258 Iter 9 subLoss 6958.0 multi 1.00 import weight 0.00
Epoch 258 Iter 10 subLoss 6835.0 multi -7.96 import weight 0.00
Epoch 258 Iter 11 subLoss 9430.5 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0146 / 0.10104 / 9.68
Entropy seen (from low to high)
[1053, 449, 516, 623, 412, 235, 155, 151, 123, 120, 116, 102, 98, 80, 62, 61, 69, 71, 50, 55, 61, 43, 35, 51, 45, 47, 39, 23, 21, 29, 29, 19, 19, 11, 6, 11, 12, 4, 9, 5, 5, 6, 3, 0, 4, 1, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 6, 27, 44, 101, 114, 157, 168, 149, 159, 187, 192, 185, 192, 172, 160, 157, 160, 190, 184, 132, 129, 151, 115, 146, 136, 120, 151, 120, 92, 112, 81, 94, 79, 78, 85, 49, 53, 47, 38, 35, 30, 20, 26, 19, 13, 6]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.1, 30.3, 33.7, 36.3, 39.8, 43.5, 47.2, 50.8, 54.4, 57.7, 61.2, 64.9, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 39.9, 49.9, 57.1, 61.5, 67.7, 49.9, 53.6, 64.7, 59.9, 78.5, 74.0, 73.2]
[0, 0, 0, 0, 0, 0, 0, 1, 5, 6, 7, 13, 31, 32, 41, 51, 50, 56, 54, 71]
Epoch 258 Acc: 93.95 BMA: 95.56 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 943 train Loss: 7342.1 test Loss: 1057.9
Epoch 259 Iter 0 subLoss 7623.0 multi 3.99 import weight 0.00
Epoch 259 Iter 1 subLoss 5889.3 multi -1.98 import weight 0.00
Epoch 259 Iter 2 subLoss 6435.4 multi -7.96 import weight 0.00
Epoch 259 Iter 3 subLoss 8371.6 multi 1.00 import weight 0.00
Epoch 259 Iter 4 subLoss 7574.6 multi -1.99 import weight 0.00
Epoch 259 Iter 5 subLoss 7948.8 multi -1.99 import weight 0.00
Epoch 259 Iter 6 subLoss 9378.7 multi 3.99 import weight 0.00
Epoch 259 Iter 7 subLoss 7990.5 multi 15.93 import weight 0.00
Epoch 259 Iter 8 subLoss 5261.3 multi -4.97 import weight 0.00
Epoch 259 Iter 9 subLoss 5910.8 multi 9.96 import weight 0.00
Epoch 259 Iter 10 subLoss 5019.7 multi 1.00 import weight 0.00
Epoch 259 Iter 11 subLoss 5491.3 multi -13.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0145 / 0.10131 / 10.06
Entropy seen (from low to high)
[1055, 456, 498, 633, 431, 240, 160, 144, 130, 141, 104, 98, 87, 68, 68, 69, 62, 59, 50, 62, 45, 46, 42, 47, 41, 44, 38, 19, 27, 33, 28, 16, 14, 17, 5, 14, 9, 6, 9, 4, 7, 6, 1, 1, 4, 1, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 5, 24, 47, 95, 120, 149, 159, 170, 164, 173, 207, 175, 199, 166, 174, 155, 152, 181, 184, 142, 128, 143, 121, 117, 146, 137, 121, 126, 101, 101, 87, 103, 74, 72, 91, 57, 55, 47, 39, 35, 36, 21, 23, 17, 16, 6]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.9, 30.3, 32.9, 36.7, 40.5, 43.6, 47.3, 50.8, 54.1, 57.6, 61.3, 65.1, 68.4]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 24.9, 74.9, 55.5, 58.8, 59.2, 53.5, 57.4, 61.2, 61.8, 83.0, 74.5, 72.7]
[0, 0, 0, 0, 0, 0, 0, 1, 4, 4, 9, 17, 27, 28, 47, 49, 55, 53, 59, 66]
Epoch 259 Acc: 95.23 BMA: 95.52 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -13.93 Pidx 549 train Loss: 5703.4 test Loss: 764.4
Epoch 260 Iter 0 subLoss 5478.7 multi 9.96 import weight 0.00
Epoch 260 Iter 1 subLoss 4873.8 multi 1.00 import weight 0.00
Epoch 260 Iter 2 subLoss 5493.2 multi -10.94 import weight 0.00
Epoch 260 Iter 3 subLoss 5582.1 multi 3.99 import weight 0.00
Epoch 260 Iter 4 subLoss 5358.3 multi -4.97 import weight 0.00
Epoch 260 Iter 5 subLoss 5608.2 multi 6.97 import weight 0.00
Epoch 260 Iter 6 subLoss 5517.7 multi 1.00 import weight 0.00
Epoch 260 Iter 7 subLoss 5279.0 multi 1.00 import weight 0.00
Epoch 260 Iter 8 subLoss 5405.4 multi -4.97 import weight 0.00
Epoch 260 Iter 9 subLoss 5266.9 multi -1.98 import weight 0.00
Epoch 260 Iter 10 subLoss 5222.8 multi 3.99 import weight 0.00
Epoch 260 Iter 11 subLoss 5916.6 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0143 / 0.10213 / 11.42
Entropy seen (from low to high)
[1054, 464, 534, 615, 436, 240, 176, 133, 143, 127, 114, 87, 75, 62, 71, 65, 67, 56, 51, 47, 57, 47, 39, 46, 37, 46, 29, 25, 27, 34, 26, 9, 19, 12, 9, 12, 9, 9, 7, 5, 4, 7, 1, 1, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 5, 24, 44, 91, 119, 138, 151, 170, 162, 173, 195, 200, 188, 174, 176, 158, 149, 176, 178, 148, 127, 131, 123, 110, 139, 145, 117, 126, 100, 115, 82, 97, 93, 76, 85, 68, 53, 48, 45, 38, 37, 23, 23, 18, 16, 7]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.4, 30.6, 33.8, 36.3, 40.0, 43.8, 47.5, 50.9, 54.2, 57.7, 61.4, 64.7, 68.4]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.9, 99.9, 62.4, 56.2, 62.9, 54.5, 64.5, 60.8, 64.2, 74.9, 77.1, 77.9]
[0, 0, 0, 0, 0, 0, 0, 1, 5, 2, 8, 16, 27, 33, 48, 46, 56, 44, 57, 68]
Epoch 260 Acc: 95.37 BMA: 95.58 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 591 train Loss: 5222.7 test Loss: 728.3
Epoch 261 Iter 0 subLoss 5110.6 multi -13.93 import weight 0.00
Epoch 261 Iter 1 subLoss 5477.5 multi 12.94 import weight 0.00
Epoch 261 Iter 2 subLoss 5647.2 multi 1.00 import weight 0.00
Epoch 261 Iter 3 subLoss 5363.7 multi 9.96 import weight 0.00
Epoch 261 Iter 4 subLoss 5148.2 multi -1.98 import weight 0.00
Epoch 261 Iter 5 subLoss 5681.3 multi -4.97 import weight 0.00
Epoch 261 Iter 6 subLoss 5463.2 multi -1.99 import weight 0.00
Epoch 261 Iter 7 subLoss 4680.6 multi 3.98 import weight 0.00
Epoch 261 Iter 8 subLoss 5153.5 multi 9.96 import weight 0.00
Epoch 261 Iter 9 subLoss 4844.5 multi 1.00 import weight 0.00
Epoch 261 Iter 10 subLoss 5341.3 multi -1.99 import weight 0.00
Epoch 261 Iter 11 subLoss 5299.9 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0141 / 0.10333 / 10.94
Entropy seen (from low to high)
[1069, 472, 586, 613, 412, 230, 170, 156, 143, 130, 93, 84, 70, 57, 80, 62, 59, 58, 36, 45, 65, 43, 41, 42, 38, 46, 27, 22, 28, 30, 24, 9, 18, 13, 12, 6, 12, 9, 8, 2, 6, 6, 1, 1, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4, 22, 44, 78, 117, 134, 145, 174, 154, 171, 191, 204, 168, 197, 157, 168, 146, 163, 177, 161, 114, 144, 109, 132, 118, 135, 130, 123, 102, 118, 90, 91, 96, 85, 82, 80, 63, 50, 56, 39, 33, 29, 25, 18, 17, 7]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.1, 33.1, 36.7, 40.3, 44.4, 47.3, 50.9, 54.2, 57.6, 61.4, 64.8, 68.4]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.9, 49.9, 58.3, 57.1, 58.3, 54.5, 62.7, 62.2, 67.8, 63.2, 86.5, 77.2]
[0, 0, 0, 0, 0, 0, 0, 0, 5, 2, 12, 14, 24, 33, 43, 45, 56, 49, 52, 66]
Epoch 261 Acc: 95.87 BMA: 95.68 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 529 train Loss: 4948.3 test Loss: 640.8
Epoch 262 Iter 0 subLoss 5418.8 multi 1.00 import weight 0.00
Epoch 262 Iter 1 subLoss 4267.5 multi 3.99 import weight 0.00
Epoch 262 Iter 2 subLoss 5225.7 multi 6.97 import weight 0.00
Epoch 262 Iter 3 subLoss 5138.0 multi 1.00 import weight 0.00
Epoch 262 Iter 4 subLoss 4634.9 multi 3.99 import weight 0.00
Epoch 262 Iter 5 subLoss 4897.3 multi -1.99 import weight 0.00
Epoch 262 Iter 6 subLoss 4897.8 multi 1.00 import weight 0.00
Epoch 262 Iter 7 subLoss 3942.5 multi 1.00 import weight 0.00
Epoch 262 Iter 8 subLoss 4381.9 multi 3.99 import weight 0.00
Epoch 262 Iter 9 subLoss 4742.9 multi 1.00 import weight 0.00
Epoch 262 Iter 10 subLoss 4963.1 multi 1.00 import weight 0.00
Epoch 262 Iter 11 subLoss 4986.3 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0139 / 0.10443 / 11.50
Entropy seen (from low to high)
[1090, 493, 642, 597, 385, 221, 168, 164, 140, 124, 91, 70, 62, 75, 66, 61, 63, 38, 42, 51, 60, 44, 40, 41, 39, 45, 22, 22, 32, 29, 15, 15, 13, 14, 11, 8, 7, 12, 7, 1, 5, 6, 2, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 24, 42, 67, 117, 135, 126, 178, 157, 172, 174, 206, 171, 186, 166, 173, 135, 154, 165, 171, 137, 123, 125, 110, 133, 117, 128, 127, 113, 98, 109, 91, 99, 100, 81, 77, 78, 54, 56, 41, 38, 36, 26, 19, 17, 8]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 33.3, 36.9, 40.3, 43.8, 47.2, 50.7, 54.6, 57.8, 61.3, 64.8, 68.4]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 66.6, 62.4, 49.9, 59.9, 59.5, 68.0, 64.2, 67.3, 81.6, 78.4]
[0, 0, 0, 0, 0, 0, 0, 0, 3, 6, 9, 16, 12, 40, 42, 47, 56, 46, 49, 65]
Epoch 262 Acc: 95.99 BMA: 95.74 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 498 train Loss: 4945.4 test Loss: 623.9
Epoch 263 Iter 0 subLoss 5163.0 multi 1.00 import weight 0.00
Epoch 263 Iter 1 subLoss 4720.6 multi 1.00 import weight 0.00
Epoch 263 Iter 2 subLoss 4974.5 multi 1.00 import weight 0.00
Epoch 263 Iter 3 subLoss 4724.5 multi 3.98 import weight 0.00
Epoch 263 Iter 4 subLoss 4421.0 multi 3.99 import weight 0.00
Epoch 263 Iter 5 subLoss 4663.7 multi 1.00 import weight 0.00
Epoch 263 Iter 6 subLoss 5173.3 multi -19.90 import weight 0.00
Epoch 263 Iter 7 subLoss 5577.7 multi 1.00 import weight 0.00
Epoch 263 Iter 8 subLoss 4606.2 multi 1.00 import weight 0.00
Epoch 263 Iter 9 subLoss 5089.1 multi 6.97 import weight 0.00
Epoch 263 Iter 10 subLoss 4298.2 multi 1.00 import weight 0.00
Epoch 263 Iter 11 subLoss 4573.7 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0137 / 0.10543 / 11.02
Entropy seen (from low to high)
[1115, 505, 689, 580, 357, 226, 163, 163, 148, 112, 89, 68, 62, 72, 62, 63, 52, 34, 40, 62, 52, 40, 51, 32, 42, 36, 26, 26, 26, 27, 14, 16, 10, 16, 10, 8, 8, 12, 5, 2, 4, 6, 2, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 21, 42, 60, 116, 129, 129, 168, 153, 177, 163, 196, 178, 189, 172, 164, 133, 149, 165, 167, 136, 132, 123, 116, 126, 123, 116, 119, 119, 112, 100, 94, 102, 101, 88, 78, 80, 74, 54, 45, 40, 39, 23, 23, 18, 8]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.8, 32.8, 36.3, 40.4, 43.8, 47.3, 50.7, 54.4, 57.6, 61.3, 65.0, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.9, 77.7, 61.1, 29.9, 66.6, 53.4, 62.4, 70.4, 65.9, 77.2, 76.2]
[0, 0, 0, 0, 0, 0, 0, 0, 3, 5, 9, 18, 10, 36, 43, 40, 61, 50, 44, 59]
Epoch 263 Acc: 95.91 BMA: 95.82 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 457 train Loss: 4818.8 test Loss: 629.1
Epoch 264 Iter 0 subLoss 4826.8 multi -1.99 import weight 0.00
Epoch 264 Iter 1 subLoss 4513.9 multi 6.97 import weight 0.00
Epoch 264 Iter 2 subLoss 4517.4 multi 9.96 import weight 0.00
Epoch 264 Iter 3 subLoss 4169.1 multi 1.00 import weight 0.00
Epoch 264 Iter 4 subLoss 4411.6 multi -4.97 import weight 0.00
Epoch 264 Iter 5 subLoss 5171.0 multi -16.91 import weight 0.00
Epoch 264 Iter 6 subLoss 5802.8 multi -7.96 import weight 0.00
Epoch 264 Iter 7 subLoss 8151.2 multi -4.97 import weight 0.00
Epoch 264 Iter 8 subLoss 24782.9 multi 1.00 import weight 0.00
Epoch 264 Iter 9 subLoss 10615.7 multi 1.00 import weight 0.00
Epoch 264 Iter 10 subLoss 7898.3 multi 1.00 import weight 0.00
Epoch 264 Iter 11 subLoss 7717.6 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0135 / 0.10570 / 10.54
Entropy seen (from low to high)
[1105, 524, 700, 581, 339, 222, 196, 151, 148, 105, 75, 78, 59, 64, 84, 54, 39, 36, 41, 57, 51, 52, 49, 37, 44, 29, 24, 31, 26, 20, 20, 13, 11, 12, 11, 11, 7, 9, 6, 0, 5, 5, 2, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 15, 37, 54, 106, 113, 141, 152, 154, 166, 183, 187, 192, 164, 189, 163, 142, 154, 159, 160, 151, 140, 124, 127, 127, 125, 115, 134, 109, 111, 116, 111, 99, 90, 85, 85, 71, 71, 52, 41, 36, 37, 25, 20, 19, 8]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.7, 33.5, 37.3, 40.7, 43.8, 47.5, 50.8, 54.1, 57.8, 61.1, 64.6, 68.4]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 66.6, 28.5, 88.8, 38.4, 39.9, 48.3, 64.4, 60.4, 69.2, 76.9, 73.3, 77.6]
[0, 0, 0, 0, 0, 0, 0, 0, 3, 7, 9, 13, 15, 31, 45, 43, 52, 52, 45, 67]
Epoch 264 Acc: 94.47 BMA: 95.86 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 771 train Loss: 6443.9 test Loss: 860.9
Epoch 265 Iter 0 subLoss 5611.5 multi 9.96 import weight 0.00
Epoch 265 Iter 1 subLoss 5710.8 multi 3.98 import weight 0.00
Epoch 265 Iter 2 subLoss 5272.6 multi 1.00 import weight 0.00
Epoch 265 Iter 3 subLoss 4748.7 multi 3.99 import weight 0.00
Epoch 265 Iter 4 subLoss 5223.3 multi 9.96 import weight 0.00
Epoch 265 Iter 5 subLoss 5019.2 multi 3.99 import weight 0.00
Epoch 265 Iter 6 subLoss 5068.8 multi 6.97 import weight 0.00
Epoch 265 Iter 7 subLoss 4357.8 multi 3.98 import weight 0.00
Epoch 265 Iter 8 subLoss 4426.9 multi 3.98 import weight 0.00
Epoch 265 Iter 9 subLoss 4574.1 multi 6.97 import weight 0.00
Epoch 265 Iter 10 subLoss 5032.5 multi -1.99 import weight 0.00
Epoch 265 Iter 11 subLoss 4334.7 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0133 / 0.10661 / 9.92
Entropy seen (from low to high)
[1118, 552, 703, 592, 331, 211, 186, 157, 150, 88, 84, 68, 58, 72, 83, 42, 35, 38, 43, 51, 54, 58, 44, 35, 49, 22, 32, 22, 27, 23, 14, 14, 14, 7, 11, 11, 10, 7, 5, 0, 5, 4, 3, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 15, 34, 54, 99, 111, 135, 149, 156, 158, 175, 188, 191, 170, 166, 167, 144, 164, 138, 174, 133, 155, 127, 137, 120, 118, 127, 115, 120, 116, 109, 102, 116, 88, 95, 93, 71, 72, 55, 53, 35, 38, 28, 20, 21, 8]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.8, 33.3, 37.5, 40.7, 43.9, 47.4, 50.7, 54.2, 58.0, 61.0, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 28.5, 77.7, 54.5, 49.9, 41.6, 54.1, 65.9, 76.5, 70.4, 77.3, 72.3]
[0, 0, 0, 0, 0, 0, 0, 0, 3, 7, 9, 11, 18, 24, 48, 47, 47, 44, 53, 65]
Epoch 265 Acc: 95.86 BMA: 95.97 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 433 train Loss: 4654.7 test Loss: 616.2
Epoch 266 Iter 0 subLoss 4344.6 multi -1.98 import weight 0.00
Epoch 266 Iter 1 subLoss 5271.4 multi 3.99 import weight 0.00
Epoch 266 Iter 2 subLoss 4926.3 multi 1.00 import weight 0.00
Epoch 266 Iter 3 subLoss 4583.6 multi -1.99 import weight 0.00
Epoch 266 Iter 4 subLoss 4388.2 multi 6.97 import weight 0.00
Epoch 266 Iter 5 subLoss 4031.6 multi 1.00 import weight 0.00
Epoch 266 Iter 6 subLoss 4221.8 multi 1.00 import weight 0.00
Epoch 266 Iter 7 subLoss 5031.9 multi 1.00 import weight 0.00
Epoch 266 Iter 8 subLoss 4588.5 multi 1.00 import weight 0.00
Epoch 266 Iter 9 subLoss 4943.5 multi 1.00 import weight 0.00
Epoch 266 Iter 10 subLoss 4950.2 multi 1.00 import weight 0.00
Epoch 266 Iter 11 subLoss 3953.3 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0131 / 0.10756 / 9.41
Entropy seen (from low to high)
[1146, 567, 733, 576, 317, 199, 189, 168, 129, 92, 89, 59, 61, 78, 57, 45, 40, 38, 37, 53, 52, 57, 47, 38, 41, 25, 25, 26, 27, 19, 16, 10, 14, 9, 13, 10, 5, 11, 2, 1, 6, 3, 2, 2, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 14, 33, 52, 90, 118, 129, 139, 153, 161, 162, 191, 178, 184, 163, 171, 145, 143, 151, 163, 146, 157, 122, 133, 126, 120, 111, 119, 122, 114, 104, 116, 111, 101, 88, 94, 80, 85, 55, 56, 41, 35, 35, 19, 21, 9]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.9, 33.1, 37.5, 40.0, 43.7, 47.5, 50.6, 54.1, 57.8, 61.3, 64.8, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 28.5, 71.4, 39.9, 57.1, 42.8, 56.2, 69.0, 73.4, 69.7, 74.1, 70.8]
[0, 0, 0, 0, 0, 0, 0, 0, 3, 7, 7, 10, 21, 21, 48, 42, 49, 43, 58, 48]
Epoch 266 Acc: 96.17 BMA: 96.05 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 395 train Loss: 4815.7 test Loss: 593.2
Epoch 267 Iter 0 subLoss 4709.4 multi -1.99 import weight 0.00
Epoch 267 Iter 1 subLoss 4532.0 multi 1.00 import weight 0.00
Epoch 267 Iter 2 subLoss 4090.3 multi 1.00 import weight 0.00
Epoch 267 Iter 3 subLoss 4740.7 multi 6.97 import weight 0.00
Epoch 267 Iter 4 subLoss 4414.3 multi -1.98 import weight 0.00
Epoch 267 Iter 5 subLoss 4884.0 multi 6.97 import weight 0.00
Epoch 267 Iter 6 subLoss 4410.1 multi 1.00 import weight 0.00
Epoch 267 Iter 7 subLoss 4825.2 multi 1.00 import weight 0.00
Epoch 267 Iter 8 subLoss 4417.8 multi 3.99 import weight 0.00
Epoch 267 Iter 9 subLoss 4699.6 multi -4.97 import weight 0.00
Epoch 267 Iter 10 subLoss 4918.7 multi -4.97 import weight 0.00
Epoch 267 Iter 11 subLoss 5172.9 multi -13.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0130 / 0.10700 / 11.58
Entropy seen (from low to high)
[1175, 598, 729, 556, 302, 199, 179, 169, 111, 94, 77, 62, 59, 82, 62, 45, 41, 43, 34, 59, 55, 48, 50, 40, 39, 24, 26, 28, 28, 21, 9, 11, 13, 11, 12, 10, 9, 6, 4, 1, 5, 3, 3, 2, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 14, 32, 58, 96, 113, 128, 145, 149, 174, 163, 181, 192, 176, 175, 162, 145, 142, 165, 159, 143, 158, 125, 129, 143, 120, 113, 107, 107, 123, 107, 89, 109, 106, 87, 83, 77, 79, 68, 50, 48, 31, 39, 20, 21, 9]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.6, 33.3, 37.3, 40.2, 43.7, 47.4, 51.0, 54.4, 57.7, 61.1, 64.6, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.9, 16.6, 88.8, 37.4, 56.2, 62.4, 66.0, 68.2, 68.1, 75.5, 70.9, 72.8]
[0, 0, 0, 0, 0, 0, 0, 0, 4, 6, 9, 8, 16, 24, 53, 41, 44, 45, 62, 59]
Epoch 267 Acc: 94.18 BMA: 96.05 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -13.93 Pidx 517 train Loss: 5926.8 test Loss: 859.4
Epoch 268 Iter 0 subLoss 5361.7 multi 12.94 import weight 0.00
Epoch 268 Iter 1 subLoss 4557.8 multi 6.97 import weight 0.00
Epoch 268 Iter 2 subLoss 4527.6 multi -10.94 import weight 0.00
Epoch 268 Iter 3 subLoss 5731.1 multi 6.97 import weight 0.00
Epoch 268 Iter 4 subLoss 4990.0 multi 1.00 import weight 0.00
Epoch 268 Iter 5 subLoss 4954.3 multi 3.99 import weight 0.00
Epoch 268 Iter 6 subLoss 5099.1 multi -4.97 import weight 0.00
Epoch 268 Iter 7 subLoss 5175.9 multi -10.94 import weight 0.00
Epoch 268 Iter 8 subLoss 4852.3 multi -1.99 import weight 0.00
Epoch 268 Iter 9 subLoss 4366.6 multi -7.96 import weight 0.00
Epoch 268 Iter 10 subLoss 6998.2 multi 3.99 import weight 0.00
Epoch 268 Iter 11 subLoss 5211.0 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0130 / 0.10673 / 10.92
Entropy seen (from low to high)
[1179, 630, 742, 531, 288, 209, 162, 165, 107, 95, 89, 50, 62, 64, 60, 59, 46, 41, 41, 59, 55, 42, 51, 40, 40, 23, 24, 29, 31, 18, 11, 8, 16, 14, 12, 8, 10, 6, 3, 1, 4, 5, 2, 2, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 15, 32, 62, 95, 113, 132, 153, 139, 184, 159, 190, 189, 172, 180, 164, 150, 135, 182, 137, 159, 147, 119, 133, 138, 118, 126, 107, 96, 112, 102, 83, 108, 109, 83, 73, 89, 79, 66, 57, 47, 36, 35, 24, 21, 10]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.5, 33.6, 37.2, 39.7, 43.5, 47.4, 50.5, 54.0, 57.6, 61.3, 64.7, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.9, 33.3, 85.7, 33.3, 64.2, 59.9, 65.9, 71.9, 57.4, 67.9, 73.6, 78.6]
[0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 7, 9, 14, 25, 44, 50, 47, 53, 57, 61]
Epoch 268 Acc: 94.38 BMA: 95.99 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 521 train Loss: 5762.0 test Loss: 848.5
Epoch 269 Iter 0 subLoss 5787.3 multi -10.94 import weight 0.00
Epoch 269 Iter 1 subLoss 8471.9 multi 9.96 import weight 0.00
Epoch 269 Iter 2 subLoss 5239.5 multi -7.96 import weight 0.00
Epoch 269 Iter 3 subLoss 11466.2 multi -1.99 import weight 0.00
Epoch 269 Iter 4 subLoss 26661.1 multi -1.99 import weight 0.00
Epoch 269 Iter 5 subLoss 87912.9 multi 1.00 import weight 0.00
Epoch 269 Iter 6 subLoss 27503.6 multi 1.00 import weight 0.00
Epoch 269 Iter 7 subLoss 17955.5 multi 3.99 import weight 0.00
Epoch 269 Iter 8 subLoss 6151.2 multi 3.99 import weight 0.00
Epoch 269 Iter 9 subLoss 5451.1 multi 1.00 import weight 0.00
Epoch 269 Iter 10 subLoss 5456.4 multi 3.98 import weight 0.00
Epoch 269 Iter 11 subLoss 6011.4 multi 15.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0130 / 0.10702 / 10.61
Entropy seen (from low to high)
[1146, 641, 736, 557, 297, 215, 158, 166, 112, 96, 73, 56, 66, 58, 63, 47, 49, 41, 42, 56, 54, 46, 52, 39, 38, 26, 21, 34, 27, 20, 11, 10, 14, 13, 13, 7, 11, 6, 3, 1, 4, 5, 2, 2, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 13, 34, 62, 96, 113, 123, 155, 147, 181, 165, 178, 193, 183, 170, 164, 148, 137, 168, 150, 154, 145, 123, 133, 131, 118, 122, 97, 105, 124, 93, 86, 109, 102, 84, 78, 84, 87, 71, 57, 48, 38, 38, 23, 20, 10]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.6, 33.5, 37.3, 40.1, 43.7, 47.3, 50.7, 54.1, 57.7, 61.3, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.9, 33.3, 87.4, 33.3, 69.2, 49.9, 64.1, 73.8, 61.2, 61.9, 78.3, 77.5]
[0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 8, 9, 13, 24, 53, 42, 49, 50, 60, 58]
Epoch 269 Acc: 95.56 BMA: 95.97 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 15.93 Pidx 601 train Loss: 5062.5 test Loss: 717.7
Epoch 270 Iter 0 subLoss 4600.0 multi -7.96 import weight 0.00
Epoch 270 Iter 1 subLoss 5302.1 multi -7.96 import weight 0.00
Epoch 270 Iter 2 subLoss 5458.1 multi 6.97 import weight 0.00
Epoch 270 Iter 3 subLoss 5458.6 multi 9.96 import weight 0.00
Epoch 270 Iter 4 subLoss 5263.7 multi 1.00 import weight 0.00
Epoch 270 Iter 5 subLoss 4841.1 multi 3.99 import weight 0.00
Epoch 270 Iter 6 subLoss 4681.3 multi 6.97 import weight 0.00
Epoch 270 Iter 7 subLoss 5080.3 multi 9.96 import weight 0.00
Epoch 270 Iter 8 subLoss 5041.3 multi 6.97 import weight 0.00
Epoch 270 Iter 9 subLoss 4424.2 multi -1.99 import weight 0.00
Epoch 270 Iter 10 subLoss 5349.8 multi 1.00 import weight 0.00
Epoch 270 Iter 11 subLoss 4203.5 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0130 / 0.10749 / 9.96
Entropy seen (from low to high)
[1152, 661, 745, 537, 302, 217, 160, 155, 112, 94, 78, 53, 63, 59, 63, 42, 48, 38, 48, 48, 58, 41, 64, 32, 34, 25, 23, 33, 27, 22, 8, 13, 12, 13, 12, 8, 11, 6, 3, 1, 5, 4, 2, 2, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 14, 35, 59, 90, 110, 121, 160, 148, 179, 159, 179, 190, 184, 172, 161, 148, 137, 168, 143, 155, 147, 125, 131, 132, 128, 101, 110, 96, 125, 97, 84, 106, 108, 88, 78, 86, 82, 82, 53, 56, 35, 45, 23, 20, 10]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.3, 33.0, 37.3, 40.6, 43.7, 47.4, 50.6, 54.1, 57.9, 61.4, 64.8, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.9, 28.5, 88.8, 33.3, 66.6, 52.1, 60.7, 70.2, 60.8, 65.3, 74.9, 77.9]
[0, 0, 0, 0, 0, 0, 0, 0, 4, 7, 9, 9, 12, 23, 51, 47, 46, 49, 56, 59]
Epoch 270 Acc: 95.87 BMA: 95.95 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 420 train Loss: 4899.9 test Loss: 649.3
Epoch 271 Iter 0 subLoss 3934.3 multi 1.00 import weight 0.00
Epoch 271 Iter 1 subLoss 5110.2 multi -10.94 import weight 0.00
Epoch 271 Iter 2 subLoss 4259.7 multi -1.99 import weight 0.00
Epoch 271 Iter 3 subLoss 5427.5 multi 1.00 import weight 0.00
Epoch 271 Iter 4 subLoss 5109.5 multi 3.99 import weight 0.00
Epoch 271 Iter 5 subLoss 4619.0 multi 1.00 import weight 0.00
Epoch 271 Iter 6 subLoss 4600.9 multi 1.00 import weight 0.00
Epoch 271 Iter 7 subLoss 4803.6 multi 24.88 import weight 0.00
Epoch 271 Iter 8 subLoss 5732.5 multi 9.96 import weight 0.00
Epoch 271 Iter 9 subLoss 4262.0 multi 3.98 import weight 0.00
Epoch 271 Iter 10 subLoss 4000.9 multi 1.00 import weight 0.00
Epoch 271 Iter 11 subLoss 4667.8 multi 3.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0129 / 0.10790 / 11.55
Entropy seen (from low to high)
[1158, 698, 750, 522, 293, 216, 161, 156, 97, 96, 75, 56, 63, 63, 52, 45, 46, 37, 54, 46, 56, 47, 57, 24, 40, 23, 26, 33, 24, 23, 7, 12, 13, 12, 11, 10, 9, 5, 4, 1, 5, 4, 2, 3, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 14, 36, 54, 91, 106, 129, 151, 150, 175, 167, 186, 171, 190, 174, 157, 147, 143, 155, 148, 140, 155, 130, 131, 127, 116, 109, 109, 96, 127, 97, 88, 89, 122, 96, 83, 76, 86, 79, 67, 54, 36, 47, 26, 20, 10]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.3, 33.0, 37.0, 40.8, 44.2, 47.7, 50.6, 54.1, 57.8, 61.2, 64.8, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.9, 42.8, 87.4, 45.4, 49.9, 69.9, 55.5, 72.5, 65.9, 55.3, 80.3, 76.6]
[0, 0, 0, 0, 0, 0, 0, 0, 4, 7, 8, 11, 14, 20, 45, 51, 44, 47, 56, 60]
Epoch 271 Acc: 96.15 BMA: 95.97 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 466 train Loss: 4667.6 test Loss: 618.5
Epoch 272 Iter 0 subLoss 4452.7 multi 1.00 import weight 0.00
Epoch 272 Iter 1 subLoss 5003.8 multi 3.98 import weight 0.00
Epoch 272 Iter 2 subLoss 4957.1 multi 6.97 import weight 0.00
Epoch 272 Iter 3 subLoss 4813.0 multi -19.90 import weight 0.00
Epoch 272 Iter 4 subLoss 5556.9 multi 6.97 import weight 0.00
Epoch 272 Iter 5 subLoss 4067.9 multi 1.00 import weight 0.00
Epoch 272 Iter 6 subLoss 4462.7 multi 1.00 import weight 0.00
Epoch 272 Iter 7 subLoss 5020.7 multi -1.99 import weight 0.00
Epoch 272 Iter 8 subLoss 4669.2 multi 6.97 import weight 0.00
Epoch 272 Iter 9 subLoss 4275.1 multi -7.96 import weight 0.00
Epoch 272 Iter 10 subLoss 4329.9 multi 1.00 import weight 0.00
Epoch 272 Iter 11 subLoss 4441.4 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0128 / 0.10836 / 11.54
Entropy seen (from low to high)
[1166, 717, 752, 531, 280, 212, 170, 144, 101, 89, 72, 60, 61, 60, 48, 45, 42, 39, 56, 45, 51, 51, 57, 26, 35, 26, 24, 31, 26, 21, 7, 12, 13, 14, 9, 9, 9, 6, 3, 0, 6, 4, 2, 3, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 14, 35, 56, 86, 104, 121, 152, 155, 183, 165, 184, 167, 192, 171, 151, 149, 142, 142, 160, 131, 154, 143, 120, 117, 126, 116, 102, 104, 110, 107, 91, 91, 113, 102, 83, 78, 90, 79, 72, 55, 42, 45, 29, 20, 11]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.5, 33.1, 36.8, 40.6, 44.2, 47.7, 50.7, 54.0, 57.9, 61.4, 64.7, 68.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.9, 59.9, 74.9, 58.3, 30.7, 59.0, 64.2, 68.6, 65.2, 59.5, 81.6, 75.8]
[0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 8, 12, 13, 22, 42, 51, 46, 47, 49, 62]
Epoch 272 Acc: 96.26 BMA: 95.95 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 444 train Loss: 4731.8 test Loss: 608.1
Epoch 273 Iter 0 subLoss 4710.0 multi 1.00 import weight 0.00
Epoch 273 Iter 1 subLoss 5302.8 multi -4.97 import weight 0.00
Epoch 273 Iter 2 subLoss 5125.5 multi 3.98 import weight 0.00
Epoch 273 Iter 3 subLoss 4578.4 multi 9.96 import weight 0.00
Epoch 273 Iter 4 subLoss 4224.6 multi 3.99 import weight 0.00
Epoch 273 Iter 5 subLoss 4425.5 multi 1.00 import weight 0.00
Epoch 273 Iter 6 subLoss 4047.0 multi -1.99 import weight 0.00
Epoch 273 Iter 7 subLoss 4693.2 multi -4.97 import weight 0.00
Epoch 273 Iter 8 subLoss 5289.6 multi -10.94 import weight 0.00
Epoch 273 Iter 9 subLoss 4856.1 multi -1.99 import weight 0.00
Epoch 273 Iter 10 subLoss 4276.1 multi -4.97 import weight 0.00
Epoch 273 Iter 11 subLoss 5087.1 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0127 / 0.10856 / 9.23
Entropy seen (from low to high)
[1183, 741, 746, 521, 285, 204, 169, 140, 99, 81, 72, 64, 54, 58, 47, 46, 45, 42, 53, 44, 52, 51, 54, 20, 39, 25, 26, 34, 22, 22, 6, 11, 13, 14, 10, 9, 8, 7, 2, 1, 6, 4, 1, 4, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 14, 36, 53, 85, 103, 123, 148, 152, 191, 153, 191, 160, 189, 186, 146, 150, 144, 141, 154, 133, 154, 142, 117, 123, 125, 115, 97, 105, 109, 108, 85, 98, 102, 104, 90, 81, 80, 90, 71, 58, 46, 47, 27, 20, 14]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.2, 32.5, 36.6, 40.5, 43.8, 47.7, 50.7, 54.0, 57.7, 61.2, 64.6, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 19.9, 77.7, 49.9, 39.9, 52.3, 67.4, 65.9, 59.1, 65.8, 78.1, 73.4]
[0, 0, 0, 0, 0, 0, 0, 0, 4, 5, 9, 10, 15, 21, 40, 50, 49, 41, 55, 64]
Epoch 273 Acc: 95.60 BMA: 95.95 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 508 train Loss: 5024.0 test Loss: 654.2
Epoch 274 Iter 0 subLoss 5526.2 multi -10.94 import weight 0.00
Epoch 274 Iter 1 subLoss 7649.6 multi -4.97 import weight 0.00
Epoch 274 Iter 2 subLoss 13007.4 multi 1.00 import weight 0.00
Epoch 274 Iter 3 subLoss 9464.0 multi 1.00 import weight 0.00
Epoch 274 Iter 4 subLoss 8264.0 multi 3.99 import weight 0.00
Epoch 274 Iter 5 subLoss 5314.3 multi -1.98 import weight 0.00
Epoch 274 Iter 6 subLoss 5045.8 multi 9.96 import weight 0.00
Epoch 274 Iter 7 subLoss 4475.6 multi -4.97 import weight 0.00
Epoch 274 Iter 8 subLoss 5008.6 multi 6.97 import weight 0.00
Epoch 274 Iter 9 subLoss 4455.0 multi 1.00 import weight 0.00
Epoch 274 Iter 10 subLoss 4799.4 multi -4.97 import weight 0.00
Epoch 274 Iter 11 subLoss 4324.7 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0127 / 0.10902 / 9.76
Entropy seen (from low to high)
[1201, 747, 753, 503, 294, 199, 168, 137, 100, 84, 58, 68, 60, 54, 45, 47, 43, 45, 51, 42, 47, 62, 45, 24, 35, 27, 25, 30, 27, 17, 8, 14, 9, 16, 9, 7, 10, 6, 2, 2, 5, 4, 2, 3, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 16, 33, 50, 85, 101, 124, 140, 151, 189, 157, 184, 162, 185, 192, 145, 144, 147, 134, 164, 141, 142, 135, 122, 124, 123, 114, 100, 109, 103, 112, 87, 96, 104, 109, 86, 82, 82, 90, 78, 58, 48, 46, 31, 21, 14]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 32.5, 37.0, 40.8, 43.9, 47.3, 50.8, 54.1, 57.6, 61.5, 64.8, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 19.9, 79.9, 44.4, 53.8, 40.9, 71.4, 63.8, 62.4, 65.9, 77.5, 72.1]
[0, 0, 0, 0, 0, 0, 0, 0, 4, 5, 10, 9, 13, 22, 42, 47, 48, 47, 49, 61]
Epoch 274 Acc: 96.09 BMA: 95.95 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 432 train Loss: 4797.3 test Loss: 601.8
Epoch 275 Iter 0 subLoss 5183.4 multi -7.96 import weight 0.00
Epoch 275 Iter 1 subLoss 4257.6 multi 1.00 import weight 0.00
Epoch 275 Iter 2 subLoss 4926.0 multi 1.00 import weight 0.00
Epoch 275 Iter 3 subLoss 4898.2 multi 1.00 import weight 0.00
Epoch 275 Iter 4 subLoss 4845.2 multi 6.97 import weight 0.00
Epoch 275 Iter 5 subLoss 4406.8 multi 6.97 import weight 0.00
Epoch 275 Iter 6 subLoss 4957.3 multi 9.96 import weight 0.00
Epoch 275 Iter 7 subLoss 4573.1 multi 12.94 import weight 0.00
Epoch 275 Iter 8 subLoss 4973.6 multi 3.99 import weight 0.00
Epoch 275 Iter 9 subLoss 4177.7 multi -1.99 import weight 0.00
Epoch 275 Iter 10 subLoss 4125.4 multi 1.00 import weight 0.00
Epoch 275 Iter 11 subLoss 4219.7 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0126 / 0.10951 / 7.98
Entropy seen (from low to high)
[1214, 768, 763, 486, 293, 189, 169, 131, 107, 80, 59, 64, 58, 52, 51, 42, 39, 48, 46, 43, 53, 57, 44, 29, 34, 23, 29, 27, 24, 17, 10, 13, 7, 15, 11, 7, 9, 6, 2, 1, 6, 4, 2, 3, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 15, 32, 50, 81, 101, 119, 137, 145, 189, 156, 186, 169, 174, 184, 160, 144, 140, 143, 155, 137, 142, 146, 119, 123, 122, 116, 99, 108, 104, 111, 87, 103, 92, 120, 86, 83, 84, 89, 85, 54, 52, 46, 35, 22, 14]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.9, 32.6, 37.3, 41.1, 43.9, 47.1, 51.0, 54.3, 57.7, 61.5, 64.8, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 19.9, 72.7, 42.8, 46.1, 45.8, 65.8, 65.9, 65.2, 64.4, 71.9, 71.9]
[0, 0, 0, 0, 0, 0, 0, 0, 4, 5, 11, 7, 13, 24, 41, 47, 46, 45, 50, 57]
Epoch 275 Acc: 96.30 BMA: 95.93 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 421 train Loss: 4520.3 test Loss: 575.9
Epoch 276 Iter 0 subLoss 4515.3 multi 12.94 import weight 0.00
Epoch 276 Iter 1 subLoss 4371.0 multi -1.99 import weight 0.00
Epoch 276 Iter 2 subLoss 3918.2 multi 1.00 import weight 0.00
Epoch 276 Iter 3 subLoss 4225.7 multi 3.98 import weight 0.00
Epoch 276 Iter 4 subLoss 4184.6 multi 1.00 import weight 0.00
Epoch 276 Iter 5 subLoss 4481.3 multi 3.98 import weight 0.00
Epoch 276 Iter 6 subLoss 3929.9 multi -1.99 import weight 0.00
Epoch 276 Iter 7 subLoss 4680.4 multi 9.96 import weight 0.00
Epoch 276 Iter 8 subLoss 4021.6 multi 1.00 import weight 0.00
Epoch 276 Iter 9 subLoss 4680.4 multi 12.94 import weight 0.00
Epoch 276 Iter 10 subLoss 4562.6 multi -7.96 import weight 0.00
Epoch 276 Iter 11 subLoss 3993.6 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0125 / 0.10990 / 7.77
Entropy seen (from low to high)
[1219, 808, 748, 489, 276, 196, 159, 130, 106, 81, 50, 77, 56, 43, 48, 49, 35, 50, 39, 50, 51, 61, 34, 32, 39, 19, 28, 28, 24, 16, 11, 10, 8, 13, 12, 7, 11, 4, 2, 2, 5, 4, 2, 3, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 16, 33, 46, 80, 99, 118, 139, 147, 176, 161, 189, 175, 173, 173, 155, 148, 138, 143, 147, 148, 139, 140, 126, 128, 110, 121, 105, 106, 101, 108, 94, 98, 97, 109, 94, 86, 81, 95, 81, 61, 59, 45, 36, 21, 15]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.9, 30.6, 32.8, 37.4, 40.4, 43.9, 47.1, 50.9, 54.3, 57.7, 61.3, 64.9, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 24.9, 24.9, 69.9, 57.1, 39.9, 52.3, 54.0, 74.9, 60.8, 61.7, 74.5, 71.6]
[0, 0, 0, 0, 0, 0, 0, 1, 4, 4, 10, 7, 15, 21, 37, 48, 46, 47, 51, 53]
Epoch 276 Acc: 96.56 BMA: 95.93 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 399 train Loss: 4500.1 test Loss: 540.2
Epoch 277 Iter 0 subLoss 4284.8 multi -4.97 import weight 0.00
Epoch 277 Iter 1 subLoss 3868.8 multi 1.00 import weight 0.00
Epoch 277 Iter 2 subLoss 4499.6 multi -7.96 import weight 0.00
Epoch 277 Iter 3 subLoss 5200.7 multi 1.00 import weight 0.00
Epoch 277 Iter 4 subLoss 4123.4 multi 3.99 import weight 0.00
Epoch 277 Iter 5 subLoss 4709.9 multi -4.97 import weight 0.00
Epoch 277 Iter 6 subLoss 4730.6 multi -1.99 import weight 0.00
Epoch 277 Iter 7 subLoss 4558.0 multi 9.96 import weight 0.00
Epoch 277 Iter 8 subLoss 4880.2 multi 9.96 import weight 0.00
Epoch 277 Iter 9 subLoss 4570.9 multi 12.94 import weight 0.00
Epoch 277 Iter 10 subLoss 4708.9 multi -1.99 import weight 0.00
Epoch 277 Iter 11 subLoss 4684.4 multi 15.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0124 / 0.11015 / 9.27
Entropy seen (from low to high)
[1227, 833, 747, 478, 270, 198, 164, 125, 96, 76, 66, 61, 62, 41, 45, 52, 36, 47, 41, 45, 57, 60, 32, 33, 35, 22, 30, 25, 22, 14, 13, 8, 9, 20, 7, 9, 7, 4, 2, 2, 5, 4, 2, 3, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 16, 30, 46, 82, 99, 111, 139, 149, 167, 174, 178, 179, 175, 171, 153, 148, 128, 156, 146, 148, 130, 139, 133, 134, 109, 116, 104, 103, 111, 93, 100, 97, 94, 107, 101, 89, 79, 96, 77, 73, 59, 47, 38, 21, 15]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.8, 30.5, 32.8, 37.3, 40.3, 44.2, 47.2, 51.0, 54.3, 57.7, 61.2, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 24.9, 24.9, 77.7, 55.5, 31.2, 64.7, 63.8, 65.9, 65.9, 62.4, 73.9, 70.3]
[0, 0, 0, 0, 0, 0, 0, 1, 4, 4, 9, 9, 16, 17, 36, 47, 47, 48, 46, 54]
Epoch 277 Acc: 96.13 BMA: 95.95 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 15.93 Pidx 468 train Loss: 4497.2 test Loss: 595.8
Epoch 278 Iter 0 subLoss 4653.6 multi -1.98 import weight 0.00
Epoch 278 Iter 1 subLoss 4570.8 multi 15.93 import weight 0.00
Epoch 278 Iter 2 subLoss 5178.1 multi -7.96 import weight 0.00
Epoch 278 Iter 3 subLoss 13681.9 multi 1.00 import weight 0.00
Epoch 278 Iter 4 subLoss 8996.7 multi -1.99 import weight 0.00
Epoch 278 Iter 5 subLoss 10747.1 multi -4.97 import weight 0.00
Epoch 278 Iter 6 subLoss 52266.0 multi 1.00 import weight 0.00
Epoch 278 Iter 7 subLoss 13957.5 multi 9.96 import weight 0.00
Epoch 278 Iter 8 subLoss 6603.1 multi -1.98 import weight 0.00
Epoch 278 Iter 9 subLoss 7432.2 multi -1.99 import weight 0.00
Epoch 278 Iter 10 subLoss 8678.2 multi 9.96 import weight 0.00
Epoch 278 Iter 11 subLoss 5074.7 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0124 / 0.10966 / 9.61
Entropy seen (from low to high)
[1152, 872, 738, 489, 276, 210, 166, 113, 99, 85, 64, 70, 60, 48, 36, 44, 48, 48, 40, 45, 49, 59, 41, 33, 34, 31, 21, 29, 20, 21, 12, 5, 14, 16, 9, 6, 9, 5, 2, 3, 5, 2, 4, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 16, 30, 45, 86, 94, 106, 153, 155, 163, 187, 168, 186, 174, 176, 146, 158, 128, 156, 148, 145, 137, 137, 124, 123, 122, 116, 115, 95, 107, 99, 111, 85, 102, 100, 95, 88, 78, 88, 74, 68, 55, 47, 39, 20, 15]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.5, 32.8, 37.4, 40.5, 43.8, 47.1, 50.8, 54.3, 57.6, 61.1, 64.7, 68.4]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.9, 24.9, 81.8, 49.9, 31.2, 64.7, 62.1, 69.3, 60.8, 63.2, 74.9, 73.6]
[0, 0, 0, 0, 0, 0, 0, 0, 5, 4, 11, 6, 16, 17, 37, 49, 46, 49, 52, 57]
Epoch 278 Acc: 95.37 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 507 train Loss: 5846.9 test Loss: 818.1
Epoch 279 Iter 0 subLoss 5682.0 multi -1.99 import weight 0.00
Epoch 279 Iter 1 subLoss 6056.1 multi -1.99 import weight 0.00
Epoch 279 Iter 2 subLoss 5928.8 multi -10.94 import weight 0.00
Epoch 279 Iter 3 subLoss 18390.7 multi 6.97 import weight 0.00
Epoch 279 Iter 4 subLoss 8976.2 multi -4.97 import weight 0.00
Epoch 279 Iter 5 subLoss 13479.4 multi -4.97 import weight 0.00
Epoch 279 Iter 6 subLoss 26499.5 multi -1.99 import weight 0.00
Epoch 279 Iter 7 subLoss 74241.4 multi 1.00 import weight 0.00
Epoch 279 Iter 8 subLoss 20731.1 multi -1.99 import weight 0.00
Epoch 279 Iter 9 subLoss 27733.5 multi 1.00 import weight 0.00
Epoch 279 Iter 10 subLoss 21782.4 multi 1.00 import weight 0.00
Epoch 279 Iter 11 subLoss 19055.5 multi 3.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0125 / 0.10747 / 9.99
Entropy seen (from low to high)
[910, 817, 782, 552, 293, 218, 171, 126, 122, 97, 96, 69, 61, 54, 42, 58, 58, 46, 36, 50, 41, 52, 56, 39, 37, 39, 25, 25, 36, 19, 21, 8, 11, 19, 8, 9, 9, 4, 2, 4, 4, 2, 5, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 17, 34, 47, 86, 111, 107, 165, 149, 192, 185, 173, 191, 173, 184, 169, 147, 156, 157, 142, 153, 126, 133, 128, 130, 112, 126, 93, 113, 108, 99, 95, 94, 108, 95, 77, 91, 82, 72, 61, 56, 50, 25, 25, 11, 12]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.7, 32.7, 36.7, 40.4, 44.0, 47.5, 50.6, 54.1, 57.8, 61.1, 64.7, 68.6]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.9, 49.9, 81.8, 57.1, 44.4, 59.0, 61.1, 67.3, 68.6, 60.8, 69.9, 81.6]
[0, 0, 0, 0, 0, 0, 0, 0, 5, 4, 11, 7, 18, 22, 36, 52, 51, 46, 60, 60]
Epoch 279 Acc: 87.18 BMA: 95.97 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 1905 train Loss: 12823.1 test Loss: 2138.3
Epoch 280 Iter 0 subLoss 12416.1 multi 3.99 import weight 0.00
Epoch 280 Iter 1 subLoss 8785.7 multi -1.98 import weight 0.00
Epoch 280 Iter 2 subLoss 10050.6 multi -4.97 import weight 0.00
Epoch 280 Iter 3 subLoss 13147.4 multi -1.99 import weight 0.00
Epoch 280 Iter 4 subLoss 16457.6 multi 1.00 import weight 0.00
Epoch 280 Iter 5 subLoss 14814.6 multi 1.00 import weight 0.00
Epoch 280 Iter 6 subLoss 13790.5 multi 6.97 import weight 0.00
Epoch 280 Iter 7 subLoss 8333.7 multi -1.99 import weight 0.00
Epoch 280 Iter 8 subLoss 8678.7 multi 12.94 import weight 0.00
Epoch 280 Iter 9 subLoss 5961.9 multi 1.00 import weight 0.00
Epoch 280 Iter 10 subLoss 5787.4 multi -7.96 import weight 0.00
Epoch 280 Iter 11 subLoss 6616.2 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0125 / 0.10725 / 9.96
Entropy seen (from low to high)
[916, 787, 780, 561, 307, 213, 175, 129, 116, 105, 90, 63, 61, 60, 47, 49, 63, 43, 42, 42, 46, 52, 50, 43, 39, 37, 29, 22, 33, 25, 22, 7, 14, 15, 9, 9, 10, 3, 4, 3, 5, 2, 5, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 16, 36, 51, 84, 113, 105, 164, 167, 186, 184, 187, 181, 180, 179, 165, 146, 155, 170, 135, 148, 129, 126, 132, 122, 120, 118, 97, 106, 118, 94, 90, 99, 96, 93, 86, 92, 72, 78, 60, 51, 54, 30, 22, 12, 11]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.6, 32.6, 36.5, 40.3, 44.2, 47.3, 50.6, 54.0, 57.8, 61.3, 64.7, 68.4]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.9, 49.9, 81.8, 49.9, 58.8, 52.1, 57.8, 69.9, 65.4, 59.5, 72.2, 79.6]
[0, 0, 0, 0, 0, 0, 0, 0, 5, 4, 11, 8, 17, 23, 38, 50, 55, 47, 54, 59]
Epoch 280 Acc: 94.84 BMA: 96.01 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 661 train Loss: 5904.3 test Loss: 818.3
Epoch 281 Iter 0 subLoss 5864.5 multi 1.00 import weight 0.00
Epoch 281 Iter 1 subLoss 5432.0 multi 3.99 import weight 0.00
Epoch 281 Iter 2 subLoss 6005.2 multi -1.99 import weight 0.00
Epoch 281 Iter 3 subLoss 5601.0 multi 9.96 import weight 0.00
Epoch 281 Iter 4 subLoss 5359.9 multi -7.96 import weight 0.00
Epoch 281 Iter 5 subLoss 5313.3 multi 1.00 import weight 0.00
Epoch 281 Iter 6 subLoss 5528.1 multi -7.96 import weight 0.00
Epoch 281 Iter 7 subLoss 6452.9 multi 3.99 import weight 0.00
Epoch 281 Iter 8 subLoss 6324.4 multi -1.99 import weight 0.00
Epoch 281 Iter 9 subLoss 5547.2 multi -16.91 import weight 0.00
Epoch 281 Iter 10 subLoss 7515.4 multi 1.00 import weight 0.00
Epoch 281 Iter 11 subLoss 7086.2 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0126 / 0.10673 / 11.15
Entropy seen (from low to high)
[900, 708, 786, 563, 348, 224, 162, 148, 120, 96, 88, 78, 59, 69, 60, 45, 56, 44, 50, 36, 47, 51, 54, 44, 39, 34, 29, 29, 30, 22, 26, 10, 11, 14, 9, 12, 10, 4, 3, 3, 6, 1, 5, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 16, 37, 45, 90, 117, 109, 174, 166, 179, 183, 184, 189, 170, 192, 158, 159, 151, 160, 138, 146, 133, 119, 145, 132, 111, 120, 99, 109, 122, 99, 93, 97, 96, 95, 86, 88, 66, 66, 55, 43, 52, 28, 21, 13, 9]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.5, 32.7, 36.9, 41.1, 44.0, 47.3, 51.0, 54.4, 58.1, 61.3, 64.6, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.9, 24.9, 76.9, 66.6, 49.9, 42.3, 63.6, 70.9, 64.5, 59.0, 69.6, 86.4]
[0, 0, 0, 0, 0, 0, 0, 0, 5, 4, 13, 6, 16, 26, 44, 55, 48, 44, 56, 59]
Epoch 281 Acc: 91.98 BMA: 96.05 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 708 train Loss: 8911.8 test Loss: 1242.5
Epoch 282 Iter 0 subLoss 8320.5 multi 1.00 import weight 0.00
Epoch 282 Iter 1 subLoss 8726.1 multi 9.96 import weight 0.00
Epoch 282 Iter 2 subLoss 6476.5 multi 3.99 import weight 0.00
Epoch 282 Iter 3 subLoss 5557.2 multi 6.97 import weight 0.00
Epoch 282 Iter 4 subLoss 5513.9 multi 3.98 import weight 0.00
Epoch 282 Iter 5 subLoss 5138.2 multi 1.00 import weight 0.00
Epoch 282 Iter 6 subLoss 4985.8 multi 1.00 import weight 0.00
Epoch 282 Iter 7 subLoss 5131.9 multi 3.99 import weight 0.00
Epoch 282 Iter 8 subLoss 6182.4 multi 3.98 import weight 0.00
Epoch 282 Iter 9 subLoss 4866.5 multi -7.96 import weight 0.00
Epoch 282 Iter 10 subLoss 5906.9 multi -1.98 import weight 0.00
Epoch 282 Iter 11 subLoss 5481.0 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0126 / 0.10680 / 13.37
Entropy seen (from low to high)
[906, 715, 764, 582, 343, 222, 167, 144, 121, 95, 86, 75, 62, 63, 66, 45, 52, 46, 46, 37, 50, 46, 56, 43, 41, 35, 30, 28, 28, 21, 27, 12, 12, 11, 14, 7, 12, 5, 2, 4, 5, 2, 5, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 15, 35, 47, 92, 117, 110, 165, 173, 179, 190, 179, 200, 175, 174, 166, 153, 154, 160, 130, 148, 142, 108, 144, 137, 107, 119, 100, 107, 120, 97, 97, 90, 99, 94, 88, 92, 62, 67, 55, 49, 51, 29, 22, 13, 9]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.3, 32.8, 36.6, 40.8, 43.8, 47.2, 51.0, 54.3, 58.0, 61.3, 64.6, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.9, 24.9, 74.9, 71.4, 59.9, 44.4, 64.4, 69.0, 68.7, 52.1, 74.5, 86.1]
[0, 0, 0, 0, 0, 0, 0, 0, 5, 4, 12, 7, 15, 27, 45, 55, 48, 46, 51, 65]
Epoch 282 Acc: 95.15 BMA: 96.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 548 train Loss: 5472.5 test Loss: 769.4
Epoch 283 Iter 0 subLoss 5194.3 multi -4.97 import weight 0.00
Epoch 283 Iter 1 subLoss 6046.7 multi 6.97 import weight 0.00
Epoch 283 Iter 2 subLoss 5304.5 multi -1.99 import weight 0.00
Epoch 283 Iter 3 subLoss 5306.9 multi 1.00 import weight 0.00
Epoch 283 Iter 4 subLoss 5049.8 multi 12.94 import weight 0.00
Epoch 283 Iter 5 subLoss 5369.6 multi 12.94 import weight 0.00
Epoch 283 Iter 6 subLoss 4496.2 multi -4.97 import weight 0.00
Epoch 283 Iter 7 subLoss 5263.6 multi 3.99 import weight 0.00
Epoch 283 Iter 8 subLoss 4825.3 multi 1.00 import weight 0.00
Epoch 283 Iter 9 subLoss 4702.0 multi 1.00 import weight 0.00
Epoch 283 Iter 10 subLoss 5045.2 multi 15.93 import weight 0.00
Epoch 283 Iter 11 subLoss 4391.1 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0126 / 0.10706 / 12.11
Entropy seen (from low to high)
[919, 724, 776, 561, 351, 212, 170, 143, 124, 90, 83, 79, 61, 61, 61, 47, 51, 48, 44, 35, 53, 43, 56, 41, 41, 33, 29, 28, 29, 23, 23, 16, 13, 10, 12, 7, 13, 5, 3, 3, 4, 4, 4, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 14, 36, 48, 86, 123, 106, 166, 171, 176, 188, 176, 201, 179, 171, 165, 158, 152, 154, 134, 149, 138, 115, 139, 136, 110, 119, 100, 105, 106, 110, 90, 97, 100, 92, 91, 86, 65, 77, 58, 46, 53, 30, 22, 13, 9]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.1, 32.1, 36.3, 40.5, 43.6, 46.9, 50.8, 54.1, 57.8, 61.2, 64.6, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.9, 33.3, 66.6, 71.4, 57.1, 44.4, 65.1, 67.2, 69.3, 57.1, 73.4, 86.1]
[0, 0, 0, 0, 0, 0, 0, 0, 5, 3, 12, 7, 14, 27, 43, 55, 49, 49, 49, 65]
Epoch 283 Acc: 95.99 BMA: 96.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 439 train Loss: 4824.2 test Loss: 667.6
Epoch 284 Iter 0 subLoss 4754.9 multi -7.96 import weight 0.00
Epoch 284 Iter 1 subLoss 4682.4 multi 18.91 import weight 0.00
Epoch 284 Iter 2 subLoss 4924.2 multi 3.98 import weight 0.00
Epoch 284 Iter 3 subLoss 4565.9 multi -7.96 import weight 0.00
Epoch 284 Iter 4 subLoss 4702.6 multi 3.99 import weight 0.00
Epoch 284 Iter 5 subLoss 4646.5 multi 1.00 import weight 0.00
Epoch 284 Iter 6 subLoss 4410.7 multi 3.99 import weight 0.00
Epoch 284 Iter 7 subLoss 5090.2 multi -7.96 import weight 0.00
Epoch 284 Iter 8 subLoss 4883.6 multi 12.94 import weight 0.00
Epoch 284 Iter 9 subLoss 4806.1 multi 24.88 import weight 0.00
Epoch 284 Iter 10 subLoss 6078.7 multi 12.94 import weight 0.00
Epoch 284 Iter 11 subLoss 5436.2 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0125 / 0.10734 / 10.85
Entropy seen (from low to high)
[935, 732, 789, 546, 345, 216, 166, 142, 116, 91, 89, 69, 68, 58, 54, 54, 48, 49, 42, 36, 53, 46, 51, 41, 40, 30, 35, 26, 25, 27, 20, 17, 12, 10, 11, 9, 11, 6, 3, 3, 4, 4, 4, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 15, 34, 50, 87, 119, 102, 165, 166, 181, 189, 181, 185, 189, 174, 153, 159, 153, 156, 135, 149, 142, 112, 144, 127, 114, 117, 98, 106, 101, 118, 92, 96, 99, 86, 102, 81, 71, 71, 60, 50, 56, 32, 21, 11, 11]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.8, 32.5, 36.5, 40.8, 43.7, 47.0, 51.1, 54.1, 57.7, 61.1, 64.8, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 19.9, 72.7, 74.9, 49.9, 48.2, 68.1, 61.7, 72.5, 60.3, 70.8, 83.6]
[0, 0, 0, 0, 0, 0, 0, 0, 4, 5, 11, 8, 12, 29, 44, 47, 51, 53, 48, 61]
Epoch 284 Acc: 96.30 BMA: 96.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 543 train Loss: 4516.2 test Loss: 584.3
Epoch 285 Iter 0 subLoss 3854.9 multi 1.00 import weight 0.00
Epoch 285 Iter 1 subLoss 4847.2 multi 9.96 import weight 0.00
Epoch 285 Iter 2 subLoss 3975.6 multi 1.00 import weight 0.00
Epoch 285 Iter 3 subLoss 4217.9 multi 1.00 import weight 0.00
Epoch 285 Iter 4 subLoss 4233.8 multi -7.96 import weight 0.00
Epoch 285 Iter 5 subLoss 4512.2 multi 15.93 import weight 0.00
Epoch 285 Iter 6 subLoss 4011.0 multi -1.99 import weight 0.00
Epoch 285 Iter 7 subLoss 4407.5 multi 6.97 import weight 0.00
Epoch 285 Iter 8 subLoss 4301.1 multi 1.00 import weight 0.00
Epoch 285 Iter 9 subLoss 4250.9 multi 3.98 import weight 0.00
Epoch 285 Iter 10 subLoss 4340.5 multi 1.00 import weight 0.00
Epoch 285 Iter 11 subLoss 3842.7 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0124 / 0.10776 / 10.69
Entropy seen (from low to high)
[950, 759, 786, 538, 336, 203, 176, 139, 111, 94, 88, 68, 63, 60, 52, 53, 44, 53, 40, 36, 58, 47, 43, 44, 39, 30, 32, 30, 25, 24, 20, 15, 12, 9, 14, 8, 11, 5, 3, 4, 3, 4, 4, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 12, 36, 49, 82, 112, 110, 152, 169, 186, 185, 174, 182, 185, 190, 143, 163, 150, 167, 132, 148, 128, 126, 132, 136, 115, 114, 106, 101, 107, 112, 91, 93, 105, 89, 97, 90, 71, 73, 63, 49, 51, 40, 22, 11, 11]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.7, 32.4, 36.7, 41.0, 43.9, 47.2, 50.9, 54.3, 57.7, 61.2, 64.8, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 19.9, 72.7, 62.4, 61.5, 49.9, 67.3, 61.7, 72.9, 62.4, 71.4, 80.3]
[0, 0, 0, 0, 0, 0, 0, 0, 4, 5, 11, 8, 13, 26, 46, 47, 48, 56, 42, 61]
Epoch 285 Acc: 96.59 BMA: 96.15 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 384 train Loss: 4241.1 test Loss: 557.5
Epoch 286 Iter 0 subLoss 4631.4 multi 6.97 import weight 0.00
Epoch 286 Iter 1 subLoss 3464.8 multi 1.00 import weight 0.00
Epoch 286 Iter 2 subLoss 3569.2 multi 1.00 import weight 0.00
Epoch 286 Iter 3 subLoss 3923.5 multi 1.00 import weight 0.00
Epoch 286 Iter 4 subLoss 4039.6 multi 1.00 import weight 0.00
Epoch 286 Iter 5 subLoss 4153.2 multi 1.00 import weight 0.00
Epoch 286 Iter 6 subLoss 4065.6 multi 3.99 import weight 0.00
Epoch 286 Iter 7 subLoss 4372.1 multi 1.00 import weight 0.00
Epoch 286 Iter 8 subLoss 4241.4 multi 1.00 import weight 0.00
Epoch 286 Iter 9 subLoss 3781.9 multi 1.00 import weight 0.00
Epoch 286 Iter 10 subLoss 4811.3 multi -19.90 import weight 0.00
Epoch 286 Iter 11 subLoss 4092.1 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0123 / 0.10825 / 11.46
Entropy seen (from low to high)
[959, 787, 780, 540, 320, 205, 176, 129, 114, 100, 82, 69, 63, 55, 51, 55, 37, 56, 36, 43, 56, 47, 40, 43, 42, 26, 36, 26, 28, 24, 20, 13, 12, 8, 16, 8, 8, 5, 3, 4, 3, 4, 4, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 12, 32, 49, 77, 107, 113, 149, 164, 180, 187, 171, 183, 195, 171, 160, 157, 142, 175, 127, 156, 132, 121, 120, 147, 123, 110, 108, 100, 106, 121, 86, 88, 105, 88, 104, 87, 81, 67, 71, 50, 51, 44, 21, 11, 11]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.7, 32.4, 36.8, 40.7, 43.9, 47.4, 50.7, 54.3, 57.7, 61.2, 64.8, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 19.9, 69.9, 49.9, 66.6, 63.6, 66.6, 67.3, 69.8, 60.7, 71.0, 79.6]
[0, 0, 0, 0, 0, 0, 0, 0, 4, 5, 10, 8, 15, 22, 45, 46, 53, 56, 38, 64]
Epoch 286 Acc: 96.22 BMA: 96.22 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 409 train Loss: 4416.8 test Loss: 584.3
Epoch 287 Iter 0 subLoss 3980.3 multi -1.99 import weight 0.00
Epoch 287 Iter 1 subLoss 5023.2 multi 1.00 import weight 0.00
Epoch 287 Iter 2 subLoss 3760.3 multi 1.00 import weight 0.00
Epoch 287 Iter 3 subLoss 3635.9 multi 1.00 import weight 0.00
Epoch 287 Iter 4 subLoss 4472.9 multi -1.98 import weight 0.00
Epoch 287 Iter 5 subLoss 4432.2 multi -13.93 import weight 0.00
Epoch 287 Iter 6 subLoss 5412.4 multi 3.99 import weight 0.00
Epoch 287 Iter 7 subLoss 4645.9 multi 1.00 import weight 0.00
Epoch 287 Iter 8 subLoss 3590.0 multi 1.00 import weight 0.00
Epoch 287 Iter 9 subLoss 4906.7 multi -1.99 import weight 0.00
Epoch 287 Iter 10 subLoss 4010.5 multi 1.00 import weight 0.00
Epoch 287 Iter 11 subLoss 4539.3 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0123 / 0.10874 / 12.01
Entropy seen (from low to high)
[965, 826, 765, 534, 314, 210, 171, 128, 112, 96, 79, 72, 61, 55, 47, 58, 45, 47, 32, 41, 57, 49, 40, 43, 38, 32, 31, 27, 28, 23, 18, 15, 12, 9, 13, 9, 8, 5, 2, 5, 3, 4, 4, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 11, 33, 47, 70, 109, 108, 142, 163, 176, 181, 182, 176, 199, 165, 160, 159, 147, 169, 141, 148, 135, 119, 128, 148, 110, 115, 115, 97, 97, 121, 98, 85, 101, 96, 95, 92, 86, 70, 71, 53, 50, 47, 23, 11, 11]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 32.4, 36.7, 40.5, 44.1, 47.6, 50.7, 54.3, 57.8, 61.2, 64.8, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 19.9, 66.6, 55.5, 56.2, 63.1, 67.3, 65.9, 69.6, 58.4, 76.9, 80.3]
[0, 0, 0, 0, 0, 0, 0, 0, 4, 5, 9, 9, 16, 19, 46, 44, 56, 53, 39, 61]
Epoch 287 Acc: 96.11 BMA: 96.28 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 453 train Loss: 4496.8 test Loss: 601.3
Epoch 288 Iter 0 subLoss 5302.6 multi 3.99 import weight 0.00
Epoch 288 Iter 1 subLoss 4555.6 multi 12.94 import weight 0.00
Epoch 288 Iter 2 subLoss 3686.4 multi 1.00 import weight 0.00
Epoch 288 Iter 3 subLoss 4011.7 multi 3.98 import weight 0.00
Epoch 288 Iter 4 subLoss 3983.4 multi 1.00 import weight 0.00
Epoch 288 Iter 5 subLoss 4419.3 multi 3.98 import weight 0.00
Epoch 288 Iter 6 subLoss 3852.7 multi 1.00 import weight 0.00
Epoch 288 Iter 7 subLoss 4094.1 multi 6.97 import weight 0.00
Epoch 288 Iter 8 subLoss 4064.9 multi 6.97 import weight 0.00
Epoch 288 Iter 9 subLoss 3564.2 multi 3.99 import weight 0.00
Epoch 288 Iter 10 subLoss 4434.1 multi -10.94 import weight 0.00
Epoch 288 Iter 11 subLoss 4553.9 multi 15.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.10905 / 11.10
Entropy seen (from low to high)
[972, 843, 778, 521, 306, 207, 170, 135, 104, 93, 81, 68, 62, 49, 60, 48, 48, 38, 36, 49, 51, 47, 44, 45, 37, 30, 28, 29, 26, 25, 16, 14, 12, 9, 14, 7, 8, 5, 2, 5, 3, 5, 3, 1, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 11, 33, 44, 71, 99, 111, 142, 157, 176, 181, 185, 182, 181, 171, 160, 157, 151, 166, 145, 151, 132, 124, 127, 142, 113, 116, 112, 98, 100, 116, 106, 80, 103, 99, 94, 93, 88, 71, 69, 52, 53, 49, 27, 11, 11]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.9, 32.8, 36.5, 40.5, 44.1, 47.4, 50.5, 54.3, 57.7, 61.0, 64.8, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.9, 24.9, 62.4, 59.9, 59.9, 52.9, 64.5, 70.7, 72.2, 59.9, 74.4, 77.9]
[0, 0, 0, 0, 0, 0, 0, 0, 5, 4, 8, 10, 15, 17, 48, 41, 54, 55, 43, 59]
Epoch 288 Acc: 96.40 BMA: 96.28 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 15.93 Pidx 455 train Loss: 4563.0 test Loss: 569.3
Epoch 289 Iter 0 subLoss 4450.4 multi 3.98 import weight 0.00
Epoch 289 Iter 1 subLoss 4156.9 multi 3.99 import weight 0.00
Epoch 289 Iter 2 subLoss 4473.9 multi 1.00 import weight 0.00
Epoch 289 Iter 3 subLoss 4121.2 multi 6.97 import weight 0.00
Epoch 289 Iter 4 subLoss 4358.7 multi 1.00 import weight 0.00
Epoch 289 Iter 5 subLoss 3984.4 multi 3.98 import weight 0.00
Epoch 289 Iter 6 subLoss 3847.9 multi 3.99 import weight 0.00
Epoch 289 Iter 7 subLoss 3415.9 multi 1.00 import weight 0.00
Epoch 289 Iter 8 subLoss 4107.4 multi -7.96 import weight 0.00
Epoch 289 Iter 9 subLoss 4543.9 multi -7.96 import weight 0.00
Epoch 289 Iter 10 subLoss 4070.4 multi -7.96 import weight 0.00
Epoch 289 Iter 11 subLoss 5896.2 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0121 / 0.10945 / 10.69
Entropy seen (from low to high)
[974, 858, 776, 518, 305, 206, 166, 131, 106, 95, 75, 73, 64, 47, 59, 51, 38, 41, 39, 41, 54, 51, 42, 53, 31, 33, 23, 31, 25, 29, 11, 14, 13, 11, 12, 10, 5, 4, 2, 5, 3, 4, 4, 1, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 10, 31, 44, 68, 98, 107, 138, 151, 172, 176, 195, 174, 179, 166, 180, 153, 157, 148, 167, 146, 124, 136, 128, 126, 132, 111, 115, 96, 97, 115, 112, 82, 104, 93, 93, 97, 87, 73, 70, 56, 57, 47, 28, 10, 11]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.7, 33.5, 36.8, 40.4, 44.1, 47.5, 50.6, 54.2, 57.8, 61.0, 64.9, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.9, 33.3, 59.9, 49.9, 61.5, 54.9, 64.4, 76.9, 66.1, 62.4, 75.5, 78.6]
[0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 5, 12, 13, 20, 45, 39, 62, 48, 45, 61]
Epoch 289 Acc: 95.14 BMA: 96.32 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 589 train Loss: 5223.9 test Loss: 736.6
Epoch 290 Iter 0 subLoss 4750.7 multi -4.97 import weight 0.00
Epoch 290 Iter 1 subLoss 7072.8 multi -7.96 import weight 0.00
Epoch 290 Iter 2 subLoss 41198.4 multi 1.00 import weight 0.00
Epoch 290 Iter 3 subLoss 9144.5 multi -1.98 import weight 0.00
Epoch 290 Iter 4 subLoss 14352.5 multi 3.99 import weight 0.00
Epoch 290 Iter 5 subLoss 4738.1 multi 1.00 import weight 0.00
Epoch 290 Iter 6 subLoss 4624.8 multi -7.96 import weight 0.00
Epoch 290 Iter 7 subLoss 6202.2 multi 1.00 import weight 0.00
Epoch 290 Iter 8 subLoss 5505.4 multi -4.97 import weight 0.00
Epoch 290 Iter 9 subLoss 7718.0 multi 3.99 import weight 0.00
Epoch 290 Iter 10 subLoss 5354.9 multi -4.97 import weight 0.00
Epoch 290 Iter 11 subLoss 5481.4 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0121 / 0.10966 / 11.95
Entropy seen (from low to high)
[987, 862, 776, 514, 302, 209, 163, 129, 101, 100, 76, 69, 62, 47, 61, 49, 39, 40, 40, 43, 50, 47, 47, 50, 31, 34, 22, 30, 26, 26, 13, 16, 12, 10, 13, 9, 6, 4, 3, 4, 3, 4, 4, 1, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 8, 32, 44, 66, 101, 108, 136, 145, 167, 182, 193, 172, 181, 166, 180, 152, 158, 157, 155, 148, 124, 136, 138, 116, 125, 119, 109, 97, 108, 105, 111, 84, 104, 98, 91, 100, 86, 70, 72, 59, 59, 50, 27, 10, 11]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.6, 33.3, 36.4, 40.5, 44.2, 47.5, 50.6, 54.2, 57.9, 61.2, 65.0, 68.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.9, 19.9, 66.6, 58.3, 74.9, 54.5, 67.4, 76.9, 64.5, 66.6, 73.8, 77.9]
[0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 6, 12, 12, 22, 43, 39, 62, 51, 42, 59]
Epoch 290 Acc: 96.22 BMA: 96.36 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 548 train Loss: 4707.5 test Loss: 598.8
Epoch 291 Iter 0 subLoss 4618.4 multi 1.00 import weight 0.00
Epoch 291 Iter 1 subLoss 4348.4 multi 3.99 import weight 0.00
Epoch 291 Iter 2 subLoss 4164.9 multi -1.98 import weight 0.00
Epoch 291 Iter 3 subLoss 4647.3 multi 3.99 import weight 0.00
Epoch 291 Iter 4 subLoss 4693.8 multi -13.93 import weight 0.00
Epoch 291 Iter 5 subLoss 4719.9 multi -7.96 import weight 0.00
Epoch 291 Iter 6 subLoss 5831.3 multi -7.96 import weight 0.00
Epoch 291 Iter 7 subLoss 8986.6 multi 1.00 import weight 0.00
Epoch 291 Iter 8 subLoss 7664.8 multi 3.99 import weight 0.00
Epoch 291 Iter 9 subLoss 5398.6 multi 3.99 import weight 0.00
Epoch 291 Iter 10 subLoss 4626.8 multi -7.96 import weight 0.00
Epoch 291 Iter 11 subLoss 5684.2 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0121 / 0.10968 / 12.82
Entropy seen (from low to high)
[959, 873, 785, 517, 298, 219, 165, 123, 99, 99, 82, 72, 58, 48, 54, 55, 43, 34, 43, 40, 52, 40, 47, 57, 29, 37, 23, 29, 24, 28, 13, 13, 15, 10, 14, 6, 9, 3, 3, 4, 4, 3, 4, 1, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 8, 33, 46, 65, 102, 109, 136, 146, 171, 189, 180, 169, 179, 166, 186, 149, 156, 162, 153, 146, 130, 130, 127, 127, 126, 118, 106, 109, 102, 98, 113, 91, 93, 99, 90, 102, 84, 73, 77, 58, 55, 55, 27, 10, 9]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.9, 30.0, 33.8, 36.6, 40.5, 44.3, 47.4, 50.9, 54.2, 57.6, 61.1, 65.0, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 24.9, 71.4, 63.6, 74.9, 54.1, 70.4, 74.9, 65.0, 72.2, 70.8, 76.7]
[0, 0, 0, 0, 0, 0, 0, 1, 5, 4, 7, 11, 12, 24, 44, 32, 63, 54, 48, 56]
Epoch 291 Acc: 95.04 BMA: 96.36 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 568 train Loss: 5758.9 test Loss: 778.4
Epoch 292 Iter 0 subLoss 5147.4 multi -7.96 import weight 0.00
Epoch 292 Iter 1 subLoss 8473.6 multi 12.94 import weight 0.00
Epoch 292 Iter 2 subLoss 4952.7 multi 12.94 import weight 0.00
Epoch 292 Iter 3 subLoss 4959.1 multi 15.93 import weight 0.00
Epoch 292 Iter 4 subLoss 4305.4 multi 3.98 import weight 0.00
Epoch 292 Iter 5 subLoss 3992.6 multi -4.97 import weight 0.00
Epoch 292 Iter 6 subLoss 4641.9 multi 6.97 import weight 0.00
Epoch 292 Iter 7 subLoss 4151.7 multi 6.97 import weight 0.00
Epoch 292 Iter 8 subLoss 3895.9 multi 1.00 import weight 0.00
Epoch 292 Iter 9 subLoss 4123.2 multi 9.96 import weight 0.00
Epoch 292 Iter 10 subLoss 4227.2 multi 3.99 import weight 0.00
Epoch 292 Iter 11 subLoss 4402.9 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0120 / 0.11001 / 12.86
Entropy seen (from low to high)
[971, 879, 779, 520, 298, 215, 161, 123, 104, 99, 78, 73, 56, 47, 55, 49, 46, 32, 43, 40, 56, 41, 43, 59, 31, 32, 25, 29, 24, 27, 10, 15, 14, 9, 14, 8, 7, 3, 3, 6, 2, 3, 3, 2, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 9, 31, 42, 68, 101, 101, 137, 147, 167, 184, 174, 182, 174, 166, 182, 151, 162, 155, 160, 148, 124, 134, 135, 113, 128, 117, 117, 105, 96, 101, 112, 95, 96, 90, 93, 101, 92, 74, 78, 59, 54, 56, 30, 10, 9]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.9, 29.9, 33.8, 36.6, 40.8, 44.3, 47.3, 50.9, 54.2, 57.8, 61.2, 65.1, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 24.9, 71.4, 63.6, 72.7, 59.9, 68.2, 71.4, 69.3, 71.6, 65.9, 79.6]
[0, 0, 0, 0, 0, 0, 0, 1, 5, 4, 7, 11, 11, 25, 41, 35, 62, 53, 50, 54]
Epoch 292 Acc: 96.65 BMA: 96.40 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 440 train Loss: 4130.2 test Loss: 555.1
Epoch 293 Iter 0 subLoss 4082.1 multi -1.99 import weight 0.00
Epoch 293 Iter 1 subLoss 4380.5 multi 3.99 import weight 0.00
Epoch 293 Iter 2 subLoss 4227.3 multi 6.97 import weight 0.00
Epoch 293 Iter 3 subLoss 3974.5 multi 3.99 import weight 0.00
Epoch 293 Iter 4 subLoss 4141.5 multi 1.00 import weight 0.00
Epoch 293 Iter 5 subLoss 3864.7 multi -1.98 import weight 0.00
Epoch 293 Iter 6 subLoss 4614.5 multi 3.99 import weight 0.00
Epoch 293 Iter 7 subLoss 3747.4 multi 1.00 import weight 0.00
Epoch 293 Iter 8 subLoss 3714.1 multi 1.00 import weight 0.00
Epoch 293 Iter 9 subLoss 4018.9 multi 6.97 import weight 0.00
Epoch 293 Iter 10 subLoss 4184.5 multi 3.98 import weight 0.00
Epoch 293 Iter 11 subLoss 4095.6 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0119 / 0.11032 / 13.13
Entropy seen (from low to high)
[984, 896, 776, 514, 296, 209, 162, 114, 112, 92, 82, 71, 57, 44, 54, 48, 45, 33, 43, 42, 53, 41, 45, 56, 32, 30, 26, 28, 27, 25, 9, 17, 12, 10, 12, 8, 6, 4, 3, 7, 1, 3, 3, 2, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 9, 31, 40, 67, 101, 101, 129, 149, 166, 177, 177, 183, 174, 162, 180, 147, 173, 154, 161, 135, 140, 128, 135, 119, 123, 115, 115, 116, 90, 102, 109, 105, 92, 87, 97, 95, 97, 80, 73, 66, 50, 58, 33, 10, 9]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.9, 29.8, 33.7, 36.5, 40.7, 43.8, 47.3, 50.8, 54.2, 57.7, 61.3, 65.1, 68.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 24.9, 57.1, 74.9, 76.9, 67.9, 61.5, 74.2, 68.8, 71.9, 67.3, 78.1]
[0, 0, 0, 0, 0, 0, 0, 1, 5, 4, 7, 8, 13, 25, 39, 35, 61, 57, 46, 55]
Epoch 293 Acc: 96.71 BMA: 96.46 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 409 train Loss: 4149.5 test Loss: 538.1
Epoch 294 Iter 0 subLoss 3503.4 multi 1.00 import weight 0.00
Epoch 294 Iter 1 subLoss 4557.2 multi 15.93 import weight 0.00
Epoch 294 Iter 2 subLoss 3956.8 multi 1.00 import weight 0.00
Epoch 294 Iter 3 subLoss 4218.9 multi 3.98 import weight 0.00
Epoch 294 Iter 4 subLoss 4290.4 multi 1.00 import weight 0.00
Epoch 294 Iter 5 subLoss 3693.1 multi -1.99 import weight 0.00
Epoch 294 Iter 6 subLoss 4199.0 multi -4.97 import weight 0.00
Epoch 294 Iter 7 subLoss 3844.5 multi 6.97 import weight 0.00
Epoch 294 Iter 8 subLoss 4318.6 multi -7.96 import weight 0.00
Epoch 294 Iter 9 subLoss 3747.1 multi 3.99 import weight 0.00
Epoch 294 Iter 10 subLoss 3749.3 multi 6.97 import weight 0.00
Epoch 294 Iter 11 subLoss 3858.0 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0119 / 0.11055 / 12.87
Entropy seen (from low to high)
[993, 914, 774, 505, 289, 212, 154, 119, 114, 87, 82, 76, 52, 50, 45, 48, 47, 32, 48, 39, 54, 36, 45, 56, 33, 30, 24, 27, 28, 24, 10, 17, 11, 11, 14, 5, 7, 3, 3, 7, 1, 3, 3, 2, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 9, 29, 42, 64, 98, 102, 124, 147, 166, 179, 178, 181, 176, 155, 181, 157, 168, 154, 168, 125, 147, 127, 136, 119, 120, 121, 111, 113, 88, 106, 107, 107, 85, 96, 96, 98, 98, 74, 77, 65, 57, 56, 33, 10, 10]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.8, 29.7, 33.6, 36.2, 40.3, 43.8, 47.6, 50.8, 54.1, 57.7, 61.2, 65.0, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 24.9, 66.6, 71.4, 73.3, 71.9, 54.2, 72.4, 72.2, 70.4, 66.6, 78.5]
[0, 0, 0, 0, 0, 0, 0, 1, 5, 4, 6, 7, 15, 25, 35, 40, 54, 61, 45, 56]
Epoch 294 Acc: 96.79 BMA: 96.46 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 385 train Loss: 4024.5 test Loss: 515.7
Epoch 295 Iter 0 subLoss 3992.5 multi -1.99 import weight 0.00
Epoch 295 Iter 1 subLoss 3562.7 multi 6.97 import weight 0.00
Epoch 295 Iter 2 subLoss 4080.5 multi 1.00 import weight 0.00
Epoch 295 Iter 3 subLoss 4199.8 multi -1.99 import weight 0.00
Epoch 295 Iter 4 subLoss 3849.5 multi 9.96 import weight 0.00
Epoch 295 Iter 5 subLoss 4527.0 multi -13.93 import weight 0.00
Epoch 295 Iter 6 subLoss 4331.3 multi 1.00 import weight 0.00
Epoch 295 Iter 7 subLoss 5198.2 multi -1.98 import weight 0.00
Epoch 295 Iter 8 subLoss 3952.4 multi 3.98 import weight 0.00
Epoch 295 Iter 9 subLoss 3951.0 multi 6.97 import weight 0.00
Epoch 295 Iter 10 subLoss 3281.0 multi 1.00 import weight 0.00
Epoch 295 Iter 11 subLoss 3987.3 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0118 / 0.11083 / 12.86
Entropy seen (from low to high)
[999, 940, 773, 491, 284, 216, 153, 116, 110, 87, 78, 77, 49, 53, 55, 40, 39, 36, 47, 39, 52, 44, 47, 55, 27, 28, 24, 26, 33, 21, 9, 16, 11, 12, 13, 6, 6, 3, 3, 7, 1, 3, 3, 2, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 8, 28, 41, 65, 95, 100, 126, 147, 159, 173, 174, 193, 167, 159, 182, 162, 161, 159, 162, 133, 149, 115, 140, 120, 124, 117, 113, 113, 90, 103, 111, 105, 85, 102, 89, 103, 95, 78, 78, 68, 57, 58, 33, 10, 10]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.8, 29.6, 33.9, 36.5, 40.6, 44.1, 47.7, 50.7, 54.2, 57.9, 61.2, 64.7, 68.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 19.9, 79.9, 71.4, 68.7, 72.7, 55.5, 73.8, 69.2, 68.9, 72.0, 76.6]
[0, 0, 0, 0, 0, 0, 0, 1, 5, 5, 5, 7, 16, 22, 36, 42, 52, 58, 43, 60]
Epoch 295 Acc: 96.79 BMA: 96.44 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 398 train Loss: 4002.2 test Loss: 515.7
Epoch 296 Iter 0 subLoss 4153.4 multi 6.97 import weight 0.00
Epoch 296 Iter 1 subLoss 4409.4 multi 12.94 import weight 0.00
Epoch 296 Iter 2 subLoss 4278.9 multi -1.99 import weight 0.00
Epoch 296 Iter 3 subLoss 4119.7 multi -1.99 import weight 0.00
Epoch 296 Iter 4 subLoss 3608.6 multi 1.00 import weight 0.00
Epoch 296 Iter 5 subLoss 3989.8 multi 6.97 import weight 0.00
Epoch 296 Iter 6 subLoss 3811.6 multi 1.00 import weight 0.00
Epoch 296 Iter 7 subLoss 3960.7 multi -10.94 import weight 0.00
Epoch 296 Iter 8 subLoss 3813.5 multi 3.99 import weight 0.00
Epoch 296 Iter 9 subLoss 3316.3 multi 1.00 import weight 0.00
Epoch 296 Iter 10 subLoss 3768.3 multi 3.99 import weight 0.00
Epoch 296 Iter 11 subLoss 4372.7 multi 3.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0117 / 0.11111 / 12.93
Entropy seen (from low to high)
[1010, 956, 771, 485, 282, 208, 162, 112, 106, 85, 80, 76, 41, 59, 50, 48, 31, 37, 45, 43, 50, 44, 46, 55, 29, 27, 23, 28, 34, 17, 9, 17, 10, 11, 14, 5, 6, 3, 4, 6, 1, 3, 3, 2, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 8, 27, 45, 57, 99, 93, 119, 154, 168, 166, 167, 191, 174, 155, 177, 167, 153, 164, 161, 134, 152, 116, 140, 117, 129, 114, 117, 108, 95, 100, 109, 103, 83, 103, 96, 101, 94, 83, 79, 68, 59, 58, 36, 11, 10]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.8, 29.9, 33.8, 36.0, 40.3, 44.0, 47.5, 50.6, 54.0, 57.9, 61.2, 64.6, 68.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 0.0, 19.9, 74.9, 71.4, 73.3, 66.6, 59.9, 70.4, 72.9, 66.1, 72.4, 79.0]
[0, 0, 0, 0, 0, 0, 0, 2, 4, 5, 4, 7, 15, 21, 35, 44, 48, 62, 40, 62]
Epoch 296 Acc: 96.94 BMA: 96.50 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 437 train Loss: 3977.4 test Loss: 498.3
Epoch 297 Iter 0 subLoss 3523.7 multi 1.00 import weight 0.00
Epoch 297 Iter 1 subLoss 3852.6 multi -1.99 import weight 0.00
Epoch 297 Iter 2 subLoss 3574.3 multi -7.96 import weight 0.00
Epoch 297 Iter 3 subLoss 3358.5 multi 1.00 import weight 0.00
Epoch 297 Iter 4 subLoss 4085.0 multi 3.98 import weight 0.00
Epoch 297 Iter 5 subLoss 3976.5 multi 3.98 import weight 0.00
Epoch 297 Iter 6 subLoss 4325.8 multi 3.98 import weight 0.00
Epoch 297 Iter 7 subLoss 3874.6 multi -4.97 import weight 0.00
Epoch 297 Iter 8 subLoss 3933.9 multi -1.98 import weight 0.00
Epoch 297 Iter 9 subLoss 4560.9 multi -13.93 import weight 0.00
Epoch 297 Iter 10 subLoss 5467.2 multi -10.94 import weight 0.00
Epoch 297 Iter 11 subLoss 26615.7 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0117 / 0.11086 / 13.68
Entropy seen (from low to high)
[1010, 951, 767, 488, 277, 201, 158, 116, 116, 89, 76, 78, 47, 50, 59, 39, 40, 37, 41, 49, 46, 44, 48, 49, 36, 29, 24, 31, 24, 21, 9, 17, 8, 11, 15, 5, 6, 3, 4, 6, 1, 3, 3, 2, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 7, 26, 43, 60, 99, 89, 119, 150, 174, 161, 174, 192, 166, 161, 180, 169, 154, 162, 158, 145, 146, 120, 145, 107, 137, 109, 128, 98, 96, 110, 110, 89, 91, 104, 85, 106, 94, 77, 82, 68, 51, 60, 36, 11, 10]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.7, 30.0, 33.8, 36.3, 40.2, 43.8, 47.6, 50.4, 53.9, 57.9, 61.1, 64.5, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 0.0, 49.9, 66.6, 85.7, 61.5, 70.8, 57.5, 74.4, 67.3, 65.5, 75.5, 84.3]
[0, 0, 0, 0, 0, 0, 0, 2, 4, 6, 3, 7, 13, 24, 33, 43, 52, 58, 45, 64]
Epoch 297 Acc: 93.42 BMA: 96.54 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2661 train Loss: 6518.1 test Loss: 1005.8
Epoch 298 Iter 0 subLoss 6301.4 multi -7.96 import weight 0.00
Epoch 298 Iter 1 subLoss 27396.4 multi 1.00 import weight 0.00
Epoch 298 Iter 2 subLoss 10213.3 multi 3.99 import weight 0.00
Epoch 298 Iter 3 subLoss 3768.8 multi 6.97 import weight 0.00
Epoch 298 Iter 4 subLoss 4208.7 multi -4.97 import weight 0.00
Epoch 298 Iter 5 subLoss 4290.0 multi -4.97 import weight 0.00
Epoch 298 Iter 6 subLoss 4200.9 multi -1.99 import weight 0.00
Epoch 298 Iter 7 subLoss 4477.4 multi 3.99 import weight 0.00
Epoch 298 Iter 8 subLoss 4551.2 multi 18.91 import weight 0.00
Epoch 298 Iter 9 subLoss 4053.0 multi -1.99 import weight 0.00
Epoch 298 Iter 10 subLoss 4637.0 multi 3.99 import weight 0.00
Epoch 298 Iter 11 subLoss 3881.2 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0116 / 0.11112 / 13.25
Entropy seen (from low to high)
[1018, 962, 773, 471, 281, 199, 159, 114, 116, 91, 70, 76, 49, 50, 55, 41, 41, 34, 42, 47, 48, 44, 47, 52, 33, 28, 25, 33, 23, 18, 10, 19, 10, 9, 13, 7, 4, 3, 4, 5, 2, 3, 3, 2, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 7, 26, 43, 59, 93, 93, 113, 146, 170, 162, 181, 189, 164, 158, 184, 172, 150, 157, 164, 146, 145, 123, 144, 118, 124, 116, 131, 95, 102, 105, 105, 91, 94, 99, 89, 98, 100, 82, 79, 72, 49, 63, 36, 12, 10]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.6, 30.0, 33.8, 36.3, 40.1, 43.7, 47.5, 50.4, 54.0, 57.9, 61.0, 64.6, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 0.0, 49.9, 66.6, 83.3, 61.5, 66.6, 59.3, 71.7, 68.0, 67.2, 75.5, 82.8]
[0, 0, 0, 0, 0, 0, 0, 2, 4, 6, 3, 6, 13, 24, 32, 46, 47, 61, 45, 64]
Epoch 298 Acc: 96.65 BMA: 96.52 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 388 train Loss: 4225.5 test Loss: 536.7
Epoch 299 Iter 0 subLoss 4123.7 multi 9.96 import weight 0.00
Epoch 299 Iter 1 subLoss 3321.2 multi -1.99 import weight 0.00
Epoch 299 Iter 2 subLoss 4021.1 multi -7.96 import weight 0.00
Epoch 299 Iter 3 subLoss 4140.9 multi 3.99 import weight 0.00
Epoch 299 Iter 4 subLoss 3950.0 multi -1.98 import weight 0.00
Epoch 299 Iter 5 subLoss 3809.4 multi 1.00 import weight 0.00
Epoch 299 Iter 6 subLoss 4041.6 multi -1.98 import weight 0.00
Epoch 299 Iter 7 subLoss 3816.2 multi 3.98 import weight 0.00
Epoch 299 Iter 8 subLoss 4053.2 multi -1.98 import weight 0.00
Epoch 299 Iter 9 subLoss 4123.8 multi 12.94 import weight 0.00
Epoch 299 Iter 10 subLoss 4291.6 multi 1.00 import weight 0.00
Epoch 299 Iter 11 subLoss 4449.5 multi -1.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0116 / 0.11138 / 12.97
Entropy seen (from low to high)
[1027, 972, 771, 467, 277, 206, 157, 109, 116, 87, 74, 71, 53, 44, 57, 40, 41, 34, 44, 41, 55, 43, 48, 50, 32, 27, 25, 32, 22, 18, 12, 16, 13, 8, 13, 7, 2, 4, 5, 4, 2, 3, 3, 2, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 7, 25, 45, 55, 91, 88, 116, 141, 173, 156, 182, 190, 162, 161, 175, 170, 158, 162, 162, 143, 148, 121, 149, 123, 122, 113, 130, 97, 104, 101, 102, 101, 86, 104, 88, 99, 98, 84, 78, 74, 52, 63, 34, 16, 10]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.5, 30.0, 33.9, 36.4, 40.3, 43.9, 47.5, 50.6, 54.2, 57.8, 61.1, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 0.0, 49.9, 66.6, 83.3, 61.5, 66.6, 52.9, 74.9, 61.3, 74.6, 71.1, 83.8]
[0, 0, 0, 0, 0, 0, 0, 2, 4, 6, 3, 6, 13, 24, 34, 44, 44, 63, 45, 62]
Epoch 299 Acc: 96.56 BMA: 96.52 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 444 train Loss: 4184.7 test Loss: 529.7
Epoch 300 Iter 0 subLoss 4348.0 multi 3.99 import weight 0.00
Epoch 300 Iter 1 subLoss 4215.4 multi 1.00 import weight 0.00
Epoch 300 Iter 2 subLoss 3806.1 multi 3.99 import weight 0.00
Epoch 300 Iter 3 subLoss 4613.4 multi 6.97 import weight 0.00
Epoch 300 Iter 4 subLoss 3813.3 multi 3.99 import weight 0.00
Epoch 300 Iter 5 subLoss 3621.2 multi 1.00 import weight 0.00
Epoch 300 Iter 6 subLoss 4032.3 multi 1.00 import weight 0.00
Epoch 300 Iter 7 subLoss 3673.7 multi 1.00 import weight 0.00
Epoch 300 Iter 8 subLoss 4059.9 multi 1.00 import weight 0.00
Epoch 300 Iter 9 subLoss 3727.1 multi -1.99 import weight 0.00
Epoch 300 Iter 10 subLoss 3716.0 multi 3.99 import weight 0.00
Epoch 300 Iter 11 subLoss 3818.4 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0115 / 0.11161 / 13.16
Entropy seen (from low to high)
[1039, 980, 778, 456, 272, 206, 156, 108, 111, 90, 72, 73, 49, 48, 55, 41, 39, 35, 43, 42, 52, 42, 48, 52, 34, 24, 24, 33, 20, 19, 13, 12, 15, 10, 11, 6, 3, 4, 7, 2, 2, 3, 3, 2, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 7, 24, 46, 55, 90, 87, 111, 147, 163, 153, 179, 198, 154, 173, 169, 171, 160, 154, 173, 138, 151, 117, 152, 122, 128, 108, 128, 100, 102, 101, 96, 108, 88, 97, 91, 101, 97, 88, 74, 75, 55, 66, 34, 18, 10]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.2, 30.0, 33.9, 36.5, 40.4, 43.5, 47.3, 50.7, 54.4, 57.9, 61.1, 64.6, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 0.0, 49.9, 66.6, 83.3, 59.9, 67.8, 48.4, 76.5, 58.9, 73.7, 72.9, 83.3]
[0, 0, 0, 0, 0, 0, 0, 2, 4, 6, 3, 6, 10, 28, 33, 47, 39, 61, 48, 60]
Epoch 300 Acc: 96.83 BMA: 96.52 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 381 train Loss: 3961.1 test Loss: 501.8
Epoch 301 Iter 0 subLoss 4053.1 multi 3.99 import weight 0.00
Epoch 301 Iter 1 subLoss 3959.5 multi 6.97 import weight 0.00
Epoch 301 Iter 2 subLoss 4165.8 multi -4.97 import weight 0.00
Epoch 301 Iter 3 subLoss 3723.4 multi -1.98 import weight 0.00
Epoch 301 Iter 4 subLoss 4110.0 multi -7.96 import weight 0.00
Epoch 301 Iter 5 subLoss 3775.4 multi -7.96 import weight 0.00
Epoch 301 Iter 6 subLoss 4575.3 multi 12.94 import weight 0.00
Epoch 301 Iter 7 subLoss 5441.0 multi -10.94 import weight 0.00
Epoch 301 Iter 8 subLoss 9197.5 multi -1.98 import weight 0.00
Epoch 301 Iter 9 subLoss 14668.6 multi 3.98 import weight 0.00
Epoch 301 Iter 10 subLoss 4996.0 multi -13.93 import weight 0.00
Epoch 301 Iter 11 subLoss 9178.9 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0115 / 0.11172 / 12.57
Entropy seen (from low to high)
[1045, 985, 776, 453, 275, 212, 143, 111, 107, 88, 72, 72, 53, 49, 52, 41, 38, 36, 44, 39, 51, 50, 49, 45, 36, 24, 23, 31, 21, 21, 13, 12, 13, 11, 11, 7, 3, 3, 7, 2, 2, 3, 3, 2, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 7, 23, 48, 51, 94, 86, 104, 150, 160, 149, 191, 188, 158, 167, 173, 169, 163, 156, 170, 140, 154, 114, 150, 131, 121, 115, 122, 101, 97, 108, 92, 113, 86, 100, 88, 101, 96, 86, 77, 77, 52, 68, 35, 18, 10]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.2, 30.0, 33.8, 36.1, 40.5, 43.8, 47.4, 50.7, 54.3, 58.0, 61.1, 64.8, 68.4]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 24.9, 59.9, 49.9, 83.3, 63.6, 59.2, 53.1, 74.4, 57.1, 76.2, 75.9, 82.4]
[0, 0, 0, 0, 0, 0, 0, 2, 4, 5, 4, 6, 11, 27, 32, 47, 42, 59, 50, 57]
Epoch 301 Acc: 96.71 BMA: 96.52 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 917 train Loss: 4320.6 test Loss: 580.0
Epoch 302 Iter 0 subLoss 4495.2 multi -1.99 import weight 0.00
Epoch 302 Iter 1 subLoss 4436.8 multi -7.96 import weight 0.00
Epoch 302 Iter 2 subLoss 4885.2 multi 15.93 import weight 0.00
Epoch 302 Iter 3 subLoss 3952.6 multi 9.96 import weight 0.00
Epoch 302 Iter 4 subLoss 4222.0 multi 3.98 import weight 0.00
Epoch 302 Iter 5 subLoss 3555.6 multi 1.00 import weight 0.00
Epoch 302 Iter 6 subLoss 4320.5 multi 6.97 import weight 0.00
Epoch 302 Iter 7 subLoss 4273.0 multi 1.00 import weight 0.00
Epoch 302 Iter 8 subLoss 4040.7 multi -1.99 import weight 0.00
Epoch 302 Iter 9 subLoss 3442.2 multi 1.00 import weight 0.00
Epoch 302 Iter 10 subLoss 4118.6 multi -1.98 import weight 0.00
Epoch 302 Iter 11 subLoss 3695.5 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0114 / 0.11196 / 12.63
Entropy seen (from low to high)
[1057, 994, 768, 452, 272, 210, 142, 114, 104, 86, 76, 65, 56, 54, 44, 45, 37, 33, 43, 42, 52, 48, 49, 44, 36, 24, 24, 30, 20, 21, 13, 13, 11, 13, 11, 6, 3, 3, 7, 3, 1, 3, 3, 2, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 7, 21, 50, 52, 89, 86, 104, 144, 162, 148, 185, 185, 166, 167, 171, 174, 162, 148, 171, 145, 156, 121, 137, 137, 120, 113, 117, 106, 99, 108, 92, 114, 89, 98, 89, 96, 97, 87, 82, 78, 53, 68, 36, 19, 10]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.0, 30.0, 33.9, 36.2, 40.7, 43.7, 47.2, 50.6, 54.3, 58.0, 61.1, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 24.9, 59.9, 49.9, 83.3, 49.9, 62.9, 56.2, 74.4, 57.1, 75.4, 75.9, 82.4]
[0, 0, 0, 0, 0, 0, 0, 2, 4, 5, 4, 6, 10, 27, 32, 47, 42, 57, 50, 57]
Epoch 302 Acc: 96.65 BMA: 96.56 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 369 train Loss: 4067.3 test Loss: 534.1
Epoch 303 Iter 0 subLoss 3535.4 multi -1.99 import weight 0.00
Epoch 303 Iter 1 subLoss 3893.5 multi 1.00 import weight 0.00
Epoch 303 Iter 2 subLoss 4279.0 multi 3.99 import weight 0.00
Epoch 303 Iter 3 subLoss 4277.7 multi 6.97 import weight 0.00
Epoch 303 Iter 4 subLoss 4195.1 multi 1.00 import weight 0.00
Epoch 303 Iter 5 subLoss 3974.4 multi 6.97 import weight 0.00
Epoch 303 Iter 6 subLoss 3578.6 multi -4.97 import weight 0.00
Epoch 303 Iter 7 subLoss 3772.9 multi -4.97 import weight 0.00
Epoch 303 Iter 8 subLoss 3976.1 multi 9.96 import weight 0.00
Epoch 303 Iter 9 subLoss 4298.3 multi 3.99 import weight 0.00
Epoch 303 Iter 10 subLoss 4259.1 multi 3.99 import weight 0.00
Epoch 303 Iter 11 subLoss 4405.2 multi 15.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0114 / 0.11219 / 11.78
Entropy seen (from low to high)
[1071, 1000, 767, 446, 267, 212, 136, 121, 100, 84, 77, 60, 62, 54, 40, 43, 39, 36, 37, 47, 51, 48, 48, 40, 41, 22, 25, 28, 21, 19, 13, 13, 12, 12, 11, 6, 3, 3, 7, 3, 1, 3, 3, 2, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 7, 21, 46, 56, 84, 86, 104, 136, 170, 147, 183, 178, 165, 173, 165, 176, 165, 148, 164, 151, 160, 118, 140, 136, 115, 118, 122, 103, 100, 108, 93, 111, 90, 99, 88, 91, 105, 86, 82, 79, 54, 70, 36, 20, 10]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.9, 30.0, 33.6, 36.0, 40.0, 43.5, 47.2, 50.7, 54.3, 58.0, 61.1, 64.5, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 24.9, 49.9, 59.9, 74.9, 58.3, 57.6, 67.6, 70.4, 60.8, 73.5, 79.1, 75.4]
[0, 0, 0, 0, 0, 0, 0, 2, 4, 4, 5, 4, 12, 26, 34, 44, 46, 53, 48, 61]
Epoch 303 Acc: 96.73 BMA: 96.56 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 15.93 Pidx 440 train Loss: 3984.2 test Loss: 522.4
Epoch 304 Iter 0 subLoss 3732.6 multi -4.97 import weight 0.00
Epoch 304 Iter 1 subLoss 4030.5 multi 3.99 import weight 0.00
Epoch 304 Iter 2 subLoss 3680.3 multi 1.00 import weight 0.00
Epoch 304 Iter 3 subLoss 3819.9 multi 9.96 import weight 0.00
Epoch 304 Iter 4 subLoss 3740.2 multi 6.97 import weight 0.00
Epoch 304 Iter 5 subLoss 4139.0 multi -16.91 import weight 0.00
Epoch 304 Iter 6 subLoss 3829.7 multi -16.91 import weight 0.00
Epoch 304 Iter 7 subLoss 4574.8 multi 15.93 import weight 0.00
Epoch 304 Iter 8 subLoss 4833.4 multi -7.96 import weight 0.00
Epoch 304 Iter 9 subLoss 11108.6 multi 3.98 import weight 0.00
Epoch 304 Iter 10 subLoss 4753.0 multi -1.98 import weight 0.00
Epoch 304 Iter 11 subLoss 4498.9 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0114 / 0.11205 / 13.31
Entropy seen (from low to high)
[1077, 1006, 761, 446, 265, 206, 136, 115, 104, 87, 79, 60, 56, 56, 44, 41, 40, 39, 38, 41, 51, 52, 46, 41, 41, 20, 25, 28, 23, 19, 12, 14, 12, 10, 12, 6, 4, 3, 6, 3, 1, 3, 3, 2, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 8, 20, 47, 53, 85, 82, 106, 136, 163, 158, 179, 190, 167, 168, 162, 178, 157, 156, 175, 143, 156, 121, 147, 127, 122, 118, 117, 110, 97, 103, 94, 111, 90, 96, 83, 92, 103, 89, 84, 72, 59, 68, 37, 20, 10]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.7, 29.9, 33.7, 36.0, 40.5, 43.6, 47.3, 50.7, 54.4, 57.9, 61.2, 64.7, 68.5]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 24.9, 49.9, 59.9, 79.9, 49.9, 69.2, 62.8, 72.7, 53.4, 78.1, 71.9, 81.6]
[0, 0, 0, 0, 0, 0, 0, 2, 4, 4, 5, 5, 12, 26, 35, 44, 43, 55, 50, 60]
Epoch 304 Acc: 95.84 BMA: 96.56 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 449 train Loss: 5084.0 test Loss: 670.0
Epoch 305 Iter 0 subLoss 4605.8 multi 3.99 import weight 0.00
Epoch 305 Iter 1 subLoss 4633.6 multi 6.97 import weight 0.00
Epoch 305 Iter 2 subLoss 3788.8 multi -1.98 import weight 0.00
Epoch 305 Iter 3 subLoss 4345.4 multi 6.97 import weight 0.00
Epoch 305 Iter 4 subLoss 4276.7 multi 9.96 import weight 0.00
Epoch 305 Iter 5 subLoss 3967.8 multi -13.93 import weight 0.00
Epoch 305 Iter 6 subLoss 3550.1 multi 3.99 import weight 0.00
Epoch 305 Iter 7 subLoss 4033.2 multi 6.97 import weight 0.00
Epoch 305 Iter 8 subLoss 3618.2 multi -1.99 import weight 0.00
Epoch 305 Iter 9 subLoss 4463.1 multi -1.99 import weight 0.00
Epoch 305 Iter 10 subLoss 3650.0 multi -1.99 import weight 0.00
Epoch 305 Iter 11 subLoss 3505.3 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.11225 / 12.79
Entropy seen (from low to high)
[1094, 1013, 756, 442, 259, 206, 137, 115, 104, 83, 79, 61, 52, 57, 43, 40, 37, 45, 36, 39, 54, 52, 43, 45, 38, 21, 26, 26, 21, 20, 11, 13, 13, 11, 11, 5, 5, 3, 6, 3, 1, 3, 3, 2, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 8, 20, 45, 56, 82, 81, 106, 135, 161, 157, 182, 178, 174, 164, 165, 173, 161, 156, 183, 139, 156, 118, 141, 135, 127, 111, 119, 107, 103, 101, 94, 111, 87, 101, 79, 97, 102, 91, 84, 74, 56, 71, 38, 20, 10]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.6, 29.9, 33.6, 36.1, 40.7, 43.6, 47.2, 50.7, 54.4, 57.9, 61.2, 64.6, 68.4]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 0.0, 49.9, 59.9, 66.6, 49.9, 61.5, 66.6, 74.4, 53.4, 77.3, 73.4, 77.0]
[0, 0, 0, 0, 0, 0, 0, 2, 4, 4, 5, 6, 10, 26, 36, 43, 43, 53, 49, 61]
Epoch 305 Acc: 96.75 BMA: 96.56 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 350 train Loss: 4057.2 test Loss: 522.5
Epoch 306 Iter 0 subLoss 4219.9 multi 3.99 import weight 0.00
Epoch 306 Iter 1 subLoss 4228.2 multi 3.99 import weight 0.00
Epoch 306 Iter 2 subLoss 4090.1 multi 3.99 import weight 0.00
Epoch 306 Iter 3 subLoss 3653.1 multi -1.99 import weight 0.00
Epoch 306 Iter 4 subLoss 3479.7 multi -1.99 import weight 0.00
Epoch 306 Iter 5 subLoss 3554.7 multi 6.97 import weight 0.00
Epoch 306 Iter 6 subLoss 4054.4 multi 3.99 import weight 0.00
Epoch 306 Iter 7 subLoss 3722.3 multi 1.00 import weight 0.00
Epoch 306 Iter 8 subLoss 4102.9 multi -7.96 import weight 0.00
Epoch 306 Iter 9 subLoss 4273.7 multi 12.94 import weight 0.00
Epoch 306 Iter 10 subLoss 3596.2 multi -1.99 import weight 0.00
Epoch 306 Iter 11 subLoss 4003.1 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.11242 / 12.87
Entropy seen (from low to high)
[1102, 1027, 752, 443, 250, 204, 139, 109, 109, 81, 77, 58, 53, 56, 44, 38, 39, 45, 34, 44, 51, 49, 49, 41, 38, 20, 25, 28, 21, 18, 10, 15, 13, 9, 12, 5, 5, 4, 6, 2, 1, 3, 3, 2, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 8, 20, 46, 52, 80, 86, 100, 134, 167, 153, 178, 181, 173, 163, 165, 175, 159, 154, 185, 138, 157, 117, 140, 139, 128, 112, 113, 115, 103, 103, 83, 116, 87, 101, 79, 95, 103, 93, 85, 74, 60, 70, 38, 20, 11]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.4, 29.9, 33.6, 36.2, 41.0, 44.2, 47.2, 50.8, 54.3, 57.7, 61.2, 64.5, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 0.0, 49.9, 59.9, 62.4, 44.4, 66.6, 68.4, 74.3, 55.5, 75.5, 75.4, 77.5]
[0, 0, 0, 0, 0, 0, 0, 2, 4, 4, 5, 8, 9, 24, 38, 39, 45, 49, 53, 58]
Epoch 306 Acc: 96.89 BMA: 96.58 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 400 train Loss: 4037.7 test Loss: 503.5
Epoch 307 Iter 0 subLoss 3660.1 multi -1.99 import weight 0.00
Epoch 307 Iter 1 subLoss 3993.9 multi -4.97 import weight 0.00
Epoch 307 Iter 2 subLoss 4162.3 multi -1.99 import weight 0.00
Epoch 307 Iter 3 subLoss 4357.6 multi -4.97 import weight 0.00
Epoch 307 Iter 4 subLoss 4897.4 multi -4.97 import weight 0.00
Epoch 307 Iter 5 subLoss 5559.6 multi 9.96 import weight 0.00
Epoch 307 Iter 6 subLoss 3996.2 multi -1.98 import weight 0.00
Epoch 307 Iter 7 subLoss 4873.9 multi 1.00 import weight 0.00
Epoch 307 Iter 8 subLoss 4393.0 multi -7.96 import weight 0.00
Epoch 307 Iter 9 subLoss 4611.9 multi 6.97 import weight 0.00
Epoch 307 Iter 10 subLoss 3916.0 multi 3.99 import weight 0.00
Epoch 307 Iter 11 subLoss 4240.8 multi 3.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0112 / 0.11261 / 12.84
Entropy seen (from low to high)
[1114, 1035, 747, 440, 250, 199, 136, 121, 102, 78, 76, 54, 55, 57, 42, 41, 39, 43, 35, 42, 52, 48, 47, 43, 38, 22, 22, 26, 23, 17, 13, 13, 13, 9, 11, 5, 5, 4, 6, 2, 1, 2, 4, 2, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 8, 19, 45, 54, 78, 87, 102, 129, 169, 145, 176, 191, 161, 167, 169, 170, 166, 153, 176, 150, 149, 121, 135, 143, 128, 111, 113, 113, 106, 100, 88, 113, 85, 105, 80, 94, 100, 103, 77, 78, 63, 67, 39, 21, 12]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.2, 29.9, 33.8, 36.5, 40.9, 44.2, 47.1, 50.8, 54.5, 57.7, 61.1, 64.6, 68.4]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 0.0, 59.9, 49.9, 62.4, 33.3, 69.5, 64.9, 76.9, 57.1, 72.9, 77.1, 76.3]
[0, 0, 0, 0, 0, 0, 0, 2, 4, 5, 4, 8, 9, 23, 40, 39, 42, 48, 57, 55]
Epoch 307 Acc: 96.96 BMA: 96.58 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 424 train Loss: 4071.6 test Loss: 492.4
Epoch 308 Iter 0 subLoss 3643.6 multi 1.00 import weight 0.00
Epoch 308 Iter 1 subLoss 3866.5 multi -4.97 import weight 0.00
Epoch 308 Iter 2 subLoss 3870.5 multi -4.97 import weight 0.00
Epoch 308 Iter 3 subLoss 3811.6 multi 12.94 import weight 0.00
Epoch 308 Iter 4 subLoss 3512.6 multi -4.97 import weight 0.00
Epoch 308 Iter 5 subLoss 3871.6 multi -1.99 import weight 0.00
Epoch 308 Iter 6 subLoss 4061.0 multi -4.97 import weight 0.00
Epoch 308 Iter 7 subLoss 4597.8 multi -4.97 import weight 0.00
Epoch 308 Iter 8 subLoss 5580.2 multi 3.99 import weight 0.00
Epoch 308 Iter 9 subLoss 4826.3 multi 1.00 import weight 0.00
Epoch 308 Iter 10 subLoss 4192.3 multi 3.99 import weight 0.00
Epoch 308 Iter 11 subLoss 3830.4 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0112 / 0.11281 / 11.93
Entropy seen (from low to high)
[1121, 1043, 746, 433, 252, 203, 126, 120, 106, 76, 74, 55, 57, 55, 44, 42, 37, 42, 32, 45, 49, 52, 45, 44, 34, 24, 21, 27, 22, 17, 15, 11, 12, 10, 11, 5, 6, 3, 6, 2, 1, 2, 4, 2, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 8, 20, 41, 58, 74, 89, 98, 132, 160, 154, 179, 179, 166, 166, 163, 176, 165, 153, 170, 155, 143, 125, 140, 142, 129, 109, 115, 110, 103, 102, 95, 107, 87, 109, 77, 93, 100, 101, 81, 80, 65, 67, 40, 21, 12]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.1, 29.8, 33.8, 36.6, 40.6, 43.7, 47.1, 50.8, 54.4, 57.6, 61.3, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 24.9, 59.9, 49.9, 49.9, 45.4, 72.7, 62.4, 74.3, 61.9, 73.0, 78.4, 74.9]
[0, 0, 0, 0, 0, 0, 0, 2, 4, 5, 4, 6, 11, 22, 40, 39, 42, 52, 51, 56]
Epoch 308 Acc: 96.87 BMA: 96.59 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 383 train Loss: 4122.6 test Loss: 503.2
Epoch 309 Iter 0 subLoss 4642.6 multi 3.99 import weight 0.00
Epoch 309 Iter 1 subLoss 4071.4 multi -7.96 import weight 0.00
Epoch 309 Iter 2 subLoss 3790.5 multi -4.97 import weight 0.00
Epoch 309 Iter 3 subLoss 3907.9 multi -4.97 import weight 0.00
Epoch 309 Iter 4 subLoss 4771.4 multi 3.99 import weight 0.00
Epoch 309 Iter 5 subLoss 4029.8 multi -4.97 import weight 0.00
Epoch 309 Iter 6 subLoss 4426.1 multi -1.99 import weight 0.00
Epoch 309 Iter 7 subLoss 5346.1 multi 3.99 import weight 0.00
Epoch 309 Iter 8 subLoss 4210.2 multi 6.97 import weight 0.00
Epoch 309 Iter 9 subLoss 4285.4 multi -16.91 import weight 0.00
Epoch 309 Iter 10 subLoss 4372.3 multi 6.97 import weight 0.00
Epoch 309 Iter 11 subLoss 4455.2 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0111 / 0.11295 / 11.74
Entropy seen (from low to high)
[1128, 1060, 741, 424, 247, 200, 130, 118, 108, 75, 76, 50, 56, 59, 40, 42, 38, 41, 35, 41, 51, 52, 47, 41, 35, 22, 21, 27, 22, 16, 17, 11, 11, 11, 12, 3, 6, 4, 5, 2, 2, 1, 4, 2, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 8, 18, 43, 56, 77, 91, 88, 139, 157, 155, 174, 175, 173, 165, 160, 179, 163, 152, 172, 158, 145, 117, 141, 142, 129, 107, 116, 111, 110, 95, 99, 107, 84, 106, 84, 91, 102, 99, 77, 88, 62, 68, 43, 20, 13]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.0, 29.8, 33.8, 37.0, 40.8, 43.9, 47.3, 50.9, 54.5, 57.7, 61.4, 64.7, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 24.9, 59.9, 59.9, 39.9, 41.6, 72.7, 57.4, 77.4, 57.4, 73.5, 78.7, 77.1]
[0, 0, 0, 0, 0, 0, 0, 2, 4, 5, 5, 5, 12, 22, 40, 40, 40, 53, 47, 57]
Epoch 309 Acc: 96.89 BMA: 96.59 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 445 train Loss: 4213.0 test Loss: 512.0
Epoch 310 Iter 0 subLoss 3866.3 multi -1.99 import weight 0.00
Epoch 310 Iter 1 subLoss 4063.2 multi -1.98 import weight 0.00
Epoch 310 Iter 2 subLoss 4062.2 multi 1.00 import weight 0.00
Epoch 310 Iter 3 subLoss 4352.9 multi -1.99 import weight 0.00
Epoch 310 Iter 4 subLoss 4064.7 multi 3.99 import weight 0.00
Epoch 310 Iter 5 subLoss 4511.7 multi 18.91 import weight 0.00
Epoch 310 Iter 6 subLoss 4217.7 multi 9.96 import weight 0.00
Epoch 310 Iter 7 subLoss 3606.0 multi 1.00 import weight 0.00
Epoch 310 Iter 8 subLoss 4280.4 multi -13.93 import weight 0.00
Epoch 310 Iter 9 subLoss 4932.5 multi -13.93 import weight 0.00
Epoch 310 Iter 10 subLoss 9818.4 multi 6.97 import weight 0.00
Epoch 310 Iter 11 subLoss 5275.9 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0111 / 0.11288 / 11.63
Entropy seen (from low to high)
[1138, 1073, 725, 424, 243, 203, 128, 116, 101, 83, 70, 54, 55, 58, 45, 37, 38, 44, 32, 43, 54, 51, 43, 44, 33, 23, 19, 29, 23, 15, 17, 10, 10, 12, 11, 4, 6, 4, 5, 2, 2, 1, 5, 1, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 8, 16, 47, 53, 80, 90, 91, 135, 153, 154, 174, 177, 177, 169, 157, 182, 158, 155, 173, 164, 133, 122, 148, 134, 126, 111, 119, 113, 106, 95, 96, 106, 87, 101, 88, 86, 103, 97, 82, 84, 65, 66, 45, 20, 13]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.2, 29.6, 33.4, 36.7, 40.8, 43.9, 47.0, 50.7, 54.4, 57.7, 61.4, 64.7, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 24.9, 49.9, 66.6, 49.9, 49.9, 59.9, 63.4, 71.4, 58.5, 73.0, 80.8, 75.9]
[0, 0, 0, 0, 0, 0, 0, 2, 4, 4, 6, 6, 10, 20, 41, 42, 41, 52, 47, 54]
Epoch 310 Acc: 96.30 BMA: 96.61 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 527 train Loss: 4665.1 test Loss: 593.2
Epoch 311 Iter 0 subLoss 5122.0 multi 6.97 import weight 0.00
Epoch 311 Iter 1 subLoss 4011.4 multi 6.97 import weight 0.00
Epoch 311 Iter 2 subLoss 3735.2 multi -4.97 import weight 0.00
Epoch 311 Iter 3 subLoss 4050.9 multi 6.97 import weight 0.00
Epoch 311 Iter 4 subLoss 4325.7 multi 9.96 import weight 0.00
Epoch 311 Iter 5 subLoss 3643.6 multi 3.98 import weight 0.00
Epoch 311 Iter 6 subLoss 4084.4 multi 3.99 import weight 0.00
Epoch 311 Iter 7 subLoss 4366.6 multi -13.93 import weight 0.00
Epoch 311 Iter 8 subLoss 3622.9 multi 1.00 import weight 0.00
Epoch 311 Iter 9 subLoss 3724.7 multi 3.99 import weight 0.00
Epoch 311 Iter 10 subLoss 4129.6 multi 12.94 import weight 0.00
Epoch 311 Iter 11 subLoss 3762.3 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0111 / 0.11316 / 12.39
Entropy seen (from low to high)
[1147, 1070, 734, 417, 250, 194, 127, 118, 98, 90, 63, 54, 55, 59, 40, 39, 39, 43, 31, 43, 57, 53, 42, 42, 33, 22, 21, 26, 22, 17, 16, 10, 10, 11, 12, 3, 6, 4, 5, 2, 2, 1, 5, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 3, 7, 16, 45, 52, 81, 86, 95, 131, 148, 156, 171, 175, 177, 170, 162, 173, 168, 147, 175, 163, 132, 129, 143, 134, 131, 110, 115, 108, 116, 96, 98, 98, 91, 100, 90, 88, 102, 100, 79, 88, 63, 68, 48, 20, 13]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.4, 29.6, 33.4, 36.8, 40.5, 43.9, 47.2, 50.7, 54.4, 57.9, 61.5, 64.7, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 24.9, 49.9, 66.6, 39.9, 46.1, 61.1, 65.7, 74.4, 56.4, 71.9, 80.4, 78.1]
[0, 0, 0, 0, 0, 0, 0, 2, 4, 4, 6, 5, 13, 18, 38, 47, 39, 50, 46, 55]
Epoch 311 Acc: 97.00 BMA: 96.61 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 376 train Loss: 4018.2 test Loss: 487.0
Epoch 312 Iter 0 subLoss 3530.1 multi 1.00 import weight 0.00
Epoch 312 Iter 1 subLoss 4503.7 multi -7.96 import weight 0.00
Epoch 312 Iter 2 subLoss 3875.7 multi -1.99 import weight 0.00
Epoch 312 Iter 3 subLoss 4907.6 multi -1.99 import weight 0.00
Epoch 312 Iter 4 subLoss 6063.2 multi -1.99 import weight 0.00
Epoch 312 Iter 5 subLoss 6921.8 multi 1.00 import weight 0.00
Epoch 312 Iter 6 subLoss 5740.1 multi 1.00 import weight 0.00
Epoch 312 Iter 7 subLoss 5468.0 multi -7.96 import weight 0.00
Epoch 312 Iter 8 subLoss 14846.6 multi -1.99 import weight 0.00
Epoch 312 Iter 9 subLoss 84305.8 multi 1.00 import weight 0.00
Epoch 312 Iter 10 subLoss 4822.1 multi 3.99 import weight 0.00
Epoch 312 Iter 11 subLoss 4339.0 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0110 / 0.11326 / 13.75
Entropy seen (from low to high)
[1148, 1080, 729, 412, 248, 197, 125, 122, 94, 88, 66, 51, 61, 55, 40, 38, 41, 42, 30, 41, 57, 58, 40, 40, 34, 23, 20, 26, 22, 16, 17, 11, 9, 13, 9, 5, 6, 4, 5, 2, 2, 1, 5, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 9, 15, 46, 50, 82, 88, 96, 128, 143, 157, 170, 177, 177, 163, 165, 181, 166, 148, 168, 167, 124, 139, 146, 126, 135, 117, 112, 101, 119, 94, 100, 98, 85, 103, 89, 89, 103, 100, 79, 90, 65, 64, 51, 21, 13]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.1, 29.4, 33.1, 37.1, 40.8, 43.9, 47.4, 50.8, 54.3, 57.7, 61.3, 64.8, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 59.9, 49.9, 57.1, 39.9, 66.6, 63.1, 61.1, 76.5, 55.2, 71.1, 80.8, 81.4]
[0, 0, 0, 0, 0, 0, 0, 1, 5, 4, 7, 5, 12, 19, 36, 47, 38, 52, 47, 54]
Epoch 312 Acc: 95.91 BMA: 96.61 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 433 train Loss: 5076.3 test Loss: 623.4
Epoch 313 Iter 0 subLoss 4662.5 multi 6.97 import weight 0.00
Epoch 313 Iter 1 subLoss 4774.8 multi 6.97 import weight 0.00
Epoch 313 Iter 2 subLoss 4394.4 multi -4.97 import weight 0.00
Epoch 313 Iter 3 subLoss 3789.0 multi 1.00 import weight 0.00
Epoch 313 Iter 4 subLoss 3746.4 multi 6.97 import weight 0.00
Epoch 313 Iter 5 subLoss 3869.5 multi 1.00 import weight 0.00
Epoch 313 Iter 6 subLoss 3570.2 multi -1.99 import weight 0.00
Epoch 313 Iter 7 subLoss 4416.2 multi -1.99 import weight 0.00
Epoch 313 Iter 8 subLoss 4239.9 multi -16.91 import weight 0.00
Epoch 313 Iter 9 subLoss 4663.4 multi 9.96 import weight 0.00
Epoch 313 Iter 10 subLoss 3871.9 multi -1.98 import weight 0.00
Epoch 313 Iter 11 subLoss 3844.8 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0110 / 0.11341 / 12.28
Entropy seen (from low to high)
[1159, 1086, 724, 408, 252, 192, 128, 115, 93, 89, 69, 48, 60, 55, 39, 43, 38, 41, 28, 44, 56, 58, 40, 38, 34, 23, 24, 23, 22, 17, 15, 10, 10, 14, 8, 6, 5, 6, 3, 2, 2, 1, 5, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 9, 15, 43, 54, 79, 85, 98, 131, 136, 153, 180, 168, 175, 167, 166, 180, 166, 148, 170, 151, 142, 137, 149, 121, 138, 111, 121, 88, 124, 102, 95, 97, 90, 100, 94, 86, 104, 97, 82, 92, 65, 65, 51, 21, 13]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.6, 29.9, 33.7, 37.1, 40.7, 43.9, 47.6, 50.8, 54.3, 57.6, 61.3, 64.8, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 49.9, 66.6, 57.1, 39.9, 61.5, 61.1, 58.3, 73.9, 57.8, 70.3, 84.0, 78.9]
[0, 0, 0, 0, 0, 0, 0, 1, 6, 3, 7, 5, 13, 18, 36, 46, 38, 54, 44, 57]
Epoch 313 Acc: 97.00 BMA: 96.61 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 384 train Loss: 4139.8 test Loss: 509.0
Epoch 314 Iter 0 subLoss 4301.8 multi -1.99 import weight 0.00
Epoch 314 Iter 1 subLoss 4522.1 multi -13.93 import weight 0.00
Epoch 314 Iter 2 subLoss 4187.9 multi 6.97 import weight 0.00
Epoch 314 Iter 3 subLoss 3979.1 multi 9.96 import weight 0.00
Epoch 314 Iter 4 subLoss 3869.3 multi 3.98 import weight 0.00
Epoch 314 Iter 5 subLoss 3873.1 multi -1.99 import weight 0.00
Epoch 314 Iter 6 subLoss 3924.9 multi 1.00 import weight 0.00
Epoch 314 Iter 7 subLoss 3389.5 multi 1.00 import weight 0.00
Epoch 314 Iter 8 subLoss 4753.4 multi 1.00 import weight 0.00
Epoch 314 Iter 9 subLoss 3703.6 multi -4.97 import weight 0.00
Epoch 314 Iter 10 subLoss 4364.0 multi -10.94 import weight 0.00
Epoch 314 Iter 11 subLoss 4298.1 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0110 / 0.11353 / 12.66
Entropy seen (from low to high)
[1165, 1098, 720, 401, 253, 186, 135, 114, 87, 86, 75, 45, 59, 57, 42, 38, 39, 41, 27, 45, 58, 56, 39, 39, 32, 23, 27, 21, 20, 18, 15, 10, 10, 13, 8, 7, 6, 5, 3, 2, 2, 1, 5, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 9, 14, 45, 52, 80, 84, 95, 130, 133, 159, 179, 167, 175, 164, 170, 180, 163, 145, 173, 150, 142, 132, 152, 128, 137, 110, 118, 89, 127, 100, 92, 95, 97, 101, 93, 87, 101, 98, 85, 91, 67, 65, 53, 19, 13]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.2, 30.0, 33.6, 36.9, 40.4, 43.9, 47.8, 51.0, 54.2, 57.5, 61.3, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 49.9, 66.6, 66.6, 28.5, 58.3, 57.8, 59.9, 74.9, 57.4, 70.5, 85.3, 79.0]
[0, 0, 0, 0, 0, 0, 0, 1, 6, 3, 6, 7, 12, 19, 35, 44, 40, 51, 41, 62]
Epoch 314 Acc: 96.56 BMA: 96.63 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 429 train Loss: 4361.5 test Loss: 530.8
Epoch 315 Iter 0 subLoss 4008.4 multi -7.96 import weight 0.00
Epoch 315 Iter 1 subLoss 4689.8 multi 21.90 import weight 0.00
Epoch 315 Iter 2 subLoss 4943.6 multi 1.00 import weight 0.00
Epoch 315 Iter 3 subLoss 5062.4 multi 9.96 import weight 0.00
Epoch 315 Iter 4 subLoss 3707.0 multi -1.98 import weight 0.00
Epoch 315 Iter 5 subLoss 4350.8 multi 1.00 import weight 0.00
Epoch 315 Iter 6 subLoss 4145.9 multi 3.98 import weight 0.00
Epoch 315 Iter 7 subLoss 4150.7 multi 3.99 import weight 0.00
Epoch 315 Iter 8 subLoss 3565.5 multi 1.00 import weight 0.00
Epoch 315 Iter 9 subLoss 3916.3 multi 3.98 import weight 0.00
Epoch 315 Iter 10 subLoss 4126.7 multi 15.93 import weight 0.00
Epoch 315 Iter 11 subLoss 3901.6 multi -1.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0109 / 0.11373 / 11.78
Entropy seen (from low to high)
[1178, 1096, 719, 396, 255, 180, 144, 110, 82, 90, 73, 44, 61, 55, 43, 39, 35, 43, 29, 46, 55, 54, 40, 39, 33, 21, 29, 21, 18, 19, 14, 11, 9, 14, 7, 7, 6, 5, 3, 2, 2, 1, 5, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 9, 14, 43, 54, 76, 83, 98, 129, 125, 160, 176, 169, 179, 161, 173, 181, 162, 145, 171, 150, 145, 132, 152, 127, 138, 111, 110, 98, 118, 111, 83, 99, 101, 97, 98, 87, 96, 101, 87, 88, 71, 66, 53, 19, 13]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.4, 30.0, 33.6, 37.0, 39.8, 43.5, 47.8, 51.0, 54.2, 57.4, 61.2, 64.6, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 49.9, 66.6, 66.6, 39.9, 49.9, 55.5, 61.1, 69.0, 63.4, 73.0, 79.9, 79.3]
[0, 0, 0, 0, 0, 0, 0, 1, 6, 3, 6, 5, 14, 18, 36, 42, 41, 52, 40, 63]
Epoch 315 Acc: 96.61 BMA: 96.63 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 390 train Loss: 3882.3 test Loss: 517.4
Epoch 316 Iter 0 subLoss 3615.7 multi -1.98 import weight 0.00
Epoch 316 Iter 1 subLoss 3811.5 multi 15.93 import weight 0.00
Epoch 316 Iter 2 subLoss 3565.6 multi 3.99 import weight 0.00
Epoch 316 Iter 3 subLoss 3925.4 multi 1.00 import weight 0.00
Epoch 316 Iter 4 subLoss 3771.2 multi -4.97 import weight 0.00
Epoch 316 Iter 5 subLoss 4165.6 multi -1.98 import weight 0.00
Epoch 316 Iter 6 subLoss 3918.9 multi 3.99 import weight 0.00
Epoch 316 Iter 7 subLoss 3712.7 multi 1.00 import weight 0.00
Epoch 316 Iter 8 subLoss 4631.3 multi 9.96 import weight 0.00
Epoch 316 Iter 9 subLoss 4088.9 multi 6.97 import weight 0.00
Epoch 316 Iter 10 subLoss 3622.2 multi 1.00 import weight 0.00
Epoch 316 Iter 11 subLoss 3823.8 multi -19.90 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0109 / 0.11382 / 12.39
Entropy seen (from low to high)
[1190, 1093, 718, 394, 255, 178, 143, 111, 77, 95, 74, 40, 61, 56, 39, 42, 36, 44, 27, 45, 54, 56, 43, 35, 34, 22, 29, 23, 15, 19, 13, 10, 10, 14, 7, 7, 6, 5, 3, 2, 2, 1, 5, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 9, 13, 43, 54, 77, 83, 94, 131, 125, 160, 173, 171, 177, 159, 166, 186, 160, 143, 183, 146, 145, 134, 152, 130, 131, 114, 105, 103, 122, 105, 87, 96, 104, 97, 98, 85, 93, 109, 89, 83, 74, 65, 53, 19, 13]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.7, 30.0, 33.6, 37.2, 40.1, 43.7, 47.8, 51.0, 54.1, 57.5, 61.3, 64.6, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 49.9, 66.6, 66.6, 33.3, 61.5, 47.3, 63.6, 69.7, 61.9, 73.0, 82.4, 79.3]
[0, 0, 0, 0, 0, 0, 0, 1, 6, 3, 6, 6, 13, 19, 33, 43, 42, 52, 40, 58]
Epoch 316 Acc: 96.91 BMA: 96.67 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -19.90 Pidx 382 train Loss: 4154.5 test Loss: 511.7
Epoch 317 Iter 0 subLoss 4174.2 multi -10.94 import weight 0.00
Epoch 317 Iter 1 subLoss 4224.1 multi 1.00 import weight 0.00
Epoch 317 Iter 2 subLoss 4182.0 multi 6.97 import weight 0.00
Epoch 317 Iter 3 subLoss 4476.3 multi 3.99 import weight 0.00
Epoch 317 Iter 4 subLoss 3676.8 multi 1.00 import weight 0.00
Epoch 317 Iter 5 subLoss 4276.6 multi 15.93 import weight 0.00
Epoch 317 Iter 6 subLoss 4031.3 multi 6.97 import weight 0.00
Epoch 317 Iter 7 subLoss 3076.0 multi 1.00 import weight 0.00
Epoch 317 Iter 8 subLoss 3834.6 multi -1.98 import weight 0.00
Epoch 317 Iter 9 subLoss 3971.8 multi 12.94 import weight 0.00
Epoch 317 Iter 10 subLoss 3659.7 multi -4.97 import weight 0.00
Epoch 317 Iter 11 subLoss 3792.6 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0109 / 0.11396 / 12.54
Entropy seen (from low to high)
[1197, 1099, 719, 389, 259, 172, 139, 109, 85, 91, 71, 43, 55, 61, 38, 40, 36, 45, 27, 47, 53, 53, 45, 35, 32, 23, 29, 22, 17, 17, 15, 8, 10, 14, 8, 6, 6, 5, 3, 3, 1, 1, 5, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 9, 12, 45, 54, 76, 80, 97, 130, 120, 165, 165, 170, 183, 160, 167, 176, 171, 137, 182, 151, 135, 142, 149, 134, 132, 110, 109, 102, 120, 106, 88, 91, 106, 95, 107, 77, 95, 113, 88, 84, 75, 63, 56, 19, 13]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.7, 33.9, 37.4, 39.7, 43.7, 47.8, 51.1, 54.1, 57.4, 61.3, 64.5, 68.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 57.1, 49.9, 74.9, 42.8, 61.5, 44.4, 68.5, 68.2, 60.9, 72.2, 83.3, 79.6]
[0, 0, 0, 0, 0, 0, 0, 0, 7, 4, 4, 7, 13, 18, 35, 41, 41, 54, 36, 59]
Epoch 317 Acc: 97.00 BMA: 96.69 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 379 train Loss: 4020.7 test Loss: 490.2
Epoch 318 Iter 0 subLoss 3938.2 multi -4.97 import weight 0.00
Epoch 318 Iter 1 subLoss 3942.7 multi -1.99 import weight 0.00
Epoch 318 Iter 2 subLoss 3863.9 multi 6.97 import weight 0.00
Epoch 318 Iter 3 subLoss 3734.4 multi -4.97 import weight 0.00
Epoch 318 Iter 4 subLoss 4428.5 multi -1.99 import weight 0.00
Epoch 318 Iter 5 subLoss 3622.5 multi 3.99 import weight 0.00
Epoch 318 Iter 6 subLoss 3690.8 multi 1.00 import weight 0.00
Epoch 318 Iter 7 subLoss 4283.8 multi -13.93 import weight 0.00
Epoch 318 Iter 8 subLoss 3389.7 multi 3.99 import weight 0.00
Epoch 318 Iter 9 subLoss 4135.9 multi -19.90 import weight 0.00
Epoch 318 Iter 10 subLoss 6030.4 multi -16.91 import weight 0.00
Epoch 318 Iter 11 subLoss 14479.6 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0110 / 0.11149 / 11.84
Entropy seen (from low to high)
[553, 783, 1003, 615, 402, 267, 171, 138, 127, 103, 81, 72, 52, 60, 59, 37, 40, 40, 37, 43, 46, 55, 51, 51, 35, 29, 25, 26, 24, 19, 13, 12, 12, 11, 10, 6, 6, 5, 3, 5, 0, 1, 5, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 11, 20, 46, 63, 81, 91, 99, 124, 158, 149, 170, 192, 167, 170, 203, 164, 146, 194, 154, 160, 138, 141, 139, 144, 119, 114, 103, 135, 104, 90, 103, 94, 114, 91, 107, 96, 104, 94, 79, 76, 61, 23, 19, 6, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.5, 33.2, 37.3, 40.2, 43.4, 47.5, 50.7, 54.3, 57.9, 61.3, 64.9, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 59.9, 24.9, 49.9, 62.4, 63.1, 64.9, 62.7, 69.2, 71.9, 80.9, 75.8]
[0, 0, 0, 0, 0, 0, 0, 0, 6, 5, 4, 10, 8, 19, 40, 51, 39, 50, 42, 58]
Epoch 318 Acc: 46.82 BMA: 96.69 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 1447 train Loss: 153193.8 test Loss: 31201.2
Epoch 319 Iter 0 subLoss 152907.0 multi 1.00 import weight 0.00
Epoch 319 Iter 1 subLoss 12821.2 multi -7.96 import weight 0.00
Epoch 319 Iter 2 subLoss 54817.4 multi 1.00 import weight 0.00
Epoch 319 Iter 3 subLoss 24125.4 multi 1.00 import weight 0.00
Epoch 319 Iter 4 subLoss 19685.9 multi 1.00 import weight 0.00
Epoch 319 Iter 5 subLoss 15351.2 multi -1.99 import weight 0.00
Epoch 319 Iter 6 subLoss 21685.0 multi 1.00 import weight 0.00
Epoch 319 Iter 7 subLoss 18219.0 multi 1.00 import weight 0.00
Epoch 319 Iter 8 subLoss 14675.4 multi -7.96 import weight 0.00
Epoch 319 Iter 9 subLoss 41856.9 multi -1.99 import weight 0.00
Epoch 319 Iter 10 subLoss 92068.8 multi 1.00 import weight 0.00
Epoch 319 Iter 11 subLoss 38125.3 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0110 / 0.11048 / 12.61
Entropy seen (from low to high)
[525, 775, 981, 525, 415, 284, 193, 164, 135, 105, 104, 71, 66, 58, 59, 49, 38, 33, 48, 43, 45, 45, 54, 57, 35, 36, 22, 29, 28, 19, 15, 12, 10, 13, 10, 7, 7, 4, 3, 5, 0, 1, 4, 3, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 11, 20, 48, 64, 77, 102, 105, 127, 150, 161, 180, 190, 167, 186, 181, 182, 156, 181, 160, 164, 146, 131, 149, 124, 119, 126, 116, 116, 98, 102, 110, 98, 98, 109, 93, 101, 107, 84, 90, 53, 37, 18, 14, 5, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.4, 33.2, 37.2, 40.0, 43.1, 47.7, 50.8, 54.3, 57.7, 61.2, 64.7, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 59.9, 24.9, 49.9, 62.4, 61.9, 65.9, 66.6, 62.7, 72.3, 84.4, 77.5]
[0, 0, 0, 0, 0, 0, 0, 0, 6, 5, 4, 10, 8, 21, 44, 45, 43, 47, 45, 58]
Epoch 319 Acc: 86.32 BMA: 96.67 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 3812 train Loss: 14177.7 test Loss: 2124.1
Epoch 320 Iter 0 subLoss 14084.7 multi 3.99 import weight 0.00
Epoch 320 Iter 1 subLoss 12010.3 multi -4.97 import weight 0.00
Epoch 320 Iter 2 subLoss 13851.8 multi -1.98 import weight 0.00
Epoch 320 Iter 3 subLoss 14851.4 multi -1.99 import weight 0.00
Epoch 320 Iter 4 subLoss 16423.5 multi 3.99 import weight 0.00
Epoch 320 Iter 5 subLoss 13792.5 multi 9.96 import weight 0.00
Epoch 320 Iter 6 subLoss 8884.7 multi -7.96 import weight 0.00
Epoch 320 Iter 7 subLoss 11687.6 multi 1.00 import weight 0.00
Epoch 320 Iter 8 subLoss 11362.6 multi -1.99 import weight 0.00
Epoch 320 Iter 9 subLoss 12633.4 multi 6.97 import weight 0.00
Epoch 320 Iter 10 subLoss 10282.3 multi 1.00 import weight 0.00
Epoch 320 Iter 11 subLoss 9584.7 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0110 / 0.11006 / 12.33
Entropy seen (from low to high)
[504, 738, 1032, 526, 413, 276, 190, 170, 129, 109, 104, 74, 63, 69, 50, 52, 38, 35, 48, 45, 45, 46, 54, 55, 39, 37, 22, 28, 27, 21, 16, 11, 13, 10, 11, 8, 5, 6, 3, 5, 0, 1, 4, 3, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 11, 21, 49, 64, 79, 103, 104, 130, 145, 170, 180, 180, 175, 197, 176, 184, 164, 173, 168, 172, 132, 136, 147, 120, 122, 133, 116, 103, 99, 109, 106, 98, 102, 100, 102, 90, 102, 87, 84, 50, 38, 17, 13, 5, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.0, 32.9, 37.4, 40.0, 43.3, 47.7, 50.7, 54.2, 57.8, 61.3, 64.7, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.9, 66.6, 39.9, 44.4, 66.6, 57.8, 67.3, 65.9, 60.4, 75.5, 86.6, 75.8]
[0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 5, 9, 9, 19, 46, 44, 48, 45, 45, 58]
Epoch 320 Acc: 95.39 BMA: 96.67 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 958 train Loss: 7003.3 test Loss: 929.0
Epoch 321 Iter 0 subLoss 7032.3 multi -7.96 import weight 0.00
Epoch 321 Iter 1 subLoss 8384.2 multi 1.00 import weight 0.00
Epoch 321 Iter 2 subLoss 7841.7 multi -1.99 import weight 0.00
Epoch 321 Iter 3 subLoss 8778.1 multi -1.99 import weight 0.00
Epoch 321 Iter 4 subLoss 9385.4 multi -4.97 import weight 0.00
Epoch 321 Iter 5 subLoss 11142.8 multi 3.98 import weight 0.00
Epoch 321 Iter 6 subLoss 9269.6 multi 3.99 import weight 0.00
Epoch 321 Iter 7 subLoss 8185.7 multi 3.98 import weight 0.00
Epoch 321 Iter 8 subLoss 7528.1 multi 12.94 import weight 0.00
Epoch 321 Iter 9 subLoss 5305.9 multi 6.97 import weight 0.00
Epoch 321 Iter 10 subLoss 4991.0 multi -10.94 import weight 0.00
Epoch 321 Iter 11 subLoss 5511.0 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0110 / 0.10998 / 11.96
Entropy seen (from low to high)
[504, 692, 1078, 526, 419, 274, 188, 172, 123, 108, 109, 70, 62, 68, 50, 55, 38, 34, 46, 49, 39, 47, 58, 53, 42, 34, 22, 29, 27, 22, 17, 11, 14, 10, 11, 6, 6, 5, 4, 5, 0, 1, 4, 3, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 11, 20, 50, 66, 80, 97, 107, 132, 151, 159, 186, 175, 179, 194, 178, 180, 173, 178, 164, 167, 139, 133, 146, 124, 122, 127, 121, 104, 98, 109, 99, 94, 107, 96, 105, 87, 102, 89, 83, 51, 38, 18, 12, 5, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.0, 33.0, 37.2, 40.3, 43.5, 47.8, 50.7, 54.2, 57.9, 61.3, 64.6, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.9, 66.6, 59.9, 39.9, 62.4, 59.0, 65.8, 66.6, 62.4, 76.7, 84.4, 73.7]
[0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 5, 10, 8, 22, 41, 48, 48, 43, 45, 61]
Epoch 321 Acc: 96.13 BMA: 96.69 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 551 train Loss: 5524.3 test Loss: 694.6
Epoch 322 Iter 0 subLoss 5431.1 multi 9.96 import weight 0.00
Epoch 322 Iter 1 subLoss 4988.2 multi 3.99 import weight 0.00
Epoch 322 Iter 2 subLoss 4759.0 multi 3.99 import weight 0.00
Epoch 322 Iter 3 subLoss 4677.0 multi -13.93 import weight 0.00
Epoch 322 Iter 4 subLoss 5746.3 multi 3.99 import weight 0.00
Epoch 322 Iter 5 subLoss 5224.5 multi 9.96 import weight 0.00
Epoch 322 Iter 6 subLoss 4649.0 multi 3.99 import weight 0.00
Epoch 322 Iter 7 subLoss 4867.2 multi -4.97 import weight 0.00
Epoch 322 Iter 8 subLoss 4428.2 multi 1.00 import weight 0.00
Epoch 322 Iter 9 subLoss 4465.0 multi -1.99 import weight 0.00
Epoch 322 Iter 10 subLoss 5168.4 multi 3.99 import weight 0.00
Epoch 322 Iter 11 subLoss 4503.4 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0110 / 0.11000 / 12.23
Entropy seen (from low to high)
[504, 666, 1105, 538, 411, 278, 193, 157, 129, 102, 112, 69, 64, 67, 46, 59, 37, 32, 46, 50, 41, 46, 56, 55, 38, 34, 23, 31, 27, 21, 17, 11, 15, 10, 11, 6, 6, 5, 4, 5, 0, 1, 4, 3, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 11, 21, 51, 63, 82, 96, 109, 127, 157, 159, 185, 171, 178, 189, 184, 181, 172, 181, 159, 172, 138, 138, 142, 124, 122, 124, 118, 109, 91, 113, 97, 98, 102, 97, 108, 82, 106, 90, 81, 53, 39, 19, 12, 5, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.0, 33.0, 37.1, 40.3, 43.5, 47.8, 50.8, 54.2, 57.6, 61.2, 64.8, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.9, 66.6, 59.9, 39.9, 62.4, 56.5, 64.2, 70.4, 59.5, 78.7, 81.2, 76.7]
[0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 5, 10, 8, 23, 42, 44, 47, 47, 48, 56]
Epoch 322 Acc: 96.15 BMA: 96.69 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 450 train Loss: 4798.4 test Loss: 626.2
Epoch 323 Iter 0 subLoss 4646.4 multi 6.97 import weight 0.00
Epoch 323 Iter 1 subLoss 4400.6 multi 12.94 import weight 0.00
Epoch 323 Iter 2 subLoss 4802.9 multi 27.87 import weight 0.00
Epoch 323 Iter 3 subLoss 4425.1 multi 3.98 import weight 0.00
Epoch 323 Iter 4 subLoss 4030.9 multi 9.96 import weight 0.00
Epoch 323 Iter 5 subLoss 3960.8 multi -10.94 import weight 0.00
Epoch 323 Iter 6 subLoss 4067.5 multi 3.99 import weight 0.00
Epoch 323 Iter 7 subLoss 4149.4 multi 3.99 import weight 0.00
Epoch 323 Iter 8 subLoss 4152.3 multi 3.98 import weight 0.00
Epoch 323 Iter 9 subLoss 4216.2 multi 12.94 import weight 0.00
Epoch 323 Iter 10 subLoss 3549.5 multi -4.97 import weight 0.00
Epoch 323 Iter 11 subLoss 4282.8 multi -10.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0110 / 0.11000 / 11.58
Entropy seen (from low to high)
[511, 661, 1114, 539, 411, 275, 190, 154, 130, 106, 101, 74, 61, 66, 49, 54, 41, 33, 48, 46, 45, 46, 55, 51, 40, 39, 17, 33, 28, 20, 17, 10, 16, 9, 12, 5, 6, 5, 4, 5, 0, 1, 4, 3, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 11, 21, 51, 65, 82, 94, 108, 125, 156, 166, 176, 177, 180, 185, 180, 185, 173, 181, 161, 169, 140, 136, 142, 124, 129, 118, 117, 108, 97, 109, 95, 102, 102, 91, 105, 85, 113, 85, 78, 58, 40, 19, 13, 4, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.4, 33.3, 36.9, 40.4, 44.0, 47.8, 50.8, 54.2, 57.5, 61.2, 64.8, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 59.9, 49.9, 41.6, 57.1, 56.5, 64.9, 67.3, 63.0, 75.9, 83.7, 74.5]
[0, 0, 0, 0, 0, 0, 0, 0, 6, 5, 4, 12, 7, 23, 40, 46, 46, 50, 43, 59]
Epoch 323 Acc: 95.74 BMA: 96.65 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -10.94 Pidx 428 train Loss: 4932.3 test Loss: 654.0
Epoch 324 Iter 0 subLoss 4929.6 multi 6.97 import weight 0.00
Epoch 324 Iter 1 subLoss 3996.3 multi 1.00 import weight 0.00
Epoch 324 Iter 2 subLoss 4259.9 multi 3.99 import weight 0.00
Epoch 324 Iter 3 subLoss 3786.2 multi 1.00 import weight 0.00
Epoch 324 Iter 4 subLoss 3700.4 multi -1.99 import weight 0.00
Epoch 324 Iter 5 subLoss 3597.9 multi 1.00 import weight 0.00
Epoch 324 Iter 6 subLoss 3686.4 multi 1.00 import weight 0.00
Epoch 324 Iter 7 subLoss 4029.8 multi -4.97 import weight 0.00
Epoch 324 Iter 8 subLoss 3836.7 multi 1.00 import weight 0.00
Epoch 324 Iter 9 subLoss 3334.3 multi -1.99 import weight 0.00
Epoch 324 Iter 10 subLoss 4451.6 multi 6.97 import weight 0.00
Epoch 324 Iter 11 subLoss 4594.9 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0110 / 0.11016 / 11.74
Entropy seen (from low to high)
[514, 664, 1118, 543, 406, 276, 188, 154, 125, 109, 99, 73, 62, 64, 51, 52, 40, 32, 47, 49, 44, 45, 55, 55, 42, 34, 18, 31, 28, 20, 18, 9, 16, 9, 12, 5, 6, 5, 4, 4, 1, 1, 4, 3, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 3, 10, 21, 51, 62, 84, 91, 108, 126, 153, 158, 180, 179, 181, 186, 183, 177, 183, 179, 159, 160, 152, 133, 137, 127, 127, 113, 128, 108, 92, 108, 94, 108, 98, 96, 99, 89, 111, 85, 82, 60, 40, 20, 13, 4, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.3, 33.2, 36.9, 40.4, 44.2, 47.7, 50.7, 54.1, 57.6, 61.2, 64.7, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 59.9, 49.9, 41.6, 62.4, 54.9, 69.2, 63.2, 61.7, 78.7, 82.9, 75.4]
[0, 0, 0, 0, 0, 0, 0, 0, 6, 5, 4, 12, 8, 20, 39, 49, 47, 47, 41, 61]
Epoch 324 Acc: 96.26 BMA: 96.65 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 459 train Loss: 4216.7 test Loss: 547.8
Epoch 325 Iter 0 subLoss 4045.6 multi -10.94 import weight 0.00
Epoch 325 Iter 1 subLoss 4572.4 multi 18.91 import weight 0.00
Epoch 325 Iter 2 subLoss 4340.3 multi 6.97 import weight 0.00
Epoch 325 Iter 3 subLoss 4032.5 multi 9.96 import weight 0.00
Epoch 325 Iter 4 subLoss 3753.2 multi -13.93 import weight 0.00
Epoch 325 Iter 5 subLoss 4816.9 multi -19.90 import weight 0.00
Epoch 325 Iter 6 subLoss 8821.5 multi 6.97 import weight 0.00
Epoch 325 Iter 7 subLoss 4286.6 multi -7.96 import weight 0.00
Epoch 325 Iter 8 subLoss 4832.9 multi -10.94 import weight 0.00
Epoch 325 Iter 9 subLoss 6669.1 multi -4.97 import weight 0.00
Epoch 325 Iter 10 subLoss 10911.4 multi 6.97 import weight 0.00
Epoch 325 Iter 11 subLoss 5124.3 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0110 / 0.11028 / 12.16
Entropy seen (from low to high)
[517, 668, 1120, 547, 405, 271, 188, 159, 119, 110, 95, 73, 61, 65, 50, 53, 38, 34, 50, 48, 41, 45, 55, 54, 41, 35, 19, 29, 30, 18, 18, 9, 16, 9, 13, 4, 6, 5, 4, 4, 1, 1, 4, 3, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 3, 11, 20, 51, 64, 81, 90, 113, 119, 158, 154, 184, 177, 173, 192, 181, 180, 180, 176, 161, 164, 152, 126, 138, 131, 126, 115, 122, 108, 95, 106, 96, 105, 98, 100, 101, 89, 110, 85, 82, 61, 43, 20, 12, 5, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.3, 33.3, 36.8, 40.3, 43.8, 47.5, 50.6, 54.1, 57.5, 61.3, 64.8, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 59.9, 49.9, 36.3, 62.4, 57.8, 67.4, 66.6, 59.1, 78.7, 80.4, 78.3]
[0, 0, 0, 0, 0, 0, 0, 0, 6, 5, 4, 11, 8, 19, 40, 48, 49, 47, 41, 60]
Epoch 325 Acc: 96.79 BMA: 96.67 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 512 train Loss: 4469.4 test Loss: 550.5
Epoch 326 Iter 0 subLoss 4901.5 multi 1.00 import weight 0.00
Epoch 326 Iter 1 subLoss 4516.2 multi 15.93 import weight 0.00
Epoch 326 Iter 2 subLoss 4758.9 multi 6.97 import weight 0.00
Epoch 326 Iter 3 subLoss 4054.9 multi 6.97 import weight 0.00
Epoch 326 Iter 4 subLoss 4269.2 multi -4.97 import weight 0.00
Epoch 326 Iter 5 subLoss 3955.4 multi 9.96 import weight 0.00
Epoch 326 Iter 6 subLoss 3937.4 multi -1.99 import weight 0.00
Epoch 326 Iter 7 subLoss 4527.6 multi -13.93 import weight 0.00
Epoch 326 Iter 8 subLoss 4663.3 multi 12.94 import weight 0.00
Epoch 326 Iter 9 subLoss 3716.1 multi 1.00 import weight 0.00
Epoch 326 Iter 10 subLoss 3939.9 multi 1.00 import weight 0.00
Epoch 326 Iter 11 subLoss 3861.8 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0109 / 0.11046 / 11.72
Entropy seen (from low to high)
[523, 707, 1088, 539, 416, 269, 185, 153, 118, 118, 86, 75, 65, 61, 47, 52, 38, 34, 52, 48, 39, 49, 54, 54, 40, 32, 23, 26, 31, 16, 19, 8, 17, 8, 13, 4, 6, 6, 3, 4, 1, 1, 4, 3, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 3, 11, 19, 49, 66, 82, 85, 117, 113, 161, 151, 188, 170, 182, 183, 184, 180, 179, 174, 159, 175, 137, 131, 143, 127, 127, 119, 115, 114, 91, 109, 97, 99, 102, 106, 96, 91, 107, 90, 78, 65, 44, 22, 12, 5, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.9, 29.6, 33.3, 36.8, 40.2, 43.7, 47.6, 50.6, 54.0, 57.5, 61.4, 64.7, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 39.9, 59.9, 49.9, 39.9, 49.9, 58.8, 65.8, 66.6, 59.6, 79.9, 79.9, 78.6]
[0, 0, 0, 0, 0, 0, 0, 1, 5, 5, 4, 10, 10, 17, 41, 45, 52, 45, 40, 61]
Epoch 326 Acc: 96.87 BMA: 96.71 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 386 train Loss: 4174.8 test Loss: 512.5
Epoch 327 Iter 0 subLoss 4309.7 multi -1.98 import weight 0.00
Epoch 327 Iter 1 subLoss 3890.2 multi 3.98 import weight 0.00
Epoch 327 Iter 2 subLoss 4212.6 multi 15.93 import weight 0.00
Epoch 327 Iter 3 subLoss 4157.9 multi 6.97 import weight 0.00
Epoch 327 Iter 4 subLoss 4111.9 multi -1.99 import weight 0.00
Epoch 327 Iter 5 subLoss 4071.7 multi -16.91 import weight 0.00
Epoch 327 Iter 6 subLoss 4023.8 multi -1.98 import weight 0.00
Epoch 327 Iter 7 subLoss 4221.2 multi -1.99 import weight 0.00
Epoch 327 Iter 8 subLoss 4922.8 multi 9.96 import weight 0.00
Epoch 327 Iter 9 subLoss 3839.0 multi 3.99 import weight 0.00
Epoch 327 Iter 10 subLoss 4024.2 multi 1.00 import weight 0.00
Epoch 327 Iter 11 subLoss 4428.3 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0109 / 0.11064 / 11.79
Entropy seen (from low to high)
[525, 729, 1080, 537, 411, 272, 186, 145, 120, 115, 86, 74, 70, 55, 55, 47, 36, 35, 51, 47, 41, 46, 57, 54, 39, 30, 23, 24, 33, 16, 18, 9, 14, 11, 11, 5, 6, 6, 3, 4, 1, 1, 4, 3, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 3, 11, 19, 48, 65, 80, 91, 106, 119, 156, 153, 188, 170, 183, 178, 191, 177, 179, 168, 156, 180, 138, 126, 147, 126, 132, 114, 119, 116, 86, 113, 95, 105, 96, 103, 101, 92, 101, 99, 75, 67, 43, 26, 12, 5, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.8, 29.7, 33.3, 36.8, 39.7, 43.5, 47.6, 50.7, 54.2, 57.5, 61.4, 64.8, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 39.9, 59.9, 49.9, 37.4, 49.9, 58.8, 65.8, 67.3, 57.1, 78.2, 84.9, 77.0]
[0, 0, 0, 0, 0, 0, 0, 1, 5, 5, 4, 8, 12, 17, 41, 46, 49, 46, 40, 61]
Epoch 327 Acc: 96.89 BMA: 96.69 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 442 train Loss: 4152.0 test Loss: 518.9
Epoch 328 Iter 0 subLoss 3937.7 multi 3.98 import weight 0.00
Epoch 328 Iter 1 subLoss 3920.1 multi 1.00 import weight 0.00
Epoch 328 Iter 2 subLoss 3840.0 multi 3.98 import weight 0.00
Epoch 328 Iter 3 subLoss 4154.4 multi 9.96 import weight 0.00
Epoch 328 Iter 4 subLoss 3958.3 multi 12.94 import weight 0.00
Epoch 328 Iter 5 subLoss 3948.1 multi -7.96 import weight 0.00
Epoch 328 Iter 6 subLoss 3395.4 multi -4.97 import weight 0.00
Epoch 328 Iter 7 subLoss 4509.8 multi -1.99 import weight 0.00
Epoch 328 Iter 8 subLoss 4148.5 multi 6.97 import weight 0.00
Epoch 328 Iter 9 subLoss 4380.5 multi 1.00 import weight 0.00
Epoch 328 Iter 10 subLoss 4217.6 multi 18.91 import weight 0.00
Epoch 328 Iter 11 subLoss 4207.3 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0109 / 0.11085 / 12.51
Entropy seen (from low to high)
[526, 751, 1070, 538, 403, 271, 187, 144, 118, 116, 94, 67, 67, 61, 49, 50, 32, 34, 55, 48, 39, 48, 52, 55, 39, 29, 25, 26, 29, 16, 19, 10, 14, 9, 11, 7, 4, 7, 3, 3, 1, 1, 4, 3, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 3, 11, 19, 46, 61, 82, 95, 97, 123, 153, 154, 182, 174, 179, 178, 193, 177, 174, 174, 158, 180, 134, 130, 148, 123, 129, 115, 118, 120, 85, 116, 99, 101, 100, 94, 107, 97, 95, 101, 74, 72, 44, 26, 12, 5, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.9, 29.7, 33.3, 36.9, 39.6, 43.5, 47.6, 50.8, 54.3, 57.7, 61.6, 64.8, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 39.9, 59.9, 49.9, 49.9, 49.9, 52.9, 65.8, 68.7, 55.1, 81.3, 87.1, 75.8]
[0, 0, 0, 0, 0, 0, 0, 1, 5, 5, 4, 8, 12, 17, 41, 48, 49, 43, 39, 62]
Epoch 328 Acc: 96.91 BMA: 96.69 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 420 train Loss: 4119.1 test Loss: 496.0
Epoch 329 Iter 0 subLoss 3600.0 multi 3.98 import weight 0.00
Epoch 329 Iter 1 subLoss 4196.0 multi 1.00 import weight 0.00
Epoch 329 Iter 2 subLoss 3712.7 multi 3.99 import weight 0.00
Epoch 329 Iter 3 subLoss 3463.7 multi 3.99 import weight 0.00
Epoch 329 Iter 4 subLoss 4067.3 multi 3.98 import weight 0.00
Epoch 329 Iter 5 subLoss 3785.2 multi 3.99 import weight 0.00
Epoch 329 Iter 6 subLoss 3821.9 multi -16.91 import weight 0.00
Epoch 329 Iter 7 subLoss 3989.8 multi -4.97 import weight 0.00
Epoch 329 Iter 8 subLoss 4117.0 multi 1.00 import weight 0.00
Epoch 329 Iter 9 subLoss 4033.4 multi 6.97 import weight 0.00
Epoch 329 Iter 10 subLoss 3776.4 multi -1.99 import weight 0.00
Epoch 329 Iter 11 subLoss 4338.3 multi -1.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0108 / 0.11100 / 12.30
Entropy seen (from low to high)
[526, 776, 1055, 543, 404, 266, 183, 146, 113, 117, 94, 66, 70, 57, 50, 50, 30, 33, 56, 48, 37, 48, 56, 52, 39, 29, 26, 28, 25, 16, 20, 9, 13, 10, 11, 7, 5, 6, 4, 2, 1, 1, 5, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 3, 11, 19, 45, 61, 80, 95, 91, 128, 150, 154, 180, 172, 185, 177, 193, 173, 175, 169, 164, 175, 142, 132, 149, 124, 121, 118, 116, 123, 87, 111, 101, 101, 100, 95, 104, 97, 99, 102, 74, 73, 45, 27, 12, 5, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.7, 29.7, 33.3, 37.1, 39.7, 43.5, 47.5, 50.6, 54.2, 57.7, 61.6, 64.8, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 39.9, 59.9, 49.9, 49.9, 49.9, 49.9, 65.7, 67.3, 56.2, 81.8, 86.4, 77.4]
[0, 0, 0, 0, 0, 0, 0, 1, 5, 5, 4, 8, 12, 16, 38, 52, 48, 44, 37, 62]
Epoch 329 Acc: 96.59 BMA: 96.69 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 433 train Loss: 4115.6 test Loss: 526.8
Epoch 330 Iter 0 subLoss 4150.3 multi 9.96 import weight 0.00
Epoch 330 Iter 1 subLoss 3958.3 multi 12.94 import weight 0.00
Epoch 330 Iter 2 subLoss 4021.3 multi 3.99 import weight 0.00
Epoch 330 Iter 3 subLoss 4439.0 multi -19.90 import weight 0.00
Epoch 330 Iter 4 subLoss 4270.2 multi 15.93 import weight 0.00
Epoch 330 Iter 5 subLoss 3902.9 multi -1.99 import weight 0.00
Epoch 330 Iter 6 subLoss 4417.3 multi -1.98 import weight 0.00
Epoch 330 Iter 7 subLoss 4862.6 multi -1.99 import weight 0.00
Epoch 330 Iter 8 subLoss 5020.8 multi 3.98 import weight 0.00
Epoch 330 Iter 9 subLoss 4535.6 multi -4.97 import weight 0.00
Epoch 330 Iter 10 subLoss 5047.2 multi 18.91 import weight 0.00
Epoch 330 Iter 11 subLoss 4355.4 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0108 / 0.11105 / 12.45
Entropy seen (from low to high)
[525, 800, 1040, 553, 397, 261, 184, 144, 119, 112, 92, 62, 71, 56, 50, 49, 31, 36, 56, 45, 39, 48, 56, 53, 35, 30, 28, 28, 23, 17, 18, 10, 13, 10, 12, 6, 5, 6, 3, 3, 1, 1, 5, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 3, 11, 19, 46, 62, 79, 92, 94, 128, 147, 151, 184, 176, 182, 178, 190, 177, 173, 170, 161, 175, 141, 134, 144, 126, 125, 112, 118, 119, 92, 111, 100, 100, 102, 90, 104, 103, 96, 103, 75, 75, 44, 28, 13, 5, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.6, 29.7, 33.3, 37.4, 39.8, 43.6, 47.7, 50.8, 54.4, 57.7, 61.7, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 39.9, 59.9, 39.9, 57.1, 58.3, 41.1, 67.4, 65.3, 59.9, 78.0, 86.4, 79.0]
[0, 0, 0, 0, 0, 0, 0, 1, 5, 5, 5, 7, 12, 17, 40, 49, 50, 41, 37, 62]
Epoch 330 Acc: 96.22 BMA: 96.69 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 435 train Loss: 4283.8 test Loss: 593.5
Epoch 331 Iter 0 subLoss 3980.2 multi -1.99 import weight 0.00
Epoch 331 Iter 1 subLoss 4456.9 multi 9.96 import weight 0.00
Epoch 331 Iter 2 subLoss 3621.8 multi 6.97 import weight 0.00
Epoch 331 Iter 3 subLoss 3826.0 multi -13.93 import weight 0.00
Epoch 331 Iter 4 subLoss 4252.8 multi 6.97 import weight 0.00
Epoch 331 Iter 5 subLoss 4208.2 multi -4.97 import weight 0.00
Epoch 331 Iter 6 subLoss 3598.3 multi 6.97 import weight 0.00
Epoch 331 Iter 7 subLoss 4157.8 multi 12.94 import weight 0.00
Epoch 331 Iter 8 subLoss 4275.0 multi 18.91 import weight 0.00
Epoch 331 Iter 9 subLoss 4016.3 multi 6.97 import weight 0.00
Epoch 331 Iter 10 subLoss 3406.2 multi -1.99 import weight 0.00
Epoch 331 Iter 11 subLoss 4185.0 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0108 / 0.11119 / 12.07
Entropy seen (from low to high)
[528, 835, 1015, 552, 396, 259, 181, 144, 119, 112, 95, 59, 73, 51, 53, 49, 28, 36, 54, 47, 40, 47, 53, 54, 38, 27, 29, 28, 22, 18, 16, 11, 13, 9, 13, 4, 6, 6, 3, 2, 2, 1, 5, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 3, 11, 19, 43, 63, 79, 93, 95, 126, 146, 149, 183, 175, 182, 178, 192, 175, 171, 173, 164, 175, 138, 138, 140, 125, 127, 107, 120, 119, 95, 110, 102, 94, 108, 90, 104, 96, 103, 101, 78, 73, 49, 28, 13, 5, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.7, 29.7, 33.2, 37.3, 39.8, 43.4, 47.4, 50.7, 54.3, 57.7, 61.6, 64.5, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 39.9, 59.9, 19.9, 71.4, 54.5, 47.0, 64.1, 65.3, 60.7, 78.3, 85.3, 77.9]
[0, 0, 0, 0, 0, 0, 0, 1, 5, 5, 5, 7, 11, 17, 39, 49, 51, 37, 41, 59]
Epoch 331 Acc: 96.69 BMA: 96.71 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 418 train Loss: 3796.7 test Loss: 506.9
Epoch 332 Iter 0 subLoss 3287.7 multi 3.99 import weight 0.00
Epoch 332 Iter 1 subLoss 3949.2 multi -4.97 import weight 0.00
Epoch 332 Iter 2 subLoss 3510.8 multi -1.98 import weight 0.00
Epoch 332 Iter 3 subLoss 4813.5 multi -16.91 import weight 0.00
Epoch 332 Iter 4 subLoss 3720.9 multi -1.98 import weight 0.00
Epoch 332 Iter 5 subLoss 3933.3 multi 3.99 import weight 0.00
Epoch 332 Iter 6 subLoss 3723.5 multi 1.00 import weight 0.00
Epoch 332 Iter 7 subLoss 3791.8 multi -7.96 import weight 0.00
Epoch 332 Iter 8 subLoss 4510.2 multi 15.93 import weight 0.00
Epoch 332 Iter 9 subLoss 3579.8 multi -4.97 import weight 0.00
Epoch 332 Iter 10 subLoss 4339.1 multi 1.00 import weight 0.00
Epoch 332 Iter 11 subLoss 4835.1 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0108 / 0.11112 / 12.43
Entropy seen (from low to high)
[477, 851, 1014, 579, 389, 268, 183, 147, 113, 116, 93, 67, 68, 51, 51, 51, 23, 45, 51, 47, 42, 51, 50, 52, 39, 27, 28, 28, 24, 17, 16, 12, 13, 7, 14, 4, 6, 6, 3, 2, 2, 1, 5, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 3, 11, 17, 45, 65, 78, 91, 96, 127, 144, 150, 191, 177, 167, 191, 186, 173, 171, 175, 162, 172, 145, 130, 141, 123, 129, 115, 120, 114, 97, 111, 100, 94, 104, 90, 103, 101, 104, 97, 78, 77, 46, 30, 12, 5, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.5, 30.0, 34.0, 37.5, 39.2, 43.7, 47.8, 50.6, 54.2, 57.7, 61.4, 64.6, 68.4]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 49.9, 39.9, 0.0, 62.4, 66.6, 42.8, 60.5, 58.8, 67.3, 72.9, 84.7, 81.8]
[0, 0, 0, 0, 0, 0, 0, 1, 6, 5, 2, 8, 15, 14, 38, 51, 49, 37, 46, 55]
Epoch 332 Acc: 92.82 BMA: 96.73 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 483 train Loss: 5988.1 test Loss: 1010.2
Epoch 333 Iter 0 subLoss 5683.5 multi 3.98 import weight 0.00
Epoch 333 Iter 1 subLoss 3470.1 multi -1.98 import weight 0.00
Epoch 333 Iter 2 subLoss 3808.6 multi -1.99 import weight 0.00
Epoch 333 Iter 3 subLoss 4009.7 multi -7.96 import weight 0.00
Epoch 333 Iter 4 subLoss 4422.9 multi 6.97 import weight 0.00
Epoch 333 Iter 5 subLoss 4238.7 multi -19.90 import weight 0.00
Epoch 333 Iter 6 subLoss 4815.7 multi -13.93 import weight 0.00
Epoch 333 Iter 7 subLoss 6996.6 multi 6.97 import weight 0.00
Epoch 333 Iter 8 subLoss 4547.7 multi -7.96 import weight 0.00
Epoch 333 Iter 9 subLoss 5146.9 multi -4.97 import weight 0.00
Epoch 333 Iter 10 subLoss 5257.9 multi 3.98 import weight 0.00
Epoch 333 Iter 11 subLoss 4739.9 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0108 / 0.11121 / 11.95
Entropy seen (from low to high)
[481, 847, 1026, 576, 384, 270, 185, 143, 109, 115, 96, 66, 71, 48, 55, 47, 23, 45, 48, 49, 44, 57, 45, 51, 39, 26, 27, 27, 28, 14, 15, 12, 14, 10, 11, 5, 5, 6, 3, 2, 2, 1, 5, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 3, 11, 18, 43, 67, 75, 94, 94, 131, 134, 155, 188, 182, 167, 184, 187, 175, 174, 172, 164, 169, 155, 127, 135, 125, 133, 107, 121, 119, 92, 113, 95, 93, 107, 94, 100, 104, 101, 101, 76, 79, 47, 30, 12, 5, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.3, 29.9, 33.8, 36.4, 38.9, 43.5, 47.9, 50.7, 54.2, 57.6, 61.3, 64.7, 68.5]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 49.9, 49.9, 0.0, 57.1, 62.4, 46.6, 61.1, 60.7, 64.5, 75.6, 83.6, 79.6]
[0, 0, 0, 0, 0, 0, 0, 1, 6, 4, 3, 7, 16, 15, 36, 51, 48, 37, 49, 54]
Epoch 333 Acc: 96.42 BMA: 96.73 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 473 train Loss: 4599.8 test Loss: 569.4
Epoch 334 Iter 0 subLoss 4054.9 multi 9.96 import weight 0.00
Epoch 334 Iter 1 subLoss 3968.9 multi -16.91 import weight 0.00
Epoch 334 Iter 2 subLoss 5327.1 multi -10.94 import weight 0.00
Epoch 334 Iter 3 subLoss 5872.6 multi 6.97 import weight 0.00
Epoch 334 Iter 4 subLoss 4279.4 multi 21.90 import weight 0.00
Epoch 334 Iter 5 subLoss 4533.8 multi -1.98 import weight 0.00
Epoch 334 Iter 6 subLoss 4340.8 multi 3.99 import weight 0.00
Epoch 334 Iter 7 subLoss 3557.8 multi 6.97 import weight 0.00
Epoch 334 Iter 8 subLoss 4264.3 multi -4.97 import weight 0.00
Epoch 334 Iter 9 subLoss 4409.9 multi 15.93 import weight 0.00
Epoch 334 Iter 10 subLoss 4142.2 multi 9.96 import weight 0.00
Epoch 334 Iter 11 subLoss 4017.1 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0107 / 0.11137 / 11.41
Entropy seen (from low to high)
[482, 864, 1027, 573, 378, 267, 187, 137, 113, 109, 101, 68, 67, 48, 57, 44, 23, 47, 48, 48, 45, 53, 45, 51, 38, 26, 28, 27, 28, 14, 17, 9, 15, 9, 11, 5, 5, 6, 3, 2, 2, 1, 5, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 3, 11, 17, 44, 67, 74, 95, 91, 129, 135, 157, 181, 188, 165, 183, 182, 178, 176, 168, 164, 166, 156, 131, 136, 124, 135, 106, 117, 128, 88, 104, 103, 91, 107, 94, 104, 102, 104, 96, 81, 83, 44, 33, 12, 5, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.3, 29.9, 33.8, 36.3, 38.8, 43.4, 47.7, 50.7, 54.3, 57.7, 61.3, 64.6, 68.5]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 49.9, 49.9, 0.0, 57.1, 59.9, 49.9, 61.1, 60.7, 64.5, 73.5, 84.3, 77.7]
[0, 0, 0, 0, 0, 0, 0, 1, 6, 4, 3, 7, 15, 16, 36, 51, 48, 34, 51, 54]
Epoch 334 Acc: 96.73 BMA: 96.73 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 401 train Loss: 3926.6 test Loss: 509.9
Epoch 335 Iter 0 subLoss 3538.0 multi 3.98 import weight 0.00
Epoch 335 Iter 1 subLoss 3434.1 multi 1.00 import weight 0.00
Epoch 335 Iter 2 subLoss 3577.6 multi -1.98 import weight 0.00
Epoch 335 Iter 3 subLoss 4304.3 multi 1.00 import weight 0.00
Epoch 335 Iter 4 subLoss 3732.4 multi -7.96 import weight 0.00
Epoch 335 Iter 5 subLoss 3514.4 multi 1.00 import weight 0.00
Epoch 335 Iter 6 subLoss 4222.7 multi -1.99 import weight 0.00
Epoch 335 Iter 7 subLoss 4329.2 multi 12.94 import weight 0.00
Epoch 335 Iter 8 subLoss 3940.9 multi -4.97 import weight 0.00
Epoch 335 Iter 9 subLoss 3517.9 multi 3.99 import weight 0.00
Epoch 335 Iter 10 subLoss 3987.9 multi 1.00 import weight 0.00
Epoch 335 Iter 11 subLoss 4101.6 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0107 / 0.11150 / 11.85
Entropy seen (from low to high)
[487, 873, 1029, 567, 382, 258, 193, 135, 111, 105, 102, 66, 65, 50, 57, 41, 32, 41, 54, 44, 43, 51, 50, 48, 38, 24, 29, 27, 27, 14, 17, 10, 14, 9, 11, 5, 5, 6, 3, 2, 2, 1, 5, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 3, 10, 18, 44, 67, 72, 94, 91, 128, 141, 151, 180, 187, 168, 185, 180, 172, 178, 172, 160, 165, 156, 131, 141, 122, 131, 111, 117, 126, 89, 110, 97, 90, 107, 92, 107, 104, 103, 92, 87, 81, 45, 36, 12, 5, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.2, 29.9, 33.8, 37.3, 39.5, 43.6, 47.7, 50.8, 54.2, 57.6, 61.2, 64.6, 68.4]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 49.9, 49.9, 16.6, 79.9, 57.1, 56.2, 62.8, 57.6, 65.2, 77.1, 81.6, 79.3]
[0, 0, 0, 0, 0, 0, 0, 1, 6, 4, 6, 5, 14, 16, 35, 52, 46, 35, 49, 58]
Epoch 335 Acc: 96.56 BMA: 96.73 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 410 train Loss: 4067.6 test Loss: 528.6
Epoch 336 Iter 0 subLoss 4043.8 multi -13.93 import weight 0.00
Epoch 336 Iter 1 subLoss 5395.2 multi 6.97 import weight 0.00
Epoch 336 Iter 2 subLoss 4255.5 multi 9.96 import weight 0.00
Epoch 336 Iter 3 subLoss 2863.9 multi 1.00 import weight 0.00
Epoch 336 Iter 4 subLoss 4174.9 multi -7.96 import weight 0.00
Epoch 336 Iter 5 subLoss 3812.8 multi 15.93 import weight 0.00
Epoch 336 Iter 6 subLoss 3814.2 multi 18.91 import weight 0.00
Epoch 336 Iter 7 subLoss 3824.5 multi -16.91 import weight 0.00
Epoch 336 Iter 8 subLoss 4535.3 multi 1.00 import weight 0.00
Epoch 336 Iter 9 subLoss 4304.5 multi 3.99 import weight 0.00
Epoch 336 Iter 10 subLoss 4270.1 multi 21.90 import weight 1.00
Epoch 336 Iter 11 subLoss 4079.8 multi -16.91 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0107 / 0.11106 / 10.86
Entropy seen (from low to high)
[483, 900, 1000, 539, 366, 249, 210, 143, 119, 102, 114, 62, 71, 56, 55, 46, 32, 40, 59, 44, 44, 46, 56, 47, 36, 28, 29, 24, 29, 17, 15, 9, 12, 11, 9, 7, 5, 6, 3, 2, 1, 2, 5, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 3, 10, 16, 48, 65, 72, 95, 95, 122, 141, 156, 184, 180, 181, 180, 180, 171, 175, 178, 170, 161, 158, 129, 131, 135, 123, 120, 123, 109, 95, 119, 94, 92, 99, 100, 105, 101, 102, 91, 83, 75, 41, 32, 14, 4, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.0, 29.6, 33.7, 37.2, 39.4, 43.6, 47.4, 50.8, 54.1, 57.4, 61.2, 64.6, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 49.9, 49.9, 33.3, 59.9, 57.1, 64.2, 60.9, 59.9, 61.5, 75.7, 83.6, 76.2]
[0, 0, 0, 0, 0, 0, 0, 1, 6, 4, 6, 5, 14, 14, 41, 45, 52, 33, 49, 59]
Epoch 336 Acc: 86.26 BMA: 96.75 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -16.91 Pidx 407 train Loss: 12522.8 test Loss: 2004.2
Epoch 337 Iter 0 subLoss 13259.3 multi -4.97 import weight 0.00
Epoch 337 Iter 1 subLoss 67088.6 multi 1.00 import weight 0.00
Epoch 337 Iter 2 subLoss 18843.0 multi -1.99 import weight 0.00
Epoch 337 Iter 3 subLoss 35239.2 multi 1.00 import weight 0.00
Epoch 337 Iter 4 subLoss 19589.8 multi -1.99 import weight 0.00
Epoch 337 Iter 5 subLoss 37638.7 multi 1.00 import weight 0.00
Epoch 337 Iter 6 subLoss 23843.6 multi 1.00 import weight 0.00
Epoch 337 Iter 7 subLoss 16947.6 multi 1.00 import weight 0.00
Epoch 337 Iter 8 subLoss 13764.9 multi 1.00 import weight 0.00
Epoch 337 Iter 9 subLoss 12516.0 multi -13.93 import weight 0.00
Epoch 337 Iter 10 subLoss 59496.1 multi 1.00 import weight 0.00
Epoch 337 Iter 11 subLoss 35549.6 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0108 / 0.11024 / 10.63
Entropy seen (from low to high)
[486, 902, 988, 453, 300, 286, 224, 160, 143, 132, 105, 91, 66, 62, 51, 51, 38, 42, 56, 48, 47, 41, 57, 51, 38, 29, 27, 23, 27, 21, 13, 11, 12, 9, 12, 7, 5, 6, 3, 2, 1, 2, 5, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4, 9, 17, 48, 63, 76, 97, 100, 129, 133, 157, 191, 177, 184, 186, 178, 174, 182, 169, 176, 164, 147, 137, 129, 141, 127, 120, 118, 112, 101, 117, 99, 84, 103, 108, 109, 100, 98, 90, 73, 53, 35, 26, 13, 4, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.8, 29.5, 33.4, 37.1, 40.0, 43.6, 47.5, 51.0, 54.3, 57.6, 61.0, 64.6, 68.4]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 33.3, 49.9, 42.8, 39.9, 61.5, 61.1, 59.9, 67.9, 57.7, 70.9, 82.1, 77.7]
[0, 0, 0, 0, 0, 0, 0, 1, 6, 4, 7, 5, 13, 18, 40, 50, 45, 31, 56, 54]
Epoch 337 Acc: 77.52 BMA: 96.63 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 3554 train Loss: 30666.6 test Loss: 4849.5
Epoch 338 Iter 0 subLoss 28390.8 multi 1.00 import weight 0.00
Epoch 338 Iter 1 subLoss 24774.4 multi -1.99 import weight 0.00
Epoch 338 Iter 2 subLoss 33623.3 multi 1.00 import weight 0.00
Epoch 338 Iter 3 subLoss 28819.7 multi 1.00 import weight 0.00
Epoch 338 Iter 4 subLoss 23265.8 multi 3.99 import weight 0.00
Epoch 338 Iter 5 subLoss 14515.1 multi -1.99 import weight 0.00
Epoch 338 Iter 6 subLoss 17003.4 multi 1.00 import weight 0.00
Epoch 338 Iter 7 subLoss 15390.5 multi 3.99 import weight 0.00
Epoch 338 Iter 8 subLoss 13019.5 multi -1.98 import weight 0.00
Epoch 338 Iter 9 subLoss 14235.9 multi -7.96 import weight 0.00
Epoch 338 Iter 10 subLoss 19860.4 multi 1.00 import weight 0.00
Epoch 338 Iter 11 subLoss 18670.0 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0109 / 0.10950 / 10.91
Entropy seen (from low to high)
[490, 916, 971, 451, 245, 206, 234, 188, 159, 154, 123, 93, 79, 60, 67, 47, 42, 52, 46, 54, 46, 41, 58, 48, 43, 26, 30, 21, 31, 21, 15, 12, 10, 12, 9, 9, 5, 6, 3, 2, 1, 2, 5, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4, 10, 16, 51, 64, 78, 97, 99, 134, 134, 164, 189, 171, 195, 181, 182, 178, 193, 164, 181, 158, 146, 137, 135, 133, 140, 123, 108, 108, 116, 109, 98, 84, 110, 110, 116, 98, 85, 86, 53, 43, 34, 26, 13, 4, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.7, 29.5, 33.1, 37.0, 40.9, 44.1, 47.5, 51.1, 54.2, 57.3, 61.0, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 33.3, 49.9, 49.9, 57.1, 59.9, 54.9, 62.7, 65.9, 55.5, 76.3, 80.7, 76.3]
[0, 0, 0, 0, 0, 0, 0, 1, 6, 4, 8, 7, 10, 20, 43, 44, 45, 38, 52, 55]
Epoch 338 Acc: 78.13 BMA: 96.56 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 1867 train Loss: 20150.5 test Loss: 3160.2
Epoch 339 Iter 0 subLoss 18076.9 multi 1.00 import weight 0.00
Epoch 339 Iter 1 subLoss 19257.5 multi -4.97 import weight 0.00
Epoch 339 Iter 2 subLoss 26116.6 multi -1.99 import weight 0.00
Epoch 339 Iter 3 subLoss 30358.0 multi 1.00 import weight 0.00
Epoch 339 Iter 4 subLoss 27195.9 multi 1.00 import weight 0.00
Epoch 339 Iter 5 subLoss 25271.8 multi 6.97 import weight 0.00
Epoch 339 Iter 6 subLoss 14527.1 multi -1.99 import weight 0.00
Epoch 339 Iter 7 subLoss 16099.4 multi 6.97 import weight 0.00
Epoch 339 Iter 8 subLoss 13745.7 multi -4.97 import weight 0.00
Epoch 339 Iter 9 subLoss 15705.4 multi 1.00 import weight 0.00
Epoch 339 Iter 10 subLoss 13566.4 multi 6.97 import weight 0.00
Epoch 339 Iter 11 subLoss 12729.5 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0110 / 0.10888 / 11.30
Entropy seen (from low to high)
[491, 927, 960, 448, 242, 157, 189, 194, 170, 156, 152, 94, 97, 73, 66, 52, 38, 54, 50, 56, 48, 41, 51, 53, 43, 28, 32, 26, 29, 21, 15, 15, 10, 13, 9, 8, 6, 6, 3, 1, 2, 2, 5, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4, 10, 19, 47, 64, 80, 98, 104, 133, 135, 177, 178, 181, 192, 185, 190, 181, 183, 173, 187, 153, 148, 123, 147, 129, 140, 125, 115, 117, 100, 117, 83, 105, 112, 112, 105, 94, 84, 62, 46, 44, 34, 25, 12, 5, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.7, 29.5, 32.9, 37.0, 41.1, 44.2, 47.4, 51.0, 54.3, 57.5, 61.2, 64.8, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 33.3, 49.9, 44.4, 71.4, 44.4, 57.1, 62.2, 65.2, 52.2, 80.4, 82.9, 73.7]
[0, 0, 0, 0, 0, 0, 0, 1, 6, 4, 9, 7, 9, 21, 45, 46, 44, 41, 47, 61]
Epoch 339 Acc: 83.71 BMA: 96.50 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1272 train Loss: 12540.0 test Loss: 2076.9
Epoch 340 Iter 0 subLoss 12523.1 multi -1.99 import weight 0.00
Epoch 340 Iter 1 subLoss 13010.2 multi 1.00 import weight 0.00
Epoch 340 Iter 2 subLoss 12025.8 multi -1.99 import weight 0.00
Epoch 340 Iter 3 subLoss 13063.1 multi -1.99 import weight 0.00
Epoch 340 Iter 4 subLoss 13705.4 multi 1.00 import weight 0.00
Epoch 340 Iter 5 subLoss 13247.5 multi 1.00 import weight 0.00
Epoch 340 Iter 6 subLoss 13590.4 multi -1.99 import weight 0.00
Epoch 340 Iter 7 subLoss 13346.4 multi 3.99 import weight 0.00
Epoch 340 Iter 8 subLoss 13466.1 multi 3.98 import weight 0.00
Epoch 340 Iter 9 subLoss 11131.4 multi -4.97 import weight 0.00
Epoch 340 Iter 10 subLoss 12580.5 multi 3.98 import weight 0.00
Epoch 340 Iter 11 subLoss 10947.7 multi 3.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0110 / 0.10832 / 10.70
Entropy seen (from low to high)
[492, 917, 971, 445, 240, 152, 156, 154, 167, 174, 156, 128, 85, 94, 60, 59, 42, 61, 49, 52, 53, 43, 42, 55, 44, 39, 32, 23, 27, 23, 17, 16, 9, 12, 10, 8, 6, 7, 3, 1, 2, 2, 5, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4, 9, 20, 47, 69, 81, 95, 107, 133, 132, 188, 181, 176, 193, 187, 191, 185, 188, 175, 186, 147, 152, 138, 139, 136, 139, 109, 125, 116, 106, 101, 99, 105, 114, 109, 100, 87, 66, 64, 39, 45, 34, 25, 11, 5, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.7, 29.5, 32.8, 36.9, 40.9, 44.0, 47.2, 50.9, 54.3, 57.6, 61.1, 64.8, 68.5]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 33.3, 49.9, 44.4, 71.4, 49.9, 49.9, 60.4, 63.8, 54.7, 79.9, 82.3, 76.5]
[0, 0, 0, 0, 0, 0, 0, 1, 6, 4, 9, 7, 8, 22, 48, 47, 42, 40, 51, 64]
Epoch 340 Acc: 86.28 BMA: 96.50 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 1094 train Loss: 10981.5 test Loss: 1845.9
Epoch 341 Iter 0 subLoss 11115.9 multi -1.99 import weight 0.00
Epoch 341 Iter 1 subLoss 10768.4 multi 3.99 import weight 0.00
Epoch 341 Iter 2 subLoss 10462.6 multi 1.00 import weight 0.00
Epoch 341 Iter 3 subLoss 10456.4 multi 1.00 import weight 0.00
Epoch 341 Iter 4 subLoss 10173.8 multi -1.99 import weight 0.00
Epoch 341 Iter 5 subLoss 9737.5 multi 3.98 import weight 0.00
Epoch 341 Iter 6 subLoss 8997.9 multi -1.98 import weight 0.00
Epoch 341 Iter 7 subLoss 9704.4 multi 1.00 import weight 0.00
Epoch 341 Iter 8 subLoss 9620.4 multi -7.96 import weight 0.00
Epoch 341 Iter 9 subLoss 11384.2 multi 3.98 import weight 0.00
Epoch 341 Iter 10 subLoss 10585.1 multi -1.99 import weight 0.00
Epoch 341 Iter 11 subLoss 11686.8 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0111 / 0.10780 / 10.97
Entropy seen (from low to high)
[488, 921, 968, 444, 238, 154, 128, 123, 167, 166, 163, 140, 106, 92, 77, 55, 52, 55, 51, 55, 49, 52, 41, 55, 45, 40, 31, 25, 29, 21, 18, 19, 8, 11, 11, 9, 5, 8, 3, 1, 1, 3, 5, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4, 9, 22, 46, 66, 84, 98, 109, 131, 141, 185, 178, 181, 197, 186, 199, 187, 198, 168, 193, 137, 152, 139, 140, 127, 147, 112, 127, 117, 109, 94, 107, 108, 108, 112, 87, 75, 58, 63, 39, 44, 32, 26, 11, 5, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.6, 29.5, 32.8, 36.5, 40.4, 43.9, 47.2, 50.7, 54.2, 57.7, 61.1, 64.8, 68.5]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 33.3, 24.9, 49.9, 62.4, 49.9, 47.8, 62.4, 64.5, 54.7, 80.4, 81.1, 77.4]
[0, 0, 0, 0, 0, 0, 0, 1, 6, 4, 8, 8, 8, 23, 48, 48, 42, 41, 53, 62]
Epoch 341 Acc: 87.94 BMA: 96.52 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 1168 train Loss: 10357.0 test Loss: 1733.8
Epoch 342 Iter 0 subLoss 10012.6 multi 3.99 import weight 0.00
Epoch 342 Iter 1 subLoss 10015.3 multi 6.97 import weight 0.00
Epoch 342 Iter 2 subLoss 8411.3 multi 1.00 import weight 0.00
Epoch 342 Iter 3 subLoss 8484.7 multi -7.96 import weight 0.00
Epoch 342 Iter 4 subLoss 9252.6 multi -1.99 import weight 0.00
Epoch 342 Iter 5 subLoss 9068.0 multi 6.97 import weight 0.00
Epoch 342 Iter 6 subLoss 9053.3 multi 1.00 import weight 0.00
Epoch 342 Iter 7 subLoss 8410.3 multi 3.98 import weight 0.00
Epoch 342 Iter 8 subLoss 8171.7 multi -4.97 import weight 0.00
Epoch 342 Iter 9 subLoss 8791.7 multi 3.99 import weight 0.00
Epoch 342 Iter 10 subLoss 8376.3 multi 3.98 import weight 0.00
Epoch 342 Iter 11 subLoss 7122.1 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0111 / 0.10748 / 11.59
Entropy seen (from low to high)
[477, 929, 959, 452, 242, 147, 132, 109, 165, 160, 160, 144, 113, 90, 85, 53, 61, 51, 54, 57, 47, 56, 39, 48, 53, 40, 30, 26, 25, 25, 19, 19, 9, 11, 10, 10, 5, 8, 3, 1, 1, 3, 5, 1, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4, 9, 22, 48, 64, 82, 101, 112, 132, 140, 187, 179, 183, 200, 183, 210, 177, 200, 175, 182, 148, 145, 146, 142, 132, 142, 103, 133, 122, 99, 101, 103, 107, 113, 100, 90, 65, 59, 61, 38, 45, 34, 24, 11, 5, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.6, 29.5, 32.7, 36.4, 40.3, 43.8, 47.3, 50.8, 54.2, 57.8, 61.1, 64.8, 68.4]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 33.3, 24.9, 49.9, 62.4, 49.9, 55.9, 61.2, 64.4, 55.5, 79.9, 83.3, 78.3]
[0, 0, 0, 0, 0, 0, 0, 1, 6, 4, 8, 8, 8, 25, 49, 45, 45, 40, 54, 60]
Epoch 342 Acc: 93.81 BMA: 96.54 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 712 train Loss: 7031.2 test Loss: 1103.4
Epoch 343 Iter 0 subLoss 6843.3 multi 3.99 import weight 0.00
Epoch 343 Iter 1 subLoss 6436.3 multi -4.97 import weight 0.00
Epoch 343 Iter 2 subLoss 7241.6 multi -1.99 import weight 0.00
Epoch 343 Iter 3 subLoss 7005.8 multi -10.94 import weight 0.00
Epoch 343 Iter 4 subLoss 8759.5 multi -1.99 import weight 0.00
Epoch 343 Iter 5 subLoss 8708.6 multi -1.98 import weight 0.00
Epoch 343 Iter 6 subLoss 9363.1 multi -1.99 import weight 0.00
Epoch 343 Iter 7 subLoss 10022.1 multi -7.96 import weight 0.00
Epoch 343 Iter 8 subLoss 11148.1 multi 3.99 import weight 0.00
Epoch 343 Iter 9 subLoss 10670.0 multi 6.97 import weight 0.00
Epoch 343 Iter 10 subLoss 9256.9 multi 1.00 import weight 0.00
Epoch 343 Iter 11 subLoss 8107.8 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0112 / 0.10708 / 13.65
Entropy seen (from low to high)
[472, 923, 964, 459, 238, 147, 128, 105, 144, 156, 160, 139, 130, 88, 95, 53, 63, 59, 51, 62, 46, 59, 37, 44, 57, 39, 33, 27, 24, 24, 21, 20, 8, 12, 9, 11, 5, 8, 3, 1, 1, 3, 5, 1, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4, 9, 20, 52, 62, 81, 109, 107, 133, 145, 188, 178, 187, 198, 190, 212, 175, 205, 175, 176, 152, 147, 147, 147, 132, 138, 120, 120, 120, 85, 121, 104, 90, 125, 93, 77, 68, 51, 57, 41, 43, 34, 26, 8, 6, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.5, 29.5, 33.0, 36.4, 40.2, 43.8, 47.4, 50.7, 54.1, 57.8, 61.2, 64.9, 68.4]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 33.3, 19.9, 71.4, 62.4, 37.4, 59.2, 62.4, 65.9, 51.0, 86.0, 83.0, 76.6]
[0, 0, 0, 0, 0, 0, 0, 1, 6, 5, 7, 8, 8, 27, 48, 44, 47, 43, 53, 60]
Epoch 343 Acc: 92.08 BMA: 96.54 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 810 train Loss: 8246.8 test Loss: 1360.7
Epoch 344 Iter 0 subLoss 7724.5 multi -10.94 import weight 0.00
Epoch 344 Iter 1 subLoss 9641.2 multi 1.00 import weight 0.00
Epoch 344 Iter 2 subLoss 9462.5 multi 3.99 import weight 0.00
Epoch 344 Iter 3 subLoss 8993.3 multi 1.00 import weight 0.00
Epoch 344 Iter 4 subLoss 8396.3 multi -4.97 import weight 0.00
Epoch 344 Iter 5 subLoss 9044.2 multi 1.00 import weight 0.00
Epoch 344 Iter 6 subLoss 9529.7 multi 1.00 import weight 0.00
Epoch 344 Iter 7 subLoss 9094.3 multi 1.00 import weight 0.00
Epoch 344 Iter 8 subLoss 8963.6 multi -1.99 import weight 0.00
Epoch 344 Iter 9 subLoss 8950.3 multi -1.99 import weight 0.00
Epoch 344 Iter 10 subLoss 10040.0 multi 1.00 import weight 0.00
Epoch 344 Iter 11 subLoss 9375.4 multi 3.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.10664 / 13.55
Entropy seen (from low to high)
[465, 902, 982, 460, 242, 151, 123, 98, 115, 156, 140, 157, 138, 102, 91, 67, 61, 58, 51, 71, 46, 52, 41, 47, 56, 39, 35, 28, 26, 21, 26, 18, 11, 10, 9, 11, 5, 9, 3, 1, 1, 3, 5, 1, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4, 9, 20, 52, 63, 87, 106, 107, 130, 152, 188, 178, 197, 191, 198, 207, 179, 206, 181, 166, 159, 147, 151, 143, 133, 141, 114, 133, 108, 99, 104, 108, 99, 116, 86, 68, 68, 49, 57, 39, 41, 37, 23, 8, 6, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.4, 29.6, 33.0, 36.5, 40.3, 44.0, 47.4, 50.7, 54.1, 57.9, 61.0, 64.7, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 33.3, 39.9, 57.1, 66.6, 28.5, 57.1, 66.6, 61.9, 52.1, 85.7, 80.7, 79.3]
[0, 0, 0, 0, 0, 0, 0, 1, 6, 5, 7, 9, 7, 28, 51, 42, 46, 42, 52, 63]
Epoch 344 Acc: 91.26 BMA: 96.54 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 937 train Loss: 9001.9 test Loss: 1502.1
Epoch 345 Iter 0 subLoss 9250.2 multi 3.98 import weight 0.00
Epoch 345 Iter 1 subLoss 8550.7 multi 1.00 import weight 0.00
Epoch 345 Iter 2 subLoss 7807.8 multi 6.97 import weight 0.00
Epoch 345 Iter 3 subLoss 7837.0 multi 3.99 import weight 0.00
Epoch 345 Iter 4 subLoss 6684.7 multi 3.99 import weight 0.00
Epoch 345 Iter 5 subLoss 6158.6 multi 6.97 import weight 0.00
Epoch 345 Iter 6 subLoss 5450.9 multi 9.96 import weight 0.00
Epoch 345 Iter 7 subLoss 5375.1 multi -10.94 import weight 0.00
Epoch 345 Iter 8 subLoss 5030.5 multi -4.97 import weight 0.00
Epoch 345 Iter 9 subLoss 5867.3 multi 3.99 import weight 0.00
Epoch 345 Iter 10 subLoss 5498.3 multi -13.93 import weight 0.00
Epoch 345 Iter 11 subLoss 6284.2 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.10650 / 13.69
Entropy seen (from low to high)
[467, 897, 989, 454, 247, 151, 121, 102, 116, 153, 138, 155, 135, 105, 90, 65, 57, 66, 49, 69, 46, 53, 44, 44, 56, 44, 32, 27, 27, 23, 24, 17, 12, 12, 8, 11, 5, 9, 3, 1, 1, 3, 4, 2, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4, 9, 20, 53, 61, 86, 104, 110, 130, 148, 191, 177, 202, 191, 200, 203, 189, 205, 180, 169, 155, 152, 148, 138, 145, 132, 117, 129, 107, 100, 111, 100, 98, 115, 89, 64, 70, 51, 54, 39, 39, 40, 19, 8, 6, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.3, 29.6, 32.9, 36.5, 40.2, 44.0, 47.3, 50.6, 54.1, 57.9, 61.0, 64.8, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 33.3, 39.9, 57.1, 66.6, 28.5, 60.7, 64.7, 61.9, 53.1, 83.3, 82.1, 81.0]
[0, 0, 0, 0, 0, 0, 0, 1, 6, 5, 7, 9, 7, 28, 51, 42, 47, 42, 56, 58]
Epoch 345 Acc: 95.29 BMA: 96.54 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 628 train Loss: 5718.2 test Loss: 808.4
Epoch 346 Iter 0 subLoss 5157.8 multi 6.97 import weight 0.00
Epoch 346 Iter 1 subLoss 4795.0 multi -1.99 import weight 0.00
Epoch 346 Iter 2 subLoss 5773.9 multi 1.00 import weight 0.00
Epoch 346 Iter 3 subLoss 5394.7 multi 9.96 import weight 0.00
Epoch 346 Iter 4 subLoss 4006.8 multi -4.97 import weight 0.00
Epoch 346 Iter 5 subLoss 5078.9 multi -4.97 import weight 0.00
Epoch 346 Iter 6 subLoss 5069.3 multi 12.94 import weight 0.00
Epoch 346 Iter 7 subLoss 4741.1 multi 1.00 import weight 0.00
Epoch 346 Iter 8 subLoss 4653.2 multi -19.90 import weight 0.00
Epoch 346 Iter 9 subLoss 6090.5 multi -1.99 import weight 0.00
Epoch 346 Iter 10 subLoss 6448.3 multi -4.97 import weight 0.00
Epoch 346 Iter 11 subLoss 11416.2 multi 3.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.10636 / 15.13
Entropy seen (from low to high)
[468, 892, 998, 450, 244, 151, 123, 106, 112, 155, 137, 151, 135, 106, 89, 65, 47, 74, 55, 64, 47, 54, 46, 44, 55, 43, 32, 27, 29, 22, 22, 19, 13, 12, 8, 11, 5, 8, 4, 1, 1, 3, 4, 2, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4, 9, 19, 55, 59, 86, 105, 114, 132, 144, 179, 186, 201, 198, 195, 208, 187, 210, 172, 185, 147, 147, 163, 128, 154, 124, 118, 126, 112, 95, 108, 102, 102, 107, 89, 64, 70, 51, 53, 38, 39, 40, 19, 8, 6, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.2, 29.6, 32.8, 36.8, 40.5, 44.4, 47.4, 50.7, 54.0, 57.8, 61.0, 64.8, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 33.3, 59.9, 62.4, 55.5, 33.3, 62.4, 60.4, 69.2, 47.9, 86.6, 79.9, 82.1]
[0, 0, 0, 0, 0, 0, 0, 1, 6, 5, 8, 9, 6, 32, 48, 39, 48, 45, 55, 56]
Epoch 346 Acc: 95.10 BMA: 96.54 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 1141 train Loss: 5624.6 test Loss: 854.9
Epoch 347 Iter 0 subLoss 5925.8 multi -7.96 import weight 0.00
Epoch 347 Iter 1 subLoss 6396.4 multi -1.98 import weight 0.00
Epoch 347 Iter 2 subLoss 6531.6 multi 1.00 import weight 0.00
Epoch 347 Iter 3 subLoss 6471.2 multi 6.97 import weight 0.00
Epoch 347 Iter 4 subLoss 5423.5 multi 1.00 import weight 0.00
Epoch 347 Iter 5 subLoss 5207.2 multi -1.98 import weight 0.00
Epoch 347 Iter 6 subLoss 5348.2 multi 6.97 import weight 0.00
Epoch 347 Iter 7 subLoss 5289.9 multi -10.94 import weight 0.00
Epoch 347 Iter 8 subLoss 5715.3 multi 6.97 import weight 0.00
Epoch 347 Iter 9 subLoss 5660.0 multi 1.00 import weight 0.00
Epoch 347 Iter 10 subLoss 4987.2 multi 6.97 import weight 0.00
Epoch 347 Iter 11 subLoss 5390.9 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.10639 / 15.13
Entropy seen (from low to high)
[469, 896, 998, 447, 246, 149, 125, 103, 119, 153, 142, 147, 133, 101, 90, 63, 52, 73, 54, 62, 50, 52, 46, 43, 56, 45, 31, 25, 28, 23, 22, 19, 13, 12, 9, 9, 6, 8, 4, 1, 1, 3, 4, 2, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4, 9, 19, 54, 52, 93, 103, 117, 133, 139, 176, 187, 199, 196, 201, 212, 186, 206, 172, 187, 151, 146, 165, 130, 155, 118, 124, 118, 114, 93, 112, 99, 102, 103, 93, 67, 66, 53, 53, 37, 40, 41, 19, 8, 6, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.2, 29.3, 32.6, 36.8, 40.5, 44.0, 47.4, 50.8, 54.0, 57.7, 61.0, 64.8, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 19.9, 49.9, 62.4, 55.5, 39.9, 58.3, 59.9, 69.2, 45.6, 85.4, 79.6, 84.4]
[0, 0, 0, 0, 0, 0, 0, 1, 5, 6, 8, 9, 5, 36, 45, 39, 46, 48, 54, 58]
Epoch 347 Acc: 96.17 BMA: 96.52 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 539 train Loss: 4692.7 test Loss: 627.3
Epoch 348 Iter 0 subLoss 4220.3 multi 1.00 import weight 0.00
Epoch 348 Iter 1 subLoss 4267.2 multi -4.97 import weight 0.00
Epoch 348 Iter 2 subLoss 4933.1 multi -16.91 import weight 0.00
Epoch 348 Iter 3 subLoss 5853.6 multi -4.97 import weight 0.00
Epoch 348 Iter 4 subLoss 6906.8 multi -13.93 import weight 0.00
Epoch 348 Iter 5 subLoss 43699.4 multi 1.00 import weight 0.00
Epoch 348 Iter 6 subLoss 12073.9 multi 1.00 import weight 0.00
Epoch 348 Iter 7 subLoss 9682.0 multi 3.99 import weight 0.00
Epoch 348 Iter 8 subLoss 6216.0 multi -4.97 import weight 0.00
Epoch 348 Iter 9 subLoss 7567.8 multi 9.96 import weight 0.00
Epoch 348 Iter 10 subLoss 5633.6 multi -19.90 import weight 0.00
Epoch 348 Iter 11 subLoss 7513.9 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.10622 / 15.72
Entropy seen (from low to high)
[464, 877, 1012, 454, 249, 143, 128, 104, 110, 154, 136, 136, 141, 109, 89, 61, 58, 75, 58, 56, 53, 51, 49, 42, 57, 43, 32, 25, 29, 25, 23, 18, 12, 14, 8, 8, 8, 8, 4, 1, 1, 3, 4, 2, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4, 9, 19, 54, 52, 96, 102, 115, 130, 141, 175, 193, 195, 200, 203, 216, 175, 210, 179, 181, 163, 147, 157, 132, 154, 123, 126, 115, 105, 104, 106, 99, 102, 97, 93, 69, 61, 52, 54, 38, 38, 41, 19, 7, 7, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.1, 29.3, 32.5, 36.9, 40.4, 44.0, 47.4, 50.8, 54.0, 57.7, 61.1, 64.9, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 19.9, 49.9, 62.4, 55.5, 39.9, 59.4, 60.8, 69.2, 43.1, 83.0, 82.6, 83.6]
[0, 0, 0, 0, 0, 0, 0, 1, 5, 6, 8, 9, 5, 37, 46, 39, 44, 53, 52, 55]
Epoch 348 Acc: 94.73 BMA: 96.50 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 751 train Loss: 6821.0 test Loss: 1059.6
Epoch 349 Iter 0 subLoss 6437.6 multi -1.99 import weight 0.00
Epoch 349 Iter 1 subLoss 6759.7 multi -1.98 import weight 0.00
Epoch 349 Iter 2 subLoss 6571.1 multi -4.97 import weight 0.00
Epoch 349 Iter 3 subLoss 8237.7 multi 1.00 import weight 0.00
Epoch 349 Iter 4 subLoss 7947.8 multi 1.00 import weight 0.00
Epoch 349 Iter 5 subLoss 7248.3 multi 1.00 import weight 0.00
Epoch 349 Iter 6 subLoss 7514.9 multi 6.97 import weight 0.00
Epoch 349 Iter 7 subLoss 6846.4 multi 6.97 import weight 0.00
Epoch 349 Iter 8 subLoss 6379.1 multi 6.97 import weight 0.00
Epoch 349 Iter 9 subLoss 5209.7 multi 1.00 import weight 0.00
Epoch 349 Iter 10 subLoss 5515.6 multi 6.97 import weight 0.00
Epoch 349 Iter 11 subLoss 5454.3 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.10623 / 15.47
Entropy seen (from low to high)
[464, 884, 1005, 452, 253, 147, 124, 102, 113, 155, 142, 137, 131, 111, 87, 60, 61, 74, 58, 54, 52, 53, 48, 44, 53, 45, 34, 23, 29, 25, 24, 17, 12, 15, 8, 7, 8, 8, 4, 1, 1, 3, 4, 2, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4, 9, 18, 54, 53, 98, 100, 116, 125, 144, 168, 202, 191, 201, 200, 218, 178, 215, 178, 175, 168, 146, 156, 129, 160, 115, 130, 116, 103, 107, 100, 103, 102, 96, 94, 65, 65, 51, 54, 39, 37, 42, 19, 7, 7, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.0, 29.3, 32.5, 36.6, 40.2, 44.2, 47.3, 50.6, 54.0, 57.7, 61.1, 64.8, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 19.9, 49.9, 57.1, 59.9, 49.9, 63.6, 54.1, 70.7, 42.8, 83.0, 82.6, 83.6]
[0, 0, 0, 0, 0, 0, 0, 1, 5, 6, 7, 10, 6, 33, 48, 41, 42, 53, 52, 55]
Epoch 349 Acc: 96.19 BMA: 96.50 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 545 train Loss: 4844.7 test Loss: 649.9
Epoch 350 Iter 0 subLoss 4481.0 multi -4.97 import weight 0.00
Epoch 350 Iter 1 subLoss 4423.8 multi 9.96 import weight 0.00
Epoch 350 Iter 2 subLoss 4488.0 multi -1.98 import weight 0.00
Epoch 350 Iter 3 subLoss 4433.0 multi -22.88 import weight 0.00
Epoch 350 Iter 4 subLoss 5546.4 multi -13.93 import weight 0.00
Epoch 350 Iter 5 subLoss 6685.3 multi 6.97 import weight 0.00
Epoch 350 Iter 6 subLoss 6101.1 multi 12.94 import weight 0.00
Epoch 350 Iter 7 subLoss 5152.1 multi 9.96 import weight 0.00
Epoch 350 Iter 8 subLoss 4894.4 multi -1.98 import weight 0.00
Epoch 350 Iter 9 subLoss 5075.2 multi -4.97 import weight 0.00
Epoch 350 Iter 10 subLoss 4901.0 multi 1.00 import weight 0.00
Epoch 350 Iter 11 subLoss 5272.1 multi 3.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.10626 / 15.55
Entropy seen (from low to high)
[462, 896, 1002, 447, 251, 146, 128, 99, 121, 149, 142, 139, 135, 104, 87, 61, 59, 71, 62, 54, 51, 53, 48, 44, 53, 44, 38, 20, 29, 25, 24, 18, 11, 15, 8, 7, 8, 7, 5, 1, 1, 3, 5, 1, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4, 8, 19, 53, 53, 96, 102, 113, 128, 146, 164, 204, 184, 204, 204, 210, 188, 213, 176, 176, 169, 145, 162, 131, 153, 115, 131, 116, 102, 107, 101, 98, 105, 94, 98, 65, 62, 53, 53, 41, 36, 41, 21, 7, 7, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.9, 29.8, 32.6, 36.8, 40.3, 44.2, 47.4, 50.7, 54.2, 57.7, 61.1, 64.8, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 49.9, 66.6, 57.1, 63.6, 53.0, 69.9, 43.9, 83.0, 81.4, 84.9]
[0, 0, 0, 0, 0, 0, 0, 2, 4, 6, 8, 9, 7, 33, 49, 40, 41, 53, 54, 53]
Epoch 350 Acc: 96.11 BMA: 96.50 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 527 train Loss: 4968.0 test Loss: 680.5
Epoch 351 Iter 0 subLoss 5372.7 multi -7.96 import weight 0.00
Epoch 351 Iter 1 subLoss 4761.4 multi -16.91 import weight 0.00
Epoch 351 Iter 2 subLoss 6094.6 multi 1.00 import weight 0.00
Epoch 351 Iter 3 subLoss 6160.5 multi -25.87 import weight 0.00
Epoch 351 Iter 4 subLoss 13131.2 multi 3.99 import weight 0.00
Epoch 351 Iter 5 subLoss 7475.6 multi 9.96 import weight 0.00
Epoch 351 Iter 6 subLoss 6167.8 multi -22.88 import weight 0.00
Epoch 351 Iter 7 subLoss 9086.7 multi 9.96 import weight 0.00
Epoch 351 Iter 8 subLoss 6779.2 multi -1.98 import weight 0.00
Epoch 351 Iter 9 subLoss 7346.4 multi 12.94 import weight 0.00
Epoch 351 Iter 10 subLoss 6158.1 multi 9.96 import weight 0.00
Epoch 351 Iter 11 subLoss 5599.6 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.10623 / 15.61
Entropy seen (from low to high)
[457, 893, 998, 458, 248, 149, 122, 107, 120, 148, 142, 135, 137, 102, 90, 60, 63, 64, 61, 56, 53, 55, 46, 44, 53, 44, 39, 22, 28, 27, 22, 18, 10, 17, 7, 8, 8, 7, 5, 1, 1, 3, 5, 1, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4, 8, 18, 52, 53, 99, 99, 114, 127, 150, 162, 203, 183, 202, 212, 206, 188, 214, 182, 175, 171, 139, 165, 132, 151, 116, 129, 119, 98, 109, 102, 100, 99, 95, 95, 70, 60, 50, 51, 44, 36, 40, 22, 7, 7, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.8, 29.9, 32.8, 36.8, 40.3, 44.1, 47.4, 50.7, 54.2, 57.5, 60.9, 64.7, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 62.4, 66.6, 57.1, 65.7, 49.9, 69.7, 44.4, 79.9, 81.8, 85.1]
[0, 0, 0, 0, 0, 0, 0, 2, 4, 6, 8, 9, 7, 35, 46, 43, 36, 55, 55, 54]
Epoch 351 Acc: 95.49 BMA: 96.50 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 559 train Loss: 5797.1 test Loss: 820.7
Epoch 352 Iter 0 subLoss 5699.2 multi -10.94 import weight 0.00
Epoch 352 Iter 1 subLoss 6332.8 multi -1.99 import weight 0.00
Epoch 352 Iter 2 subLoss 6879.4 multi 3.99 import weight 0.00
Epoch 352 Iter 3 subLoss 6242.5 multi 6.97 import weight 0.00
Epoch 352 Iter 4 subLoss 5320.8 multi -7.96 import weight 0.00
Epoch 352 Iter 5 subLoss 5567.3 multi -16.91 import weight 0.00
Epoch 352 Iter 6 subLoss 7636.1 multi -1.99 import weight 0.00
Epoch 352 Iter 7 subLoss 7438.1 multi 1.00 import weight 0.00
Epoch 352 Iter 8 subLoss 7592.5 multi 6.97 import weight 0.00
Epoch 352 Iter 9 subLoss 6373.1 multi 9.96 import weight 0.00
Epoch 352 Iter 10 subLoss 6080.4 multi -7.96 import weight 0.00
Epoch 352 Iter 11 subLoss 6462.2 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.10605 / 14.90
Entropy seen (from low to high)
[454, 867, 1017, 459, 254, 143, 129, 106, 118, 145, 145, 130, 138, 100, 92, 64, 59, 71, 61, 45, 61, 58, 45, 42, 54, 47, 38, 24, 28, 26, 23, 16, 11, 18, 6, 9, 8, 6, 6, 1, 1, 3, 5, 1, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4, 8, 17, 50, 56, 100, 98, 113, 130, 147, 162, 209, 180, 203, 211, 210, 195, 217, 173, 182, 164, 144, 162, 128, 158, 113, 129, 123, 95, 116, 95, 103, 94, 92, 92, 75, 58, 49, 49, 44, 36, 38, 22, 7, 7, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.7, 30.0, 32.9, 36.7, 40.3, 44.4, 47.6, 50.8, 54.3, 57.7, 61.0, 64.6, 68.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 62.4, 55.5, 59.9, 67.6, 48.8, 66.6, 48.5, 79.9, 80.7, 85.7]
[0, 0, 0, 0, 0, 0, 0, 2, 4, 6, 8, 9, 10, 34, 45, 45, 35, 55, 52, 56]
Epoch 352 Acc: 94.71 BMA: 96.50 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 646 train Loss: 6852.0 test Loss: 1021.9
Epoch 353 Iter 0 subLoss 6811.4 multi -4.97 import weight 0.00
Epoch 353 Iter 1 subLoss 7198.2 multi -19.90 import weight 0.00
Epoch 353 Iter 2 subLoss 11400.6 multi 3.99 import weight 0.00
Epoch 353 Iter 3 subLoss 8124.1 multi -1.99 import weight 0.00
Epoch 353 Iter 4 subLoss 8501.2 multi -7.96 import weight 0.00
Epoch 353 Iter 5 subLoss 10489.7 multi 3.99 import weight 0.00
Epoch 353 Iter 6 subLoss 9231.2 multi -1.99 import weight 0.00
Epoch 353 Iter 7 subLoss 8903.7 multi 6.97 import weight 0.00
Epoch 353 Iter 8 subLoss 8419.5 multi 6.97 import weight 0.00
Epoch 353 Iter 9 subLoss 7945.8 multi 3.99 import weight 0.00
Epoch 353 Iter 10 subLoss 7024.2 multi 1.00 import weight 0.00
Epoch 353 Iter 11 subLoss 7013.3 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.10590 / 14.26
Entropy seen (from low to high)
[452, 833, 1036, 460, 266, 146, 124, 105, 119, 147, 134, 134, 140, 99, 94, 65, 60, 68, 64, 46, 65, 56, 46, 41, 55, 48, 39, 24, 27, 27, 23, 16, 12, 15, 8, 9, 7, 6, 7, 1, 1, 3, 5, 1, 5, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4, 8, 17, 48, 58, 97, 103, 114, 128, 146, 163, 204, 188, 206, 206, 205, 204, 211, 185, 174, 169, 147, 161, 127, 157, 117, 123, 122, 96, 115, 104, 99, 92, 93, 87, 69, 63, 46, 49, 43, 36, 39, 22, 6, 7, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.6, 30.4, 33.3, 36.7, 40.1, 44.1, 47.6, 50.7, 54.3, 57.6, 61.0, 64.6, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 59.9, 62.4, 49.9, 58.3, 69.6, 51.1, 65.2, 48.5, 79.9, 81.8, 81.8]
[0, 0, 0, 0, 0, 0, 0, 2, 5, 5, 8, 8, 12, 33, 45, 46, 35, 55, 55, 55]
Epoch 353 Acc: 94.49 BMA: 96.50 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 701 train Loss: 6935.6 test Loss: 1068.3
Epoch 354 Iter 0 subLoss 6985.7 multi -1.99 import weight 0.00
Epoch 354 Iter 1 subLoss 7092.8 multi 12.94 import weight 0.00
Epoch 354 Iter 2 subLoss 6207.7 multi 3.99 import weight 0.00
Epoch 354 Iter 3 subLoss 6033.2 multi -13.93 import weight 0.00
Epoch 354 Iter 4 subLoss 6832.2 multi -4.97 import weight 0.00
Epoch 354 Iter 5 subLoss 6854.6 multi -10.94 import weight 0.00
Epoch 354 Iter 6 subLoss 8508.7 multi -4.97 import weight 0.00
Epoch 354 Iter 7 subLoss 11024.7 multi 3.99 import weight 0.00
Epoch 354 Iter 8 subLoss 8426.5 multi -10.94 import weight 0.00
Epoch 354 Iter 9 subLoss 11546.1 multi 9.96 import weight 0.00
Epoch 354 Iter 10 subLoss 8359.8 multi 3.99 import weight 0.00
Epoch 354 Iter 11 subLoss 7379.8 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0114 / 0.10575 / 14.63
Entropy seen (from low to high)
[448, 818, 1048, 453, 274, 147, 122, 105, 119, 141, 133, 137, 133, 105, 94, 71, 57, 74, 61, 49, 62, 59, 44, 43, 55, 48, 41, 20, 30, 28, 22, 19, 11, 14, 10, 8, 8, 5, 7, 1, 1, 3, 5, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4, 8, 17, 47, 59, 97, 103, 117, 124, 151, 163, 196, 193, 203, 213, 207, 205, 203, 197, 175, 165, 150, 158, 134, 153, 116, 121, 127, 92, 113, 106, 97, 97, 91, 80, 68, 61, 45, 50, 41, 38, 39, 21, 6, 7, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.6, 30.4, 33.3, 36.8, 40.4, 44.0, 47.6, 50.7, 54.2, 57.7, 61.0, 64.6, 68.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 59.9, 44.4, 57.1, 58.3, 65.7, 55.8, 65.9, 47.2, 79.9, 81.4, 83.0]
[0, 0, 0, 0, 0, 0, 0, 2, 5, 5, 9, 7, 12, 35, 43, 47, 36, 55, 54, 53]
Epoch 354 Acc: 94.53 BMA: 96.52 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 737 train Loss: 7320.1 test Loss: 1101.4
Epoch 355 Iter 0 subLoss 6983.5 multi 1.00 import weight 0.00
Epoch 355 Iter 1 subLoss 7151.7 multi -7.96 import weight 0.00
Epoch 355 Iter 2 subLoss 7952.7 multi -4.97 import weight 0.00
Epoch 355 Iter 3 subLoss 8014.1 multi 6.97 import weight 0.00
Epoch 355 Iter 4 subLoss 7323.5 multi -16.91 import weight 0.00
Epoch 355 Iter 5 subLoss 8971.0 multi -4.97 import weight 0.00
Epoch 355 Iter 6 subLoss 9723.6 multi -1.98 import weight 0.00
Epoch 355 Iter 7 subLoss 10993.6 multi 1.00 import weight 0.00
Epoch 355 Iter 8 subLoss 10027.7 multi -4.97 import weight 0.00
Epoch 355 Iter 9 subLoss 11785.7 multi 3.99 import weight 0.00
Epoch 355 Iter 10 subLoss 9837.3 multi 3.99 import weight 0.00
Epoch 355 Iter 11 subLoss 9677.4 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0114 / 0.10539 / 13.97
Entropy seen (from low to high)
[434, 742, 1081, 489, 274, 149, 124, 105, 119, 123, 124, 140, 141, 115, 92, 81, 54, 70, 70, 51, 58, 60, 46, 47, 53, 47, 43, 29, 27, 26, 24, 18, 15, 13, 11, 9, 6, 7, 6, 1, 1, 3, 5, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4, 8, 17, 48, 60, 97, 105, 120, 122, 154, 166, 198, 194, 203, 211, 210, 212, 192, 207, 171, 168, 158, 146, 142, 142, 131, 115, 121, 92, 117, 112, 94, 95, 88, 73, 71, 55, 40, 53, 39, 35, 39, 20, 6, 7, 3]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.7, 30.1, 33.0, 36.9, 40.3, 44.1, 47.6, 50.8, 54.3, 57.8, 61.3, 64.7, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 49.9, 44.4, 57.1, 53.8, 66.6, 58.6, 62.7, 52.3, 83.3, 81.1, 82.6]
[0, 0, 0, 0, 0, 0, 0, 2, 4, 6, 9, 7, 13, 36, 46, 43, 42, 54, 53, 52]
Epoch 355 Acc: 92.72 BMA: 96.54 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 967 train Loss: 10174.4 test Loss: 1616.8
Epoch 356 Iter 0 subLoss 10602.6 multi 1.00 import weight 0.00
Epoch 356 Iter 1 subLoss 9511.6 multi -1.98 import weight 0.00
Epoch 356 Iter 2 subLoss 10129.9 multi -7.96 import weight 0.00
Epoch 356 Iter 3 subLoss 11714.3 multi -4.97 import weight 0.00
Epoch 356 Iter 4 subLoss 13718.0 multi -1.98 import weight 0.00
Epoch 356 Iter 5 subLoss 15950.6 multi 1.00 import weight 0.00
Epoch 356 Iter 6 subLoss 13813.3 multi 3.99 import weight 0.00
Epoch 356 Iter 7 subLoss 11283.9 multi -7.96 import weight 0.00
Epoch 356 Iter 8 subLoss 14757.1 multi 3.99 import weight 0.00
Epoch 356 Iter 9 subLoss 11961.0 multi -4.97 import weight 0.00
Epoch 356 Iter 10 subLoss 14203.0 multi -10.94 import weight 0.00
Epoch 356 Iter 11 subLoss 21070.2 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0115 / 0.10473 / 13.07
Entropy seen (from low to high)
[391, 625, 1078, 551, 302, 163, 147, 103, 103, 112, 133, 127, 148, 126, 94, 96, 66, 60, 80, 55, 55, 59, 50, 53, 49, 52, 36, 40, 26, 31, 23, 20, 16, 13, 10, 11, 5, 8, 5, 2, 1, 3, 5, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4, 8, 18, 48, 63, 100, 109, 113, 127, 162, 162, 211, 194, 206, 211, 209, 218, 191, 208, 185, 149, 165, 140, 152, 145, 130, 112, 117, 100, 110, 108, 92, 98, 89, 68, 61, 51, 41, 49, 42, 32, 31, 18, 5, 7, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.6, 29.8, 33.6, 37.2, 40.2, 44.2, 47.4, 50.7, 54.3, 57.7, 61.2, 64.7, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 33.3, 49.9, 49.9, 62.4, 49.9, 63.8, 58.3, 61.3, 56.0, 84.2, 81.1, 83.6]
[0, 0, 0, 0, 0, 0, 0, 1, 6, 6, 8, 8, 12, 36, 48, 44, 41, 57, 53, 55]
Epoch 356 Acc: 84.45 BMA: 96.58 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 2107 train Loss: 17222.6 test Loss: 2769.6
Epoch 357 Iter 0 subLoss 16941.4 multi 3.99 import weight 0.00
Epoch 357 Iter 1 subLoss 14948.9 multi 1.00 import weight 0.00
Epoch 357 Iter 2 subLoss 13944.7 multi -1.99 import weight 0.00
Epoch 357 Iter 3 subLoss 15270.4 multi 3.99 import weight 0.00
Epoch 357 Iter 4 subLoss 13700.9 multi 3.98 import weight 0.00
Epoch 357 Iter 5 subLoss 13454.4 multi 3.99 import weight 0.00
Epoch 357 Iter 6 subLoss 11624.5 multi -1.99 import weight 0.00
Epoch 357 Iter 7 subLoss 11784.7 multi 6.97 import weight 0.00
Epoch 357 Iter 8 subLoss 10802.7 multi 1.00 import weight 0.00
Epoch 357 Iter 9 subLoss 10616.8 multi 1.00 import weight 0.00
Epoch 357 Iter 10 subLoss 10047.1 multi 1.00 import weight 0.00
Epoch 357 Iter 11 subLoss 10604.0 multi 3.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0116 / 0.10440 / 13.29
Entropy seen (from low to high)
[385, 614, 1051, 579, 305, 163, 152, 100, 88, 113, 126, 123, 142, 141, 105, 86, 81, 61, 77, 57, 51, 66, 51, 51, 48, 56, 39, 41, 26, 31, 20, 25, 15, 12, 12, 10, 6, 8, 5, 2, 1, 3, 5, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4, 8, 18, 47, 67, 99, 108, 115, 129, 163, 161, 216, 190, 213, 208, 214, 214, 207, 198, 180, 155, 163, 143, 159, 138, 125, 121, 109, 103, 108, 118, 89, 91, 90, 57, 64, 47, 40, 48, 37, 33, 32, 19, 4, 7, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.5, 29.8, 33.6, 37.0, 40.2, 44.5, 47.4, 50.6, 54.2, 57.9, 61.3, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 16.6, 49.9, 57.1, 49.9, 61.5, 61.1, 58.6, 59.5, 61.9, 82.1, 83.3, 84.2]
[0, 0, 0, 0, 0, 0, 0, 1, 6, 6, 7, 10, 13, 36, 46, 47, 42, 56, 54, 57]
Epoch 357 Acc: 91.91 BMA: 96.56 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 1060 train Loss: 10049.5 test Loss: 1593.1
Epoch 358 Iter 0 subLoss 9747.1 multi -1.99 import weight 0.00
Epoch 358 Iter 1 subLoss 10085.1 multi 1.00 import weight 0.00
Epoch 358 Iter 2 subLoss 10071.4 multi -1.99 import weight 0.00
Epoch 358 Iter 3 subLoss 10561.3 multi 3.98 import weight 0.00
Epoch 358 Iter 4 subLoss 10047.0 multi 3.99 import weight 0.00
Epoch 358 Iter 5 subLoss 9118.6 multi 1.00 import weight 0.00
Epoch 358 Iter 6 subLoss 9525.3 multi 1.00 import weight 0.00
Epoch 358 Iter 7 subLoss 9062.5 multi 6.97 import weight 0.00
Epoch 358 Iter 8 subLoss 8099.1 multi -1.99 import weight 0.00
Epoch 358 Iter 9 subLoss 8302.1 multi 1.00 import weight 0.00
Epoch 358 Iter 10 subLoss 8208.6 multi 12.94 import weight 0.00
Epoch 358 Iter 11 subLoss 7065.7 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0116 / 0.10426 / 13.38
Entropy seen (from low to high)
[383, 610, 1035, 599, 301, 168, 152, 97, 91, 110, 123, 120, 134, 146, 104, 89, 84, 54, 83, 61, 50, 63, 60, 49, 48, 50, 40, 46, 25, 32, 22, 25, 14, 13, 12, 10, 7, 7, 5, 2, 1, 3, 5, 3, 3, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 3, 8, 19, 47, 70, 101, 102, 121, 121, 165, 165, 210, 196, 212, 211, 213, 216, 206, 198, 185, 165, 158, 146, 150, 142, 128, 116, 107, 100, 119, 112, 84, 89, 85, 63, 59, 47, 35, 53, 36, 33, 33, 19, 4, 7, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 29.8, 33.4, 36.7, 40.2, 44.4, 47.4, 50.6, 54.2, 57.9, 61.4, 64.8, 68.4]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 16.6, 59.9, 49.9, 49.9, 69.2, 55.2, 61.3, 61.2, 60.4, 81.8, 84.4, 84.3]
[0, 0, 0, 0, 0, 0, 0, 1, 6, 5, 8, 10, 13, 38, 44, 49, 43, 55, 58, 51]
Epoch 358 Acc: 93.93 BMA: 96.56 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 706 train Loss: 7569.8 test Loss: 1167.5
Epoch 359 Iter 0 subLoss 7584.2 multi -7.96 import weight 0.00
Epoch 359 Iter 1 subLoss 7821.4 multi -4.97 import weight 0.00
Epoch 359 Iter 2 subLoss 8455.9 multi 15.93 import weight 0.00
Epoch 359 Iter 3 subLoss 7814.8 multi 1.00 import weight 0.00
Epoch 359 Iter 4 subLoss 7660.2 multi 6.97 import weight 0.00
Epoch 359 Iter 5 subLoss 6562.0 multi 12.94 import weight 0.00
Epoch 359 Iter 6 subLoss 6498.7 multi 12.94 import weight 0.00
Epoch 359 Iter 7 subLoss 5526.3 multi -13.93 import weight 0.00
Epoch 359 Iter 8 subLoss 6386.1 multi 1.00 import weight 0.00
Epoch 359 Iter 9 subLoss 5848.1 multi -1.98 import weight 0.00
Epoch 359 Iter 10 subLoss 6556.4 multi -1.99 import weight 0.00
Epoch 359 Iter 11 subLoss 6547.0 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0117 / 0.10420 / 13.33
Entropy seen (from low to high)
[382, 615, 1023, 610, 297, 170, 151, 98, 91, 111, 116, 121, 134, 147, 104, 88, 86, 55, 77, 62, 54, 56, 68, 47, 50, 50, 38, 49, 24, 33, 22, 25, 13, 14, 14, 8, 7, 7, 5, 2, 1, 3, 5, 3, 3, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 3, 6, 21, 46, 68, 104, 104, 118, 124, 161, 165, 205, 200, 207, 216, 212, 219, 209, 203, 186, 160, 160, 139, 154, 147, 127, 113, 112, 95, 127, 105, 85, 87, 84, 62, 58, 46, 37, 49, 38, 34, 33, 19, 4, 7, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.5, 30.2, 33.6, 36.4, 40.1, 44.2, 47.3, 50.7, 54.2, 57.8, 61.4, 64.8, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 39.9, 57.1, 45.4, 74.9, 48.7, 67.3, 60.4, 60.9, 81.3, 83.0, 83.3]
[0, 0, 0, 0, 0, 0, 0, 2, 5, 5, 7, 11, 12, 39, 46, 48, 41, 59, 53, 54]
Epoch 359 Acc: 94.80 BMA: 96.58 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 654 train Loss: 6549.4 test Loss: 938.3
Epoch 360 Iter 0 subLoss 5976.9 multi -4.97 import weight 0.00
Epoch 360 Iter 1 subLoss 6373.2 multi 12.94 import weight 0.00
Epoch 360 Iter 2 subLoss 6081.2 multi -4.97 import weight 0.00
Epoch 360 Iter 3 subLoss 6272.8 multi 3.99 import weight 0.00
Epoch 360 Iter 4 subLoss 6063.6 multi 1.00 import weight 0.00
Epoch 360 Iter 5 subLoss 5712.0 multi 9.96 import weight 0.00
Epoch 360 Iter 6 subLoss 5963.5 multi 3.99 import weight 0.00
Epoch 360 Iter 7 subLoss 5131.2 multi 1.00 import weight 0.00
Epoch 360 Iter 8 subLoss 5342.6 multi 9.96 import weight 0.00
Epoch 360 Iter 9 subLoss 4937.7 multi -13.93 import weight 0.00
Epoch 360 Iter 10 subLoss 5654.5 multi 3.98 import weight 0.00
Epoch 360 Iter 11 subLoss 5917.2 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0117 / 0.10428 / 13.38
Entropy seen (from low to high)
[382, 619, 1026, 605, 295, 170, 154, 99, 90, 116, 111, 126, 129, 149, 102, 87, 85, 54, 79, 62, 52, 58, 62, 53, 51, 52, 35, 48, 24, 33, 20, 26, 13, 13, 15, 8, 7, 7, 5, 2, 1, 3, 5, 3, 3, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 3, 5, 22, 44, 71, 96, 110, 113, 126, 161, 160, 201, 206, 206, 217, 211, 228, 202, 207, 180, 158, 165, 142, 156, 146, 126, 113, 112, 93, 129, 104, 89, 83, 81, 66, 58, 46, 37, 50, 39, 31, 36, 19, 4, 7, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.4, 30.2, 33.7, 36.6, 40.3, 44.2, 47.5, 50.7, 54.2, 57.7, 61.4, 64.7, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 39.9, 49.9, 49.9, 64.2, 52.6, 67.3, 59.9, 59.5, 79.6, 84.9, 83.9]
[0, 0, 0, 0, 0, 0, 0, 2, 5, 5, 8, 10, 14, 38, 46, 45, 42, 59, 53, 56]
Epoch 360 Acc: 96.01 BMA: 96.59 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 591 train Loss: 5232.1 test Loss: 689.9
Epoch 361 Iter 0 subLoss 5590.5 multi -1.98 import weight 0.00
Epoch 361 Iter 1 subLoss 5132.7 multi 3.99 import weight 0.00
Epoch 361 Iter 2 subLoss 4724.2 multi 1.00 import weight 0.00
Epoch 361 Iter 3 subLoss 4616.7 multi 9.96 import weight 0.00
Epoch 361 Iter 4 subLoss 4195.0 multi 1.00 import weight 0.00
Epoch 361 Iter 5 subLoss 4405.6 multi 18.91 import weight 0.00
Epoch 361 Iter 6 subLoss 5025.2 multi 6.97 import weight 0.00
Epoch 361 Iter 7 subLoss 4222.5 multi 3.98 import weight 0.00
Epoch 361 Iter 8 subLoss 4685.3 multi 21.90 import weight 0.00
Epoch 361 Iter 9 subLoss 4450.2 multi 12.94 import weight 0.00
Epoch 361 Iter 10 subLoss 4391.9 multi -4.97 import weight 0.00
Epoch 361 Iter 11 subLoss 4946.1 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0116 / 0.10440 / 13.33
Entropy seen (from low to high)
[386, 628, 1034, 587, 296, 170, 150, 102, 93, 111, 118, 123, 136, 143, 101, 86, 84, 57, 79, 61, 53, 59, 58, 51, 49, 55, 36, 45, 26, 30, 21, 25, 17, 11, 14, 8, 7, 6, 7, 1, 1, 3, 5, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 6, 20, 45, 71, 94, 107, 115, 123, 164, 162, 198, 205, 204, 225, 197, 238, 200, 208, 174, 163, 166, 137, 159, 149, 121, 117, 106, 100, 123, 107, 89, 87, 78, 72, 57, 43, 39, 51, 36, 35, 35, 20, 3, 8, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.3, 30.3, 33.8, 36.5, 40.3, 44.0, 47.4, 50.7, 54.2, 57.7, 61.4, 64.6, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 39.9, 49.9, 49.9, 69.2, 51.2, 65.9, 59.5, 61.9, 79.9, 83.9, 84.2]
[0, 0, 0, 0, 0, 0, 0, 2, 5, 5, 8, 10, 13, 39, 44, 47, 42, 55, 56, 57]
Epoch 361 Acc: 96.07 BMA: 96.58 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 494 train Loss: 4659.0 test Loss: 611.0
Epoch 362 Iter 0 subLoss 4588.8 multi -16.91 import weight 0.00
Epoch 362 Iter 1 subLoss 6017.0 multi 15.93 import weight 0.00
Epoch 362 Iter 2 subLoss 6563.9 multi 12.94 import weight 0.00
Epoch 362 Iter 3 subLoss 5583.2 multi 6.97 import weight 0.00
Epoch 362 Iter 4 subLoss 4245.9 multi 1.00 import weight 0.00
Epoch 362 Iter 5 subLoss 4547.5 multi -10.94 import weight 0.00
Epoch 362 Iter 6 subLoss 4899.8 multi 1.00 import weight 0.00
Epoch 362 Iter 7 subLoss 5152.8 multi 12.94 import weight 0.00
Epoch 362 Iter 8 subLoss 4531.5 multi 3.99 import weight 0.00
Epoch 362 Iter 9 subLoss 4819.4 multi -10.94 import weight 0.00
Epoch 362 Iter 10 subLoss 4539.4 multi 6.97 import weight 0.00
Epoch 362 Iter 11 subLoss 4510.7 multi 18.91 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0116 / 0.10457 / 13.09
Entropy seen (from low to high)
[387, 638, 1036, 584, 293, 167, 149, 101, 96, 112, 120, 123, 137, 137, 108, 82, 81, 61, 77, 61, 50, 60, 58, 49, 50, 55, 38, 42, 25, 31, 22, 23, 18, 11, 13, 9, 6, 6, 7, 1, 1, 3, 5, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 6, 18, 45, 72, 94, 105, 115, 125, 160, 162, 195, 204, 209, 224, 196, 231, 200, 213, 179, 156, 165, 140, 158, 150, 120, 124, 106, 92, 122, 114, 87, 88, 79, 71, 58, 46, 39, 49, 38, 36, 35, 19, 4, 8, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.3, 30.3, 33.7, 36.2, 40.2, 44.0, 47.5, 50.8, 54.2, 57.7, 61.5, 64.6, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 24.9, 55.5, 44.4, 62.4, 52.7, 65.9, 61.9, 58.6, 82.6, 82.4, 82.1]
[0, 0, 0, 0, 0, 0, 0, 2, 5, 4, 9, 9, 16, 36, 47, 42, 46, 52, 57, 56]
Epoch 362 Acc: 96.42 BMA: 96.58 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 18.91 Pidx 451 train Loss: 4354.5 test Loss: 524.5
Epoch 363 Iter 0 subLoss 4034.9 multi 6.97 import weight 0.00
Epoch 363 Iter 1 subLoss 3913.4 multi 3.99 import weight 0.00
Epoch 363 Iter 2 subLoss 3740.8 multi 3.98 import weight 0.00
Epoch 363 Iter 3 subLoss 3666.4 multi -1.98 import weight 0.00
Epoch 363 Iter 4 subLoss 4097.2 multi 1.00 import weight 0.00
Epoch 363 Iter 5 subLoss 4355.5 multi 1.00 import weight 0.00
Epoch 363 Iter 6 subLoss 4076.3 multi -13.93 import weight 0.00
Epoch 363 Iter 7 subLoss 4455.0 multi 15.93 import weight 0.00
Epoch 363 Iter 8 subLoss 4001.1 multi -1.99 import weight 0.00
Epoch 363 Iter 9 subLoss 4163.5 multi -13.93 import weight 0.00
Epoch 363 Iter 10 subLoss 5105.0 multi 3.98 import weight 0.00
Epoch 363 Iter 11 subLoss 4050.0 multi -13.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0116 / 0.10473 / 12.66
Entropy seen (from low to high)
[392, 640, 1037, 581, 289, 167, 147, 101, 100, 109, 123, 125, 139, 131, 107, 89, 77, 59, 80, 57, 51, 64, 54, 47, 54, 54, 37, 43, 23, 31, 22, 22, 18, 12, 12, 10, 6, 5, 8, 1, 1, 4, 4, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 6, 17, 46, 72, 93, 104, 116, 127, 154, 158, 196, 208, 203, 224, 197, 223, 212, 210, 177, 158, 158, 153, 151, 152, 114, 125, 109, 99, 118, 109, 94, 91, 75, 74, 57, 46, 41, 49, 40, 34, 36, 19, 4, 8, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.3, 29.9, 33.6, 36.3, 40.0, 43.9, 47.4, 50.7, 54.3, 57.7, 61.5, 64.6, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 0.0, 16.6, 62.4, 49.9, 58.8, 52.9, 66.6, 57.7, 59.0, 81.1, 83.0, 82.4]
[0, 0, 0, 0, 0, 0, 0, 2, 4, 6, 8, 8, 17, 34, 48, 45, 44, 53, 53, 57]
Epoch 363 Acc: 95.04 BMA: 96.58 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -13.93 Pidx 404 train Loss: 4891.0 test Loss: 753.0
Epoch 364 Iter 0 subLoss 4923.1 multi 12.94 import weight 0.00
Epoch 364 Iter 1 subLoss 3960.9 multi -13.93 import weight 0.00
Epoch 364 Iter 2 subLoss 4309.0 multi 6.97 import weight 0.00
Epoch 364 Iter 3 subLoss 3753.4 multi -13.93 import weight 0.00
Epoch 364 Iter 4 subLoss 5255.1 multi 6.97 import weight 0.00
Epoch 364 Iter 5 subLoss 4772.4 multi 6.97 import weight 0.00
Epoch 364 Iter 6 subLoss 4152.3 multi 12.94 import weight 0.00
Epoch 364 Iter 7 subLoss 4579.9 multi 21.90 import weight 0.00
Epoch 364 Iter 8 subLoss 4289.2 multi -16.91 import weight 0.00
Epoch 364 Iter 9 subLoss 5643.6 multi 1.00 import weight 0.00
Epoch 364 Iter 10 subLoss 5649.6 multi 3.98 import weight 0.00
Epoch 364 Iter 11 subLoss 4131.4 multi -16.91 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0116 / 0.10476 / 12.58
Entropy seen (from low to high)
[389, 645, 1040, 562, 298, 166, 148, 101, 105, 105, 130, 123, 144, 129, 104, 89, 80, 58, 75, 58, 54, 60, 55, 49, 54, 53, 39, 39, 25, 29, 24, 23, 18, 11, 12, 10, 8, 3, 8, 1, 1, 4, 4, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 2, 6, 17, 47, 71, 90, 105, 112, 134, 144, 167, 191, 206, 201, 207, 218, 221, 202, 211, 184, 160, 168, 147, 154, 152, 112, 123, 113, 100, 123, 110, 89, 93, 77, 72, 58, 49, 43, 45, 38, 36, 31, 19, 3, 8, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.5, 30.2, 34.1, 36.5, 40.5, 44.1, 47.4, 50.6, 54.0, 57.5, 61.5, 64.7, 68.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 19.9, 19.9, 55.5, 55.5, 59.9, 48.5, 67.4, 56.5, 60.8, 79.6, 88.8, 81.4]
[0, 0, 0, 0, 0, 0, 0, 2, 5, 5, 9, 9, 15, 35, 43, 46, 46, 54, 54, 54]
Epoch 364 Acc: 93.50 BMA: 96.61 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -16.91 Pidx 413 train Loss: 6611.7 test Loss: 1021.5
Epoch 365 Iter 0 subLoss 6233.8 multi 12.94 import weight 0.00
Epoch 365 Iter 1 subLoss 6426.4 multi 9.96 import weight 0.00
Epoch 365 Iter 2 subLoss 4429.7 multi 12.94 import weight 1.00
Epoch 365 Iter 3 subLoss 4082.1 multi 1.00 import weight 0.00
Epoch 365 Iter 4 subLoss 3762.8 multi 6.97 import weight 0.00
Epoch 365 Iter 5 subLoss 3940.0 multi 6.97 import weight 0.00
Epoch 365 Iter 6 subLoss 4429.9 multi 15.93 import weight 1.00
Epoch 365 Iter 7 subLoss 4212.6 multi 15.93 import weight 0.00
Epoch 365 Iter 8 subLoss 4529.5 multi -16.91 import weight 0.00
Epoch 365 Iter 9 subLoss 4904.6 multi 1.00 import weight 0.00
Epoch 365 Iter 10 subLoss 4547.0 multi -13.93 import weight 0.00
Epoch 365 Iter 11 subLoss 10400.7 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0116 / 0.10479 / 13.32
Entropy seen (from low to high)
[390, 654, 1044, 556, 294, 169, 144, 100, 108, 104, 133, 125, 142, 130, 100, 93, 74, 57, 79, 57, 52, 61, 54, 46, 56, 52, 40, 39, 26, 29, 21, 23, 18, 13, 12, 9, 7, 4, 8, 1, 1, 4, 4, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 7, 17, 46, 72, 89, 103, 112, 137, 145, 162, 191, 212, 201, 206, 209, 227, 206, 209, 182, 159, 167, 149, 151, 155, 113, 120, 112, 106, 120, 106, 90, 90, 82, 74, 59, 49, 41, 46, 38, 38, 29, 19, 4, 8, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.6, 29.9, 33.8, 36.4, 40.5, 44.1, 47.4, 50.6, 54.2, 57.5, 61.4, 64.5, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 0.0, 16.6, 55.5, 55.5, 56.2, 54.5, 65.9, 58.3, 63.4, 78.1, 84.6, 84.2]
[0, 0, 0, 0, 0, 0, 0, 2, 4, 6, 9, 9, 16, 33, 44, 48, 41, 55, 52, 57]
Epoch 365 Acc: 95.84 BMA: 96.63 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 1040 train Loss: 5164.2 test Loss: 658.3
Epoch 366 Iter 0 subLoss 5506.5 multi -4.97 import weight 0.00
Epoch 366 Iter 1 subLoss 5762.6 multi 3.99 import weight 0.00
Epoch 366 Iter 2 subLoss 4201.6 multi -4.97 import weight 0.00
Epoch 366 Iter 3 subLoss 6339.2 multi 1.00 import weight 0.00
Epoch 366 Iter 4 subLoss 6355.5 multi -1.98 import weight 0.00
Epoch 366 Iter 5 subLoss 6075.2 multi 9.96 import weight 0.00
Epoch 366 Iter 6 subLoss 3847.8 multi 6.97 import weight 0.00
Epoch 366 Iter 7 subLoss 3443.2 multi 1.00 import weight 0.00
Epoch 366 Iter 8 subLoss 4209.0 multi -1.99 import weight 0.00
Epoch 366 Iter 9 subLoss 3853.5 multi -7.96 import weight 0.00
Epoch 366 Iter 10 subLoss 4055.8 multi 6.97 import weight 0.00
Epoch 366 Iter 11 subLoss 3922.9 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0115 / 0.10493 / 13.32
Entropy seen (from low to high)
[393, 660, 1053, 548, 288, 168, 144, 100, 114, 105, 130, 126, 146, 125, 97, 93, 74, 58, 77, 55, 57, 56, 53, 48, 57, 54, 38, 37, 27, 28, 23, 21, 17, 13, 13, 9, 7, 3, 8, 1, 1, 4, 4, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 7, 17, 45, 70, 90, 104, 110, 135, 148, 161, 193, 204, 204, 201, 217, 222, 206, 202, 184, 169, 162, 150, 149, 151, 120, 112, 124, 100, 120, 106, 90, 95, 79, 75, 59, 50, 40, 50, 37, 38, 29, 21, 3, 9, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.7, 29.9, 33.3, 36.1, 40.5, 44.0, 47.4, 50.6, 54.2, 57.5, 61.5, 64.6, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 0.0, 0.0, 54.5, 55.5, 56.2, 54.8, 65.2, 60.4, 59.9, 76.7, 86.5, 83.6]
[0, 0, 0, 0, 0, 0, 0, 2, 4, 4, 11, 9, 16, 31, 46, 48, 40, 56, 52, 55]
Epoch 366 Acc: 96.50 BMA: 96.63 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 392 train Loss: 4075.7 test Loss: 552.4
Epoch 367 Iter 0 subLoss 3328.7 multi 1.00 import weight 0.00
Epoch 367 Iter 1 subLoss 3740.3 multi 6.97 import weight 0.00
Epoch 367 Iter 2 subLoss 3811.1 multi 21.90 import weight 0.00
Epoch 367 Iter 3 subLoss 4370.3 multi 3.99 import weight 0.00
Epoch 367 Iter 4 subLoss 4069.0 multi 1.00 import weight 0.00
Epoch 367 Iter 5 subLoss 3682.6 multi 3.99 import weight 0.00
Epoch 367 Iter 6 subLoss 3879.5 multi -4.97 import weight 0.00
Epoch 367 Iter 7 subLoss 3457.8 multi -4.97 import weight 0.00
Epoch 367 Iter 8 subLoss 4417.2 multi -4.97 import weight 0.00
Epoch 367 Iter 9 subLoss 4221.7 multi 3.99 import weight 0.00
Epoch 367 Iter 10 subLoss 3348.6 multi -1.99 import weight 0.00
Epoch 367 Iter 11 subLoss 4284.0 multi -13.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0115 / 0.10499 / 12.92
Entropy seen (from low to high)
[394, 671, 1066, 525, 288, 169, 146, 103, 110, 108, 131, 126, 151, 121, 91, 100, 64, 60, 82, 48, 56, 58, 52, 51, 57, 52, 38, 38, 26, 26, 26, 20, 17, 12, 13, 9, 8, 2, 8, 1, 1, 4, 4, 2, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 6, 18, 45, 70, 87, 105, 109, 136, 146, 161, 193, 209, 202, 203, 213, 224, 212, 198, 183, 169, 160, 150, 153, 146, 117, 118, 119, 99, 119, 108, 91, 98, 76, 78, 59, 49, 42, 49, 36, 38, 31, 21, 3, 9, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.7, 30.0, 33.6, 36.1, 40.6, 44.1, 47.5, 50.6, 54.2, 57.5, 61.5, 64.6, 68.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 0.0, 19.9, 49.9, 55.5, 58.8, 51.6, 65.9, 56.2, 65.8, 77.7, 85.1, 83.6]
[0, 0, 0, 0, 0, 0, 0, 2, 4, 5, 10, 9, 17, 31, 44, 48, 41, 54, 54, 55]
Epoch 367 Acc: 96.05 BMA: 96.63 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -13.93 Pidx 428 train Loss: 4622.2 test Loss: 603.4
Epoch 368 Iter 0 subLoss 4299.7 multi -10.94 import weight 0.00
Epoch 368 Iter 1 subLoss 7122.7 multi 6.97 import weight 0.00
Epoch 368 Iter 2 subLoss 4001.0 multi 1.00 import weight 0.00
Epoch 368 Iter 3 subLoss 3691.4 multi -1.99 import weight 0.00
Epoch 368 Iter 4 subLoss 4464.8 multi -10.94 import weight 0.00
Epoch 368 Iter 5 subLoss 4914.7 multi -16.91 import weight 0.00
Epoch 368 Iter 6 subLoss 9392.1 multi 1.00 import weight 0.00
Epoch 368 Iter 7 subLoss 8149.9 multi 1.00 import weight 0.00
Epoch 368 Iter 8 subLoss 8222.8 multi -1.99 import weight 0.00
Epoch 368 Iter 9 subLoss 8916.8 multi -7.96 import weight 0.00
Epoch 368 Iter 10 subLoss 35283.6 multi -1.99 import weight 0.00
Epoch 368 Iter 11 subLoss 208859.9 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0116 / 0.10408 / 13.18
Entropy seen (from low to high)
[353, 483, 1203, 553, 321, 183, 143, 104, 112, 111, 124, 118, 134, 134, 113, 81, 83, 51, 82, 56, 56, 57, 51, 51, 59, 53, 37, 44, 28, 30, 21, 24, 15, 14, 14, 8, 7, 5, 7, 1, 1, 3, 4, 3, 4, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 7, 22, 48, 73, 90, 100, 124, 131, 159, 163, 197, 202, 209, 220, 194, 243, 205, 207, 171, 174, 150, 155, 148, 152, 110, 118, 122, 111, 105, 104, 85, 95, 90, 69, 52, 55, 42, 46, 31, 36, 26, 8, 6, 3, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.1, 30.1, 34.1, 36.3, 40.3, 44.0, 47.5, 50.7, 54.3, 57.6, 61.4, 64.6, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 0.0, 19.9, 55.5, 62.4, 49.9, 55.8, 63.6, 60.3, 62.8, 74.5, 86.4, 83.9]
[0, 0, 0, 0, 0, 0, 0, 2, 5, 5, 9, 8, 18, 34, 44, 53, 35, 55, 59, 50]
Epoch 368 Acc: 76.18 BMA: 96.61 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 20885 train Loss: 37990.5 test Loss: 6064.3
Epoch 369 Iter 0 subLoss 35839.6 multi 1.00 import weight 0.00
Epoch 369 Iter 1 subLoss 12063.2 multi 1.00 import weight 0.00
Epoch 369 Iter 2 subLoss 10067.3 multi 1.00 import weight 0.00
Epoch 369 Iter 3 subLoss 9575.8 multi 1.00 import weight 0.00
Epoch 369 Iter 4 subLoss 9056.8 multi 1.00 import weight 0.00
Epoch 369 Iter 5 subLoss 8713.8 multi 3.99 import weight 0.00
Epoch 369 Iter 6 subLoss 6904.9 multi -10.94 import weight 0.00
Epoch 369 Iter 7 subLoss 9456.5 multi 6.97 import weight 0.00
Epoch 369 Iter 8 subLoss 6983.1 multi 3.98 import weight 0.00
Epoch 369 Iter 9 subLoss 6697.0 multi -1.99 import weight 0.00
Epoch 369 Iter 10 subLoss 6161.9 multi -22.88 import weight 0.00
Epoch 369 Iter 11 subLoss 10106.2 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0116 / 0.10373 / 12.83
Entropy seen (from low to high)
[345, 472, 1182, 572, 320, 188, 147, 111, 112, 116, 121, 116, 137, 135, 112, 76, 87, 54, 79, 58, 57, 61, 47, 53, 53, 52, 40, 47, 27, 32, 19, 25, 16, 13, 14, 8, 8, 4, 7, 1, 1, 3, 4, 4, 3, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 7, 22, 48, 79, 85, 106, 120, 132, 161, 166, 206, 195, 210, 226, 199, 230, 214, 209, 166, 173, 155, 151, 147, 143, 122, 117, 117, 115, 107, 96, 92, 98, 90, 68, 59, 41, 44, 51, 26, 30, 19, 9, 4, 3, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.5, 29.7, 34.1, 36.5, 40.2, 44.0, 47.6, 50.7, 54.1, 57.5, 61.5, 64.7, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 33.3, 19.9, 66.6, 49.9, 49.9, 54.2, 67.4, 63.2, 58.5, 76.7, 86.2, 82.3]
[0, 0, 0, 0, 0, 0, 0, 1, 6, 5, 9, 8, 18, 35, 43, 49, 41, 56, 58, 51]
Epoch 369 Acc: 94.18 BMA: 96.63 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 1010 train Loss: 8276.6 test Loss: 1084.5
Epoch 370 Iter 0 subLoss 8523.5 multi 1.00 import weight 0.00
Epoch 370 Iter 1 subLoss 7805.4 multi 9.96 import weight 0.00
Epoch 370 Iter 2 subLoss 6095.3 multi -1.99 import weight 0.00
Epoch 370 Iter 3 subLoss 6109.7 multi 9.96 import weight 0.00
Epoch 370 Iter 4 subLoss 5481.6 multi 9.96 import weight 0.00
Epoch 370 Iter 5 subLoss 5227.7 multi 12.94 import weight 0.00
Epoch 370 Iter 6 subLoss 4874.3 multi -1.99 import weight 0.00
Epoch 370 Iter 7 subLoss 4701.2 multi 3.98 import weight 0.00
Epoch 370 Iter 8 subLoss 5085.6 multi 6.97 import weight 0.00
Epoch 370 Iter 9 subLoss 4270.3 multi 21.90 import weight 1.00
Epoch 370 Iter 10 subLoss 4914.4 multi -13.93 import weight 0.00
Epoch 370 Iter 11 subLoss 5771.3 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0116 / 0.10366 / 12.86
Entropy seen (from low to high)
[347, 478, 1195, 559, 318, 185, 145, 114, 113, 114, 125, 118, 136, 132, 111, 76, 88, 51, 79, 59, 54, 64, 46, 52, 54, 51, 39, 48, 28, 30, 18, 25, 16, 14, 14, 8, 8, 5, 6, 1, 1, 3, 4, 4, 3, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 7, 23, 46, 79, 83, 110, 119, 133, 166, 163, 212, 192, 211, 225, 203, 229, 208, 210, 161, 176, 154, 151, 150, 143, 118, 115, 125, 112, 104, 100, 89, 98, 96, 62, 61, 39, 49, 47, 26, 28, 19, 9, 4, 3, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.4, 29.8, 33.8, 36.4, 40.2, 44.0, 47.6, 50.7, 54.1, 57.5, 61.5, 64.7, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 33.3, 24.9, 59.9, 49.9, 49.9, 54.2, 67.4, 61.2, 59.9, 78.5, 83.9, 85.1]
[0, 0, 0, 0, 0, 0, 0, 1, 6, 4, 10, 8, 18, 35, 43, 49, 40, 56, 56, 54]
Epoch 370 Acc: 96.07 BMA: 96.63 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 577 train Loss: 5324.2 test Loss: 637.9
Epoch 371 Iter 0 subLoss 4465.0 multi -7.96 import weight 0.00
Epoch 371 Iter 1 subLoss 7640.2 multi -4.97 import weight 0.00
Epoch 371 Iter 2 subLoss 20182.6 multi 1.00 import weight 0.00
Epoch 371 Iter 3 subLoss 9067.2 multi 6.97 import weight 0.00
Epoch 371 Iter 4 subLoss 5037.3 multi -4.97 import weight 0.00
Epoch 371 Iter 5 subLoss 5321.6 multi -4.97 import weight 0.00
Epoch 371 Iter 6 subLoss 6747.2 multi -4.97 import weight 0.00
Epoch 371 Iter 7 subLoss 10994.4 multi 3.99 import weight 0.00
Epoch 371 Iter 8 subLoss 5404.8 multi -13.93 import weight 0.00
Epoch 371 Iter 9 subLoss 10868.4 multi 6.97 import weight 0.00
Epoch 371 Iter 10 subLoss 5366.1 multi 12.94 import weight 0.00
Epoch 371 Iter 11 subLoss 5093.8 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0115 / 0.10363 / 13.39
Entropy seen (from low to high)
[350, 474, 1190, 567, 317, 182, 148, 111, 121, 109, 127, 123, 142, 121, 110, 83, 79, 53, 78, 59, 54, 60, 50, 52, 52, 53, 38, 48, 28, 29, 18, 27, 14, 16, 12, 10, 7, 5, 6, 1, 1, 2, 5, 4, 3, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 7, 22, 47, 80, 82, 111, 121, 132, 164, 166, 216, 190, 213, 216, 209, 223, 210, 202, 168, 180, 145, 160, 152, 139, 116, 116, 129, 105, 110, 96, 91, 102, 90, 67, 62, 37, 53, 42, 24, 28, 19, 9, 4, 3, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.2, 29.9, 33.8, 36.5, 40.2, 44.0, 47.6, 50.7, 54.1, 57.4, 61.5, 64.7, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 49.9, 24.9, 59.9, 62.4, 49.9, 49.9, 65.2, 63.9, 60.5, 78.9, 84.2, 84.9]
[0, 0, 0, 0, 0, 0, 0, 1, 6, 4, 10, 8, 18, 32, 46, 50, 38, 57, 57, 53]
Epoch 371 Acc: 95.64 BMA: 96.63 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 509 train Loss: 5234.0 test Loss: 688.2
Epoch 372 Iter 0 subLoss 4759.9 multi 6.97 import weight 0.00
Epoch 372 Iter 1 subLoss 5242.9 multi 1.00 import weight 0.00
Epoch 372 Iter 2 subLoss 4916.5 multi -10.94 import weight 0.00
Epoch 372 Iter 3 subLoss 5100.2 multi 3.99 import weight 0.00
Epoch 372 Iter 4 subLoss 5292.5 multi 3.99 import weight 0.00
Epoch 372 Iter 5 subLoss 5194.8 multi 1.00 import weight 0.00
Epoch 372 Iter 6 subLoss 5377.5 multi -7.96 import weight 0.00
Epoch 372 Iter 7 subLoss 5227.8 multi 15.93 import weight 0.00
Epoch 372 Iter 8 subLoss 4595.7 multi -1.98 import weight 0.00
Epoch 372 Iter 9 subLoss 4832.7 multi -4.97 import weight 0.00
Epoch 372 Iter 10 subLoss 4922.3 multi 6.97 import weight 0.00
Epoch 372 Iter 11 subLoss 5162.6 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0115 / 0.10364 / 13.16
Entropy seen (from low to high)
[350, 481, 1184, 569, 315, 185, 148, 110, 120, 112, 127, 129, 139, 121, 108, 85, 76, 48, 79, 59, 54, 62, 48, 51, 52, 56, 37, 48, 25, 30, 17, 28, 14, 16, 12, 10, 7, 5, 6, 1, 1, 2, 5, 5, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 7, 22, 47, 84, 80, 107, 122, 139, 160, 163, 218, 197, 204, 214, 211, 225, 212, 200, 165, 184, 139, 160, 158, 135, 121, 115, 122, 105, 112, 96, 89, 109, 86, 69, 64, 36, 51, 43, 25, 26, 20, 9, 4, 3, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.1, 30.0, 33.8, 36.6, 40.2, 44.0, 47.6, 50.8, 54.3, 57.6, 61.5, 64.7, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 49.9, 24.9, 59.9, 62.4, 49.9, 51.6, 65.3, 62.4, 59.9, 79.2, 84.2, 84.2]
[0, 0, 0, 0, 0, 0, 0, 1, 6, 4, 10, 8, 18, 31, 49, 48, 40, 53, 57, 57]
Epoch 372 Acc: 96.13 BMA: 96.63 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 516 train Loss: 4962.5 test Loss: 629.3
Epoch 373 Iter 0 subLoss 4630.4 multi 12.94 import weight 0.00
Epoch 373 Iter 1 subLoss 4458.1 multi 18.91 import weight 0.00
Epoch 373 Iter 2 subLoss 5038.5 multi -1.99 import weight 0.00
Epoch 373 Iter 3 subLoss 4859.1 multi -4.97 import weight 0.00
Epoch 373 Iter 4 subLoss 5631.7 multi -16.91 import weight 0.00
Epoch 373 Iter 5 subLoss 13385.8 multi 1.00 import weight 0.00
Epoch 373 Iter 6 subLoss 8303.3 multi 3.98 import weight 0.00
Epoch 373 Iter 7 subLoss 4958.4 multi 12.94 import weight 0.00
Epoch 373 Iter 8 subLoss 4495.4 multi -1.98 import weight 0.00
Epoch 373 Iter 9 subLoss 4812.1 multi -7.96 import weight 0.00
Epoch 373 Iter 10 subLoss 4831.8 multi -1.99 import weight 0.00
Epoch 373 Iter 11 subLoss 5255.0 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0115 / 0.10371 / 13.29
Entropy seen (from low to high)
[353, 489, 1174, 573, 313, 183, 150, 109, 124, 112, 130, 132, 134, 121, 103, 92, 69, 51, 78, 57, 52, 63, 49, 50, 54, 53, 40, 45, 24, 33, 17, 26, 15, 15, 13, 9, 7, 4, 7, 1, 1, 2, 5, 5, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 7, 22, 47, 84, 84, 103, 118, 146, 161, 157, 225, 189, 211, 202, 222, 217, 208, 202, 168, 182, 142, 161, 157, 137, 122, 111, 123, 103, 115, 91, 95, 109, 84, 70, 63, 39, 51, 43, 24, 27, 20, 8, 5, 3, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.0, 30.1, 33.8, 36.8, 40.6, 44.1, 47.5, 50.6, 54.1, 57.4, 61.4, 64.7, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 49.9, 24.9, 54.5, 62.4, 47.0, 58.6, 63.8, 59.1, 61.9, 80.3, 84.9, 83.6]
[0, 0, 0, 0, 0, 0, 0, 1, 6, 4, 11, 8, 17, 29, 47, 49, 42, 51, 60, 55]
Epoch 373 Acc: 96.07 BMA: 96.63 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 525 train Loss: 4762.5 test Loss: 607.1
Epoch 374 Iter 0 subLoss 3969.0 multi -10.94 import weight 0.00
Epoch 374 Iter 1 subLoss 5239.9 multi -13.93 import weight 0.00
Epoch 374 Iter 2 subLoss 4814.2 multi -4.97 import weight 0.00
Epoch 374 Iter 3 subLoss 5773.8 multi 3.98 import weight 0.00
Epoch 374 Iter 4 subLoss 5297.3 multi 6.97 import weight 0.00
Epoch 374 Iter 5 subLoss 4951.0 multi 15.93 import weight 0.00
Epoch 374 Iter 6 subLoss 5070.2 multi -1.98 import weight 0.00
Epoch 374 Iter 7 subLoss 4769.3 multi -16.91 import weight 0.00
Epoch 374 Iter 8 subLoss 4862.3 multi -1.98 import weight 0.00
Epoch 374 Iter 9 subLoss 5439.8 multi 9.96 import weight 0.00
Epoch 374 Iter 10 subLoss 4408.7 multi 18.91 import weight 0.00
Epoch 374 Iter 11 subLoss 5153.5 multi 15.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0115 / 0.10376 / 13.09
Entropy seen (from low to high)
[355, 500, 1169, 574, 304, 188, 149, 110, 122, 116, 133, 130, 141, 113, 100, 91, 68, 52, 78, 56, 54, 60, 50, 50, 52, 53, 44, 41, 25, 32, 17, 26, 15, 15, 13, 9, 6, 5, 7, 1, 1, 2, 5, 5, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 7, 22, 46, 82, 88, 99, 123, 144, 159, 165, 229, 182, 205, 205, 223, 211, 216, 193, 170, 188, 139, 157, 156, 138, 120, 112, 124, 103, 111, 100, 92, 111, 78, 76, 66, 38, 49, 44, 24, 26, 21, 8, 5, 3, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.8, 30.1, 33.9, 37.0, 40.9, 44.2, 47.7, 50.6, 54.0, 57.3, 61.5, 64.9, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 49.9, 24.9, 58.3, 57.1, 44.4, 58.6, 63.6, 61.9, 61.9, 79.2, 80.9, 86.7]
[0, 0, 0, 0, 0, 0, 0, 1, 6, 4, 12, 7, 18, 29, 44, 50, 42, 53, 63, 53]
Epoch 374 Acc: 96.38 BMA: 96.63 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 15.93 Pidx 515 train Loss: 4571.9 test Loss: 581.3
Epoch 375 Iter 0 subLoss 4028.3 multi 1.00 import weight 0.00
Epoch 375 Iter 1 subLoss 4179.5 multi -7.96 import weight 0.00
Epoch 375 Iter 2 subLoss 4959.0 multi 18.91 import weight 0.00
Epoch 375 Iter 3 subLoss 5210.4 multi -7.96 import weight 0.00
Epoch 375 Iter 4 subLoss 6991.7 multi 1.00 import weight 0.00
Epoch 375 Iter 5 subLoss 5974.8 multi -4.97 import weight 0.00
Epoch 375 Iter 6 subLoss 9891.0 multi 3.99 import weight 0.00
Epoch 375 Iter 7 subLoss 5370.2 multi -4.97 import weight 0.00
Epoch 375 Iter 8 subLoss 7321.8 multi -13.93 import weight 0.00
Epoch 375 Iter 9 subLoss 21920.0 multi 1.00 import weight 0.00
Epoch 375 Iter 10 subLoss 16215.6 multi 1.00 import weight 0.00
Epoch 375 Iter 11 subLoss 12179.8 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0115 / 0.10362 / 13.26
Entropy seen (from low to high)
[350, 483, 1137, 572, 318, 194, 153, 125, 127, 121, 132, 127, 146, 110, 105, 93, 69, 54, 75, 59, 55, 56, 52, 53, 52, 50, 47, 37, 26, 31, 21, 24, 14, 15, 12, 10, 7, 5, 7, 0, 1, 3, 3, 6, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 7, 21, 47, 79, 89, 103, 120, 149, 156, 159, 228, 184, 208, 212, 216, 213, 215, 188, 181, 178, 138, 167, 153, 140, 122, 123, 114, 110, 104, 99, 98, 104, 91, 64, 66, 46, 43, 41, 29, 21, 17, 7, 5, 3, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.2, 30.3, 33.8, 37.0, 40.1, 43.9, 47.6, 50.6, 54.1, 57.4, 61.5, 64.8, 68.4]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 49.9, 24.9, 63.6, 49.9, 49.9, 57.1, 65.2, 62.7, 58.5, 82.3, 81.8, 83.3]
[0, 0, 0, 0, 0, 0, 0, 1, 6, 4, 11, 6, 20, 28, 46, 51, 41, 51, 66, 54]
Epoch 375 Acc: 85.97 BMA: 96.67 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1217 train Loss: 12033.3 test Loss: 2324.8
Epoch 376 Iter 0 subLoss 11386.6 multi 6.97 import weight 0.00
Epoch 376 Iter 1 subLoss 6449.9 multi -4.97 import weight 0.00
Epoch 376 Iter 2 subLoss 8229.6 multi 1.00 import weight 0.00
Epoch 376 Iter 3 subLoss 7307.1 multi -4.97 import weight 0.00
Epoch 376 Iter 4 subLoss 8941.1 multi 6.97 import weight 0.00
Epoch 376 Iter 5 subLoss 6034.5 multi -10.94 import weight 0.00
Epoch 376 Iter 6 subLoss 8333.9 multi -1.98 import weight 0.00
Epoch 376 Iter 7 subLoss 8919.5 multi -4.97 import weight 0.00
Epoch 376 Iter 8 subLoss 11193.9 multi 3.99 import weight 0.00
Epoch 376 Iter 9 subLoss 9007.6 multi -1.99 import weight 0.00
Epoch 376 Iter 10 subLoss 10201.6 multi 1.00 import weight 0.00
Epoch 376 Iter 11 subLoss 9094.9 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0115 / 0.10363 / 13.37
Entropy seen (from low to high)
[354, 476, 1121, 569, 312, 204, 152, 130, 128, 128, 133, 129, 150, 113, 93, 103, 66, 54, 74, 57, 60, 56, 48, 57, 50, 50, 44, 40, 28, 31, 19, 24, 15, 15, 12, 9, 7, 6, 7, 0, 1, 3, 3, 6, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 7, 21, 46, 78, 90, 101, 125, 149, 153, 156, 225, 193, 204, 210, 217, 217, 217, 178, 185, 175, 146, 161, 153, 136, 133, 118, 116, 110, 102, 99, 102, 100, 94, 69, 63, 46, 41, 43, 31, 17, 15, 8, 5, 3, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.2, 30.4, 33.8, 37.1, 40.1, 43.9, 47.4, 50.6, 54.3, 57.5, 61.5, 64.8, 68.4]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 49.9, 24.9, 63.6, 49.9, 52.6, 55.5, 59.9, 68.6, 57.4, 82.6, 82.8, 82.1]
[0, 0, 0, 0, 0, 0, 0, 1, 6, 4, 11, 6, 19, 27, 50, 51, 40, 52, 64, 56]
Epoch 376 Acc: 90.10 BMA: 96.71 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 909 train Loss: 8787.0 test Loss: 1628.2
Epoch 377 Iter 0 subLoss 7460.3 multi -4.97 import weight 0.00
Epoch 377 Iter 1 subLoss 10653.8 multi 1.00 import weight 0.00
Epoch 377 Iter 2 subLoss 9968.0 multi 1.00 import weight 0.00
Epoch 377 Iter 3 subLoss 10130.8 multi -1.99 import weight 0.00
Epoch 377 Iter 4 subLoss 10831.4 multi 6.97 import weight 0.00
Epoch 377 Iter 5 subLoss 7131.2 multi -10.94 import weight 0.00
Epoch 377 Iter 6 subLoss 10856.1 multi 3.99 import weight 0.00
Epoch 377 Iter 7 subLoss 8162.6 multi 3.99 import weight 0.00
Epoch 377 Iter 8 subLoss 7620.2 multi 6.97 import weight 0.00
Epoch 377 Iter 9 subLoss 5583.6 multi 9.96 import weight 0.00
Epoch 377 Iter 10 subLoss 5380.9 multi -19.90 import weight 0.00
Epoch 377 Iter 11 subLoss 6388.9 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0115 / 0.10365 / 13.62
Entropy seen (from low to high)
[358, 475, 1120, 573, 309, 198, 155, 130, 127, 131, 133, 133, 146, 113, 90, 103, 65, 61, 68, 58, 61, 55, 47, 60, 46, 52, 45, 38, 27, 33, 19, 22, 17, 15, 12, 9, 7, 6, 7, 0, 2, 2, 3, 6, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 8, 20, 47, 81, 91, 97, 127, 151, 149, 157, 225, 193, 203, 208, 220, 216, 214, 178, 185, 178, 143, 168, 140, 142, 136, 112, 120, 110, 101, 99, 106, 96, 93, 71, 64, 45, 41, 45, 29, 18, 15, 8, 5, 3, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.1, 30.3, 32.9, 36.9, 40.3, 44.1, 47.5, 50.7, 54.4, 57.7, 61.5, 64.8, 68.4]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 39.9, 24.9, 63.6, 55.5, 52.9, 55.1, 63.2, 67.9, 56.4, 80.8, 83.8, 81.8]
[0, 0, 0, 0, 0, 0, 0, 1, 5, 4, 11, 9, 17, 29, 49, 53, 39, 47, 68, 55]
Epoch 377 Acc: 94.43 BMA: 96.71 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 638 train Loss: 5911.4 test Loss: 869.2
Epoch 378 Iter 0 subLoss 5830.8 multi -4.97 import weight 0.00
Epoch 378 Iter 1 subLoss 6147.6 multi 15.93 import weight 0.00
Epoch 378 Iter 2 subLoss 5050.0 multi 12.94 import weight 0.00
Epoch 378 Iter 3 subLoss 4673.9 multi -13.93 import weight 0.00
Epoch 378 Iter 4 subLoss 5220.2 multi 15.93 import weight 0.00
Epoch 378 Iter 5 subLoss 5080.5 multi 6.97 import weight 0.00
Epoch 378 Iter 6 subLoss 4133.0 multi -13.93 import weight 0.00
Epoch 378 Iter 7 subLoss 4711.1 multi -7.96 import weight 0.00
Epoch 378 Iter 8 subLoss 5138.6 multi 6.97 import weight 0.00
Epoch 378 Iter 9 subLoss 4583.2 multi -16.91 import weight 0.00
Epoch 378 Iter 10 subLoss 5580.0 multi 12.94 import weight 0.00
Epoch 378 Iter 11 subLoss 4660.3 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0115 / 0.10370 / 14.63
Entropy seen (from low to high)
[361, 474, 1124, 568, 310, 198, 154, 132, 126, 137, 126, 134, 153, 113, 83, 103, 65, 64, 64, 58, 63, 53, 49, 56, 51, 50, 46, 35, 27, 33, 19, 22, 18, 15, 11, 9, 8, 4, 8, 0, 2, 2, 3, 6, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 8, 20, 46, 83, 90, 98, 127, 152, 147, 162, 227, 182, 207, 209, 221, 216, 213, 173, 190, 173, 138, 175, 142, 144, 125, 117, 121, 112, 97, 101, 105, 98, 93, 73, 61, 49, 40, 44, 28, 20, 15, 8, 5, 3, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.9, 30.4, 33.0, 36.7, 39.9, 43.9, 47.3, 50.7, 54.4, 57.7, 61.5, 64.8, 68.4]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 39.9, 24.9, 59.9, 55.5, 58.8, 58.6, 61.9, 69.2, 52.4, 82.9, 85.2, 79.6]
[0, 0, 0, 0, 0, 0, 0, 1, 5, 4, 10, 9, 17, 29, 50, 52, 40, 47, 68, 54]
Epoch 378 Acc: 95.74 BMA: 96.71 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 466 train Loss: 4743.3 test Loss: 659.1
Epoch 379 Iter 0 subLoss 4770.5 multi 6.97 import weight 0.00
Epoch 379 Iter 1 subLoss 4492.6 multi 1.00 import weight 0.00
Epoch 379 Iter 2 subLoss 4562.2 multi -13.93 import weight 0.00
Epoch 379 Iter 3 subLoss 5042.6 multi 15.93 import weight 0.00
Epoch 379 Iter 4 subLoss 4646.9 multi 6.97 import weight 0.00
Epoch 379 Iter 5 subLoss 4064.5 multi 3.99 import weight 0.00
Epoch 379 Iter 6 subLoss 4398.5 multi -1.98 import weight 0.00
Epoch 379 Iter 7 subLoss 3884.7 multi -16.91 import weight 0.00
Epoch 379 Iter 8 subLoss 4772.3 multi 9.96 import weight 0.00
Epoch 379 Iter 9 subLoss 3939.3 multi 6.97 import weight 0.00
Epoch 379 Iter 10 subLoss 4496.7 multi 3.99 import weight 0.00
Epoch 379 Iter 11 subLoss 4538.4 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0115 / 0.10379 / 14.53
Entropy seen (from low to high)
[364, 482, 1118, 567, 307, 200, 155, 131, 131, 134, 125, 139, 152, 114, 77, 106, 61, 69, 61, 56, 65, 50, 49, 55, 54, 49, 47, 34, 27, 33, 17, 23, 17, 15, 11, 9, 8, 4, 8, 0, 2, 2, 3, 6, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 7, 21, 44, 85, 91, 95, 126, 155, 148, 163, 227, 176, 208, 206, 229, 209, 209, 178, 188, 175, 142, 173, 139, 145, 125, 114, 121, 113, 97, 99, 106, 98, 94, 77, 62, 49, 39, 45, 28, 21, 15, 8, 5, 3, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.8, 30.4, 33.0, 36.7, 40.2, 44.2, 47.3, 50.7, 54.4, 57.6, 61.4, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 39.9, 24.9, 59.9, 63.6, 59.9, 58.6, 61.2, 67.9, 53.8, 84.7, 83.8, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 5, 4, 10, 11, 15, 29, 49, 53, 39, 46, 68, 55]
Epoch 379 Acc: 96.13 BMA: 96.73 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 453 train Loss: 4465.9 test Loss: 592.8
Epoch 380 Iter 0 subLoss 4584.4 multi -13.93 import weight 0.00
Epoch 380 Iter 1 subLoss 4159.8 multi 15.93 import weight 0.00
Epoch 380 Iter 2 subLoss 4303.0 multi 6.97 import weight 0.00
Epoch 380 Iter 3 subLoss 4249.3 multi 3.99 import weight 0.00
Epoch 380 Iter 4 subLoss 4488.4 multi 1.00 import weight 0.00
Epoch 380 Iter 5 subLoss 4314.6 multi -22.88 import weight 0.00
Epoch 380 Iter 6 subLoss 4376.9 multi 6.97 import weight 0.00
Epoch 380 Iter 7 subLoss 3884.4 multi -13.93 import weight 0.00
Epoch 380 Iter 8 subLoss 4348.0 multi 6.97 import weight 0.00
Epoch 380 Iter 9 subLoss 4520.1 multi -13.93 import weight 0.00
Epoch 380 Iter 10 subLoss 5600.4 multi 6.97 import weight 0.00
Epoch 380 Iter 11 subLoss 4369.6 multi -16.91 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0114 / 0.10389 / 14.49
Entropy seen (from low to high)
[364, 488, 1125, 558, 313, 196, 155, 130, 134, 134, 119, 145, 148, 112, 83, 103, 61, 67, 59, 55, 66, 51, 48, 59, 50, 49, 44, 37, 25, 33, 18, 23, 17, 16, 10, 9, 8, 5, 7, 0, 3, 1, 3, 6, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 7, 20, 45, 83, 89, 98, 125, 155, 148, 162, 230, 174, 203, 211, 228, 210, 205, 179, 191, 176, 133, 179, 134, 149, 126, 113, 117, 116, 100, 97, 106, 98, 97, 77, 63, 49, 38, 46, 27, 22, 15, 9, 5, 3, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.7, 30.6, 33.4, 37.1, 40.4, 44.3, 47.3, 50.7, 54.5, 57.8, 61.5, 64.7, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 39.9, 39.9, 49.9, 69.9, 73.3, 49.9, 63.9, 66.6, 53.8, 86.3, 83.3, 80.3]
[0, 0, 0, 0, 0, 0, 0, 1, 5, 5, 10, 10, 15, 28, 50, 54, 39, 44, 66, 56]
Epoch 380 Acc: 96.13 BMA: 96.71 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -16.91 Pidx 436 train Loss: 4696.9 test Loss: 577.4
Epoch 381 Iter 0 subLoss 4681.0 multi 21.90 import weight 0.00
Epoch 381 Iter 1 subLoss 4144.6 multi 6.97 import weight 0.00
Epoch 381 Iter 2 subLoss 5190.4 multi 3.99 import weight 0.00
Epoch 381 Iter 3 subLoss 4352.5 multi 1.00 import weight 0.00
Epoch 381 Iter 4 subLoss 4102.1 multi -4.97 import weight 0.00
Epoch 381 Iter 5 subLoss 4119.1 multi -1.98 import weight 0.00
Epoch 381 Iter 6 subLoss 4455.3 multi 21.90 import weight 0.00
Epoch 381 Iter 7 subLoss 4241.5 multi 6.97 import weight 0.00
Epoch 381 Iter 8 subLoss 3933.2 multi 9.96 import weight 0.00
Epoch 381 Iter 9 subLoss 4923.1 multi 9.96 import weight 0.00
Epoch 381 Iter 10 subLoss 4009.4 multi 3.99 import weight 0.00
Epoch 381 Iter 11 subLoss 3807.3 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0114 / 0.10399 / 14.64
Entropy seen (from low to high)
[367, 495, 1130, 553, 307, 193, 158, 132, 133, 134, 124, 143, 148, 108, 85, 101, 58, 69, 61, 53, 68, 47, 47, 61, 50, 49, 43, 38, 26, 31, 19, 21, 17, 16, 11, 9, 8, 4, 7, 0, 3, 1, 3, 6, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 7, 20, 45, 80, 92, 96, 127, 149, 154, 162, 225, 177, 200, 210, 229, 214, 198, 186, 185, 175, 134, 179, 141, 147, 124, 113, 117, 115, 102, 100, 105, 93, 100, 72, 70, 48, 39, 45, 28, 23, 14, 10, 5, 3, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.6, 30.6, 33.6, 37.3, 40.4, 44.2, 47.2, 50.7, 54.5, 57.8, 61.4, 64.7, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 39.9, 49.9, 44.4, 69.9, 71.4, 51.7, 63.2, 66.6, 53.8, 86.0, 83.5, 81.8]
[0, 0, 0, 0, 0, 0, 0, 1, 5, 6, 9, 10, 14, 29, 49, 54, 39, 43, 67, 55]
Epoch 381 Acc: 96.83 BMA: 96.69 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 380 train Loss: 3995.7 test Loss: 517.7
Epoch 382 Iter 0 subLoss 3772.0 multi -1.98 import weight 0.00
Epoch 382 Iter 1 subLoss 4297.5 multi -7.96 import weight 0.00
Epoch 382 Iter 2 subLoss 3683.8 multi 6.97 import weight 0.00
Epoch 382 Iter 3 subLoss 4441.0 multi -7.96 import weight 0.00
Epoch 382 Iter 4 subLoss 4053.8 multi 9.96 import weight 0.00
Epoch 382 Iter 5 subLoss 3768.3 multi 9.96 import weight 0.00
Epoch 382 Iter 6 subLoss 4108.5 multi -1.99 import weight 0.00
Epoch 382 Iter 7 subLoss 4510.8 multi 21.90 import weight 0.00
Epoch 382 Iter 8 subLoss 3810.4 multi 21.90 import weight 0.00
Epoch 382 Iter 9 subLoss 3957.2 multi 9.96 import weight 0.00
Epoch 382 Iter 10 subLoss 4124.9 multi 9.96 import weight 0.00
Epoch 382 Iter 11 subLoss 3520.8 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0114 / 0.10410 / 15.87
Entropy seen (from low to high)
[368, 505, 1124, 554, 305, 198, 154, 132, 130, 142, 119, 145, 147, 107, 83, 100, 62, 67, 62, 52, 64, 48, 51, 56, 51, 50, 42, 37, 28, 29, 21, 20, 16, 16, 12, 8, 8, 3, 8, 0, 3, 1, 3, 6, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 7, 19, 46, 80, 90, 95, 127, 148, 154, 168, 219, 178, 197, 213, 226, 211, 200, 190, 184, 173, 137, 173, 150, 141, 123, 109, 121, 111, 111, 98, 104, 95, 98, 78, 63, 53, 39, 44, 30, 22, 15, 10, 5, 3, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.5, 30.6, 33.7, 37.2, 40.4, 44.4, 47.4, 50.7, 54.3, 57.6, 61.5, 64.8, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 39.9, 49.9, 55.5, 69.9, 66.6, 56.6, 59.0, 70.3, 48.7, 86.9, 84.1, 81.8]
[0, 0, 0, 0, 0, 0, 0, 1, 5, 6, 9, 10, 15, 30, 44, 54, 41, 46, 63, 55]
Epoch 382 Acc: 96.69 BMA: 96.69 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 352 train Loss: 3920.2 test Loss: 543.7
Epoch 383 Iter 0 subLoss 4011.4 multi -1.98 import weight 0.00
Epoch 383 Iter 1 subLoss 4238.1 multi -28.85 import weight 0.00
Epoch 383 Iter 2 subLoss 5555.5 multi 9.96 import weight 0.00
Epoch 383 Iter 3 subLoss 4282.7 multi -13.93 import weight 0.00
Epoch 383 Iter 4 subLoss 4907.5 multi 3.99 import weight 0.00
Epoch 383 Iter 5 subLoss 4807.4 multi 27.87 import weight 0.00
Epoch 383 Iter 6 subLoss 6058.6 multi -1.99 import weight 0.00
Epoch 383 Iter 7 subLoss 8882.1 multi -4.97 import weight 0.00
Epoch 383 Iter 8 subLoss 74037.4 multi 1.00 import weight 0.00
Epoch 383 Iter 9 subLoss 6109.9 multi 12.94 import weight 0.00
Epoch 383 Iter 10 subLoss 4722.3 multi 1.00 import weight 0.00
Epoch 383 Iter 11 subLoss 4596.3 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0114 / 0.10405 / 16.13
Entropy seen (from low to high)
[377, 509, 1123, 549, 302, 202, 149, 136, 130, 144, 113, 147, 145, 106, 87, 98, 57, 70, 59, 56, 61, 48, 52, 56, 50, 49, 43, 37, 28, 27, 22, 20, 18, 16, 10, 9, 8, 4, 7, 0, 3, 1, 3, 6, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 7, 20, 44, 80, 92, 95, 129, 145, 154, 172, 215, 183, 198, 208, 226, 213, 201, 188, 186, 176, 139, 166, 152, 139, 126, 106, 122, 111, 104, 101, 103, 100, 95, 77, 63, 52, 41, 44, 30, 22, 15, 10, 5, 3, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 30.6, 33.3, 37.1, 40.3, 44.3, 47.2, 50.7, 54.3, 57.6, 61.2, 64.7, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 39.9, 39.9, 49.9, 69.9, 73.3, 55.1, 59.9, 69.6, 47.2, 84.4, 84.2, 83.9]
[0, 0, 0, 0, 0, 0, 0, 1, 5, 5, 10, 10, 15, 29, 45, 56, 36, 45, 70, 50]
Epoch 383 Acc: 95.15 BMA: 96.69 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 459 train Loss: 5199.7 test Loss: 762.5
Epoch 384 Iter 0 subLoss 5223.7 multi 18.91 import weight 0.00
Epoch 384 Iter 1 subLoss 4550.5 multi 12.94 import weight 0.00
Epoch 384 Iter 2 subLoss 4421.0 multi 15.93 import weight 1.00
Epoch 384 Iter 3 subLoss 4421.2 multi 18.91 import weight 1.00
Epoch 384 Iter 4 subLoss 4288.2 multi -10.94 import weight 0.00
Epoch 384 Iter 5 subLoss 4794.2 multi 1.00 import weight 0.00
Epoch 384 Iter 6 subLoss 5042.3 multi 18.91 import weight 0.00
Epoch 384 Iter 7 subLoss 4894.3 multi 3.99 import weight 0.00
Epoch 384 Iter 8 subLoss 4451.3 multi 21.90 import weight 0.00
Epoch 384 Iter 9 subLoss 3887.0 multi -10.94 import weight 0.00
Epoch 384 Iter 10 subLoss 6800.3 multi 12.94 import weight 0.00
Epoch 384 Iter 11 subLoss 5894.0 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0114 / 0.10414 / 16.57
Entropy seen (from low to high)
[380, 521, 1121, 538, 304, 197, 150, 142, 122, 151, 111, 148, 147, 100, 89, 95, 62, 67, 61, 56, 62, 45, 53, 54, 53, 46, 43, 36, 29, 28, 22, 18, 19, 16, 10, 9, 9, 3, 7, 0, 3, 1, 3, 6, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 7, 19, 46, 79, 89, 97, 129, 144, 153, 172, 213, 187, 196, 207, 226, 213, 203, 182, 191, 171, 137, 168, 150, 144, 124, 104, 127, 113, 100, 104, 100, 98, 101, 80, 57, 57, 40, 46, 30, 21, 15, 10, 5, 3, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.6, 30.6, 33.2, 37.1, 40.3, 44.3, 47.3, 50.8, 54.3, 57.6, 61.4, 64.8, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 39.9, 39.9, 49.9, 69.9, 71.4, 56.2, 61.3, 71.6, 44.9, 86.6, 83.5, 82.6]
[0, 0, 0, 0, 0, 0, 0, 1, 5, 5, 10, 10, 14, 32, 44, 53, 40, 45, 67, 52]
Epoch 384 Acc: 95.17 BMA: 96.69 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 589 train Loss: 4633.0 test Loss: 731.6
Epoch 385 Iter 0 subLoss 4341.4 multi 9.96 import weight 0.00
Epoch 385 Iter 1 subLoss 3761.6 multi 12.94 import weight 0.00
Epoch 385 Iter 2 subLoss 3654.7 multi -1.99 import weight 0.00
Epoch 385 Iter 3 subLoss 3538.0 multi 3.99 import weight 0.00
Epoch 385 Iter 4 subLoss 3897.4 multi -1.99 import weight 0.00
Epoch 385 Iter 5 subLoss 3546.5 multi -7.96 import weight 0.00
Epoch 385 Iter 6 subLoss 4060.7 multi 3.98 import weight 0.00
Epoch 385 Iter 7 subLoss 3809.7 multi 3.99 import weight 0.00
Epoch 385 Iter 8 subLoss 4098.2 multi 1.00 import weight 0.00
Epoch 385 Iter 9 subLoss 3833.3 multi -1.98 import weight 0.00
Epoch 385 Iter 10 subLoss 3835.6 multi 1.00 import weight 0.00
Epoch 385 Iter 11 subLoss 3847.5 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.10426 / 15.40
Entropy seen (from low to high)
[381, 535, 1114, 538, 300, 197, 151, 141, 123, 154, 111, 147, 145, 101, 94, 90, 60, 68, 60, 54, 60, 48, 51, 53, 54, 44, 48, 33, 28, 28, 22, 22, 16, 15, 10, 11, 7, 4, 6, 0, 3, 1, 3, 6, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 7, 19, 46, 78, 91, 92, 132, 142, 151, 173, 214, 183, 191, 214, 221, 216, 205, 180, 190, 172, 144, 163, 150, 144, 124, 103, 130, 108, 102, 104, 99, 103, 100, 78, 62, 56, 42, 45, 30, 20, 16, 10, 5, 3, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.5, 30.6, 33.2, 37.1, 40.3, 44.4, 47.4, 50.8, 54.3, 57.5, 61.5, 64.7, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 39.9, 39.9, 39.9, 69.9, 71.4, 54.5, 61.9, 69.8, 48.7, 86.3, 83.0, 82.6]
[0, 0, 0, 0, 0, 0, 0, 1, 5, 5, 10, 10, 14, 33, 42, 53, 41, 44, 65, 52]
Epoch 385 Acc: 96.79 BMA: 96.69 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 384 train Loss: 3892.4 test Loss: 498.9
Epoch 386 Iter 0 subLoss 3997.7 multi -4.97 import weight 0.00
Epoch 386 Iter 1 subLoss 3555.7 multi 6.97 import weight 0.00
Epoch 386 Iter 2 subLoss 3315.4 multi 3.99 import weight 0.00
Epoch 386 Iter 3 subLoss 4270.5 multi 24.88 import weight 0.00
Epoch 386 Iter 4 subLoss 4437.3 multi -31.84 import weight 0.00
Epoch 386 Iter 5 subLoss 19841.7 multi 1.00 import weight 0.00
Epoch 386 Iter 6 subLoss 6556.3 multi -1.99 import weight 0.00
Epoch 386 Iter 7 subLoss 9054.9 multi 3.98 import weight 0.00
Epoch 386 Iter 8 subLoss 4152.1 multi 15.93 import weight 0.00
Epoch 386 Iter 9 subLoss 3444.4 multi 3.98 import weight 0.00
Epoch 386 Iter 10 subLoss 3911.2 multi 6.97 import weight 0.00
Epoch 386 Iter 11 subLoss 3776.9 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.10439 / 16.02
Entropy seen (from low to high)
[382, 541, 1117, 532, 304, 192, 151, 144, 124, 151, 115, 150, 142, 99, 100, 82, 59, 67, 58, 59, 60, 43, 52, 58, 49, 46, 46, 31, 30, 28, 21, 23, 15, 15, 10, 11, 7, 4, 6, 0, 3, 1, 3, 6, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 7, 19, 45, 78, 89, 93, 129, 142, 154, 166, 215, 185, 191, 219, 210, 217, 212, 181, 184, 170, 150, 157, 154, 140, 124, 112, 123, 112, 105, 103, 94, 105, 103, 78, 63, 57, 42, 45, 31, 19, 17, 10, 5, 3, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.5, 30.7, 33.3, 37.1, 40.3, 44.2, 47.2, 50.7, 54.2, 57.4, 61.5, 64.8, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 39.9, 19.9, 49.9, 69.9, 66.6, 57.1, 60.5, 70.9, 46.3, 83.3, 86.8, 80.3]
[0, 0, 0, 0, 0, 0, 0, 1, 5, 5, 10, 10, 12, 35, 38, 55, 41, 48, 61, 56]
Epoch 386 Acc: 96.59 BMA: 96.71 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 377 train Loss: 3924.3 test Loss: 516.3
Epoch 387 Iter 0 subLoss 3413.2 multi 1.00 import weight 0.00
Epoch 387 Iter 1 subLoss 3791.1 multi -4.97 import weight 0.00
Epoch 387 Iter 2 subLoss 3556.5 multi 9.96 import weight 0.00
Epoch 387 Iter 3 subLoss 4356.5 multi 1.00 import weight 0.00
Epoch 387 Iter 4 subLoss 3531.6 multi 6.97 import weight 0.00
Epoch 387 Iter 5 subLoss 3683.1 multi 9.96 import weight 0.00
Epoch 387 Iter 6 subLoss 3534.0 multi 9.96 import weight 0.00
Epoch 387 Iter 7 subLoss 3867.8 multi 9.96 import weight 0.00
Epoch 387 Iter 8 subLoss 3332.9 multi -1.98 import weight 0.00
Epoch 387 Iter 9 subLoss 4189.3 multi 6.97 import weight 0.00
Epoch 387 Iter 10 subLoss 3782.1 multi -1.99 import weight 0.00
Epoch 387 Iter 11 subLoss 4041.5 multi -10.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.10450 / 15.82
Entropy seen (from low to high)
[382, 551, 1117, 523, 309, 189, 151, 147, 124, 151, 120, 149, 136, 102, 101, 79, 58, 71, 57, 55, 59, 45, 49, 62, 47, 47, 43, 30, 31, 28, 20, 24, 14, 14, 12, 9, 8, 3, 7, 0, 3, 1, 3, 6, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 7, 20, 44, 78, 88, 91, 129, 140, 156, 169, 209, 182, 195, 221, 205, 211, 221, 180, 182, 170, 153, 154, 158, 137, 125, 113, 124, 108, 111, 94, 100, 102, 104, 81, 65, 58, 42, 46, 31, 18, 17, 11, 5, 3, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 30.7, 33.4, 37.1, 40.1, 44.1, 47.3, 50.6, 54.2, 57.4, 61.5, 64.7, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 39.9, 19.9, 49.9, 66.6, 69.2, 59.9, 55.5, 71.9, 46.3, 79.9, 88.7, 79.6]
[0, 0, 0, 0, 0, 0, 0, 1, 5, 5, 10, 9, 13, 35, 36, 57, 41, 45, 62, 54]
Epoch 387 Acc: 96.79 BMA: 96.71 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -10.94 Pidx 404 train Loss: 3829.6 test Loss: 507.9
Epoch 388 Iter 0 subLoss 4074.7 multi -19.90 import weight 0.00
Epoch 388 Iter 1 subLoss 4301.0 multi 6.97 import weight 0.00
Epoch 388 Iter 2 subLoss 4346.3 multi 12.94 import weight 0.00
Epoch 388 Iter 3 subLoss 3562.9 multi -1.99 import weight 0.00
Epoch 388 Iter 4 subLoss 3886.6 multi -7.96 import weight 0.00
Epoch 388 Iter 5 subLoss 3940.0 multi -10.94 import weight 0.00
Epoch 388 Iter 6 subLoss 3691.4 multi -4.97 import weight 0.00
Epoch 388 Iter 7 subLoss 3588.8 multi -10.94 import weight 0.00
Epoch 388 Iter 8 subLoss 5261.7 multi -1.98 import weight 0.00
Epoch 388 Iter 9 subLoss 5960.0 multi 6.97 import weight 0.00
Epoch 388 Iter 10 subLoss 4322.4 multi 12.94 import weight 0.00
Epoch 388 Iter 11 subLoss 4138.6 multi -13.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.10458 / 15.62
Entropy seen (from low to high)
[384, 558, 1113, 525, 309, 185, 148, 151, 125, 151, 127, 141, 138, 101, 98, 81, 58, 68, 58, 59, 55, 44, 49, 59, 49, 46, 43, 32, 31, 27, 20, 25, 13, 14, 12, 9, 8, 3, 7, 0, 3, 1, 3, 6, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 7, 21, 44, 77, 89, 88, 129, 143, 151, 168, 208, 183, 203, 212, 208, 214, 216, 179, 184, 167, 158, 151, 162, 132, 129, 111, 128, 101, 111, 103, 95, 100, 109, 78, 66, 58, 43, 47, 30, 19, 17, 11, 5, 3, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 30.7, 33.4, 36.9, 39.9, 43.9, 47.2, 50.7, 54.2, 57.5, 61.5, 64.7, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 39.9, 19.9, 44.4, 59.9, 63.6, 62.1, 55.5, 71.9, 46.3, 79.9, 88.7, 80.3]
[0, 0, 0, 0, 0, 0, 0, 1, 5, 5, 9, 10, 11, 37, 36, 57, 41, 45, 62, 56]
Epoch 388 Acc: 96.36 BMA: 96.71 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -13.93 Pidx 413 train Loss: 4186.7 test Loss: 556.9
Epoch 389 Iter 0 subLoss 3702.0 multi -4.97 import weight 0.00
Epoch 389 Iter 1 subLoss 4387.7 multi -1.99 import weight 0.00
Epoch 389 Iter 2 subLoss 4469.7 multi -13.93 import weight 0.00
Epoch 389 Iter 3 subLoss 6466.3 multi -1.98 import weight 0.00
Epoch 389 Iter 4 subLoss 6795.0 multi -7.96 import weight 0.00
Epoch 389 Iter 5 subLoss 23902.9 multi -1.99 import weight 0.00
Epoch 389 Iter 6 subLoss 112082.9 multi 1.00 import weight 0.00
Epoch 389 Iter 7 subLoss 10308.0 multi 3.99 import weight 0.00
Epoch 389 Iter 8 subLoss 6872.8 multi 6.97 import weight 0.00
Epoch 389 Iter 9 subLoss 4892.9 multi 6.97 import weight 0.00
Epoch 389 Iter 10 subLoss 4800.7 multi 27.87 import weight 0.00
Epoch 389 Iter 11 subLoss 4070.4 multi -16.91 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.10471 / 15.04
Entropy seen (from low to high)
[387, 564, 1113, 512, 318, 182, 148, 158, 120, 153, 131, 148, 126, 103, 92, 79, 61, 67, 59, 59, 54, 44, 48, 64, 46, 47, 42, 30, 34, 24, 22, 22, 15, 13, 11, 10, 8, 2, 8, 0, 3, 1, 3, 6, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 7, 20, 44, 76, 91, 87, 124, 144, 151, 172, 204, 182, 196, 219, 211, 207, 217, 183, 180, 171, 155, 150, 157, 140, 128, 111, 124, 107, 111, 106, 91, 101, 111, 78, 63, 60, 48, 45, 31, 19, 17, 11, 5, 3, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.2, 30.7, 33.5, 36.7, 39.8, 43.9, 47.1, 50.6, 54.3, 57.5, 61.4, 64.5, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 39.9, 19.9, 49.9, 54.5, 49.9, 64.7, 57.8, 71.9, 48.7, 75.6, 90.3, 79.6]
[0, 0, 0, 0, 0, 0, 0, 1, 5, 5, 8, 11, 12, 34, 38, 57, 41, 41, 62, 59]
Epoch 389 Acc: 95.74 BMA: 96.71 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -16.91 Pidx 407 train Loss: 4477.2 test Loss: 636.1
Epoch 390 Iter 0 subLoss 5038.0 multi 1.00 import weight 0.00
Epoch 390 Iter 1 subLoss 4603.5 multi -4.97 import weight 0.00
Epoch 390 Iter 2 subLoss 4822.3 multi -10.94 import weight 0.00
Epoch 390 Iter 3 subLoss 5979.2 multi -4.97 import weight 0.00
Epoch 390 Iter 4 subLoss 14416.5 multi -1.99 import weight 0.00
Epoch 390 Iter 5 subLoss 52754.7 multi 1.00 import weight 0.00
Epoch 390 Iter 6 subLoss 7194.3 multi -16.91 import weight 0.00
Epoch 390 Iter 7 subLoss 123061.4 multi 1.00 import weight 0.00
Epoch 390 Iter 8 subLoss 28532.6 multi -4.97 import weight 0.00
Epoch 390 Iter 9 subLoss 200752.6 multi 1.00 import weight 0.00
Epoch 390 Iter 10 subLoss 33754.8 multi 1.00 import weight 0.00
Epoch 390 Iter 11 subLoss 25149.9 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.10450 / 14.58
Entropy seen (from low to high)
[362, 446, 802, 762, 386, 252, 178, 156, 144, 149, 136, 149, 127, 102, 96, 80, 60, 69, 58, 62, 49, 47, 49, 58, 53, 48, 43, 32, 28, 27, 24, 20, 16, 15, 12, 9, 8, 2, 8, 0, 3, 1, 3, 6, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 7, 21, 46, 76, 88, 93, 124, 142, 155, 176, 205, 176, 205, 211, 211, 219, 206, 179, 189, 170, 153, 150, 157, 136, 128, 112, 134, 106, 103, 106, 98, 103, 104, 79, 66, 57, 52, 37, 25, 23, 16, 7, 4, 3, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.2, 30.5, 33.5, 37.3, 40.1, 43.7, 47.0, 50.5, 54.3, 57.3, 61.3, 64.5, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 49.9, 42.8, 44.4, 55.5, 54.5, 65.7, 56.4, 73.2, 49.9, 74.9, 90.4, 76.6]
[0, 0, 0, 0, 0, 0, 0, 1, 4, 7, 9, 9, 11, 35, 39, 56, 40, 44, 63, 60]
Epoch 390 Acc: 67.25 BMA: 96.71 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2514 train Loss: 20468.2 test Loss: 3895.8
Epoch 391 Iter 0 subLoss 19521.5 multi 6.97 import weight 0.00
Epoch 391 Iter 1 subLoss 6840.0 multi 6.97 import weight 0.00
Epoch 391 Iter 2 subLoss 6262.1 multi -28.85 import weight 0.00
Epoch 391 Iter 3 subLoss 12589.4 multi 6.97 import weight 0.00
Epoch 391 Iter 4 subLoss 7943.6 multi 6.97 import weight 0.00
Epoch 391 Iter 5 subLoss 6382.5 multi 3.99 import weight 0.00
Epoch 391 Iter 6 subLoss 5930.1 multi -4.97 import weight 0.00
Epoch 391 Iter 7 subLoss 6293.1 multi -7.96 import weight 0.00
Epoch 391 Iter 8 subLoss 7172.0 multi 1.00 import weight 0.00
Epoch 391 Iter 9 subLoss 7175.8 multi 3.99 import weight 0.00
Epoch 391 Iter 10 subLoss 6982.1 multi 6.97 import weight 0.00
Epoch 391 Iter 11 subLoss 5847.3 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.10442 / 14.57
Entropy seen (from low to high)
[363, 453, 804, 748, 381, 256, 165, 170, 153, 142, 135, 148, 133, 97, 94, 80, 67, 68, 54, 62, 51, 43, 52, 57, 54, 46, 45, 33, 26, 29, 24, 21, 14, 15, 13, 10, 8, 2, 8, 0, 3, 1, 3, 6, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 7, 21, 46, 79, 87, 92, 127, 145, 148, 179, 205, 183, 211, 204, 211, 219, 205, 177, 188, 170, 154, 148, 157, 139, 122, 112, 136, 103, 101, 105, 102, 102, 105, 78, 70, 49, 57, 35, 25, 24, 16, 7, 4, 3, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.1, 30.5, 33.5, 37.2, 40.2, 44.2, 47.1, 50.5, 54.3, 57.4, 61.3, 64.5, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 49.9, 28.5, 44.4, 49.9, 61.5, 63.6, 54.9, 74.9, 49.9, 76.0, 90.6, 75.8]
[0, 0, 0, 0, 0, 0, 0, 1, 4, 7, 9, 10, 13, 33, 40, 56, 38, 46, 64, 58]
Epoch 391 Acc: 94.59 BMA: 96.75 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 584 train Loss: 5958.0 test Loss: 980.2
Epoch 392 Iter 0 subLoss 5976.9 multi -1.99 import weight 0.00
Epoch 392 Iter 1 subLoss 5543.4 multi -10.94 import weight 0.00
Epoch 392 Iter 2 subLoss 7377.5 multi 6.97 import weight 0.00
Epoch 392 Iter 3 subLoss 6159.1 multi 9.96 import weight 0.00
Epoch 392 Iter 4 subLoss 5432.1 multi 12.94 import weight 0.00
Epoch 392 Iter 5 subLoss 4307.5 multi 9.96 import weight 0.00
Epoch 392 Iter 6 subLoss 5149.5 multi -10.94 import weight 0.00
Epoch 392 Iter 7 subLoss 5208.2 multi -1.99 import weight 0.00
Epoch 392 Iter 8 subLoss 4890.0 multi 9.96 import weight 0.00
Epoch 392 Iter 9 subLoss 4495.4 multi 3.99 import weight 0.00
Epoch 392 Iter 10 subLoss 4747.4 multi 3.99 import weight 0.00
Epoch 392 Iter 11 subLoss 4486.1 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.10447 / 14.80
Entropy seen (from low to high)
[367, 451, 816, 737, 378, 253, 170, 173, 148, 148, 135, 147, 131, 96, 94, 77, 71, 65, 55, 63, 50, 44, 51, 58, 54, 45, 43, 35, 23, 29, 26, 21, 14, 15, 12, 11, 8, 2, 8, 0, 3, 1, 3, 6, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 7, 21, 46, 79, 90, 91, 125, 146, 148, 178, 207, 183, 209, 206, 207, 221, 204, 177, 188, 170, 152, 148, 159, 137, 123, 107, 139, 103, 104, 102, 101, 102, 106, 81, 66, 55, 55, 36, 25, 24, 15, 8, 4, 3, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.2, 30.6, 33.6, 37.2, 40.2, 44.0, 47.2, 50.6, 54.4, 57.4, 61.2, 64.5, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 28.5, 44.4, 59.9, 58.3, 61.1, 56.7, 74.5, 49.9, 76.7, 89.7, 76.3]
[0, 0, 0, 0, 0, 0, 0, 1, 4, 7, 9, 10, 12, 36, 37, 59, 36, 43, 68, 55]
Epoch 392 Acc: 96.15 BMA: 96.75 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 448 train Loss: 4577.2 test Loss: 675.3
Epoch 393 Iter 0 subLoss 4609.0 multi -1.99 import weight 0.00
Epoch 393 Iter 1 subLoss 4451.0 multi 24.88 import weight 0.00
Epoch 393 Iter 2 subLoss 4154.3 multi 18.91 import weight 0.00
Epoch 393 Iter 3 subLoss 4081.2 multi -1.99 import weight 0.00
Epoch 393 Iter 4 subLoss 4323.7 multi 15.93 import weight 0.00
Epoch 393 Iter 5 subLoss 4438.9 multi -28.85 import weight 0.00
Epoch 393 Iter 6 subLoss 5765.7 multi 6.97 import weight 0.00
Epoch 393 Iter 7 subLoss 4214.0 multi 12.94 import weight 0.00
Epoch 393 Iter 8 subLoss 4207.5 multi 1.00 import weight 0.00
Epoch 393 Iter 9 subLoss 4497.9 multi 3.98 import weight 0.00
Epoch 393 Iter 10 subLoss 3625.8 multi 9.96 import weight 0.00
Epoch 393 Iter 11 subLoss 4163.9 multi -22.88 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.10451 / 15.50
Entropy seen (from low to high)
[369, 456, 827, 726, 376, 249, 172, 177, 145, 147, 139, 144, 135, 89, 95, 78, 72, 65, 52, 65, 49, 41, 52, 59, 54, 44, 43, 35, 21, 33, 24, 21, 15, 14, 11, 12, 8, 2, 8, 0, 3, 1, 3, 6, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 7, 21, 45, 80, 90, 90, 128, 145, 149, 178, 208, 179, 211, 203, 209, 217, 206, 179, 186, 172, 150, 150, 156, 139, 123, 101, 142, 105, 102, 106, 96, 105, 102, 86, 65, 57, 52, 39, 25, 24, 15, 8, 4, 3, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.2, 30.6, 33.7, 37.1, 40.1, 43.8, 47.3, 50.6, 54.3, 57.3, 61.2, 64.5, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 49.9, 28.5, 44.4, 55.5, 61.5, 62.1, 55.5, 77.1, 47.3, 79.0, 88.2, 76.3]
[0, 0, 0, 0, 0, 0, 0, 1, 4, 7, 9, 9, 13, 37, 36, 57, 38, 43, 68, 55]
Epoch 393 Acc: 95.89 BMA: 96.75 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -22.88 Pidx 416 train Loss: 4511.9 test Loss: 641.1
Epoch 394 Iter 0 subLoss 4934.2 multi -19.90 import weight 0.00
Epoch 394 Iter 1 subLoss 6114.2 multi -19.90 import weight 0.00
Epoch 394 Iter 2 subLoss 157723.7 multi 1.00 import weight 0.00
Epoch 394 Iter 3 subLoss 9141.0 multi 1.00 import weight 0.00
Epoch 394 Iter 4 subLoss 8005.9 multi -16.91 import weight 0.00
Epoch 394 Iter 5 subLoss 42799.3 multi 1.00 import weight 0.00
Epoch 394 Iter 6 subLoss 15042.5 multi 3.99 import weight 0.00
Epoch 394 Iter 7 subLoss 8453.5 multi 18.91 import weight 0.00
Epoch 394 Iter 8 subLoss 6361.0 multi -1.98 import weight 0.00
Epoch 394 Iter 9 subLoss 5501.1 multi -1.99 import weight 0.00
Epoch 394 Iter 10 subLoss 6043.8 multi 1.00 import weight 0.00
Epoch 394 Iter 11 subLoss 6101.0 multi 15.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.10442 / 16.24
Entropy seen (from low to high)
[370, 451, 809, 742, 377, 251, 179, 173, 145, 155, 134, 140, 137, 88, 96, 76, 71, 67, 52, 65, 48, 42, 50, 60, 52, 47, 40, 36, 23, 29, 27, 21, 15, 14, 13, 10, 9, 2, 8, 0, 3, 1, 3, 6, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 8, 20, 45, 82, 89, 89, 130, 147, 149, 177, 209, 183, 209, 202, 213, 211, 209, 175, 186, 177, 146, 149, 159, 131, 126, 106, 132, 116, 99, 107, 96, 104, 105, 85, 65, 53, 57, 32, 26, 26, 13, 8, 4, 3, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.3, 30.6, 33.5, 36.9, 39.8, 43.5, 47.2, 50.5, 54.3, 57.3, 61.2, 64.6, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 33.3, 49.9, 37.4, 61.5, 62.1, 55.5, 78.3, 42.8, 80.8, 87.6, 78.1]
[0, 0, 0, 0, 0, 0, 0, 1, 4, 6, 10, 8, 13, 37, 36, 60, 35, 47, 65, 55]
Epoch 394 Acc: 95.00 BMA: 96.75 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 15.93 Pidx 610 train Loss: 5555.9 test Loss: 836.1
Epoch 395 Iter 0 subLoss 5104.2 multi 6.97 import weight 0.00
Epoch 395 Iter 1 subLoss 5463.0 multi -10.94 import weight 0.00
Epoch 395 Iter 2 subLoss 6054.8 multi -1.98 import weight 0.00
Epoch 395 Iter 3 subLoss 6201.9 multi 6.97 import weight 0.00
Epoch 395 Iter 4 subLoss 5333.5 multi 3.99 import weight 0.00
Epoch 395 Iter 5 subLoss 4690.6 multi -19.90 import weight 0.00
Epoch 395 Iter 6 subLoss 5465.7 multi -7.96 import weight 0.00
Epoch 395 Iter 7 subLoss 6572.6 multi -7.96 import weight 0.00
Epoch 395 Iter 8 subLoss 6624.3 multi 6.97 import weight 0.00
Epoch 395 Iter 9 subLoss 5638.3 multi -13.93 import weight 0.00
Epoch 395 Iter 10 subLoss 6888.4 multi -7.96 import weight 0.00
Epoch 395 Iter 11 subLoss 8797.7 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.10432 / 15.91
Entropy seen (from low to high)
[367, 444, 799, 749, 385, 253, 176, 174, 149, 155, 133, 145, 134, 89, 93, 79, 70, 65, 50, 64, 49, 43, 52, 59, 49, 51, 38, 36, 26, 29, 27, 20, 16, 14, 13, 9, 10, 2, 7, 1, 3, 1, 3, 6, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 8, 20, 45, 83, 89, 90, 128, 150, 148, 182, 214, 176, 211, 204, 216, 205, 204, 185, 181, 171, 151, 151, 163, 126, 127, 106, 125, 119, 101, 106, 93, 111, 96, 94, 68, 45, 55, 33, 26, 27, 10, 8, 4, 3, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.5, 30.6, 33.5, 36.8, 39.8, 43.5, 47.3, 50.6, 54.3, 57.5, 61.4, 64.6, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 33.3, 49.9, 37.4, 61.5, 59.9, 55.8, 78.3, 45.9, 82.9, 86.8, 78.9]
[0, 0, 0, 0, 0, 0, 0, 1, 4, 6, 10, 8, 13, 40, 34, 60, 37, 47, 61, 57]
Epoch 395 Acc: 94.01 BMA: 96.75 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 879 train Loss: 6490.7 test Loss: 978.8
Epoch 396 Iter 0 subLoss 6458.8 multi 1.00 import weight 0.00
Epoch 396 Iter 1 subLoss 5962.7 multi 9.96 import weight 0.00
Epoch 396 Iter 2 subLoss 5872.5 multi 6.97 import weight 0.00
Epoch 396 Iter 3 subLoss 6272.7 multi 3.98 import weight 0.00
Epoch 396 Iter 4 subLoss 5400.3 multi -10.94 import weight 0.00
Epoch 396 Iter 5 subLoss 5727.3 multi -19.90 import weight 0.00
Epoch 396 Iter 6 subLoss 7751.1 multi -7.96 import weight 0.00
Epoch 396 Iter 7 subLoss 17343.4 multi 1.00 import weight 0.00
Epoch 396 Iter 8 subLoss 9196.8 multi 1.00 import weight 0.00
Epoch 396 Iter 9 subLoss 8207.2 multi 15.93 import weight 0.00
Epoch 396 Iter 10 subLoss 8195.8 multi -1.99 import weight 0.00
Epoch 396 Iter 11 subLoss 8002.7 multi -13.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.10407 / 14.93
Entropy seen (from low to high)
[250, 377, 781, 863, 435, 250, 193, 191, 151, 157, 138, 143, 131, 88, 101, 72, 73, 62, 52, 65, 48, 43, 53, 59, 49, 51, 37, 35, 27, 28, 28, 20, 16, 15, 13, 9, 10, 2, 6, 2, 3, 1, 3, 6, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 8, 20, 46, 79, 92, 89, 134, 151, 145, 178, 215, 180, 216, 201, 215, 211, 197, 188, 183, 168, 156, 151, 158, 139, 120, 106, 123, 120, 107, 102, 101, 117, 96, 81, 66, 58, 44, 31, 25, 20, 12, 5, 1, 3, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.7, 30.7, 33.6, 36.8, 40.1, 43.6, 47.3, 50.7, 54.3, 57.5, 61.3, 64.6, 68.4]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.9, 33.3, 39.9, 33.3, 66.6, 58.5, 60.6, 74.9, 48.6, 82.9, 87.0, 76.2]
[0, 0, 0, 0, 0, 0, 0, 1, 4, 6, 10, 9, 12, 41, 33, 60, 37, 47, 62, 59]
Epoch 396 Acc: 80.52 BMA: 96.77 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -13.93 Pidx 800 train Loss: 19818.1 test Loss: 2866.1
Epoch 397 Iter 0 subLoss 19360.1 multi -1.99 import weight 0.00
Epoch 397 Iter 1 subLoss 27344.8 multi 1.00 import weight 0.00
Epoch 397 Iter 2 subLoss 20027.7 multi -1.99 import weight 0.00
Epoch 397 Iter 3 subLoss 28846.7 multi 1.00 import weight 0.00
Epoch 397 Iter 4 subLoss 20293.5 multi -1.99 import weight 0.00
Epoch 397 Iter 5 subLoss 30964.2 multi 1.00 import weight 0.00
Epoch 397 Iter 6 subLoss 24734.1 multi 1.00 import weight 0.00
Epoch 397 Iter 7 subLoss 20034.8 multi 3.98 import weight 0.00
Epoch 397 Iter 8 subLoss 13151.6 multi 9.96 import weight 0.00
Epoch 397 Iter 9 subLoss 7518.9 multi 9.96 import weight 0.00
Epoch 397 Iter 10 subLoss 5684.6 multi 6.97 import weight 0.00
Epoch 397 Iter 11 subLoss 5964.8 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.10403 / 14.64
Entropy seen (from low to high)
[251, 372, 773, 874, 437, 246, 195, 197, 149, 157, 140, 140, 129, 96, 90, 79, 67, 65, 50, 66, 49, 44, 50, 60, 48, 51, 37, 36, 26, 29, 28, 21, 14, 16, 13, 9, 10, 2, 6, 2, 2, 2, 4, 5, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 8, 20, 46, 80, 91, 92, 140, 144, 149, 178, 217, 176, 215, 202, 214, 206, 204, 185, 178, 172, 157, 148, 158, 140, 119, 108, 125, 118, 107, 104, 107, 107, 100, 83, 62, 61, 43, 28, 28, 17, 12, 4, 2, 3, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.8, 30.4, 33.3, 36.8, 40.2, 43.6, 47.3, 50.7, 54.3, 57.7, 61.3, 64.6, 68.4]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 66.6, 28.5, 59.9, 33.3, 66.6, 57.1, 62.4, 72.5, 54.0, 84.4, 85.4, 76.2]
[0, 0, 0, 0, 0, 0, 0, 1, 3, 7, 10, 9, 12, 42, 32, 62, 37, 45, 62, 59]
Epoch 397 Acc: 95.19 BMA: 96.75 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 596 train Loss: 5515.5 test Loss: 777.1
Epoch 398 Iter 0 subLoss 5676.9 multi 3.99 import weight 0.00
Epoch 398 Iter 1 subLoss 5984.7 multi -1.99 import weight 0.00
Epoch 398 Iter 2 subLoss 5840.9 multi 1.00 import weight 0.00
Epoch 398 Iter 3 subLoss 5631.2 multi -10.94 import weight 0.00
Epoch 398 Iter 4 subLoss 5367.0 multi 15.93 import weight 0.00
Epoch 398 Iter 5 subLoss 6061.1 multi -1.98 import weight 0.00
Epoch 398 Iter 6 subLoss 4790.8 multi 3.99 import weight 0.00
Epoch 398 Iter 7 subLoss 5434.9 multi 15.93 import weight 0.00
Epoch 398 Iter 8 subLoss 4803.2 multi 27.87 import weight 0.00
Epoch 398 Iter 9 subLoss 4806.1 multi 30.85 import weight 1.00
Epoch 398 Iter 10 subLoss 5714.1 multi 12.94 import weight 0.00
Epoch 398 Iter 11 subLoss 4364.0 multi -19.90 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.10408 / 14.76
Entropy seen (from low to high)
[254, 369, 775, 875, 436, 248, 194, 199, 146, 157, 136, 146, 130, 94, 89, 78, 69, 60, 54, 68, 46, 44, 50, 58, 51, 51, 35, 33, 30, 29, 26, 22, 13, 17, 15, 7, 10, 2, 6, 2, 2, 2, 4, 5, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 8, 20, 45, 78, 93, 95, 136, 145, 152, 174, 219, 182, 204, 198, 221, 211, 201, 184, 180, 167, 159, 152, 154, 133, 125, 107, 123, 118, 108, 108, 103, 111, 97, 85, 65, 58, 45, 27, 28, 19, 11, 4, 2, 3, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.9, 30.3, 33.4, 36.8, 40.2, 43.7, 47.4, 50.7, 54.3, 57.8, 61.3, 64.7, 68.5]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 66.6, 28.5, 59.9, 33.3, 69.2, 57.1, 61.2, 71.4, 54.0, 86.3, 84.3, 77.9]
[0, 0, 0, 0, 0, 0, 0, 1, 3, 7, 10, 9, 13, 42, 31, 63, 37, 44, 64, 59]
Epoch 398 Acc: 95.37 BMA: 96.75 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -19.90 Pidx 436 train Loss: 5098.4 test Loss: 747.6
Epoch 399 Iter 0 subLoss 5160.4 multi -1.99 import weight 0.00
Epoch 399 Iter 1 subLoss 5695.2 multi -10.94 import weight 0.00
Epoch 399 Iter 2 subLoss 6144.8 multi 18.91 import weight 0.00
Epoch 399 Iter 3 subLoss 6082.9 multi -4.97 import weight 0.00
Epoch 399 Iter 4 subLoss 6024.8 multi -4.97 import weight 0.00
Epoch 399 Iter 5 subLoss 8535.5 multi 1.00 import weight 0.00
Epoch 399 Iter 6 subLoss 8372.6 multi 6.97 import weight 0.00
Epoch 399 Iter 7 subLoss 5382.3 multi -16.91 import weight 0.00
Epoch 399 Iter 8 subLoss 7329.6 multi -10.94 import weight 0.00
Epoch 399 Iter 9 subLoss 12303.1 multi 1.00 import weight 0.00
Epoch 399 Iter 10 subLoss 11854.5 multi 1.00 import weight 0.00
Epoch 399 Iter 11 subLoss 10110.3 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.10387 / 14.75
Entropy seen (from low to high)
[255, 369, 780, 876, 430, 247, 195, 195, 142, 164, 126, 143, 132, 96, 87, 77, 73, 64, 54, 64, 51, 41, 49, 64, 49, 49, 40, 33, 28, 29, 27, 23, 12, 18, 14, 7, 11, 2, 6, 2, 2, 2, 4, 5, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 8, 20, 45, 81, 90, 98, 138, 145, 151, 176, 222, 182, 207, 207, 210, 207, 200, 189, 182, 162, 162, 151, 161, 129, 119, 112, 128, 115, 112, 97, 108, 104, 100, 80, 68, 49, 47, 30, 26, 20, 10, 5, 2, 3, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.0, 30.3, 33.3, 36.9, 40.2, 43.7, 47.4, 50.8, 54.3, 57.6, 61.3, 64.6, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 66.6, 28.5, 59.9, 33.3, 78.5, 57.1, 58.0, 70.4, 55.2, 84.4, 85.4, 79.3]
[0, 0, 0, 0, 0, 0, 0, 1, 3, 7, 10, 9, 14, 42, 31, 61, 38, 45, 62, 58]
Epoch 399 Acc: 92.41 BMA: 96.75 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 1011 train Loss: 8559.4 test Loss: 1312.4
Epoch 400 Iter 0 subLoss 9310.9 multi 6.97 import weight 0.00
Epoch 400 Iter 1 subLoss 6031.1 multi -10.94 import weight 0.00
Epoch 400 Iter 2 subLoss 7740.9 multi -1.98 import weight 0.00
Epoch 400 Iter 3 subLoss 8623.1 multi -4.97 import weight 0.00
Epoch 400 Iter 4 subLoss 9751.1 multi -7.96 import weight 0.00
Epoch 400 Iter 5 subLoss 17068.0 multi 1.00 import weight 0.00
Epoch 400 Iter 6 subLoss 16169.2 multi -4.97 import weight 0.00
Epoch 400 Iter 7 subLoss 25810.8 multi 1.00 import weight 0.00
Epoch 400 Iter 8 subLoss 20804.2 multi 1.00 import weight 0.00
Epoch 400 Iter 9 subLoss 16995.2 multi -1.99 import weight 0.00
Epoch 400 Iter 10 subLoss 23790.1 multi 3.99 import weight 0.00
Epoch 400 Iter 11 subLoss 13399.7 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.10356 / 14.06
Entropy seen (from low to high)
[256, 372, 781, 878, 429, 236, 199, 183, 129, 161, 124, 147, 132, 111, 88, 75, 70, 71, 62, 55, 56, 42, 50, 63, 46, 53, 37, 36, 30, 27, 29, 22, 16, 15, 15, 8, 10, 2, 6, 2, 2, 2, 4, 5, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 8, 21, 43, 83, 90, 101, 138, 143, 160, 178, 220, 181, 212, 201, 213, 206, 214, 177, 182, 165, 164, 157, 155, 127, 119, 115, 132, 112, 111, 93, 104, 109, 99, 75, 66, 43, 46, 31, 24, 19, 11, 5, 2, 3, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.2, 30.4, 33.3, 37.1, 40.4, 43.7, 47.4, 50.7, 54.2, 57.6, 61.2, 64.6, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 66.6, 28.5, 54.5, 37.4, 79.9, 60.9, 53.1, 70.4, 56.4, 80.9, 87.6, 76.6]
[0, 0, 0, 0, 0, 0, 0, 1, 3, 7, 11, 8, 15, 41, 32, 61, 39, 42, 65, 60]
Epoch 400 Acc: 87.64 BMA: 96.73 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1339 train Loss: 12320.8 test Loss: 1968.1
Epoch 401 Iter 0 subLoss 13059.4 multi 3.99 import weight 0.00
Epoch 401 Iter 1 subLoss 10094.6 multi -1.99 import weight 0.00
Epoch 401 Iter 2 subLoss 10719.1 multi 9.96 import weight 0.00
Epoch 401 Iter 3 subLoss 7814.0 multi 1.00 import weight 0.00
Epoch 401 Iter 4 subLoss 7546.3 multi 6.97 import weight 0.00
Epoch 401 Iter 5 subLoss 6605.8 multi 1.00 import weight 0.00
Epoch 401 Iter 6 subLoss 6348.4 multi -7.96 import weight 0.00
Epoch 401 Iter 7 subLoss 7072.1 multi -7.96 import weight 0.00
Epoch 401 Iter 8 subLoss 9497.0 multi 3.99 import weight 0.00
Epoch 401 Iter 9 subLoss 7875.7 multi -4.97 import weight 0.00
Epoch 401 Iter 10 subLoss 9614.8 multi 6.97 import weight 0.00
Epoch 401 Iter 11 subLoss 7742.5 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0114 / 0.10334 / 13.56
Entropy seen (from low to high)
[255, 370, 785, 871, 433, 240, 193, 183, 130, 154, 128, 143, 135, 108, 86, 75, 71, 74, 61, 56, 59, 46, 41, 68, 48, 49, 41, 37, 32, 26, 24, 24, 19, 16, 15, 8, 10, 2, 5, 3, 2, 2, 4, 5, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 8, 22, 42, 84, 94, 100, 137, 146, 161, 182, 219, 184, 218, 196, 210, 212, 207, 181, 179, 170, 163, 156, 156, 133, 114, 110, 130, 110, 112, 90, 107, 106, 100, 73, 62, 44, 43, 33, 24, 19, 11, 5, 3, 2, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.3, 30.5, 33.2, 37.1, 40.0, 43.6, 47.4, 50.8, 54.2, 57.6, 61.3, 64.6, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 66.6, 28.5, 45.4, 49.9, 73.6, 58.9, 55.8, 65.5, 63.1, 82.2, 87.0, 76.6]
[0, 0, 0, 0, 0, 0, 0, 1, 3, 7, 11, 6, 19, 39, 34, 61, 38, 45, 62, 60]
Epoch 401 Acc: 94.30 BMA: 96.73 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 774 train Loss: 7617.4 test Loss: 1185.4
Epoch 402 Iter 0 subLoss 7489.6 multi -1.98 import weight 0.00
Epoch 402 Iter 1 subLoss 7933.9 multi 1.00 import weight 0.00
Epoch 402 Iter 2 subLoss 7475.1 multi 9.96 import weight 0.00
Epoch 402 Iter 3 subLoss 5513.9 multi 3.98 import weight 0.00
Epoch 402 Iter 4 subLoss 6046.5 multi 1.00 import weight 0.00
Epoch 402 Iter 5 subLoss 6158.1 multi 9.96 import weight 0.00
Epoch 402 Iter 6 subLoss 5448.9 multi -19.90 import weight 0.00
Epoch 402 Iter 7 subLoss 5780.6 multi -13.93 import weight 0.00
Epoch 402 Iter 8 subLoss 7756.9 multi -10.94 import weight 0.00
Epoch 402 Iter 9 subLoss 12818.4 multi 3.99 import weight 0.00
Epoch 402 Iter 10 subLoss 8847.3 multi 9.96 import weight 0.00
Epoch 402 Iter 11 subLoss 6725.4 multi 15.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0114 / 0.10331 / 13.59
Entropy seen (from low to high)
[255, 369, 779, 874, 439, 243, 187, 186, 129, 153, 127, 147, 131, 107, 89, 70, 75, 74, 56, 60, 59, 47, 39, 67, 50, 49, 42, 35, 31, 27, 23, 26, 20, 16, 15, 8, 8, 4, 5, 3, 2, 2, 4, 5, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 8, 22, 42, 83, 96, 100, 137, 147, 162, 183, 219, 182, 217, 199, 205, 216, 204, 182, 180, 173, 165, 152, 154, 133, 113, 112, 130, 104, 113, 92, 107, 109, 97, 72, 63, 44, 44, 32, 25, 18, 12, 5, 3, 2, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.3, 30.4, 33.3, 37.1, 40.6, 44.0, 47.4, 50.8, 54.2, 57.6, 61.3, 64.6, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 66.6, 28.5, 45.4, 44.4, 76.4, 63.1, 55.5, 64.4, 64.1, 79.9, 88.8, 75.4]
[0, 0, 0, 0, 0, 0, 0, 1, 3, 7, 11, 9, 17, 38, 36, 59, 39, 45, 63, 57]
Epoch 402 Acc: 95.78 BMA: 96.73 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 15.93 Pidx 672 train Loss: 5593.4 test Loss: 822.3
Epoch 403 Iter 0 subLoss 5558.1 multi 9.96 import weight 0.00
Epoch 403 Iter 1 subLoss 5526.1 multi -13.93 import weight 0.00
Epoch 403 Iter 2 subLoss 6059.9 multi -1.99 import weight 0.00
Epoch 403 Iter 3 subLoss 5509.5 multi 1.00 import weight 0.00
Epoch 403 Iter 4 subLoss 5594.4 multi -7.96 import weight 0.00
Epoch 403 Iter 5 subLoss 6301.7 multi -7.96 import weight 0.00
Epoch 403 Iter 6 subLoss 5837.6 multi -1.99 import weight 0.00
Epoch 403 Iter 7 subLoss 6765.5 multi -7.96 import weight 0.00
Epoch 403 Iter 8 subLoss 7421.6 multi 3.99 import weight 0.00
Epoch 403 Iter 9 subLoss 7224.4 multi 3.99 import weight 0.00
Epoch 403 Iter 10 subLoss 7110.7 multi -4.97 import weight 0.00
Epoch 403 Iter 11 subLoss 6076.2 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0114 / 0.10324 / 14.13
Entropy seen (from low to high)
[255, 370, 774, 878, 442, 241, 186, 186, 130, 153, 128, 141, 134, 107, 88, 71, 75, 73, 57, 60, 61, 46, 38, 66, 48, 52, 43, 30, 35, 27, 23, 26, 21, 15, 16, 8, 7, 5, 5, 3, 2, 2, 4, 5, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 8, 22, 41, 85, 94, 101, 138, 148, 163, 186, 213, 185, 215, 201, 211, 216, 202, 183, 176, 178, 161, 153, 153, 133, 106, 118, 127, 106, 111, 94, 107, 105, 99, 72, 62, 44, 42, 34, 24, 19, 12, 5, 3, 2, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.4, 30.4, 33.3, 37.2, 40.7, 43.8, 47.3, 50.8, 54.2, 57.7, 61.4, 64.7, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 66.6, 28.5, 49.9, 57.1, 72.2, 63.1, 55.5, 64.9, 59.9, 84.4, 87.0, 78.5]
[0, 0, 0, 0, 0, 0, 0, 1, 3, 7, 12, 7, 18, 38, 36, 60, 40, 45, 62, 56]
Epoch 403 Acc: 95.54 BMA: 96.73 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 607 train Loss: 6164.3 test Loss: 874.1
Epoch 404 Iter 0 subLoss 5894.5 multi 6.97 import weight 0.00
Epoch 404 Iter 1 subLoss 5623.3 multi 1.00 import weight 0.00
Epoch 404 Iter 2 subLoss 4912.1 multi -10.94 import weight 0.00
Epoch 404 Iter 3 subLoss 6423.7 multi 12.94 import weight 0.00
Epoch 404 Iter 4 subLoss 5681.7 multi 6.97 import weight 0.00
Epoch 404 Iter 5 subLoss 5320.2 multi -1.99 import weight 0.00
Epoch 404 Iter 6 subLoss 5113.9 multi -19.90 import weight 0.00
Epoch 404 Iter 7 subLoss 5861.3 multi 3.99 import weight 0.00
Epoch 404 Iter 8 subLoss 6202.2 multi 9.96 import weight 0.00
Epoch 404 Iter 9 subLoss 5449.9 multi -16.91 import weight 0.00
Epoch 404 Iter 10 subLoss 6135.8 multi 6.97 import weight 0.00
Epoch 404 Iter 11 subLoss 5425.2 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0114 / 0.10322 / 13.75
Entropy seen (from low to high)
[255, 375, 765, 878, 450, 240, 190, 184, 126, 157, 127, 141, 133, 105, 87, 71, 78, 70, 58, 57, 61, 48, 38, 64, 49, 52, 39, 35, 34, 28, 22, 27, 21, 14, 16, 9, 6, 6, 5, 3, 2, 2, 4, 5, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 8, 23, 40, 84, 96, 101, 136, 149, 163, 193, 208, 185, 213, 206, 204, 220, 202, 186, 177, 175, 160, 155, 150, 133, 107, 118, 126, 104, 113, 96, 102, 108, 96, 75, 60, 45, 42, 34, 24, 20, 11, 5, 3, 2, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.4, 30.3, 33.0, 37.0, 40.7, 43.8, 47.3, 50.8, 54.2, 57.7, 61.5, 64.7, 68.3]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 66.6, 33.3, 46.1, 57.1, 72.2, 60.5, 56.7, 63.3, 62.4, 84.7, 87.0, 77.7]
[0, 0, 0, 0, 0, 0, 0, 1, 3, 6, 13, 7, 18, 38, 37, 60, 40, 46, 62, 54]
Epoch 404 Acc: 95.70 BMA: 96.73 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 542 train Loss: 5607.1 test Loss: 803.3
Epoch 405 Iter 0 subLoss 5183.2 multi -7.96 import weight 0.00
Epoch 405 Iter 1 subLoss 5551.8 multi 12.94 import weight 0.00
Epoch 405 Iter 2 subLoss 5850.4 multi -10.94 import weight 0.00
Epoch 405 Iter 3 subLoss 5386.3 multi -13.93 import weight 0.00
Epoch 405 Iter 4 subLoss 6843.5 multi 9.96 import weight 0.00
Epoch 405 Iter 5 subLoss 6016.2 multi 18.91 import weight 0.00
Epoch 405 Iter 6 subLoss 5287.1 multi -10.94 import weight 0.00
Epoch 405 Iter 7 subLoss 5495.1 multi -13.93 import weight 0.00
Epoch 405 Iter 8 subLoss 6571.8 multi -4.97 import weight 0.00
Epoch 405 Iter 9 subLoss 7703.7 multi 9.96 import weight 0.00
Epoch 405 Iter 10 subLoss 6095.6 multi -1.99 import weight 0.00
Epoch 405 Iter 11 subLoss 5831.4 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0114 / 0.10320 / 13.74
Entropy seen (from low to high)
[257, 379, 754, 882, 447, 244, 191, 187, 127, 156, 127, 138, 136, 101, 87, 70, 77, 68, 62, 55, 61, 49, 37, 65, 50, 49, 37, 40, 33, 28, 21, 30, 20, 10, 20, 9, 5, 7, 5, 3, 2, 2, 4, 5, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 8, 23, 40, 84, 97, 101, 136, 151, 160, 200, 205, 182, 212, 212, 200, 217, 204, 188, 176, 179, 163, 150, 148, 126, 114, 118, 124, 103, 115, 94, 107, 98, 99, 78, 58, 47, 41, 33, 25, 21, 11, 5, 3, 2, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.5, 30.3, 33.0, 37.0, 40.8, 43.9, 47.3, 50.8, 54.2, 57.8, 61.6, 64.7, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 66.6, 33.3, 46.1, 62.4, 70.5, 58.9, 58.3, 62.2, 64.2, 85.7, 87.3, 77.3]
[0, 0, 0, 0, 0, 0, 0, 1, 3, 6, 13, 8, 17, 39, 36, 61, 42, 42, 63, 53]
Epoch 405 Acc: 95.60 BMA: 96.73 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 583 train Loss: 5930.0 test Loss: 793.6
Epoch 406 Iter 0 subLoss 5690.3 multi -10.94 import weight 0.00
Epoch 406 Iter 1 subLoss 6083.0 multi -4.97 import weight 0.00
Epoch 406 Iter 2 subLoss 7364.3 multi 1.00 import weight 0.00
Epoch 406 Iter 3 subLoss 7285.7 multi 1.00 import weight 0.00
Epoch 406 Iter 4 subLoss 6373.1 multi 12.94 import weight 0.00
Epoch 406 Iter 5 subLoss 5475.0 multi 1.00 import weight 0.00
Epoch 406 Iter 6 subLoss 6022.4 multi -4.97 import weight 0.00
Epoch 406 Iter 7 subLoss 5705.0 multi -10.94 import weight 0.00
Epoch 406 Iter 8 subLoss 7055.7 multi 18.91 import weight 0.00
Epoch 406 Iter 9 subLoss 5347.3 multi 9.96 import weight 0.00
Epoch 406 Iter 10 subLoss 4894.7 multi 12.94 import weight 0.00
Epoch 406 Iter 11 subLoss 5246.2 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0114 / 0.10324 / 13.49
Entropy seen (from low to high)
[260, 386, 747, 869, 458, 244, 195, 183, 127, 156, 130, 137, 136, 101, 85, 70, 73, 71, 62, 56, 60, 50, 38, 61, 51, 52, 38, 36, 34, 28, 22, 28, 20, 10, 21, 9, 5, 7, 5, 3, 2, 2, 4, 5, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 8, 23, 39, 86, 95, 102, 137, 151, 159, 202, 207, 177, 210, 210, 206, 219, 199, 189, 173, 179, 166, 150, 148, 123, 116, 114, 125, 107, 115, 91, 111, 94, 102, 77, 60, 47, 41, 32, 25, 23, 10, 5, 3, 2, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.6, 30.2, 33.0, 36.9, 40.8, 43.8, 47.3, 50.7, 54.2, 57.8, 61.6, 64.6, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 66.6, 33.3, 38.4, 62.4, 68.7, 61.5, 55.5, 64.5, 62.7, 87.4, 85.9, 77.3]
[0, 0, 0, 0, 0, 0, 0, 1, 3, 6, 13, 8, 16, 39, 36, 62, 43, 40, 64, 53]
Epoch 406 Acc: 95.87 BMA: 96.75 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 524 train Loss: 4986.2 test Loss: 701.1
Epoch 407 Iter 0 subLoss 4670.0 multi 15.93 import weight 0.00
Epoch 407 Iter 1 subLoss 4979.2 multi 6.97 import weight 0.00
Epoch 407 Iter 2 subLoss 4588.9 multi -10.94 import weight 0.00
Epoch 407 Iter 3 subLoss 6161.1 multi -25.87 import weight 0.00
Epoch 407 Iter 4 subLoss 7336.8 multi -4.97 import weight 0.00
Epoch 407 Iter 5 subLoss 10042.1 multi 6.97 import weight 0.00
Epoch 407 Iter 6 subLoss 5522.7 multi -10.94 import weight 0.00
Epoch 407 Iter 7 subLoss 5911.3 multi 15.93 import weight 0.00
Epoch 407 Iter 8 subLoss 4935.7 multi -16.91 import weight 0.00
Epoch 407 Iter 9 subLoss 5597.6 multi -4.97 import weight 0.00
Epoch 407 Iter 10 subLoss 6290.2 multi -4.97 import weight 0.00
Epoch 407 Iter 11 subLoss 6202.7 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0114 / 0.10326 / 13.62
Entropy seen (from low to high)
[265, 386, 737, 877, 457, 245, 198, 180, 128, 156, 128, 137, 137, 101, 85, 68, 72, 71, 61, 57, 61, 49, 39, 59, 51, 54, 35, 36, 37, 26, 22, 29, 19, 12, 18, 10, 6, 8, 4, 3, 2, 2, 4, 5, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 8, 23, 39, 88, 93, 101, 139, 154, 156, 202, 207, 173, 215, 212, 204, 222, 192, 194, 172, 179, 161, 144, 157, 124, 112, 114, 126, 110, 112, 89, 109, 98, 98, 80, 62, 47, 41, 33, 26, 22, 10, 5, 3, 2, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.8, 30.1, 33.2, 37.0, 40.5, 43.8, 47.2, 50.8, 54.1, 57.7, 61.5, 64.6, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 66.6, 42.8, 27.2, 66.6, 62.4, 64.1, 52.6, 66.1, 62.7, 83.3, 87.0, 76.3]
[0, 0, 0, 0, 0, 0, 0, 1, 3, 7, 11, 9, 16, 39, 38, 59, 43, 42, 62, 55]
Epoch 407 Acc: 95.41 BMA: 96.75 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 620 train Loss: 5591.9 test Loss: 780.5
Epoch 408 Iter 0 subLoss 5502.2 multi 1.00 import weight 0.00
Epoch 408 Iter 1 subLoss 5240.9 multi 3.99 import weight 0.00
Epoch 408 Iter 2 subLoss 5305.5 multi 3.99 import weight 0.00
Epoch 408 Iter 3 subLoss 5119.9 multi -16.91 import weight 0.00
Epoch 408 Iter 4 subLoss 6041.7 multi 3.99 import weight 0.00
Epoch 408 Iter 5 subLoss 5914.3 multi 18.91 import weight 0.00
Epoch 408 Iter 6 subLoss 4958.5 multi 21.90 import weight 0.00
Epoch 408 Iter 7 subLoss 5133.4 multi 9.96 import weight 0.00
Epoch 408 Iter 8 subLoss 4051.0 multi 9.96 import weight 0.00
Epoch 408 Iter 9 subLoss 4262.4 multi -1.99 import weight 0.00
Epoch 408 Iter 10 subLoss 4461.0 multi -13.93 import weight 0.00
Epoch 408 Iter 11 subLoss 4636.4 multi 15.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0114 / 0.10333 / 13.12
Entropy seen (from low to high)
[268, 391, 730, 878, 460, 243, 198, 180, 130, 155, 130, 139, 132, 100, 87, 68, 69, 71, 61, 55, 63, 49, 39, 60, 50, 54, 35, 35, 37, 26, 22, 29, 19, 13, 17, 10, 6, 8, 4, 3, 2, 2, 4, 5, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 8, 23, 42, 84, 96, 99, 138, 153, 161, 197, 206, 177, 214, 208, 209, 220, 193, 190, 168, 183, 161, 145, 158, 119, 116, 111, 126, 115, 106, 89, 114, 95, 101, 80, 60, 48, 43, 31, 29, 22, 10, 5, 3, 2, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.8, 30.1, 33.4, 37.1, 40.3, 43.9, 47.3, 50.8, 54.2, 57.7, 61.5, 64.6, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 66.6, 37.4, 33.3, 59.9, 64.7, 64.8, 52.4, 65.5, 62.7, 82.9, 87.3, 75.4]
[0, 0, 0, 0, 0, 0, 0, 1, 3, 8, 9, 10, 17, 37, 40, 58, 43, 41, 63, 53]
Epoch 408 Acc: 96.03 BMA: 96.75 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 15.93 Pidx 463 train Loss: 4842.4 test Loss: 646.8
Epoch 409 Iter 0 subLoss 4893.8 multi 15.93 import weight 0.00
Epoch 409 Iter 1 subLoss 4447.4 multi -10.94 import weight 0.00
Epoch 409 Iter 2 subLoss 4390.4 multi -1.99 import weight 0.00
Epoch 409 Iter 3 subLoss 4684.6 multi 24.88 import weight 0.00
Epoch 409 Iter 4 subLoss 4698.6 multi -19.90 import weight 0.00
Epoch 409 Iter 5 subLoss 6438.4 multi -4.97 import weight 0.00
Epoch 409 Iter 6 subLoss 10548.9 multi 6.97 import weight 0.00
Epoch 409 Iter 7 subLoss 5055.7 multi -31.84 import weight 0.00
Epoch 409 Iter 8 subLoss 6551.1 multi 1.00 import weight 0.00
Epoch 409 Iter 9 subLoss 6101.9 multi 15.93 import weight 0.00
Epoch 409 Iter 10 subLoss 5479.2 multi 3.99 import weight 0.00
Epoch 409 Iter 11 subLoss 4792.1 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.10339 / 12.93
Entropy seen (from low to high)
[270, 393, 725, 877, 466, 242, 202, 179, 129, 155, 131, 133, 137, 97, 88, 67, 70, 70, 58, 57, 60, 50, 40, 62, 47, 54, 36, 33, 39, 26, 22, 30, 18, 13, 16, 11, 6, 8, 4, 3, 2, 2, 4, 5, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 8, 25, 41, 82, 96, 98, 143, 149, 165, 193, 204, 181, 213, 204, 209, 221, 191, 190, 171, 181, 161, 143, 162, 115, 121, 110, 123, 112, 115, 86, 115, 94, 99, 82, 62, 46, 43, 33, 29, 21, 11, 5, 3, 2, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.9, 30.0, 33.4, 36.7, 40.0, 43.9, 47.3, 50.7, 54.2, 57.7, 61.6, 64.7, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 66.6, 37.4, 42.8, 49.9, 64.7, 65.7, 51.3, 65.5, 61.9, 81.3, 88.5, 75.4]
[0, 0, 0, 0, 0, 0, 0, 1, 3, 8, 7, 12, 17, 38, 37, 61, 42, 43, 61, 53]
Epoch 409 Acc: 96.17 BMA: 96.73 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 479 train Loss: 4895.3 test Loss: 637.7
Epoch 410 Iter 0 subLoss 5044.1 multi 18.91 import weight 0.00
Epoch 410 Iter 1 subLoss 4918.0 multi -7.96 import weight 0.00
Epoch 410 Iter 2 subLoss 4564.2 multi -13.93 import weight 0.00
Epoch 410 Iter 3 subLoss 4834.0 multi -1.98 import weight 0.00
Epoch 410 Iter 4 subLoss 5418.4 multi 1.00 import weight 0.00
Epoch 410 Iter 5 subLoss 5110.6 multi -13.93 import weight 0.00
Epoch 410 Iter 6 subLoss 6170.0 multi -22.88 import weight 0.00
Epoch 410 Iter 7 subLoss 12362.5 multi -4.97 import weight 0.00
Epoch 410 Iter 8 subLoss 36175.2 multi 1.00 import weight 0.00
Epoch 410 Iter 9 subLoss 22376.9 multi -4.97 import weight 0.00
Epoch 410 Iter 10 subLoss 98866.0 multi 1.00 import weight 0.00
Epoch 410 Iter 11 subLoss 28765.5 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0114 / 0.10322 / 13.31
Entropy seen (from low to high)
[270, 396, 704, 878, 476, 250, 199, 182, 127, 155, 133, 136, 136, 92, 93, 68, 65, 69, 61, 55, 60, 51, 41, 58, 49, 54, 36, 33, 39, 27, 22, 30, 18, 14, 14, 12, 5, 9, 4, 3, 2, 2, 4, 5, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 8, 25, 40, 84, 93, 104, 140, 150, 163, 199, 201, 184, 212, 205, 211, 219, 190, 193, 172, 182, 159, 145, 157, 118, 121, 107, 125, 110, 118, 88, 117, 95, 92, 79, 63, 48, 42, 30, 30, 19, 10, 5, 3, 2, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.9, 29.5, 33.2, 36.7, 40.0, 43.9, 47.4, 50.7, 54.1, 57.6, 61.5, 64.7, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 33.3, 42.8, 49.9, 61.1, 67.5, 48.6, 64.4, 63.6, 80.9, 86.8, 79.2]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 9, 7, 12, 18, 37, 37, 59, 44, 42, 61, 53]
Epoch 410 Acc: 93.23 BMA: 96.77 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 2876 train Loss: 8863.2 test Loss: 1045.7
Epoch 411 Iter 0 subLoss 9038.4 multi -4.97 import weight 0.00
Epoch 411 Iter 1 subLoss 10652.2 multi 3.98 import weight 0.00
Epoch 411 Iter 2 subLoss 7918.5 multi 3.98 import weight 0.00
Epoch 411 Iter 3 subLoss 7109.6 multi -7.96 import weight 0.00
Epoch 411 Iter 4 subLoss 9470.1 multi -4.97 import weight 0.00
Epoch 411 Iter 5 subLoss 13093.3 multi 6.97 import weight 0.00
Epoch 411 Iter 6 subLoss 7595.6 multi 6.97 import weight 0.00
Epoch 411 Iter 7 subLoss 6592.1 multi -4.97 import weight 0.00
Epoch 411 Iter 8 subLoss 7610.7 multi 3.98 import weight 0.00
Epoch 411 Iter 9 subLoss 6682.7 multi 9.96 import weight 0.00
Epoch 411 Iter 10 subLoss 6221.8 multi -1.99 import weight 0.00
Epoch 411 Iter 11 subLoss 5712.4 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.10325 / 12.90
Entropy seen (from low to high)
[271, 400, 699, 880, 476, 245, 204, 182, 131, 150, 133, 139, 137, 88, 94, 69, 63, 67, 62, 57, 58, 53, 40, 57, 49, 57, 33, 34, 37, 27, 24, 29, 18, 14, 13, 12, 6, 9, 4, 3, 2, 2, 4, 5, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 1, 8, 26, 39, 85, 94, 103, 138, 153, 163, 198, 198, 184, 217, 199, 210, 221, 194, 188, 174, 181, 157, 149, 153, 118, 124, 109, 121, 109, 122, 85, 117, 96, 90, 80, 64, 47, 45, 30, 29, 20, 10, 5, 3, 2, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.0, 29.5, 33.2, 36.7, 40.0, 44.0, 47.4, 50.7, 54.1, 57.6, 61.6, 64.7, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 33.3, 42.8, 58.3, 57.8, 65.7, 51.2, 63.7, 63.6, 77.2, 91.5, 77.3]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 9, 7, 12, 19, 35, 39, 58, 44, 44, 59, 53]
Epoch 411 Acc: 96.15 BMA: 96.77 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 571 train Loss: 5347.6 test Loss: 679.7
Epoch 412 Iter 0 subLoss 5147.2 multi -10.94 import weight 0.00
Epoch 412 Iter 1 subLoss 5322.4 multi 1.00 import weight 0.00
Epoch 412 Iter 2 subLoss 5930.8 multi -1.99 import weight 0.00
Epoch 412 Iter 3 subLoss 5584.6 multi 15.93 import weight 0.00
Epoch 412 Iter 4 subLoss 4366.1 multi -16.91 import weight 0.00
Epoch 412 Iter 5 subLoss 4692.9 multi -16.91 import weight 0.00
Epoch 412 Iter 6 subLoss 5954.9 multi -7.96 import weight 0.00
Epoch 412 Iter 7 subLoss 7598.4 multi 9.96 import weight 0.00
Epoch 412 Iter 8 subLoss 5588.9 multi 18.91 import weight 0.00
Epoch 412 Iter 9 subLoss 5197.7 multi 3.99 import weight 0.00
Epoch 412 Iter 10 subLoss 6000.3 multi 1.00 import weight 0.00
Epoch 412 Iter 11 subLoss 5114.3 multi -10.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.10325 / 13.18
Entropy seen (from low to high)
[273, 401, 691, 888, 473, 249, 205, 179, 134, 147, 136, 137, 133, 92, 91, 70, 65, 65, 61, 56, 61, 51, 42, 53, 51, 55, 34, 33, 39, 25, 26, 28, 20, 13, 13, 12, 6, 8, 5, 3, 2, 2, 4, 5, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 9, 26, 38, 88, 90, 104, 140, 153, 163, 197, 199, 185, 215, 201, 214, 216, 192, 188, 173, 184, 154, 154, 152, 116, 124, 109, 122, 109, 121, 84, 117, 97, 89, 82, 59, 50, 45, 31, 28, 21, 10, 5, 3, 2, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.0, 29.7, 33.2, 36.7, 40.0, 44.0, 47.4, 50.7, 54.1, 57.5, 61.6, 64.7, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 33.3, 42.8, 49.9, 63.1, 62.8, 53.8, 64.9, 62.2, 77.2, 91.5, 79.2]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 9, 7, 12, 19, 35, 39, 57, 45, 44, 59, 53]
Epoch 412 Acc: 95.82 BMA: 96.75 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -10.94 Pidx 511 train Loss: 5611.1 test Loss: 724.0
Epoch 413 Iter 0 subLoss 5568.5 multi -22.88 import weight 0.00
Epoch 413 Iter 1 subLoss 6969.9 multi 1.00 import weight 0.00
Epoch 413 Iter 2 subLoss 6618.9 multi 9.96 import weight 0.00
Epoch 413 Iter 3 subLoss 5660.9 multi 1.00 import weight 0.00
Epoch 413 Iter 4 subLoss 5614.4 multi 6.97 import weight 0.00
Epoch 413 Iter 5 subLoss 5003.1 multi 3.99 import weight 0.00
Epoch 413 Iter 6 subLoss 5470.6 multi 6.97 import weight 0.00
Epoch 413 Iter 7 subLoss 5211.2 multi -7.96 import weight 0.00
Epoch 413 Iter 8 subLoss 5277.1 multi 3.99 import weight 0.00
Epoch 413 Iter 9 subLoss 5104.9 multi 9.96 import weight 0.00
Epoch 413 Iter 10 subLoss 5143.3 multi -7.96 import weight 0.00
Epoch 413 Iter 11 subLoss 6274.7 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.10330 / 13.20
Entropy seen (from low to high)
[275, 402, 692, 884, 474, 251, 208, 178, 136, 142, 137, 139, 133, 89, 90, 70, 67, 63, 60, 56, 63, 51, 41, 53, 50, 55, 35, 34, 35, 27, 26, 27, 21, 11, 15, 12, 6, 8, 5, 3, 2, 2, 4, 5, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 9, 26, 38, 89, 90, 103, 137, 154, 167, 193, 200, 187, 215, 201, 207, 219, 193, 188, 172, 183, 156, 154, 155, 111, 124, 113, 119, 110, 118, 90, 116, 91, 92, 82, 62, 50, 45, 31, 28, 21, 10, 5, 3, 2, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.0, 29.6, 33.2, 36.7, 40.0, 44.0, 47.3, 50.7, 54.2, 57.5, 61.5, 64.7, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 33.3, 42.8, 49.9, 63.1, 61.7, 54.7, 66.6, 62.2, 75.5, 91.2, 80.3]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 9, 7, 12, 19, 34, 42, 54, 45, 45, 57, 56]
Epoch 413 Acc: 95.97 BMA: 96.77 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 627 train Loss: 5090.1 test Loss: 674.8
Epoch 414 Iter 0 subLoss 5329.7 multi 3.99 import weight 0.00
Epoch 414 Iter 1 subLoss 4692.6 multi -13.93 import weight 0.00
Epoch 414 Iter 2 subLoss 5386.0 multi -10.94 import weight 0.00
Epoch 414 Iter 3 subLoss 5635.0 multi -10.94 import weight 0.00
Epoch 414 Iter 4 subLoss 6573.5 multi -1.98 import weight 0.00
Epoch 414 Iter 5 subLoss 6373.1 multi 15.93 import weight 0.00
Epoch 414 Iter 6 subLoss 5907.9 multi -7.96 import weight 0.00
Epoch 414 Iter 7 subLoss 5781.0 multi -10.94 import weight 0.00
Epoch 414 Iter 8 subLoss 5533.7 multi 9.96 import weight 0.00
Epoch 414 Iter 9 subLoss 5745.3 multi 6.97 import weight 0.00
Epoch 414 Iter 10 subLoss 4940.3 multi -4.97 import weight 0.00
Epoch 414 Iter 11 subLoss 5560.8 multi -19.90 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.10330 / 13.27
Entropy seen (from low to high)
[279, 402, 686, 886, 473, 254, 205, 177, 137, 146, 137, 138, 135, 89, 88, 69, 66, 60, 62, 56, 62, 53, 41, 53, 48, 59, 36, 33, 31, 29, 24, 28, 22, 10, 16, 12, 6, 8, 5, 3, 2, 2, 4, 5, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 9, 27, 36, 90, 89, 106, 136, 152, 170, 191, 201, 184, 218, 206, 197, 225, 189, 190, 171, 178, 162, 155, 151, 111, 123, 118, 115, 114, 117, 90, 114, 93, 91, 81, 62, 51, 47, 30, 28, 21, 10, 5, 3, 2, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.1, 29.6, 33.2, 36.7, 40.0, 44.1, 47.4, 50.7, 54.2, 57.4, 61.5, 64.8, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 33.3, 42.8, 49.9, 63.1, 62.8, 54.7, 63.4, 65.2, 78.7, 87.7, 81.8]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 9, 7, 12, 19, 35, 42, 52, 46, 47, 57, 55]
Epoch 414 Acc: 95.49 BMA: 96.77 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -19.90 Pidx 556 train Loss: 6457.3 test Loss: 775.4
Epoch 415 Iter 0 subLoss 5223.8 multi 18.91 import weight 0.00
Epoch 415 Iter 1 subLoss 5603.8 multi 3.98 import weight 0.00
Epoch 415 Iter 2 subLoss 5941.8 multi -1.99 import weight 0.00
Epoch 415 Iter 3 subLoss 5716.1 multi 15.93 import weight 0.00
Epoch 415 Iter 4 subLoss 5115.4 multi -10.94 import weight 0.00
Epoch 415 Iter 5 subLoss 5663.9 multi 3.99 import weight 0.00
Epoch 415 Iter 6 subLoss 5690.2 multi -7.96 import weight 0.00
Epoch 415 Iter 7 subLoss 5633.8 multi -7.96 import weight 0.00
Epoch 415 Iter 8 subLoss 5832.2 multi 3.98 import weight 0.00
Epoch 415 Iter 9 subLoss 6421.9 multi 15.93 import weight 0.00
Epoch 415 Iter 10 subLoss 5266.2 multi 1.00 import weight 0.00
Epoch 415 Iter 11 subLoss 5258.4 multi 3.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.10335 / 13.24
Entropy seen (from low to high)
[282, 406, 678, 886, 477, 254, 207, 173, 143, 142, 141, 135, 133, 90, 88, 66, 68, 62, 58, 56, 62, 51, 43, 53, 47, 59, 37, 32, 32, 29, 24, 26, 24, 11, 15, 12, 6, 8, 5, 3, 2, 2, 4, 5, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 9, 27, 36, 88, 91, 106, 137, 148, 171, 193, 200, 186, 211, 207, 203, 219, 191, 193, 168, 178, 159, 159, 150, 111, 123, 120, 114, 116, 117, 85, 114, 94, 87, 87, 65, 50, 46, 28, 31, 21, 10, 5, 3, 2, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.1, 29.5, 33.2, 36.7, 40.0, 44.1, 47.4, 50.8, 54.2, 57.5, 61.5, 64.8, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 33.3, 42.8, 49.9, 68.4, 58.3, 54.7, 63.4, 66.6, 80.8, 84.2, 83.3]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 9, 7, 12, 19, 36, 42, 52, 45, 47, 57, 54]
Epoch 415 Acc: 96.03 BMA: 96.77 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 525 train Loss: 5194.5 test Loss: 681.6
Epoch 416 Iter 0 subLoss 5028.5 multi 9.96 import weight 0.00
Epoch 416 Iter 1 subLoss 5565.2 multi -16.91 import weight 0.00
Epoch 416 Iter 2 subLoss 4947.1 multi -1.99 import weight 0.00
Epoch 416 Iter 3 subLoss 5688.6 multi 9.96 import weight 0.00
Epoch 416 Iter 4 subLoss 4962.8 multi -25.87 import weight 0.00
Epoch 416 Iter 5 subLoss 6001.5 multi 3.99 import weight 0.00
Epoch 416 Iter 6 subLoss 5602.3 multi 6.97 import weight 0.00
Epoch 416 Iter 7 subLoss 5810.6 multi -1.99 import weight 0.00
Epoch 416 Iter 8 subLoss 5237.4 multi -19.90 import weight 0.00
Epoch 416 Iter 9 subLoss 6302.6 multi -7.96 import weight 0.00
Epoch 416 Iter 10 subLoss 5688.9 multi 12.94 import weight 0.00
Epoch 416 Iter 11 subLoss 5602.3 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.10340 / 13.30
Entropy seen (from low to high)
[284, 408, 680, 874, 484, 259, 204, 174, 147, 136, 139, 139, 132, 91, 87, 65, 69, 62, 53, 57, 64, 49, 44, 53, 48, 58, 36, 32, 31, 29, 26, 26, 23, 12, 15, 12, 6, 8, 5, 3, 2, 2, 4, 5, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 10, 26, 36, 90, 90, 105, 135, 149, 174, 192, 195, 192, 205, 211, 202, 222, 189, 190, 175, 173, 154, 166, 146, 109, 128, 119, 107, 122, 116, 87, 113, 94, 89, 86, 62, 54, 44, 30, 31, 20, 11, 5, 3, 2, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.2, 29.5, 33.2, 36.6, 40.0, 44.1, 47.4, 50.8, 54.2, 57.6, 61.5, 64.8, 68.2]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 33.3, 42.8, 49.9, 68.4, 58.3, 54.7, 63.4, 65.2, 82.6, 83.6, 84.4]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 9, 7, 12, 19, 36, 42, 52, 46, 46, 55, 58]
Epoch 416 Acc: 95.97 BMA: 96.77 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 560 train Loss: 5593.4 test Loss: 687.3
Epoch 417 Iter 0 subLoss 5596.4 multi -7.96 import weight 0.00
Epoch 417 Iter 1 subLoss 4771.0 multi 12.94 import weight 0.00
Epoch 417 Iter 2 subLoss 5197.0 multi 6.97 import weight 0.00
Epoch 417 Iter 3 subLoss 5220.6 multi 21.90 import weight 0.00
Epoch 417 Iter 4 subLoss 4848.9 multi -4.97 import weight 0.00
Epoch 417 Iter 5 subLoss 5458.7 multi 9.96 import weight 0.00
Epoch 417 Iter 6 subLoss 5643.4 multi -7.96 import weight 0.00
Epoch 417 Iter 7 subLoss 5120.6 multi -1.99 import weight 0.00
Epoch 417 Iter 8 subLoss 4836.2 multi 1.00 import weight 0.00
Epoch 417 Iter 9 subLoss 5510.1 multi 1.00 import weight 0.00
Epoch 417 Iter 10 subLoss 4679.9 multi -16.91 import weight 0.00
Epoch 417 Iter 11 subLoss 5448.9 multi -13.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0113 / 0.10338 / 13.07
Entropy seen (from low to high)
[286, 411, 680, 868, 485, 261, 201, 179, 148, 133, 139, 139, 131, 96, 82, 65, 68, 59, 55, 59, 63, 50, 43, 53, 46, 57, 38, 34, 29, 30, 24, 27, 24, 11, 15, 13, 6, 8, 6, 2, 2, 2, 4, 5, 2, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 10, 26, 37, 92, 86, 106, 137, 147, 171, 192, 201, 189, 208, 212, 201, 219, 188, 201, 161, 177, 163, 158, 145, 110, 129, 110, 113, 116, 122, 85, 114, 97, 86, 88, 61, 51, 47, 30, 32, 20, 11, 5, 3, 2, 2]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.3, 29.4, 33.2, 36.6, 40.0, 43.9, 47.3, 50.7, 54.2, 57.5, 61.5, 64.8, 68.1]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 99.9, 33.3, 42.8, 49.9, 64.7, 56.7, 55.8, 64.7, 63.8, 82.6, 81.4, 86.4]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 9, 7, 12, 17, 37, 43, 51, 47, 46, 54, 59]
Epoch 417 Acc: 95.10 BMA: 96.77 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -13.93 Pidx 544 train Loss: 6512.8 test Loss: 816.2
Epoch 418 Iter 0 subLoss 6372.5 multi 18.91 import weight 0.00
Epoch 418 Iter 1 subLoss 5476.1 multi 9.96 import weight 0.00
Epoch 418 Iter 2 subLoss 5196.7 multi 9.96 import weight 0.00
Epoch 418 Iter 3 subLoss 4408.9 multi 15.93 import weight 0.00
Epoch 418 Iter 4 subLoss 5319.9 multi -10.94 import weight 0.00
Epoch 418 Iter 5 subLoss 5421.9 multi 3.99 import weight 0.00
Epoch 418 Iter 6 subLoss 4825.6 multi -7.96 import weight 0.00
Epoch 418 Iter 7 subLoss 4774.8 multi 15.93 import weight 0.00
Epoch 418 Iter 8 subLoss 4291.1 multi -10.94 import weight 0.00
Epoch 418 Iter 9 subLoss 4532.0 multi 6.97 import weight 0.00
Epoch 418 Iter 10 subLoss 5159.8 multi 9.96 import weight 0.00
Epoch 418 Iter 11 subLoss 4423.5 multi 21.90 import weight 1.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 418 Acc: 96.03 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 21.90 Pidx 442 train Loss: 4755.2 test Loss: 641.7
Epoch 419 Iter 0 subLoss 4559.4 multi 15.93 import weight 0.00
Epoch 419 Iter 1 subLoss 4109.3 multi -1.99 import weight 0.00
Epoch 419 Iter 2 subLoss 4790.0 multi 9.96 import weight 0.00
Epoch 419 Iter 3 subLoss 4927.5 multi 6.97 import weight 0.00
Epoch 419 Iter 4 subLoss 5610.7 multi 1.00 import weight 0.00
Epoch 419 Iter 5 subLoss 4454.7 multi 24.88 import weight 0.00
Epoch 419 Iter 6 subLoss 4234.9 multi -25.87 import weight 0.00
Epoch 419 Iter 7 subLoss 7020.2 multi 1.00 import weight 0.00
Epoch 419 Iter 8 subLoss 6041.7 multi 6.97 import weight 0.00
Epoch 419 Iter 9 subLoss 4531.5 multi 9.96 import weight 0.00
Epoch 419 Iter 10 subLoss 4619.2 multi 6.97 import weight 0.00
Epoch 419 Iter 11 subLoss 4284.9 multi -10.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 419 Acc: 95.84 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -10.94 Pidx 428 train Loss: 4497.8 test Loss: 656.7
Epoch 420 Iter 0 subLoss 4289.8 multi -7.96 import weight 0.00
Epoch 420 Iter 1 subLoss 4552.2 multi 18.91 import weight 0.00
Epoch 420 Iter 2 subLoss 4221.5 multi 3.99 import weight 0.00
Epoch 420 Iter 3 subLoss 4714.1 multi -4.97 import weight 0.00
Epoch 420 Iter 4 subLoss 4479.6 multi -7.96 import weight 0.00
Epoch 420 Iter 5 subLoss 5001.5 multi 6.97 import weight 0.00
Epoch 420 Iter 6 subLoss 4873.0 multi -1.98 import weight 0.00
Epoch 420 Iter 7 subLoss 5331.0 multi -1.98 import weight 0.00
Epoch 420 Iter 8 subLoss 4538.7 multi 12.94 import weight 0.00
Epoch 420 Iter 9 subLoss 4172.6 multi -7.96 import weight 0.00
Epoch 420 Iter 10 subLoss 4840.7 multi -4.97 import weight 0.00
Epoch 420 Iter 11 subLoss 4328.6 multi 18.91 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 420 Acc: 95.70 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 18.91 Pidx 432 train Loss: 4675.2 test Loss: 680.3
Epoch 421 Iter 0 subLoss 4757.2 multi 6.97 import weight 0.00
Epoch 421 Iter 1 subLoss 3545.2 multi -10.94 import weight 0.00
Epoch 421 Iter 2 subLoss 3848.0 multi 6.97 import weight 0.00
Epoch 421 Iter 3 subLoss 4270.1 multi 24.88 import weight 0.00
Epoch 421 Iter 4 subLoss 4448.6 multi -7.96 import weight 0.00
Epoch 421 Iter 5 subLoss 4723.0 multi 1.00 import weight 0.00
Epoch 421 Iter 6 subLoss 4222.6 multi 6.97 import weight 0.00
Epoch 421 Iter 7 subLoss 4898.0 multi 18.91 import weight 0.00
Epoch 421 Iter 8 subLoss 4688.8 multi 24.88 import weight 0.00
Epoch 421 Iter 9 subLoss 4593.7 multi -4.97 import weight 0.00
Epoch 421 Iter 10 subLoss 5807.2 multi -4.97 import weight 0.00
Epoch 421 Iter 11 subLoss 9184.2 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 421 Acc: 73.34 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 918 train Loss: 42503.9 test Loss: 9738.8
Epoch 422 Iter 0 subLoss 42467.7 multi 1.00 import weight 0.00
Epoch 422 Iter 1 subLoss 18748.5 multi 6.97 import weight 0.00
Epoch 422 Iter 2 subLoss 6099.1 multi -1.98 import weight 0.00
Epoch 422 Iter 3 subLoss 6499.5 multi 15.93 import weight 0.00
Epoch 422 Iter 4 subLoss 4352.1 multi 1.00 import weight 0.00
Epoch 422 Iter 5 subLoss 4913.7 multi -4.97 import weight 0.00
Epoch 422 Iter 6 subLoss 5233.8 multi -19.90 import weight 0.00
Epoch 422 Iter 7 subLoss 5704.5 multi -10.94 import weight 0.00
Epoch 422 Iter 8 subLoss 11245.9 multi -1.99 import weight 0.00
Epoch 422 Iter 9 subLoss 19339.6 multi 3.99 import weight 0.00
Epoch 422 Iter 10 subLoss 5847.8 multi -4.97 import weight 0.00
Epoch 422 Iter 11 subLoss 6858.9 multi -13.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 422 Acc: 84.84 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -13.93 Pidx 685 train Loss: 13457.4 test Loss: 2028.6
Epoch 423 Iter 0 subLoss 12794.0 multi 3.99 import weight 0.00
Epoch 423 Iter 1 subLoss 8757.0 multi 1.00 import weight 0.00
Epoch 423 Iter 2 subLoss 8133.4 multi 6.97 import weight 0.00
Epoch 423 Iter 3 subLoss 5391.4 multi 3.98 import weight 0.00
Epoch 423 Iter 4 subLoss 5788.1 multi -7.96 import weight 0.00
Epoch 423 Iter 5 subLoss 6277.2 multi 9.96 import weight 0.00
Epoch 423 Iter 6 subLoss 4850.2 multi -7.96 import weight 0.00
Epoch 423 Iter 7 subLoss 5642.8 multi -4.97 import weight 0.00
Epoch 423 Iter 8 subLoss 6733.3 multi -4.97 import weight 0.00
Epoch 423 Iter 9 subLoss 6825.3 multi 6.97 import weight 0.00
Epoch 423 Iter 10 subLoss 6013.9 multi 15.93 import weight 0.00
Epoch 423 Iter 11 subLoss 4774.4 multi 18.91 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 423 Acc: 96.01 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 18.91 Pidx 477 train Loss: 4610.6 test Loss: 642.5
Epoch 424 Iter 0 subLoss 4392.3 multi 1.00 import weight 0.00
Epoch 424 Iter 1 subLoss 4272.9 multi 27.87 import weight 1.00
Epoch 424 Iter 2 subLoss 4318.0 multi -25.87 import weight 0.00
Epoch 424 Iter 3 subLoss 5963.8 multi 12.94 import weight 0.00
Epoch 424 Iter 4 subLoss 5354.7 multi -13.93 import weight 0.00
Epoch 424 Iter 5 subLoss 4844.3 multi -1.99 import weight 0.00
Epoch 424 Iter 6 subLoss 5007.2 multi 9.96 import weight 0.00
Epoch 424 Iter 7 subLoss 4694.4 multi -13.93 import weight 0.00
Epoch 424 Iter 8 subLoss 4544.8 multi -22.88 import weight 0.00
Epoch 424 Iter 9 subLoss 5689.2 multi 15.93 import weight 0.00
Epoch 424 Iter 10 subLoss 5468.0 multi -7.96 import weight 0.00
Epoch 424 Iter 11 subLoss 5160.2 multi -1.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 424 Acc: 95.37 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 516 train Loss: 5356.8 test Loss: 767.1
Epoch 425 Iter 0 subLoss 5654.8 multi -4.97 import weight 0.00
Epoch 425 Iter 1 subLoss 6277.2 multi 12.94 import weight 0.00
Epoch 425 Iter 2 subLoss 4297.3 multi -13.93 import weight 0.00
Epoch 425 Iter 3 subLoss 5619.5 multi 3.99 import weight 0.00
Epoch 425 Iter 4 subLoss 5248.5 multi 1.00 import weight 0.00
Epoch 425 Iter 5 subLoss 5346.0 multi 9.96 import weight 0.00
Epoch 425 Iter 6 subLoss 4833.6 multi 1.00 import weight 0.00
Epoch 425 Iter 7 subLoss 4725.2 multi 3.99 import weight 0.00
Epoch 425 Iter 8 subLoss 5468.2 multi -4.97 import weight 0.00
Epoch 425 Iter 9 subLoss 4453.1 multi 24.88 import weight 0.00
Epoch 425 Iter 10 subLoss 4760.2 multi -16.91 import weight 0.00
Epoch 425 Iter 11 subLoss 4841.3 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 425 Acc: 95.80 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 484 train Loss: 4822.7 test Loss: 699.8
Epoch 426 Iter 0 subLoss 5007.2 multi 12.94 import weight 0.00
Epoch 426 Iter 1 subLoss 4416.9 multi -7.96 import weight 0.00
Epoch 426 Iter 2 subLoss 4612.3 multi 9.96 import weight 0.00
Epoch 426 Iter 3 subLoss 4487.9 multi 3.99 import weight 0.00
Epoch 426 Iter 4 subLoss 4607.9 multi -1.99 import weight 0.00
Epoch 426 Iter 5 subLoss 4028.8 multi 1.00 import weight 0.00
Epoch 426 Iter 6 subLoss 3933.1 multi 12.94 import weight 0.00
Epoch 426 Iter 7 subLoss 4827.7 multi -4.97 import weight 0.00
Epoch 426 Iter 8 subLoss 5385.9 multi -7.96 import weight 0.00
Epoch 426 Iter 9 subLoss 5572.5 multi -7.96 import weight 0.00
Epoch 426 Iter 10 subLoss 5504.8 multi 3.99 import weight 0.00
Epoch 426 Iter 11 subLoss 5086.6 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 426 Acc: 95.91 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 508 train Loss: 4429.3 test Loss: 661.2
Epoch 427 Iter 0 subLoss 4442.1 multi -4.97 import weight 0.00
Epoch 427 Iter 1 subLoss 4429.0 multi 21.90 import weight 1.00
Epoch 427 Iter 2 subLoss 4450.9 multi 24.88 import weight 0.00
Epoch 427 Iter 3 subLoss 5073.1 multi 1.00 import weight 0.00
Epoch 427 Iter 4 subLoss 5152.5 multi 12.94 import weight 0.00
Epoch 427 Iter 5 subLoss 4099.1 multi 1.00 import weight 0.00
Epoch 427 Iter 6 subLoss 4310.1 multi -22.88 import weight 0.00
Epoch 427 Iter 7 subLoss 4570.6 multi 18.91 import weight 0.00
Epoch 427 Iter 8 subLoss 4752.9 multi 9.96 import weight 0.00
Epoch 427 Iter 9 subLoss 4223.3 multi 9.96 import weight 0.00
Epoch 427 Iter 10 subLoss 4276.3 multi 30.85 import weight 1.00
Epoch 427 Iter 11 subLoss 4026.5 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 427 Acc: 96.65 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 402 train Loss: 4122.0 test Loss: 556.9
Epoch 428 Iter 0 subLoss 3982.9 multi 3.98 import weight 0.00
Epoch 428 Iter 1 subLoss 4551.2 multi 18.91 import weight 0.00
Epoch 428 Iter 2 subLoss 3690.6 multi -1.99 import weight 0.00
Epoch 428 Iter 3 subLoss 4122.2 multi 12.94 import weight 0.00
Epoch 428 Iter 4 subLoss 3271.6 multi 1.00 import weight 0.00
Epoch 428 Iter 5 subLoss 3633.1 multi -13.93 import weight 0.00
Epoch 428 Iter 6 subLoss 4248.0 multi 3.99 import weight 0.00
Epoch 428 Iter 7 subLoss 3473.9 multi 1.00 import weight 0.00
Epoch 428 Iter 8 subLoss 3947.0 multi -10.94 import weight 0.00
Epoch 428 Iter 9 subLoss 5074.7 multi 3.99 import weight 0.00
Epoch 428 Iter 10 subLoss 4678.5 multi -13.93 import weight 0.00
Epoch 428 Iter 11 subLoss 4578.5 multi 21.90 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 428 Acc: 96.46 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 21.90 Pidx 457 train Loss: 4221.4 test Loss: 572.5
Epoch 429 Iter 0 subLoss 4646.5 multi 6.97 import weight 0.00
Epoch 429 Iter 1 subLoss 4158.6 multi 21.90 import weight 0.00
Epoch 429 Iter 2 subLoss 4217.0 multi 12.94 import weight 0.00
Epoch 429 Iter 3 subLoss 3839.0 multi 3.99 import weight 0.00
Epoch 429 Iter 4 subLoss 3917.8 multi 9.96 import weight 0.00
Epoch 429 Iter 5 subLoss 3620.5 multi 12.94 import weight 0.00
Epoch 429 Iter 6 subLoss 4315.8 multi -19.90 import weight 0.00
Epoch 429 Iter 7 subLoss 4216.2 multi 15.93 import weight 0.00
Epoch 429 Iter 8 subLoss 3597.8 multi 6.97 import weight 0.00
Epoch 429 Iter 9 subLoss 3683.9 multi 12.94 import weight 0.00
Epoch 429 Iter 10 subLoss 3455.1 multi -4.97 import weight 0.00
Epoch 429 Iter 11 subLoss 4038.5 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 429 Acc: 96.81 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 403 train Loss: 3797.0 test Loss: 532.7
Epoch 430 Iter 0 subLoss 3884.9 multi -4.97 import weight 0.00
Epoch 430 Iter 1 subLoss 3721.0 multi 3.99 import weight 0.00
Epoch 430 Iter 2 subLoss 3231.0 multi 1.00 import weight 0.00
Epoch 430 Iter 3 subLoss 3942.8 multi -7.96 import weight 0.00
Epoch 430 Iter 4 subLoss 3141.2 multi 1.00 import weight 0.00
Epoch 430 Iter 5 subLoss 3769.5 multi 15.93 import weight 0.00
Epoch 430 Iter 6 subLoss 4660.7 multi 18.91 import weight 0.00
Epoch 430 Iter 7 subLoss 4093.9 multi 3.98 import weight 0.00
Epoch 430 Iter 8 subLoss 3860.6 multi 12.94 import weight 0.00
Epoch 430 Iter 9 subLoss 3700.6 multi -4.97 import weight 0.00
Epoch 430 Iter 10 subLoss 3859.3 multi -10.94 import weight 0.00
Epoch 430 Iter 11 subLoss 3605.1 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 430 Acc: 96.01 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 360 train Loss: 4023.2 test Loss: 590.0
Epoch 431 Iter 0 subLoss 3992.2 multi -4.97 import weight 0.00
Epoch 431 Iter 1 subLoss 4229.8 multi 6.97 import weight 0.00
Epoch 431 Iter 2 subLoss 3435.7 multi 3.99 import weight 0.00
Epoch 431 Iter 3 subLoss 4012.9 multi 1.00 import weight 0.00
Epoch 431 Iter 4 subLoss 3661.2 multi -1.99 import weight 0.00
Epoch 431 Iter 5 subLoss 4325.0 multi 12.94 import weight 0.00
Epoch 431 Iter 6 subLoss 3268.6 multi 1.00 import weight 0.00
Epoch 431 Iter 7 subLoss 3501.4 multi 6.97 import weight 0.00
Epoch 431 Iter 8 subLoss 3219.1 multi 1.00 import weight 0.00
Epoch 431 Iter 9 subLoss 3835.5 multi 6.97 import weight 0.00
Epoch 431 Iter 10 subLoss 4236.6 multi -34.82 import weight 0.00
Epoch 431 Iter 11 subLoss 3734.5 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 431 Acc: 96.61 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 373 train Loss: 4206.4 test Loss: 544.7
Epoch 432 Iter 0 subLoss 3444.3 multi 3.99 import weight 0.00
Epoch 432 Iter 1 subLoss 3893.6 multi -4.97 import weight 0.00
Epoch 432 Iter 2 subLoss 3827.9 multi -19.90 import weight 0.00
Epoch 432 Iter 3 subLoss 5206.0 multi -7.96 import weight 0.00
Epoch 432 Iter 4 subLoss 7015.0 multi 6.97 import weight 0.00
Epoch 432 Iter 5 subLoss 3781.2 multi 1.00 import weight 0.00
Epoch 432 Iter 6 subLoss 4645.0 multi 9.96 import weight 0.00
Epoch 432 Iter 7 subLoss 4519.3 multi 24.88 import weight 0.00
Epoch 432 Iter 8 subLoss 4156.1 multi 24.88 import weight 0.00
Epoch 432 Iter 9 subLoss 4064.8 multi 3.99 import weight 0.00
Epoch 432 Iter 10 subLoss 4060.6 multi 6.97 import weight 0.00
Epoch 432 Iter 11 subLoss 3397.1 multi -1.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 432 Acc: 96.87 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 339 train Loss: 3827.9 test Loss: 516.7
Epoch 433 Iter 0 subLoss 3696.4 multi -1.99 import weight 0.00
Epoch 433 Iter 1 subLoss 3610.3 multi -1.99 import weight 0.00
Epoch 433 Iter 2 subLoss 3689.7 multi 15.93 import weight 0.00
Epoch 433 Iter 3 subLoss 3924.4 multi -1.99 import weight 0.00
Epoch 433 Iter 4 subLoss 3325.5 multi 1.00 import weight 0.00
Epoch 433 Iter 5 subLoss 3841.5 multi 3.99 import weight 0.00
Epoch 433 Iter 6 subLoss 3974.0 multi 3.99 import weight 0.00
Epoch 433 Iter 7 subLoss 3512.5 multi 3.99 import weight 0.00
Epoch 433 Iter 8 subLoss 3447.1 multi 6.97 import weight 0.00
Epoch 433 Iter 9 subLoss 3719.8 multi 1.00 import weight 0.00
Epoch 433 Iter 10 subLoss 3316.8 multi 6.97 import weight 0.00
Epoch 433 Iter 11 subLoss 3775.1 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 433 Acc: 96.87 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 377 train Loss: 3749.6 test Loss: 523.4
Epoch 434 Iter 0 subLoss 3288.4 multi 3.98 import weight 0.00
Epoch 434 Iter 1 subLoss 3535.4 multi 12.94 import weight 0.00
Epoch 434 Iter 2 subLoss 3385.1 multi 6.97 import weight 0.00
Epoch 434 Iter 3 subLoss 3085.9 multi -1.99 import weight 0.00
Epoch 434 Iter 4 subLoss 3451.3 multi -7.96 import weight 0.00
Epoch 434 Iter 5 subLoss 3943.0 multi -4.97 import weight 0.00
Epoch 434 Iter 6 subLoss 4112.2 multi -4.97 import weight 0.00
Epoch 434 Iter 7 subLoss 4020.0 multi 3.99 import weight 0.00
Epoch 434 Iter 8 subLoss 4048.8 multi -10.94 import weight 0.00
Epoch 434 Iter 9 subLoss 4550.2 multi 21.90 import weight 0.00
Epoch 434 Iter 10 subLoss 4795.9 multi 12.94 import weight 0.00
Epoch 434 Iter 11 subLoss 3890.6 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 434 Acc: 96.65 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 389 train Loss: 4208.6 test Loss: 548.2
Epoch 435 Iter 0 subLoss 4139.9 multi -13.93 import weight 0.00
Epoch 435 Iter 1 subLoss 5326.7 multi 3.98 import weight 0.00
Epoch 435 Iter 2 subLoss 4183.3 multi 6.97 import weight 0.00
Epoch 435 Iter 3 subLoss 4061.4 multi 9.96 import weight 0.00
Epoch 435 Iter 4 subLoss 3784.9 multi 1.00 import weight 0.00
Epoch 435 Iter 5 subLoss 3703.1 multi -4.97 import weight 0.00
Epoch 435 Iter 6 subLoss 3401.5 multi -1.98 import weight 0.00
Epoch 435 Iter 7 subLoss 3694.0 multi -1.98 import weight 0.00
Epoch 435 Iter 8 subLoss 4400.0 multi 15.93 import weight 0.00
Epoch 435 Iter 9 subLoss 3552.6 multi 9.96 import weight 0.00
Epoch 435 Iter 10 subLoss 3831.3 multi 6.97 import weight 0.00
Epoch 435 Iter 11 subLoss 3322.9 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 435 Acc: 97.04 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 332 train Loss: 3730.2 test Loss: 483.8
Epoch 436 Iter 0 subLoss 3288.7 multi 6.97 import weight 0.00
Epoch 436 Iter 1 subLoss 3861.4 multi 12.94 import weight 0.00
Epoch 436 Iter 2 subLoss 3758.4 multi -13.93 import weight 0.00
Epoch 436 Iter 3 subLoss 3451.1 multi -4.97 import weight 0.00
Epoch 436 Iter 4 subLoss 4051.3 multi 9.96 import weight 0.00
Epoch 436 Iter 5 subLoss 3918.6 multi 12.94 import weight 0.00
Epoch 436 Iter 6 subLoss 3519.9 multi 6.97 import weight 0.00
Epoch 436 Iter 7 subLoss 3674.9 multi -1.99 import weight 0.00
Epoch 436 Iter 8 subLoss 3020.6 multi 1.00 import weight 0.00
Epoch 436 Iter 9 subLoss 3727.3 multi 3.99 import weight 0.00
Epoch 436 Iter 10 subLoss 3475.7 multi 3.99 import weight 0.00
Epoch 436 Iter 11 subLoss 3123.1 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 436 Acc: 97.06 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 312 train Loss: 3504.7 test Loss: 480.5
Epoch 437 Iter 0 subLoss 3437.4 multi 6.97 import weight 0.00
Epoch 437 Iter 1 subLoss 3712.8 multi 1.00 import weight 0.00
Epoch 437 Iter 2 subLoss 3667.0 multi 1.00 import weight 0.00
Epoch 437 Iter 3 subLoss 3512.5 multi 9.96 import weight 0.00
Epoch 437 Iter 4 subLoss 3314.7 multi 9.96 import weight 0.00
Epoch 437 Iter 5 subLoss 3887.6 multi -1.99 import weight 0.00
Epoch 437 Iter 6 subLoss 3427.2 multi -4.97 import weight 0.00
Epoch 437 Iter 7 subLoss 3226.4 multi -1.99 import weight 0.00
Epoch 437 Iter 8 subLoss 3706.9 multi -4.97 import weight 0.00
Epoch 437 Iter 9 subLoss 3086.1 multi 1.00 import weight 0.00
Epoch 437 Iter 10 subLoss 3618.1 multi 1.00 import weight 0.00
Epoch 437 Iter 11 subLoss 3539.5 multi 15.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 437 Acc: 96.93 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 15.93 Pidx 353 train Loss: 3594.0 test Loss: 476.1
Epoch 438 Iter 0 subLoss 3652.5 multi 1.00 import weight 0.00
Epoch 438 Iter 1 subLoss 4015.8 multi 6.97 import weight 0.00
Epoch 438 Iter 2 subLoss 2909.6 multi 1.00 import weight 0.00
Epoch 438 Iter 3 subLoss 3454.0 multi -1.98 import weight 0.00
Epoch 438 Iter 4 subLoss 3634.7 multi -13.93 import weight 0.00
Epoch 438 Iter 5 subLoss 3560.0 multi 12.94 import weight 0.00
Epoch 438 Iter 6 subLoss 3014.5 multi 1.00 import weight 0.00
Epoch 438 Iter 7 subLoss 3298.7 multi -10.94 import weight 0.00
Epoch 438 Iter 8 subLoss 3856.4 multi -10.94 import weight 0.00
Epoch 438 Iter 9 subLoss 4214.7 multi 18.91 import weight 0.00
Epoch 438 Iter 10 subLoss 3767.1 multi 15.93 import weight 0.00
Epoch 438 Iter 11 subLoss 3449.3 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 438 Acc: 97.02 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 344 train Loss: 3484.3 test Loss: 474.5
Epoch 439 Iter 0 subLoss 3344.7 multi -1.98 import weight 0.00
Epoch 439 Iter 1 subLoss 3305.8 multi -1.99 import weight 0.00
Epoch 439 Iter 2 subLoss 3543.1 multi -13.93 import weight 0.00
Epoch 439 Iter 3 subLoss 3362.7 multi -1.99 import weight 0.00
Epoch 439 Iter 4 subLoss 3621.3 multi 9.96 import weight 0.00
Epoch 439 Iter 5 subLoss 3033.2 multi -1.99 import weight 0.00
Epoch 439 Iter 6 subLoss 3895.8 multi -1.99 import weight 0.00
Epoch 439 Iter 7 subLoss 3366.8 multi 1.00 import weight 0.00
Epoch 439 Iter 8 subLoss 4119.2 multi -1.99 import weight 0.00
Epoch 439 Iter 9 subLoss 3346.8 multi 1.00 import weight 0.00
Epoch 439 Iter 10 subLoss 3348.2 multi 3.99 import weight 0.00
Epoch 439 Iter 11 subLoss 3440.3 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 439 Acc: 97.10 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 344 train Loss: 3506.9 test Loss: 470.4
Epoch 440 Iter 0 subLoss 2811.7 multi 1.00 import weight 0.00
Epoch 440 Iter 1 subLoss 3780.3 multi 3.98 import weight 0.00
Epoch 440 Iter 2 subLoss 3348.3 multi 6.97 import weight 0.00
Epoch 440 Iter 3 subLoss 3567.3 multi -4.97 import weight 0.00
Epoch 440 Iter 4 subLoss 3966.9 multi -10.94 import weight 0.00
Epoch 440 Iter 5 subLoss 3468.8 multi -7.96 import weight 0.00
Epoch 440 Iter 6 subLoss 3321.9 multi 1.00 import weight 0.00
Epoch 440 Iter 7 subLoss 3561.3 multi -1.98 import weight 0.00
Epoch 440 Iter 8 subLoss 3550.2 multi 12.94 import weight 0.00
Epoch 440 Iter 9 subLoss 3966.5 multi -7.96 import weight 0.00
Epoch 440 Iter 10 subLoss 3920.9 multi -1.98 import weight 0.00
Epoch 440 Iter 11 subLoss 4019.9 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 440 Acc: 97.18 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 401 train Loss: 3521.2 test Loss: 460.2
Epoch 441 Iter 0 subLoss 3336.2 multi -7.96 import weight 0.00
Epoch 441 Iter 1 subLoss 3439.8 multi 6.97 import weight 0.00
Epoch 441 Iter 2 subLoss 3442.8 multi 9.96 import weight 0.00
Epoch 441 Iter 3 subLoss 3026.6 multi 1.00 import weight 0.00
Epoch 441 Iter 4 subLoss 3972.5 multi 1.00 import weight 0.00
Epoch 441 Iter 5 subLoss 3337.3 multi -4.97 import weight 0.00
Epoch 441 Iter 6 subLoss 4655.3 multi -25.87 import weight 0.00
Epoch 441 Iter 7 subLoss 4202.3 multi 3.98 import weight 0.00
Epoch 441 Iter 8 subLoss 3183.5 multi 1.00 import weight 0.00
Epoch 441 Iter 9 subLoss 3345.0 multi 3.98 import weight 0.00
Epoch 441 Iter 10 subLoss 3467.6 multi -4.97 import weight 0.00
Epoch 441 Iter 11 subLoss 4531.4 multi 15.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 441 Acc: 96.77 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 15.93 Pidx 453 train Loss: 3768.2 test Loss: 509.4
Epoch 442 Iter 0 subLoss 3950.7 multi 1.00 import weight 0.00
Epoch 442 Iter 1 subLoss 3642.0 multi 1.00 import weight 0.00
Epoch 442 Iter 2 subLoss 3618.9 multi 3.99 import weight 0.00
Epoch 442 Iter 3 subLoss 3691.6 multi 1.00 import weight 0.00
Epoch 442 Iter 4 subLoss 3177.8 multi 1.00 import weight 0.00
Epoch 442 Iter 5 subLoss 3407.5 multi 1.00 import weight 0.00
Epoch 442 Iter 6 subLoss 3574.4 multi -7.96 import weight 0.00
Epoch 442 Iter 7 subLoss 3988.7 multi 1.00 import weight 0.00
Epoch 442 Iter 8 subLoss 3404.8 multi 3.99 import weight 0.00
Epoch 442 Iter 9 subLoss 2904.3 multi 3.99 import weight 0.00
Epoch 442 Iter 10 subLoss 4110.4 multi 1.00 import weight 0.00
Epoch 442 Iter 11 subLoss 3258.9 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 442 Acc: 96.96 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 325 train Loss: 3721.8 test Loss: 480.5
Epoch 443 Iter 0 subLoss 3669.2 multi 1.00 import weight 0.00
Epoch 443 Iter 1 subLoss 3663.4 multi 3.98 import weight 0.00
Epoch 443 Iter 2 subLoss 3478.7 multi 1.00 import weight 0.00
Epoch 443 Iter 3 subLoss 3773.6 multi -4.97 import weight 0.00
Epoch 443 Iter 4 subLoss 3872.7 multi -10.94 import weight 0.00
Epoch 443 Iter 5 subLoss 3215.6 multi 3.99 import weight 0.00
Epoch 443 Iter 6 subLoss 3230.8 multi 1.00 import weight 0.00
Epoch 443 Iter 7 subLoss 3057.7 multi 1.00 import weight 0.00
Epoch 443 Iter 8 subLoss 3542.8 multi -10.94 import weight 0.00
Epoch 443 Iter 9 subLoss 3464.8 multi -1.98 import weight 0.00
Epoch 443 Iter 10 subLoss 4001.5 multi 1.00 import weight 0.00
Epoch 443 Iter 11 subLoss 3986.0 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 443 Acc: 96.77 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 398 train Loss: 3769.4 test Loss: 511.1
Epoch 444 Iter 0 subLoss 4029.3 multi -4.97 import weight 0.00
Epoch 444 Iter 1 subLoss 4053.0 multi 12.94 import weight 0.00
Epoch 444 Iter 2 subLoss 3409.7 multi 6.97 import weight 0.00
Epoch 444 Iter 3 subLoss 3331.0 multi -1.98 import weight 0.00
Epoch 444 Iter 4 subLoss 2889.5 multi 1.00 import weight 0.00
Epoch 444 Iter 5 subLoss 3339.2 multi 1.00 import weight 0.00
Epoch 444 Iter 6 subLoss 3621.4 multi 9.96 import weight 0.00
Epoch 444 Iter 7 subLoss 2864.5 multi 3.99 import weight 0.00
Epoch 444 Iter 8 subLoss 3241.7 multi -4.97 import weight 0.00
Epoch 444 Iter 9 subLoss 3883.9 multi -1.98 import weight 0.00
Epoch 444 Iter 10 subLoss 3477.8 multi 1.00 import weight 0.00
Epoch 444 Iter 11 subLoss 3991.6 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 444 Acc: 96.40 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 399 train Loss: 4060.5 test Loss: 546.8
Epoch 445 Iter 0 subLoss 3820.5 multi -16.91 import weight 0.00
Epoch 445 Iter 1 subLoss 6621.3 multi 6.97 import weight 0.00
Epoch 445 Iter 2 subLoss 4081.7 multi 1.00 import weight 0.00
Epoch 445 Iter 3 subLoss 3857.3 multi -7.96 import weight 0.00
Epoch 445 Iter 4 subLoss 4315.7 multi -16.91 import weight 0.00
Epoch 445 Iter 5 subLoss 7183.0 multi 6.97 import weight 0.00
Epoch 445 Iter 6 subLoss 4696.8 multi -10.94 import weight 0.00
Epoch 445 Iter 7 subLoss 5563.8 multi -13.93 import weight 0.00
Epoch 445 Iter 8 subLoss 12075.2 multi 1.00 import weight 0.00
Epoch 445 Iter 9 subLoss 10170.2 multi 1.00 import weight 0.00
Epoch 445 Iter 10 subLoss 9046.7 multi 1.00 import weight 0.00
Epoch 445 Iter 11 subLoss 7669.2 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 445 Acc: 95.68 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 766 train Loss: 4604.7 test Loss: 668.0
Epoch 446 Iter 0 subLoss 4362.1 multi -16.91 import weight 0.00
Epoch 446 Iter 1 subLoss 5975.7 multi -7.96 import weight 0.00
Epoch 446 Iter 2 subLoss 10302.6 multi 6.97 import weight 0.00
Epoch 446 Iter 3 subLoss 5733.5 multi 9.96 import weight 0.00
Epoch 446 Iter 4 subLoss 4302.2 multi 6.97 import weight 0.00
Epoch 446 Iter 5 subLoss 3640.2 multi 3.99 import weight 0.00
Epoch 446 Iter 6 subLoss 3497.3 multi 1.00 import weight 0.00
Epoch 446 Iter 7 subLoss 4931.5 multi -16.91 import weight 0.00
Epoch 446 Iter 8 subLoss 5062.6 multi 12.94 import weight 0.00
Epoch 446 Iter 9 subLoss 4087.7 multi 3.98 import weight 0.00
Epoch 446 Iter 10 subLoss 4251.7 multi 1.00 import weight 0.00
Epoch 446 Iter 11 subLoss 3754.5 multi -10.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 446 Acc: 95.93 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -10.94 Pidx 375 train Loss: 4378.9 test Loss: 669.7
Epoch 447 Iter 0 subLoss 4157.1 multi 27.87 import weight 0.00
Epoch 447 Iter 1 subLoss 4302.1 multi 9.96 import weight 0.00
Epoch 447 Iter 2 subLoss 3134.1 multi -1.99 import weight 0.00
Epoch 447 Iter 3 subLoss 3326.4 multi 3.98 import weight 0.00
Epoch 447 Iter 4 subLoss 3932.1 multi 9.96 import weight 0.00
Epoch 447 Iter 5 subLoss 3517.8 multi 12.94 import weight 0.00
Epoch 447 Iter 6 subLoss 4061.0 multi 6.97 import weight 0.00
Epoch 447 Iter 7 subLoss 3206.0 multi 1.00 import weight 0.00
Epoch 447 Iter 8 subLoss 3373.1 multi -4.97 import weight 0.00
Epoch 447 Iter 9 subLoss 3871.8 multi -7.96 import weight 0.00
Epoch 447 Iter 10 subLoss 3632.9 multi -16.91 import weight 0.00
Epoch 447 Iter 11 subLoss 3748.7 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 447 Acc: 96.61 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 374 train Loss: 3680.6 test Loss: 529.1
Epoch 448 Iter 0 subLoss 2847.0 multi 1.00 import weight 0.00
Epoch 448 Iter 1 subLoss 3466.7 multi 1.00 import weight 0.00
Epoch 448 Iter 2 subLoss 3536.6 multi 18.91 import weight 0.00
Epoch 448 Iter 3 subLoss 3400.3 multi 9.96 import weight 0.00
Epoch 448 Iter 4 subLoss 3534.4 multi 21.90 import weight 0.00
Epoch 448 Iter 5 subLoss 3840.9 multi 3.99 import weight 0.00
Epoch 448 Iter 6 subLoss 3522.3 multi -16.91 import weight 0.00
Epoch 448 Iter 7 subLoss 3943.0 multi -4.97 import weight 0.00
Epoch 448 Iter 8 subLoss 4385.0 multi 1.00 import weight 0.00
Epoch 448 Iter 9 subLoss 4914.3 multi -1.98 import weight 0.00
Epoch 448 Iter 10 subLoss 4706.1 multi -10.94 import weight 0.00
Epoch 448 Iter 11 subLoss 20398.6 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 448 Acc: 88.01 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 2039 train Loss: 15082.0 test Loss: 2038.9
Epoch 449 Iter 0 subLoss 14853.0 multi 1.00 import weight 0.00
Epoch 449 Iter 1 subLoss 12641.8 multi -1.99 import weight 0.00
Epoch 449 Iter 2 subLoss 15446.4 multi -1.99 import weight 0.00
Epoch 449 Iter 3 subLoss 19345.1 multi -4.97 import weight 0.00
Epoch 449 Iter 4 subLoss 66233.1 multi 1.00 import weight 0.00
Epoch 449 Iter 5 subLoss 25863.4 multi 1.00 import weight 0.00
Epoch 449 Iter 6 subLoss 20677.2 multi -1.99 import weight 0.00
Epoch 449 Iter 7 subLoss 29099.2 multi 1.00 import weight 0.00
Epoch 449 Iter 8 subLoss 23877.7 multi 6.97 import weight 0.00
Epoch 449 Iter 9 subLoss 11069.8 multi 3.98 import weight 0.00
Epoch 449 Iter 10 subLoss 9293.7 multi 6.97 import weight 0.00
Epoch 449 Iter 11 subLoss 6909.7 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 449 Acc: 93.56 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 690 train Loss: 8576.7 test Loss: 1238.0
Epoch 450 Iter 0 subLoss 8624.1 multi -1.98 import weight 0.00
Epoch 450 Iter 1 subLoss 9433.6 multi 6.97 import weight 0.00
Epoch 450 Iter 2 subLoss 7024.2 multi 1.00 import weight 0.00
Epoch 450 Iter 3 subLoss 7585.2 multi -4.97 import weight 0.00
Epoch 450 Iter 4 subLoss 8235.7 multi -1.99 import weight 0.00
Epoch 450 Iter 5 subLoss 8923.3 multi -1.99 import weight 0.00
Epoch 450 Iter 6 subLoss 9419.1 multi -1.98 import weight 0.00
Epoch 450 Iter 7 subLoss 9639.1 multi 6.97 import weight 0.00
Epoch 450 Iter 8 subLoss 7914.6 multi 6.97 import weight 0.00
Epoch 450 Iter 9 subLoss 6897.5 multi 12.94 import weight 0.00
Epoch 450 Iter 10 subLoss 5000.3 multi 15.93 import weight 0.00
Epoch 450 Iter 11 subLoss 5236.9 multi -16.91 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 450 Acc: 95.82 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -16.91 Pidx 523 train Loss: 5340.2 test Loss: 784.1
Epoch 451 Iter 0 subLoss 4688.9 multi 24.88 import weight 0.00
Epoch 451 Iter 1 subLoss 4319.4 multi -19.90 import weight 0.00
Epoch 451 Iter 2 subLoss 4424.3 multi 24.88 import weight 1.00
Epoch 451 Iter 3 subLoss 4027.7 multi -1.99 import weight 0.00
Epoch 451 Iter 4 subLoss 4015.3 multi 9.96 import weight 0.00
Epoch 451 Iter 5 subLoss 4359.9 multi 3.99 import weight 0.00
Epoch 451 Iter 6 subLoss 4151.4 multi 30.85 import weight 0.00
Epoch 451 Iter 7 subLoss 4483.6 multi 6.97 import weight 0.00
Epoch 451 Iter 8 subLoss 3779.3 multi -1.99 import weight 0.00
Epoch 451 Iter 9 subLoss 4394.3 multi 1.00 import weight 0.00
Epoch 451 Iter 10 subLoss 4540.6 multi -22.88 import weight 0.00
Epoch 451 Iter 11 subLoss 3969.6 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 451 Acc: 95.08 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 396 train Loss: 5026.0 test Loss: 765.1
Epoch 452 Iter 0 subLoss 4697.5 multi -10.94 import weight 0.00
Epoch 452 Iter 1 subLoss 10361.2 multi -4.97 import weight 0.00
Epoch 452 Iter 2 subLoss 44145.5 multi 1.00 import weight 0.00
Epoch 452 Iter 3 subLoss 11696.4 multi 1.00 import weight 0.00
Epoch 452 Iter 4 subLoss 8193.6 multi 1.00 import weight 0.00
Epoch 452 Iter 5 subLoss 7618.9 multi 6.97 import weight 0.00
Epoch 452 Iter 6 subLoss 4215.9 multi 18.91 import weight 0.00
Epoch 452 Iter 7 subLoss 3877.7 multi -4.97 import weight 0.00
Epoch 452 Iter 8 subLoss 4467.1 multi -19.90 import weight 0.00
Epoch 452 Iter 9 subLoss 4205.8 multi 6.97 import weight 0.00
Epoch 452 Iter 10 subLoss 4838.4 multi 1.00 import weight 0.00
Epoch 452 Iter 11 subLoss 3892.4 multi -1.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 452 Acc: 96.44 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 389 train Loss: 4668.7 test Loss: 605.6
Epoch 453 Iter 0 subLoss 4983.9 multi 6.97 import weight 0.00
Epoch 453 Iter 1 subLoss 4231.1 multi -31.84 import weight 0.00
Epoch 453 Iter 2 subLoss 5281.9 multi -10.94 import weight 0.00
Epoch 453 Iter 3 subLoss 5950.8 multi -7.96 import weight 0.00
Epoch 453 Iter 4 subLoss 7005.7 multi -10.94 import weight 0.00
Epoch 453 Iter 5 subLoss 13532.6 multi -4.97 import weight 0.00
Epoch 453 Iter 6 subLoss 67692.1 multi 1.00 import weight 0.00
Epoch 453 Iter 7 subLoss 11656.6 multi -1.99 import weight 0.00
Epoch 453 Iter 8 subLoss 14132.7 multi 1.00 import weight 0.00
Epoch 453 Iter 9 subLoss 11888.8 multi 1.00 import weight 0.00
Epoch 453 Iter 10 subLoss 11821.9 multi 1.00 import weight 0.00
Epoch 453 Iter 11 subLoss 10426.6 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 453 Acc: 93.77 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 1042 train Loss: 7774.4 test Loss: 1058.4
Epoch 454 Iter 0 subLoss 7326.6 multi -7.96 import weight 0.00
Epoch 454 Iter 1 subLoss 9446.8 multi -7.96 import weight 0.00
Epoch 454 Iter 2 subLoss 19624.3 multi -1.99 import weight 0.00
Epoch 454 Iter 3 subLoss 30026.9 multi 1.00 import weight 0.00
Epoch 454 Iter 4 subLoss 21619.1 multi 1.00 import weight 0.00
Epoch 454 Iter 5 subLoss 16566.4 multi 6.97 import weight 0.00
Epoch 454 Iter 6 subLoss 8387.6 multi -1.99 import weight 0.00
Epoch 454 Iter 7 subLoss 7780.1 multi 3.99 import weight 0.00
Epoch 454 Iter 8 subLoss 7025.0 multi 3.99 import weight 0.00
Epoch 454 Iter 9 subLoss 7090.7 multi 15.93 import weight 0.00
Epoch 454 Iter 10 subLoss 6273.4 multi 15.93 import weight 0.00
Epoch 454 Iter 11 subLoss 4541.4 multi -19.90 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 454 Acc: 95.80 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -19.90 Pidx 454 train Loss: 5292.6 test Loss: 726.2
Epoch 455 Iter 0 subLoss 4976.6 multi 6.97 import weight 0.00
Epoch 455 Iter 1 subLoss 5057.2 multi -31.84 import weight 0.00
Epoch 455 Iter 2 subLoss 7560.1 multi 12.94 import weight 0.00
Epoch 455 Iter 3 subLoss 4700.9 multi -10.94 import weight 0.00
Epoch 455 Iter 4 subLoss 5890.7 multi 9.96 import weight 0.00
Epoch 455 Iter 5 subLoss 4893.9 multi 21.90 import weight 0.00
Epoch 455 Iter 6 subLoss 4342.0 multi 15.93 import weight 0.00
Epoch 455 Iter 7 subLoss 4201.8 multi 9.96 import weight 0.00
Epoch 455 Iter 8 subLoss 4886.7 multi 9.96 import weight 0.00
Epoch 455 Iter 9 subLoss 4357.6 multi 3.99 import weight 0.00
Epoch 455 Iter 10 subLoss 4199.8 multi -1.98 import weight 0.00
Epoch 455 Iter 11 subLoss 3990.5 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 455 Acc: 96.71 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 399 train Loss: 4137.7 test Loss: 576.6
Epoch 456 Iter 0 subLoss 3950.4 multi 1.00 import weight 0.00
Epoch 456 Iter 1 subLoss 4224.4 multi 3.98 import weight 0.00
Epoch 456 Iter 2 subLoss 4181.9 multi 9.96 import weight 0.00
Epoch 456 Iter 3 subLoss 3844.7 multi 6.97 import weight 0.00
Epoch 456 Iter 4 subLoss 3889.4 multi -4.97 import weight 0.00
Epoch 456 Iter 5 subLoss 4044.8 multi -7.96 import weight 0.00
Epoch 456 Iter 6 subLoss 3945.9 multi -1.99 import weight 0.00
Epoch 456 Iter 7 subLoss 3766.9 multi 15.93 import weight 0.00
Epoch 456 Iter 8 subLoss 3858.6 multi -10.94 import weight 0.00
Epoch 456 Iter 9 subLoss 4342.7 multi 18.91 import weight 0.00
Epoch 456 Iter 10 subLoss 3803.7 multi 3.98 import weight 0.00
Epoch 456 Iter 11 subLoss 3811.1 multi 18.91 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 456 Acc: 96.73 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 18.91 Pidx 381 train Loss: 3941.0 test Loss: 549.2
Epoch 457 Iter 0 subLoss 3729.1 multi 3.98 import weight 0.00
Epoch 457 Iter 1 subLoss 3688.1 multi 15.93 import weight 0.00
Epoch 457 Iter 2 subLoss 4148.8 multi 3.99 import weight 0.00
Epoch 457 Iter 3 subLoss 3973.5 multi 1.00 import weight 0.00
Epoch 457 Iter 4 subLoss 3833.0 multi 6.97 import weight 0.00
Epoch 457 Iter 5 subLoss 3516.5 multi 15.93 import weight 0.00
Epoch 457 Iter 6 subLoss 3538.0 multi 21.90 import weight 0.00
Epoch 457 Iter 7 subLoss 3780.1 multi 1.00 import weight 0.00
Epoch 457 Iter 8 subLoss 3564.1 multi -1.99 import weight 0.00
Epoch 457 Iter 9 subLoss 3568.4 multi 1.00 import weight 0.00
Epoch 457 Iter 10 subLoss 3577.0 multi -10.94 import weight 0.00
Epoch 457 Iter 11 subLoss 3820.7 multi -16.91 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 457 Acc: 93.68 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -16.91 Pidx 382 train Loss: 5993.6 test Loss: 1008.9
Epoch 458 Iter 0 subLoss 6997.9 multi 1.00 import weight 0.00
Epoch 458 Iter 1 subLoss 5975.1 multi -4.97 import weight 0.00
Epoch 458 Iter 2 subLoss 7055.8 multi 21.90 import weight 0.00
Epoch 458 Iter 3 subLoss 6142.8 multi 18.91 import weight 0.00
Epoch 458 Iter 4 subLoss 4494.1 multi 1.00 import weight 0.00
Epoch 458 Iter 5 subLoss 4087.3 multi 6.97 import weight 0.00
Epoch 458 Iter 6 subLoss 3473.2 multi 1.00 import weight 0.00
Epoch 458 Iter 7 subLoss 3602.6 multi -4.97 import weight 0.00
Epoch 458 Iter 8 subLoss 4089.6 multi 9.96 import weight 0.00
Epoch 458 Iter 9 subLoss 3507.9 multi 6.97 import weight 0.00
Epoch 458 Iter 10 subLoss 3892.6 multi -1.99 import weight 0.00
Epoch 458 Iter 11 subLoss 3494.7 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 458 Acc: 96.65 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 349 train Loss: 3774.8 test Loss: 540.9
Epoch 459 Iter 0 subLoss 4597.3 multi -1.98 import weight 0.00
Epoch 459 Iter 1 subLoss 3058.4 multi 3.99 import weight 0.00
Epoch 459 Iter 2 subLoss 3342.5 multi 1.00 import weight 0.00
Epoch 459 Iter 3 subLoss 3914.8 multi 15.93 import weight 0.00
Epoch 459 Iter 4 subLoss 3111.8 multi 1.00 import weight 0.00
Epoch 459 Iter 5 subLoss 3868.2 multi 6.97 import weight 0.00
Epoch 459 Iter 6 subLoss 3898.6 multi 1.00 import weight 0.00
Epoch 459 Iter 7 subLoss 3679.7 multi -7.96 import weight 0.00
Epoch 459 Iter 8 subLoss 3052.5 multi 6.97 import weight 0.00
Epoch 459 Iter 9 subLoss 3552.5 multi 12.94 import weight 0.00
Epoch 459 Iter 10 subLoss 3107.3 multi 1.00 import weight 0.00
Epoch 459 Iter 11 subLoss 3952.5 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 459 Acc: 96.81 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 395 train Loss: 3558.0 test Loss: 506.5
Epoch 460 Iter 0 subLoss 3777.8 multi -1.99 import weight 0.00
Epoch 460 Iter 1 subLoss 3415.5 multi -10.94 import weight 0.00
Epoch 460 Iter 2 subLoss 3501.2 multi 6.97 import weight 0.00
Epoch 460 Iter 3 subLoss 3515.0 multi 12.94 import weight 0.00
Epoch 460 Iter 4 subLoss 3609.4 multi -1.98 import weight 0.00
Epoch 460 Iter 5 subLoss 3379.2 multi -1.98 import weight 0.00
Epoch 460 Iter 6 subLoss 3165.2 multi 1.00 import weight 0.00
Epoch 460 Iter 7 subLoss 3123.4 multi 1.00 import weight 0.00
Epoch 460 Iter 8 subLoss 3665.8 multi 6.97 import weight 0.00
Epoch 460 Iter 9 subLoss 3630.8 multi -13.93 import weight 0.00
Epoch 460 Iter 10 subLoss 3562.3 multi 1.00 import weight 0.00
Epoch 460 Iter 11 subLoss 3874.5 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 460 Acc: 96.69 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 387 train Loss: 3544.2 test Loss: 527.7
Epoch 461 Iter 0 subLoss 3988.4 multi 3.98 import weight 0.00
Epoch 461 Iter 1 subLoss 3860.8 multi 9.96 import weight 0.00
Epoch 461 Iter 2 subLoss 3416.1 multi -7.96 import weight 0.00
Epoch 461 Iter 3 subLoss 3940.7 multi 1.00 import weight 0.00
Epoch 461 Iter 4 subLoss 4272.3 multi 33.84 import weight 1.00
Epoch 461 Iter 5 subLoss 3451.7 multi -7.96 import weight 0.00
Epoch 461 Iter 6 subLoss 4679.4 multi -13.93 import weight 0.00
Epoch 461 Iter 7 subLoss 12241.7 multi -1.99 import weight 0.00
Epoch 461 Iter 8 subLoss 32279.4 multi -1.99 import weight 0.00
Epoch 461 Iter 9 subLoss 145504.2 multi 1.00 import weight 0.00
Epoch 461 Iter 10 subLoss 19744.7 multi 1.00 import weight 0.00
Epoch 461 Iter 11 subLoss 12176.5 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 461 Acc: 94.71 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 1217 train Loss: 5698.8 test Loss: 836.4
Epoch 462 Iter 0 subLoss 5298.7 multi 3.98 import weight 0.00
Epoch 462 Iter 1 subLoss 5056.0 multi -28.85 import weight 0.00
Epoch 462 Iter 2 subLoss 11704.5 multi -1.99 import weight 0.00
Epoch 462 Iter 3 subLoss 13294.4 multi -4.97 import weight 0.00
Epoch 462 Iter 4 subLoss 24938.4 multi 1.00 import weight 0.00
Epoch 462 Iter 5 subLoss 19658.0 multi 1.00 import weight 0.00
Epoch 462 Iter 6 subLoss 16299.0 multi -4.97 import weight 0.00
Epoch 462 Iter 7 subLoss 30787.4 multi 1.00 import weight 0.00
Epoch 462 Iter 8 subLoss 23176.3 multi 3.99 import weight 0.00
Epoch 462 Iter 9 subLoss 13049.5 multi -1.99 import weight 0.00
Epoch 462 Iter 10 subLoss 15039.6 multi -1.99 import weight 0.00
Epoch 462 Iter 11 subLoss 17716.0 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 462 Acc: 83.87 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1771 train Loss: 15982.9 test Loss: 2360.2
Epoch 463 Iter 0 subLoss 15712.9 multi -1.98 import weight 0.00
Epoch 463 Iter 1 subLoss 18336.2 multi 1.00 import weight 0.00
Epoch 463 Iter 2 subLoss 17263.7 multi 3.99 import weight 0.00
Epoch 463 Iter 3 subLoss 11768.9 multi 3.99 import weight 0.00
Epoch 463 Iter 4 subLoss 10288.0 multi 3.98 import weight 0.00
Epoch 463 Iter 5 subLoss 8561.1 multi 1.00 import weight 0.00
Epoch 463 Iter 6 subLoss 8398.4 multi -4.97 import weight 0.00
Epoch 463 Iter 7 subLoss 8893.2 multi -4.97 import weight 0.00
Epoch 463 Iter 8 subLoss 10785.7 multi 3.98 import weight 0.00
Epoch 463 Iter 9 subLoss 9818.4 multi 9.96 import weight 0.00
Epoch 463 Iter 10 subLoss 5831.9 multi 6.97 import weight 0.00
Epoch 463 Iter 11 subLoss 5323.4 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 463 Acc: 95.62 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 532 train Loss: 4746.5 test Loss: 710.6
Epoch 464 Iter 0 subLoss 4442.8 multi -1.99 import weight 0.00
Epoch 464 Iter 1 subLoss 5080.2 multi 6.97 import weight 0.00
Epoch 464 Iter 2 subLoss 4628.3 multi -22.88 import weight 0.00
Epoch 464 Iter 3 subLoss 6349.5 multi -4.97 import weight 0.00
Epoch 464 Iter 4 subLoss 6787.4 multi 3.99 import weight 0.00
Epoch 464 Iter 5 subLoss 5295.0 multi 6.97 import weight 0.00
Epoch 464 Iter 6 subLoss 5093.6 multi -13.93 import weight 0.00
Epoch 464 Iter 7 subLoss 6645.2 multi 24.88 import weight 0.00
Epoch 464 Iter 8 subLoss 4034.4 multi -1.99 import weight 0.00
Epoch 464 Iter 9 subLoss 4219.4 multi 15.93 import weight 0.00
Epoch 464 Iter 10 subLoss 3814.4 multi 21.90 import weight 0.00
Epoch 464 Iter 11 subLoss 3382.3 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 464 Acc: 96.83 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 338 train Loss: 3707.3 test Loss: 540.3
Epoch 465 Iter 0 subLoss 3638.0 multi -10.94 import weight 0.00
Epoch 465 Iter 1 subLoss 3923.6 multi -1.99 import weight 0.00
Epoch 465 Iter 2 subLoss 3299.2 multi -7.96 import weight 0.00
Epoch 465 Iter 3 subLoss 3343.4 multi 3.99 import weight 0.00
Epoch 465 Iter 4 subLoss 3969.2 multi -10.94 import weight 0.00
Epoch 465 Iter 5 subLoss 3946.4 multi 3.99 import weight 0.00
Epoch 465 Iter 6 subLoss 4247.6 multi 1.00 import weight 0.00
Epoch 465 Iter 7 subLoss 3703.8 multi -4.97 import weight 0.00
Epoch 465 Iter 8 subLoss 4229.6 multi 3.99 import weight 1.00
Epoch 465 Iter 9 subLoss 3614.4 multi 1.00 import weight 0.00
Epoch 465 Iter 10 subLoss 3886.7 multi -4.97 import weight 0.00
Epoch 465 Iter 11 subLoss 4287.4 multi -16.91 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 465 Acc: 96.11 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -16.91 Pidx 428 train Loss: 4543.9 test Loss: 680.6
Epoch 466 Iter 0 subLoss 4051.2 multi 12.94 import weight 0.00
Epoch 466 Iter 1 subLoss 3731.4 multi -10.94 import weight 0.00
Epoch 466 Iter 2 subLoss 4022.4 multi -1.99 import weight 0.00
Epoch 466 Iter 3 subLoss 4576.2 multi 24.88 import weight 0.00
Epoch 466 Iter 4 subLoss 4192.9 multi -1.99 import weight 0.00
Epoch 466 Iter 5 subLoss 3647.7 multi -1.99 import weight 0.00
Epoch 466 Iter 6 subLoss 4323.5 multi 9.96 import weight 0.00
Epoch 466 Iter 7 subLoss 3840.6 multi 6.97 import weight 0.00
Epoch 466 Iter 8 subLoss 3697.4 multi 1.00 import weight 0.00
Epoch 466 Iter 9 subLoss 3529.3 multi -19.90 import weight 0.00
Epoch 466 Iter 10 subLoss 3577.3 multi -10.94 import weight 0.00
Epoch 466 Iter 11 subLoss 4500.8 multi -16.91 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 466 Acc: 94.06 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -16.91 Pidx 450 train Loss: 5623.2 test Loss: 924.0
Epoch 467 Iter 0 subLoss 5689.3 multi 18.91 import weight 0.00
Epoch 467 Iter 1 subLoss 4943.0 multi -1.99 import weight 0.00
Epoch 467 Iter 2 subLoss 5492.0 multi -10.94 import weight 0.00
Epoch 467 Iter 3 subLoss 10428.1 multi 6.97 import weight 0.00
Epoch 467 Iter 4 subLoss 5133.6 multi 9.96 import weight 0.00
Epoch 467 Iter 5 subLoss 3819.1 multi 24.88 import weight 0.00
Epoch 467 Iter 6 subLoss 3792.5 multi -16.91 import weight 0.00
Epoch 467 Iter 7 subLoss 3520.2 multi -16.91 import weight 0.00
Epoch 467 Iter 8 subLoss 3948.4 multi 6.97 import weight 0.00
Epoch 467 Iter 9 subLoss 3638.0 multi -7.96 import weight 0.00
Epoch 467 Iter 10 subLoss 4167.7 multi -31.84 import weight 0.00
Epoch 467 Iter 11 subLoss 5117.3 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 467 Acc: 84.18 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 511 train Loss: 9993.7 test Loss: 2352.5
Epoch 468 Iter 0 subLoss 9876.8 multi -1.98 import weight 0.00
Epoch 468 Iter 1 subLoss 19892.4 multi 1.00 import weight 0.00
Epoch 468 Iter 2 subLoss 10030.2 multi 1.00 import weight 0.00
Epoch 468 Iter 3 subLoss 7444.4 multi -1.99 import weight 0.00
Epoch 468 Iter 4 subLoss 9765.6 multi 1.00 import weight 0.00
Epoch 468 Iter 5 subLoss 7791.1 multi -7.96 import weight 0.00
Epoch 468 Iter 6 subLoss 36844.8 multi 1.00 import weight 0.00
Epoch 468 Iter 7 subLoss 12499.9 multi 1.00 import weight 0.00
Epoch 468 Iter 8 subLoss 8008.3 multi -10.94 import weight 0.00
Epoch 468 Iter 9 subLoss 59377.4 multi 1.00 import weight 0.00
Epoch 468 Iter 10 subLoss 23215.9 multi 6.97 import weight 0.00
Epoch 468 Iter 11 subLoss 5518.6 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 468 Acc: 95.35 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 551 train Loss: 5702.2 test Loss: 821.5
Epoch 469 Iter 0 subLoss 5467.9 multi -1.98 import weight 0.00
Epoch 469 Iter 1 subLoss 5559.1 multi 15.93 import weight 0.00
Epoch 469 Iter 2 subLoss 5692.7 multi -16.91 import weight 0.00
Epoch 469 Iter 3 subLoss 5457.4 multi 9.96 import weight 0.00
Epoch 469 Iter 4 subLoss 5415.1 multi 3.99 import weight 0.00
Epoch 469 Iter 5 subLoss 4798.4 multi 15.93 import weight 0.00
Epoch 469 Iter 6 subLoss 4695.9 multi -7.96 import weight 0.00
Epoch 469 Iter 7 subLoss 4649.4 multi 12.94 import weight 0.00
Epoch 469 Iter 8 subLoss 4318.7 multi -16.91 import weight 0.00
Epoch 469 Iter 9 subLoss 4235.6 multi -34.82 import weight 0.00
Epoch 469 Iter 10 subLoss 5514.5 multi 3.98 import weight 0.00
Epoch 469 Iter 11 subLoss 5592.0 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 469 Acc: 95.58 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 559 train Loss: 5938.8 test Loss: 785.4
Epoch 470 Iter 0 subLoss 5733.1 multi 12.94 import weight 0.00
Epoch 470 Iter 1 subLoss 5380.1 multi -4.97 import weight 0.00
Epoch 470 Iter 2 subLoss 4970.5 multi 9.96 import weight 0.00
Epoch 470 Iter 3 subLoss 4332.3 multi -13.93 import weight 0.00
Epoch 470 Iter 4 subLoss 4962.8 multi -22.88 import weight 0.00
Epoch 470 Iter 5 subLoss 6892.3 multi 15.93 import weight 0.00
Epoch 470 Iter 6 subLoss 5641.0 multi -1.99 import weight 0.00
Epoch 470 Iter 7 subLoss 4867.1 multi -1.99 import weight 0.00
Epoch 470 Iter 8 subLoss 6322.6 multi 1.00 import weight 0.00
Epoch 470 Iter 9 subLoss 5395.8 multi 1.00 import weight 0.00
Epoch 470 Iter 10 subLoss 5750.7 multi 1.00 import weight 0.00
Epoch 470 Iter 11 subLoss 5896.2 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 470 Acc: 95.97 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 589 train Loss: 5156.6 test Loss: 728.3
Epoch 471 Iter 0 subLoss 4686.2 multi 24.88 import weight 0.00
Epoch 471 Iter 1 subLoss 4351.1 multi 3.98 import weight 0.00
Epoch 471 Iter 2 subLoss 4380.5 multi 3.99 import weight 0.00
Epoch 471 Iter 3 subLoss 4404.4 multi 15.93 import weight 0.00
Epoch 471 Iter 4 subLoss 4198.6 multi 1.00 import weight 0.00
Epoch 471 Iter 5 subLoss 4162.1 multi -28.85 import weight 0.00
Epoch 471 Iter 6 subLoss 4326.2 multi 9.96 import weight 0.00
Epoch 471 Iter 7 subLoss 4508.0 multi -13.93 import weight 0.00
Epoch 471 Iter 8 subLoss 5156.5 multi 15.93 import weight 0.00
Epoch 471 Iter 9 subLoss 4368.4 multi -22.88 import weight 0.00
Epoch 471 Iter 10 subLoss 5350.4 multi -13.93 import weight 0.00
Epoch 471 Iter 11 subLoss 6823.9 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 471 Acc: 96.28 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 682 train Loss: 4862.2 test Loss: 670.9
Epoch 472 Iter 0 subLoss 5267.8 multi 1.00 import weight 0.00
Epoch 472 Iter 1 subLoss 4755.3 multi 12.94 import weight 0.00
Epoch 472 Iter 2 subLoss 4108.6 multi -4.97 import weight 0.00
Epoch 472 Iter 3 subLoss 4257.8 multi 1.00 import weight 0.00
Epoch 472 Iter 4 subLoss 4754.2 multi 15.93 import weight 0.00
Epoch 472 Iter 5 subLoss 4521.7 multi -16.91 import weight 0.00
Epoch 472 Iter 6 subLoss 4407.9 multi 18.91 import weight 0.00
Epoch 472 Iter 7 subLoss 4176.0 multi -10.94 import weight 0.00
Epoch 472 Iter 8 subLoss 4647.8 multi 15.93 import weight 0.00
Epoch 472 Iter 9 subLoss 4853.2 multi -10.94 import weight 0.00
Epoch 472 Iter 10 subLoss 4491.9 multi 3.99 import weight 0.00
Epoch 472 Iter 11 subLoss 3856.8 multi -10.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 472 Acc: 96.11 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -10.94 Pidx 385 train Loss: 4702.7 test Loss: 653.6
Epoch 473 Iter 0 subLoss 4213.2 multi 18.91 import weight 0.00
Epoch 473 Iter 1 subLoss 4026.9 multi 1.00 import weight 0.00
Epoch 473 Iter 2 subLoss 4751.5 multi 18.91 import weight 0.00
Epoch 473 Iter 3 subLoss 4082.5 multi 12.94 import weight 0.00
Epoch 473 Iter 4 subLoss 3718.7 multi -1.98 import weight 0.00
Epoch 473 Iter 5 subLoss 3556.0 multi 15.93 import weight 0.00
Epoch 473 Iter 6 subLoss 3884.6 multi -1.98 import weight 0.00
Epoch 473 Iter 7 subLoss 4233.3 multi -31.84 import weight 0.00
Epoch 473 Iter 8 subLoss 4603.0 multi -1.98 import weight 0.00
Epoch 473 Iter 9 subLoss 4872.6 multi -1.99 import weight 0.00
Epoch 473 Iter 10 subLoss 3785.5 multi 1.00 import weight 0.00
Epoch 473 Iter 11 subLoss 4408.2 multi 21.90 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 473 Acc: 96.28 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 21.90 Pidx 440 train Loss: 4321.7 test Loss: 643.4
Epoch 474 Iter 0 subLoss 4421.1 multi 27.87 import weight 1.00
Epoch 474 Iter 1 subLoss 3854.0 multi -7.96 import weight 0.00
Epoch 474 Iter 2 subLoss 3946.4 multi 9.96 import weight 0.00
Epoch 474 Iter 3 subLoss 3542.2 multi -16.91 import weight 0.00
Epoch 474 Iter 4 subLoss 3960.1 multi -7.96 import weight 0.00
Epoch 474 Iter 5 subLoss 4142.9 multi 6.97 import weight 0.00
Epoch 474 Iter 6 subLoss 4167.5 multi -25.87 import weight 0.00
Epoch 474 Iter 7 subLoss 5412.0 multi 6.97 import weight 0.00
Epoch 474 Iter 8 subLoss 4187.5 multi 9.96 import weight 0.00
Epoch 474 Iter 9 subLoss 4078.6 multi -25.87 import weight 0.00
Epoch 474 Iter 10 subLoss 3857.3 multi -4.97 import weight 0.00
Epoch 474 Iter 11 subLoss 4736.7 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 474 Acc: 95.80 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 473 train Loss: 5214.7 test Loss: 732.6
Epoch 475 Iter 0 subLoss 4682.5 multi 27.87 import weight 0.00
Epoch 475 Iter 1 subLoss 4295.4 multi -13.93 import weight 0.00
Epoch 475 Iter 2 subLoss 5359.3 multi -10.94 import weight 0.00
Epoch 475 Iter 3 subLoss 9418.2 multi 1.00 import weight 0.00
Epoch 475 Iter 4 subLoss 7267.0 multi -4.97 import weight 0.00
Epoch 475 Iter 5 subLoss 12603.8 multi 3.99 import weight 0.00
Epoch 475 Iter 6 subLoss 6590.9 multi -1.99 import weight 0.00
Epoch 475 Iter 7 subLoss 7547.6 multi 9.96 import weight 0.00
Epoch 475 Iter 8 subLoss 4589.2 multi -16.91 import weight 0.00
Epoch 475 Iter 9 subLoss 5212.3 multi -7.96 import weight 0.00
Epoch 475 Iter 10 subLoss 5778.1 multi 3.99 import weight 0.00
Epoch 475 Iter 11 subLoss 5323.0 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 475 Acc: 96.56 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 532 train Loss: 4663.3 test Loss: 625.5
Epoch 476 Iter 0 subLoss 4602.9 multi 1.00 import weight 0.00
Epoch 476 Iter 1 subLoss 4474.5 multi -7.96 import weight 0.00
Epoch 476 Iter 2 subLoss 4117.9 multi 1.00 import weight 0.00
Epoch 476 Iter 3 subLoss 4388.4 multi 6.97 import weight 0.00
Epoch 476 Iter 4 subLoss 3957.6 multi -7.96 import weight 0.00
Epoch 476 Iter 5 subLoss 4928.9 multi 3.99 import weight 0.00
Epoch 476 Iter 6 subLoss 4662.5 multi 18.91 import weight 0.00
Epoch 476 Iter 7 subLoss 4297.8 multi -10.94 import weight 0.00
Epoch 476 Iter 8 subLoss 4274.0 multi 36.82 import weight 1.00
Epoch 476 Iter 9 subLoss 5102.2 multi 9.96 import weight 0.00
Epoch 476 Iter 10 subLoss 3745.4 multi 6.97 import weight 0.00
Epoch 476 Iter 11 subLoss 4479.1 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 476 Acc: 96.54 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 447 train Loss: 4053.6 test Loss: 585.5
Epoch 477 Iter 0 subLoss 3927.2 multi 1.00 import weight 0.00
Epoch 477 Iter 1 subLoss 3738.2 multi -7.96 import weight 0.00
Epoch 477 Iter 2 subLoss 3981.6 multi 6.97 import weight 0.00
Epoch 477 Iter 3 subLoss 4056.9 multi 15.93 import weight 0.00
Epoch 477 Iter 4 subLoss 4177.0 multi -10.94 import weight 0.00
Epoch 477 Iter 5 subLoss 4269.8 multi -4.97 import weight 0.00
Epoch 477 Iter 6 subLoss 3666.6 multi 9.96 import weight 0.00
Epoch 477 Iter 7 subLoss 3994.1 multi -7.96 import weight 0.00
Epoch 477 Iter 8 subLoss 4485.8 multi 3.99 import weight 0.00
Epoch 477 Iter 9 subLoss 3481.4 multi -19.90 import weight 0.00
Epoch 477 Iter 10 subLoss 4144.0 multi 9.96 import weight 0.00
Epoch 477 Iter 11 subLoss 3798.0 multi -16.91 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 477 Acc: 96.28 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -16.91 Pidx 379 train Loss: 4498.9 test Loss: 632.6
Epoch 478 Iter 0 subLoss 4617.2 multi 3.99 import weight 0.00
Epoch 478 Iter 1 subLoss 4035.6 multi -4.97 import weight 0.00
Epoch 478 Iter 2 subLoss 4087.6 multi 12.94 import weight 0.00
Epoch 478 Iter 3 subLoss 4407.7 multi 24.88 import weight 0.00
Epoch 478 Iter 4 subLoss 4054.5 multi 18.91 import weight 0.00
Epoch 478 Iter 5 subLoss 3620.6 multi 9.96 import weight 0.00
Epoch 478 Iter 6 subLoss 3855.6 multi -1.99 import weight 0.00
Epoch 478 Iter 7 subLoss 3687.4 multi 15.93 import weight 0.00
Epoch 478 Iter 8 subLoss 3883.4 multi 1.00 import weight 0.00
Epoch 478 Iter 9 subLoss 4105.6 multi -1.99 import weight 0.00
Epoch 478 Iter 10 subLoss 3493.0 multi 3.98 import weight 0.00
Epoch 478 Iter 11 subLoss 3953.4 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 478 Acc: 96.69 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 395 train Loss: 3784.2 test Loss: 555.3
Epoch 479 Iter 0 subLoss 3781.1 multi 3.98 import weight 0.00
Epoch 479 Iter 1 subLoss 4051.8 multi 21.90 import weight 0.00
Epoch 479 Iter 2 subLoss 3938.6 multi 6.97 import weight 0.00
Epoch 479 Iter 3 subLoss 3490.1 multi 6.97 import weight 0.00
Epoch 479 Iter 4 subLoss 4009.2 multi -4.97 import weight 0.00
Epoch 479 Iter 5 subLoss 3762.5 multi 18.91 import weight 0.00
Epoch 479 Iter 6 subLoss 4051.2 multi 24.88 import weight 0.00
Epoch 479 Iter 7 subLoss 3984.2 multi 9.96 import weight 0.00
Epoch 479 Iter 8 subLoss 2926.6 multi 1.00 import weight 0.00
Epoch 479 Iter 9 subLoss 3170.3 multi 1.00 import weight 0.00
Epoch 479 Iter 10 subLoss 3629.8 multi 12.94 import weight 0.00
Epoch 479 Iter 11 subLoss 3989.3 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 479 Acc: 96.83 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 398 train Loss: 3625.6 test Loss: 518.8
Epoch 480 Iter 0 subLoss 3806.3 multi 1.00 import weight 0.00
Epoch 480 Iter 1 subLoss 3642.7 multi -1.99 import weight 0.00
Epoch 480 Iter 2 subLoss 2965.9 multi 1.00 import weight 0.00
Epoch 480 Iter 3 subLoss 3742.6 multi 6.97 import weight 0.00
Epoch 480 Iter 4 subLoss 3304.6 multi -1.98 import weight 0.00
Epoch 480 Iter 5 subLoss 3456.1 multi -4.97 import weight 0.00
Epoch 480 Iter 6 subLoss 3560.0 multi 15.93 import weight 0.00
Epoch 480 Iter 7 subLoss 2929.9 multi 3.99 import weight 0.00
Epoch 480 Iter 8 subLoss 3966.4 multi -10.94 import weight 0.00
Epoch 480 Iter 9 subLoss 3908.6 multi -19.90 import weight 0.00
Epoch 480 Iter 10 subLoss 3397.9 multi -4.97 import weight 0.00
Epoch 480 Iter 11 subLoss 3282.5 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 480 Acc: 96.65 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 328 train Loss: 3651.9 test Loss: 517.6
Epoch 481 Iter 0 subLoss 3522.0 multi -13.93 import weight 0.00
Epoch 481 Iter 1 subLoss 3439.2 multi 9.96 import weight 0.00
Epoch 481 Iter 2 subLoss 3835.2 multi 6.97 import weight 0.00
Epoch 481 Iter 3 subLoss 3944.9 multi 9.96 import weight 0.00
Epoch 481 Iter 4 subLoss 3118.2 multi 1.00 import weight 0.00
Epoch 481 Iter 5 subLoss 3369.1 multi 3.98 import weight 0.00
Epoch 481 Iter 6 subLoss 3765.0 multi 21.90 import weight 0.00
Epoch 481 Iter 7 subLoss 3634.5 multi -10.94 import weight 0.00
Epoch 481 Iter 8 subLoss 3417.1 multi -4.97 import weight 0.00
Epoch 481 Iter 9 subLoss 4152.7 multi 24.88 import weight 0.00
Epoch 481 Iter 10 subLoss 3425.3 multi -10.94 import weight 0.00
Epoch 481 Iter 11 subLoss 4178.5 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 481 Acc: 93.38 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 417 train Loss: 6437.9 test Loss: 1020.8
Epoch 482 Iter 0 subLoss 5759.5 multi 3.99 import weight 0.00
Epoch 482 Iter 1 subLoss 4135.6 multi -10.94 import weight 0.00
Epoch 482 Iter 2 subLoss 7897.7 multi 3.98 import weight 0.00
Epoch 482 Iter 3 subLoss 5227.4 multi 21.90 import weight 0.00
Epoch 482 Iter 4 subLoss 3677.9 multi -10.94 import weight 0.00
Epoch 482 Iter 5 subLoss 6032.0 multi -10.94 import weight 0.00
Epoch 482 Iter 6 subLoss 25909.1 multi 1.00 import weight 0.00
Epoch 482 Iter 7 subLoss 9387.1 multi -4.97 import weight 0.00
Epoch 482 Iter 8 subLoss 31403.7 multi 1.00 import weight 0.00
Epoch 482 Iter 9 subLoss 12968.9 multi -1.99 import weight 0.00
Epoch 482 Iter 10 subLoss 22285.4 multi 1.00 import weight 0.00
Epoch 482 Iter 11 subLoss 13085.4 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 482 Acc: 60.42 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 1308 train Loss: 65579.6 test Loss: 12670.1
Epoch 483 Iter 0 subLoss 65046.5 multi 1.00 import weight 0.00
Epoch 483 Iter 1 subLoss 16215.0 multi 3.99 import weight 0.00
Epoch 483 Iter 2 subLoss 7723.9 multi -7.96 import weight 0.00
Epoch 483 Iter 3 subLoss 13419.4 multi -1.99 import weight 0.00
Epoch 483 Iter 4 subLoss 17759.0 multi 6.97 import weight 0.00
Epoch 483 Iter 5 subLoss 6282.4 multi -1.99 import weight 0.00
Epoch 483 Iter 6 subLoss 6383.0 multi -1.99 import weight 0.00
Epoch 483 Iter 7 subLoss 8017.9 multi 1.00 import weight 0.00
Epoch 483 Iter 8 subLoss 6532.0 multi 3.99 import weight 0.00
Epoch 483 Iter 9 subLoss 6175.6 multi -16.91 import weight 0.00
Epoch 483 Iter 10 subLoss 11998.6 multi 3.98 import weight 0.00
Epoch 483 Iter 11 subLoss 8496.3 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 483 Acc: 89.92 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 849 train Loss: 9512.8 test Loss: 1412.1
Epoch 484 Iter 0 subLoss 9129.1 multi 3.98 import weight 0.00
Epoch 484 Iter 1 subLoss 7460.5 multi -1.99 import weight 0.00
Epoch 484 Iter 2 subLoss 8058.9 multi 6.97 import weight 0.00
Epoch 484 Iter 3 subLoss 6051.2 multi -4.97 import weight 0.00
Epoch 484 Iter 4 subLoss 6325.9 multi 3.98 import weight 0.00
Epoch 484 Iter 5 subLoss 5669.4 multi 3.98 import weight 0.00
Epoch 484 Iter 6 subLoss 5300.0 multi 1.00 import weight 0.00
Epoch 484 Iter 7 subLoss 5794.3 multi -4.97 import weight 0.00
Epoch 484 Iter 8 subLoss 5932.9 multi 1.00 import weight 0.00
Epoch 484 Iter 9 subLoss 5498.0 multi -7.96 import weight 0.00
Epoch 484 Iter 10 subLoss 7060.3 multi -1.98 import weight 0.00
Epoch 484 Iter 11 subLoss 7579.1 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 484 Acc: 89.59 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 757 train Loss: 9263.2 test Loss: 1423.1
Epoch 485 Iter 0 subLoss 8715.5 multi 6.97 import weight 0.00
Epoch 485 Iter 1 subLoss 7495.6 multi 1.00 import weight 0.00
Epoch 485 Iter 2 subLoss 6395.2 multi -10.94 import weight 0.00
Epoch 485 Iter 3 subLoss 9063.6 multi 6.97 import weight 0.00
Epoch 485 Iter 4 subLoss 6170.5 multi -13.93 import weight 0.00
Epoch 485 Iter 5 subLoss 10893.9 multi 1.00 import weight 0.00
Epoch 485 Iter 6 subLoss 9811.9 multi 12.94 import weight 0.00
Epoch 485 Iter 7 subLoss 5363.9 multi 9.96 import weight 0.00
Epoch 485 Iter 8 subLoss 4547.4 multi -16.91 import weight 0.00
Epoch 485 Iter 9 subLoss 5757.1 multi 6.97 import weight 0.00
Epoch 485 Iter 10 subLoss 5398.4 multi 3.99 import weight 0.00
Epoch 485 Iter 11 subLoss 4822.1 multi -1.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 485 Acc: 95.91 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 482 train Loss: 5154.1 test Loss: 737.8
Epoch 486 Iter 0 subLoss 5533.7 multi 12.94 import weight 0.00
Epoch 486 Iter 1 subLoss 4621.9 multi -22.88 import weight 0.00
Epoch 486 Iter 2 subLoss 5483.5 multi 1.00 import weight 0.00
Epoch 486 Iter 3 subLoss 5118.3 multi -7.96 import weight 0.00
Epoch 486 Iter 4 subLoss 6514.0 multi -1.99 import weight 0.00
Epoch 486 Iter 5 subLoss 5944.0 multi -1.98 import weight 0.00
Epoch 486 Iter 6 subLoss 6544.7 multi 1.00 import weight 0.00
Epoch 486 Iter 7 subLoss 6667.3 multi -1.99 import weight 0.00
Epoch 486 Iter 8 subLoss 6748.8 multi -4.97 import weight 0.00
Epoch 486 Iter 9 subLoss 7878.6 multi -1.99 import weight 0.00
Epoch 486 Iter 10 subLoss 10375.4 multi 1.00 import weight 0.00
Epoch 486 Iter 11 subLoss 8861.4 multi 3.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 486 Acc: 93.73 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 886 train Loss: 7156.7 test Loss: 1169.5
Epoch 487 Iter 0 subLoss 7024.2 multi 6.97 import weight 0.00
Epoch 487 Iter 1 subLoss 5876.7 multi 6.97 import weight 0.00
Epoch 487 Iter 2 subLoss 5169.1 multi -4.97 import weight 0.00
Epoch 487 Iter 3 subLoss 5332.5 multi -7.96 import weight 0.00
Epoch 487 Iter 4 subLoss 6593.1 multi 1.00 import weight 0.00
Epoch 487 Iter 5 subLoss 6002.0 multi 6.97 import weight 0.00
Epoch 487 Iter 6 subLoss 4785.4 multi -22.88 import weight 0.00
Epoch 487 Iter 7 subLoss 6952.0 multi 3.99 import weight 0.00
Epoch 487 Iter 8 subLoss 6324.1 multi 6.97 import weight 0.00
Epoch 487 Iter 9 subLoss 5801.7 multi -4.97 import weight 0.00
Epoch 487 Iter 10 subLoss 6023.0 multi -4.97 import weight 0.00
Epoch 487 Iter 11 subLoss 6124.3 multi -10.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 487 Acc: 91.46 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -10.94 Pidx 612 train Loss: 8508.5 test Loss: 1529.8
Epoch 488 Iter 0 subLoss 8449.8 multi 1.00 import weight 0.00
Epoch 488 Iter 1 subLoss 8043.7 multi 6.97 import weight 0.00
Epoch 488 Iter 2 subLoss 6434.2 multi -4.97 import weight 0.00
Epoch 488 Iter 3 subLoss 7712.5 multi 3.98 import weight 0.00
Epoch 488 Iter 4 subLoss 6414.5 multi -1.99 import weight 0.00
Epoch 488 Iter 5 subLoss 6736.6 multi -1.99 import weight 0.00
Epoch 488 Iter 6 subLoss 6835.5 multi -7.96 import weight 0.00
Epoch 488 Iter 7 subLoss 8271.4 multi 3.99 import weight 0.00
Epoch 488 Iter 8 subLoss 7434.8 multi 1.00 import weight 0.00
Epoch 488 Iter 9 subLoss 7686.7 multi -1.98 import weight 0.00
Epoch 488 Iter 10 subLoss 7201.0 multi 3.99 import weight 0.00
Epoch 488 Iter 11 subLoss 6862.3 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 488 Acc: 94.28 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 686 train Loss: 7350.1 test Loss: 1179.9
Epoch 489 Iter 0 subLoss 7537.5 multi -16.91 import weight 0.00
Epoch 489 Iter 1 subLoss 11128.2 multi 1.00 import weight 0.00
Epoch 489 Iter 2 subLoss 11188.8 multi 1.00 import weight 0.00
Epoch 489 Iter 3 subLoss 10259.7 multi -4.97 import weight 0.00
Epoch 489 Iter 4 subLoss 13321.1 multi 9.96 import weight 0.00
Epoch 489 Iter 5 subLoss 7292.7 multi -1.99 import weight 0.00
Epoch 489 Iter 6 subLoss 8053.0 multi 6.97 import weight 0.00
Epoch 489 Iter 7 subLoss 6698.7 multi -1.99 import weight 0.00
Epoch 489 Iter 8 subLoss 7017.1 multi 6.97 import weight 0.00
Epoch 489 Iter 9 subLoss 6164.4 multi -19.90 import weight 0.00
Epoch 489 Iter 10 subLoss 8298.8 multi 1.00 import weight 0.00
Epoch 489 Iter 11 subLoss 8983.7 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 489 Acc: 93.89 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 898 train Loss: 8393.8 test Loss: 1287.6
Epoch 490 Iter 0 subLoss 8236.3 multi 1.00 import weight 0.00
Epoch 490 Iter 1 subLoss 7502.8 multi -16.91 import weight 0.00
Epoch 490 Iter 2 subLoss 11389.2 multi 9.96 import weight 0.00
Epoch 490 Iter 3 subLoss 8316.5 multi -4.97 import weight 0.00
Epoch 490 Iter 4 subLoss 9254.8 multi 6.97 import weight 0.00
Epoch 490 Iter 5 subLoss 7705.7 multi 12.94 import weight 0.00
Epoch 490 Iter 6 subLoss 6489.1 multi -7.96 import weight 0.00
Epoch 490 Iter 7 subLoss 6889.2 multi -4.97 import weight 0.00
Epoch 490 Iter 8 subLoss 7359.3 multi -13.93 import weight 0.00
Epoch 490 Iter 9 subLoss 10419.3 multi -4.97 import weight 0.00
Epoch 490 Iter 10 subLoss 12027.7 multi 1.00 import weight 0.00
Epoch 490 Iter 11 subLoss 12425.4 multi -1.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 490 Acc: 88.81 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 1242 train Loss: 12968.6 test Loss: 2168.8
Epoch 491 Iter 0 subLoss 12186.7 multi -4.97 import weight 0.00
Epoch 491 Iter 1 subLoss 17233.0 multi 1.00 import weight 0.00
Epoch 491 Iter 2 subLoss 15477.8 multi 1.00 import weight 0.00
Epoch 491 Iter 3 subLoss 14465.5 multi 1.00 import weight 0.00
Epoch 491 Iter 4 subLoss 13261.0 multi 3.98 import weight 0.00
Epoch 491 Iter 5 subLoss 11330.6 multi 6.97 import weight 0.00
Epoch 491 Iter 6 subLoss 8985.8 multi 3.99 import weight 0.00
Epoch 491 Iter 7 subLoss 7896.3 multi 6.97 import weight 0.00
Epoch 491 Iter 8 subLoss 7650.7 multi -1.99 import weight 0.00
Epoch 491 Iter 9 subLoss 7154.9 multi -4.97 import weight 0.00
Epoch 491 Iter 10 subLoss 7844.0 multi -1.99 import weight 0.00
Epoch 491 Iter 11 subLoss 8131.9 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 491 Acc: 95.15 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 813 train Loss: 6876.5 test Loss: 988.0
Epoch 492 Iter 0 subLoss 6605.7 multi -4.97 import weight 0.00
Epoch 492 Iter 1 subLoss 7128.8 multi 6.97 import weight 0.00
Epoch 492 Iter 2 subLoss 7282.2 multi 3.99 import weight 0.00
Epoch 492 Iter 3 subLoss 6503.4 multi -13.93 import weight 0.00
Epoch 492 Iter 4 subLoss 7595.9 multi 9.96 import weight 0.00
Epoch 492 Iter 5 subLoss 6070.0 multi 12.94 import weight 0.00
Epoch 492 Iter 6 subLoss 5773.9 multi 6.97 import weight 0.00
Epoch 492 Iter 7 subLoss 5762.8 multi 1.00 import weight 0.00
Epoch 492 Iter 8 subLoss 4774.1 multi 18.91 import weight 0.00
Epoch 492 Iter 9 subLoss 4997.4 multi -16.91 import weight 0.00
Epoch 492 Iter 10 subLoss 5322.4 multi 12.94 import weight 0.00
Epoch 492 Iter 11 subLoss 4746.6 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 492 Acc: 96.34 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 474 train Loss: 4795.2 test Loss: 650.0
Epoch 493 Iter 0 subLoss 4762.7 multi -25.87 import weight 0.00
Epoch 493 Iter 1 subLoss 5223.0 multi 24.88 import weight 0.00
Epoch 493 Iter 2 subLoss 4415.9 multi -19.90 import weight 0.00
Epoch 493 Iter 3 subLoss 5431.1 multi 12.94 import weight 0.00
Epoch 493 Iter 4 subLoss 4549.6 multi -13.93 import weight 0.00
Epoch 493 Iter 5 subLoss 4608.9 multi 3.99 import weight 0.00
Epoch 493 Iter 6 subLoss 4897.0 multi 21.90 import weight 0.00
Epoch 493 Iter 7 subLoss 4614.3 multi 3.98 import weight 0.00
Epoch 493 Iter 8 subLoss 3500.7 multi 3.98 import weight 0.00
Epoch 493 Iter 9 subLoss 4452.2 multi 24.88 import weight 0.00
Epoch 493 Iter 10 subLoss 3970.9 multi -4.97 import weight 0.00
Epoch 493 Iter 11 subLoss 4078.8 multi -22.88 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 493 Acc: 96.13 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -22.88 Pidx 407 train Loss: 4635.1 test Loss: 667.2
Epoch 494 Iter 0 subLoss 4274.6 multi 36.82 import weight 1.00
Epoch 494 Iter 1 subLoss 3772.4 multi -4.97 import weight 0.00
Epoch 494 Iter 2 subLoss 4268.3 multi -1.99 import weight 0.00
Epoch 494 Iter 3 subLoss 4400.6 multi 27.87 import weight 0.00
Epoch 494 Iter 4 subLoss 4499.0 multi 3.98 import weight 0.00
Epoch 494 Iter 5 subLoss 3858.2 multi 1.00 import weight 0.00
Epoch 494 Iter 6 subLoss 4090.3 multi -10.94 import weight 0.00
Epoch 494 Iter 7 subLoss 4275.5 multi 36.82 import weight 1.00
Epoch 494 Iter 8 subLoss 4160.7 multi -25.87 import weight 0.00
Epoch 494 Iter 9 subLoss 10363.2 multi -1.98 import weight 0.00
Epoch 494 Iter 10 subLoss 13200.9 multi 6.97 import weight 0.00
Epoch 494 Iter 11 subLoss 7011.9 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 494 Acc: 95.54 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 701 train Loss: 4825.2 test Loss: 749.4
Epoch 495 Iter 0 subLoss 4645.2 multi 18.91 import weight 0.00
Epoch 495 Iter 1 subLoss 3605.8 multi 1.00 import weight 0.00
Epoch 495 Iter 2 subLoss 3537.8 multi 15.93 import weight 0.00
Epoch 495 Iter 3 subLoss 4024.1 multi 3.98 import weight 0.00
Epoch 495 Iter 4 subLoss 3458.4 multi -1.98 import weight 0.00
Epoch 495 Iter 5 subLoss 3847.7 multi 6.97 import weight 0.00
Epoch 495 Iter 6 subLoss 4034.7 multi -4.97 import weight 0.00
Epoch 495 Iter 7 subLoss 3677.6 multi -7.96 import weight 0.00
Epoch 495 Iter 8 subLoss 3386.6 multi 6.97 import weight 0.00
Epoch 495 Iter 9 subLoss 3502.6 multi 6.97 import weight 0.00
Epoch 495 Iter 10 subLoss 3737.6 multi -4.97 import weight 0.00
Epoch 495 Iter 11 subLoss 4023.5 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 495 Acc: 96.81 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 402 train Loss: 3712.7 test Loss: 535.5
Epoch 496 Iter 0 subLoss 3415.5 multi -1.99 import weight 0.00
Epoch 496 Iter 1 subLoss 3368.9 multi 6.97 import weight 0.00
Epoch 496 Iter 2 subLoss 3765.0 multi 24.88 import weight 0.00
Epoch 496 Iter 3 subLoss 3936.6 multi 9.96 import weight 0.00
Epoch 496 Iter 4 subLoss 3506.8 multi 9.96 import weight 0.00
Epoch 496 Iter 5 subLoss 3553.8 multi 18.91 import weight 0.00
Epoch 496 Iter 6 subLoss 3494.9 multi 9.96 import weight 0.00
Epoch 496 Iter 7 subLoss 3885.7 multi 3.99 import weight 0.00
Epoch 496 Iter 8 subLoss 3408.0 multi 9.96 import weight 0.00
Epoch 496 Iter 9 subLoss 3848.2 multi 9.96 import weight 0.00
Epoch 496 Iter 10 subLoss 3034.3 multi -1.98 import weight 0.00
Epoch 496 Iter 11 subLoss 3060.2 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 496 Acc: 96.94 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 306 train Loss: 3454.2 test Loss: 488.2
Epoch 497 Iter 0 subLoss 3424.3 multi -10.94 import weight 0.00
Epoch 497 Iter 1 subLoss 3516.4 multi 6.97 import weight 0.00
Epoch 497 Iter 2 subLoss 3614.5 multi 1.00 import weight 0.00
Epoch 497 Iter 3 subLoss 3256.4 multi 1.00 import weight 0.00
Epoch 497 Iter 4 subLoss 3114.2 multi 3.98 import weight 0.00
Epoch 497 Iter 5 subLoss 3326.1 multi 6.97 import weight 0.00
Epoch 497 Iter 6 subLoss 3254.7 multi 3.98 import weight 0.00
Epoch 497 Iter 7 subLoss 3290.3 multi -7.96 import weight 0.00
Epoch 497 Iter 8 subLoss 3706.9 multi -4.97 import weight 0.00
Epoch 497 Iter 9 subLoss 3601.9 multi 3.99 import weight 0.00
Epoch 497 Iter 10 subLoss 3428.0 multi -7.96 import weight 0.00
Epoch 497 Iter 11 subLoss 3639.3 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 497 Acc: 96.93 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 363 train Loss: 3562.5 test Loss: 498.7
Epoch 498 Iter 0 subLoss 3822.5 multi -19.90 import weight 0.00
Epoch 498 Iter 1 subLoss 3968.6 multi -7.96 import weight 0.00
Epoch 498 Iter 2 subLoss 3981.0 multi 12.94 import weight 0.00
Epoch 498 Iter 3 subLoss 3287.2 multi 12.94 import weight 0.00
Epoch 498 Iter 4 subLoss 3573.4 multi -7.96 import weight 0.00
Epoch 498 Iter 5 subLoss 3174.8 multi 3.98 import weight 0.00
Epoch 498 Iter 6 subLoss 3828.2 multi -16.91 import weight 0.00
Epoch 498 Iter 7 subLoss 3829.4 multi -13.93 import weight 0.00
Epoch 498 Iter 8 subLoss 4863.9 multi -1.99 import weight 0.00
Epoch 498 Iter 9 subLoss 4552.3 multi 12.94 import weight 0.00
Epoch 498 Iter 10 subLoss 4070.5 multi -19.90 import weight 0.00
Epoch 498 Iter 11 subLoss 4164.2 multi -22.88 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 498 Acc: 95.19 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -22.88 Pidx 416 train Loss: 7035.0 test Loss: 847.2
Epoch 499 Iter 0 subLoss 6914.0 multi -4.97 import weight 0.00
Epoch 499 Iter 1 subLoss 11668.3 multi 1.00 import weight 0.00
Epoch 499 Iter 2 subLoss 9543.6 multi 1.00 import weight 0.00
Epoch 499 Iter 3 subLoss 7359.7 multi -10.94 import weight 0.00
Epoch 499 Iter 4 subLoss 31795.6 multi 3.99 import weight 0.00
Epoch 499 Iter 5 subLoss 4843.2 multi -1.98 import weight 0.00
Epoch 499 Iter 6 subLoss 5483.4 multi 3.99 import weight 0.00
Epoch 499 Iter 7 subLoss 5376.1 multi -7.96 import weight 0.00
Epoch 499 Iter 8 subLoss 4808.3 multi 21.90 import weight 0.00
Epoch 499 Iter 9 subLoss 3820.6 multi -10.94 import weight 0.00
Epoch 499 Iter 10 subLoss 4666.8 multi 21.90 import weight 0.00
Epoch 499 Iter 11 subLoss 3816.6 multi 24.88 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.0122 / 0.12614 / 8.14
Entropy seen (from low to high)
[2346, 345, 316, 790, 246, 132, 95, 66, 61, 56, 46, 48, 37, 31, 31, 30, 30, 35, 29, 31, 40, 34, 32, 23, 19, 22, 21, 24, 15, 12, 10, 7, 12, 13, 9, 8, 8, 7, 7, 3, 5, 4, 0, 2, 1, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 3, 10, 20, 30, 52, 58, 70, 97, 117, 105, 124, 136, 144, 138, 153, 149, 142, 147, 128, 156, 123, 118, 139, 114, 102, 108, 110, 107, 104, 90, 104, 110, 114, 94, 102, 103, 100, 108, 91, 124, 125, 130, 143, 137, 182]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 31.4, 34.7, 36.6, 40.6, 44.0, 47.2, 50.5, 54.1, 57.7, 61.5, 64.7, 67.9]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.3, 39.9, 42.8, 54.5, 59.9, 57.5, 70.8, 72.9, 70.3, 79.9]
[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 9, 15, 14, 11, 35, 33, 24, 37, 54, 40]
Epoch 499 Acc: 96.58 BMA: 96.03 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 24.88 Pidx 381 train Loss: 3851.9 test Loss: 537.4
Sampling Time used: 15932.5
Grad mul
