Namespace(N=50000, T=0.1, batch=5000, c='csghmc', classes=5, div=10, filters=16, gpu=3, hidden=10, ifprint=1.0, ifsave=1.0, lr=1e-06, part=1000000, seed=31746, sn=500, stepsize=0.01, warm=0.5, wdecay=25, zeta=30000.0)
adjust the learning rate 2.000e-06 weight decay 1.200e+01
(16, 1, 5, 5)
(16,)
(32, 16, 5, 5)
(32,)
(10, 1568)
(10,)
(5, 10)
(5,)
Current Theta
tensor([1.0000e-06, 1.0000e-06, 1.0000e-06,  ..., 1.0000e-06, 1.0000e-06,
        1.0000e-06], device='cuda:3')
Epoch 0 Iter 0 subLoss 48811.7 multi 1.00 import weight 1.00
Epoch 0 Iter 1 subLoss 48462.6 multi 1.00 import weight 1.00
Epoch 0 Iter 2 subLoss 48297.8 multi 1.00 import weight 1.00
Epoch 0 Iter 3 subLoss 48087.4 multi 1.00 import weight 1.00
Epoch 0 Iter 4 subLoss 47945.2 multi 1.00 import weight 1.00
Epoch 0 Iter 5 subLoss 47806.2 multi 1.00 import weight 1.00
Epoch 0 Iter 6 subLoss 47606.0 multi 1.00 import weight 1.00
Epoch 0 Iter 7 subLoss 47300.8 multi 1.00 import weight 1.00
Epoch 0 Iter 8 subLoss 47058.1 multi 1.00 import weight 1.00
Epoch 0 Iter 9 subLoss 46639.2 multi 1.00 import weight 1.00
Epoch 0 Iter 10 subLoss 46482.7 multi 1.00 import weight 1.00
Epoch 0 Iter 11 subLoss 46176.3 multi 1.00 import weight 1.00
Epoch 0 Acc: 39.19 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 1.00 Pidx 4617 train Loss: 46846.6 test Loss: 7610.5
Epoch 1 Iter 0 subLoss 45959.6 multi 1.00 import weight 1.00
Epoch 1 Iter 1 subLoss 45826.8 multi 1.00 import weight 1.00
Epoch 1 Iter 2 subLoss 45485.6 multi 1.00 import weight 1.00
Epoch 1 Iter 3 subLoss 46080.0 multi 1.00 import weight 1.00
Epoch 1 Iter 4 subLoss 48310.0 multi -1.99 import weight 1.00
Epoch 1 Iter 5 subLoss 131180.7 multi 1.00 import weight 1.00
Epoch 1 Iter 6 subLoss 48621.2 multi 1.00 import weight 1.00
Epoch 1 Iter 7 subLoss 48496.6 multi 1.00 import weight 1.00
Epoch 1 Iter 8 subLoss 48517.2 multi 1.00 import weight 1.00
Epoch 1 Iter 9 subLoss 48495.5 multi 3.99 import weight 1.00
Epoch 1 Iter 10 subLoss 48369.6 multi 1.00 import weight 0.00
Epoch 1 Iter 11 subLoss 48552.1 multi 1.00 import weight 0.00
Epoch 1 Acc: 20.08 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4855 train Loss: 49376.7 test Loss: 8265.3
Epoch 2 Iter 0 subLoss 48502.3 multi -4.97 import weight 0.00
Epoch 2 Iter 1 subLoss 48561.8 multi -1.99 import weight 0.00
Epoch 2 Iter 2 subLoss 48487.3 multi 1.00 import weight 0.00
Epoch 2 Iter 3 subLoss 48481.0 multi 3.99 import weight 1.00
Epoch 2 Iter 4 subLoss 48495.6 multi 1.00 import weight 1.00
Epoch 2 Iter 5 subLoss 48461.5 multi 3.99 import weight 0.00
Epoch 2 Iter 6 subLoss 48270.6 multi 1.00 import weight 0.00
Epoch 2 Iter 7 subLoss 48432.2 multi 1.00 import weight 0.00
Epoch 2 Iter 8 subLoss 48430.3 multi 3.99 import weight 0.00
Epoch 2 Iter 9 subLoss 48138.5 multi 1.00 import weight 0.00
Epoch 2 Iter 10 subLoss 48204.6 multi 1.00 import weight 0.00
Epoch 2 Iter 11 subLoss 48203.0 multi 3.99 import weight 0.00
Epoch 2 Acc: 20.08 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 4820 train Loss: 49047.4 test Loss: 8191.7
Epoch 3 Iter 0 subLoss 47961.0 multi 1.00 import weight 0.00
Epoch 3 Iter 1 subLoss 48094.7 multi -1.99 import weight 0.00
Epoch 3 Iter 2 subLoss 48089.9 multi 3.99 import weight 0.00
Epoch 3 Iter 3 subLoss 48091.6 multi -1.98 import weight 0.00
Epoch 3 Iter 4 subLoss 48036.4 multi 1.00 import weight 0.00
Epoch 3 Iter 5 subLoss 48078.1 multi 1.00 import weight 0.00
Epoch 3 Iter 6 subLoss 48066.7 multi 1.00 import weight 0.00
Epoch 3 Iter 7 subLoss 47979.0 multi -1.99 import weight 0.00
Epoch 3 Iter 8 subLoss 48029.3 multi 1.00 import weight 0.00
Epoch 3 Iter 9 subLoss 48033.5 multi 1.00 import weight 0.00
Epoch 3 Iter 10 subLoss 48055.7 multi 1.00 import weight 0.00
Epoch 3 Iter 11 subLoss 47867.6 multi 1.00 import weight 0.00
Epoch 3 Acc: 20.08 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4786 train Loss: 48839.9 test Loss: 8142.4
Epoch 4 Iter 0 subLoss 47869.2 multi 3.99 import weight 0.00
Epoch 4 Iter 1 subLoss 47735.8 multi 1.00 import weight 0.00
Epoch 4 Iter 2 subLoss 47701.8 multi 1.00 import weight 0.00
Epoch 4 Iter 3 subLoss 47600.1 multi 3.99 import weight 0.00
Epoch 4 Iter 4 subLoss 47272.2 multi 1.00 import weight 0.00
Epoch 4 Iter 5 subLoss 47130.3 multi 1.00 import weight 0.00
Epoch 4 Iter 6 subLoss 46877.5 multi 1.00 import weight 0.00
Epoch 4 Iter 7 subLoss 46903.5 multi 1.00 import weight 0.00
Epoch 4 Iter 8 subLoss 46830.7 multi 1.00 import weight 0.00
Epoch 4 Iter 9 subLoss 46574.5 multi 1.00 import weight 0.00
Epoch 4 Iter 10 subLoss 46487.9 multi 3.99 import weight 0.00
Epoch 4 Iter 11 subLoss 45826.5 multi 3.99 import weight 0.00
Epoch 4 Acc: 24.99 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 4582 train Loss: 46088.2 test Loss: 7474.2
Epoch 5 Iter 0 subLoss 45077.8 multi 1.00 import weight 0.00
Epoch 5 Iter 1 subLoss 45097.5 multi 1.00 import weight 0.00
Epoch 5 Iter 2 subLoss 44697.8 multi 1.00 import weight 0.00
Epoch 5 Iter 3 subLoss 44674.9 multi 1.00 import weight 0.00
Epoch 5 Iter 4 subLoss 44544.2 multi 1.00 import weight 0.00
Epoch 5 Iter 5 subLoss 44161.2 multi 1.00 import weight 0.00
Epoch 5 Iter 6 subLoss 43927.8 multi 1.00 import weight 0.00
Epoch 5 Iter 7 subLoss 43889.5 multi 1.00 import weight 0.00
Epoch 5 Iter 8 subLoss 43777.3 multi 1.00 import weight 0.00
Epoch 5 Iter 9 subLoss 43591.5 multi 1.00 import weight 0.00
Epoch 5 Iter 10 subLoss 43113.2 multi 1.00 import weight 0.00
Epoch 5 Iter 11 subLoss 43043.8 multi 1.00 import weight 0.00
Epoch 5 Acc: 33.66 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4304 train Loss: 43776.2 test Loss: 7000.1
Epoch 6 Iter 0 subLoss 43120.4 multi -1.99 import weight 0.00
Epoch 6 Iter 1 subLoss 43284.4 multi 1.00 import weight 0.00
Epoch 6 Iter 2 subLoss 43353.4 multi 1.00 import weight 0.00
Epoch 6 Iter 3 subLoss 42817.9 multi 1.00 import weight 0.00
Epoch 6 Iter 4 subLoss 42585.3 multi 1.00 import weight 0.00
Epoch 6 Iter 5 subLoss 42585.4 multi 3.99 import weight 0.00
Epoch 6 Iter 6 subLoss 41798.3 multi 1.00 import weight 0.00
Epoch 6 Iter 7 subLoss 41771.1 multi 1.00 import weight 0.00
Epoch 6 Iter 8 subLoss 41221.3 multi 1.00 import weight 0.00
Epoch 6 Iter 9 subLoss 41023.1 multi 1.00 import weight 0.00
Epoch 6 Iter 10 subLoss 41354.1 multi 1.00 import weight 0.00
Epoch 6 Iter 11 subLoss 41455.3 multi 1.00 import weight 0.00
Epoch 6 Acc: 48.47 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4145 train Loss: 42399.0 test Loss: 6693.8
Epoch 7 Iter 0 subLoss 41282.0 multi 1.00 import weight 0.00
Epoch 7 Iter 1 subLoss 41414.7 multi 1.00 import weight 0.00
Epoch 7 Iter 2 subLoss 41720.7 multi 1.00 import weight 0.00
Epoch 7 Iter 3 subLoss 40778.1 multi 1.00 import weight 0.00
Epoch 7 Iter 4 subLoss 40769.4 multi 1.00 import weight 0.00
Epoch 7 Iter 5 subLoss 40665.1 multi 1.00 import weight 0.00
Epoch 7 Iter 6 subLoss 41144.0 multi 1.00 import weight 0.00
Epoch 7 Iter 7 subLoss 39930.0 multi 1.00 import weight 0.00
Epoch 7 Iter 8 subLoss 40494.8 multi 1.00 import weight 0.00
Epoch 7 Iter 9 subLoss 40148.7 multi 1.00 import weight 0.00
Epoch 7 Iter 10 subLoss 40770.5 multi 1.00 import weight 0.00
Epoch 7 Iter 11 subLoss 39073.3 multi 1.00 import weight 0.00
Epoch 7 Acc: 53.36 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 3907 train Loss: 40005.0 test Loss: 6170.2
Epoch 8 Iter 0 subLoss 39493.1 multi 1.00 import weight 0.00
Epoch 8 Iter 1 subLoss 38911.1 multi 1.00 import weight 0.00
Epoch 8 Iter 2 subLoss 38649.5 multi 1.00 import weight 0.00
Epoch 8 Iter 3 subLoss 38822.4 multi 1.00 import weight 0.00
Epoch 8 Iter 4 subLoss 39762.5 multi 1.00 import weight 0.00
Epoch 8 Iter 5 subLoss 38148.9 multi 1.00 import weight 0.00
Epoch 8 Iter 6 subLoss 38776.0 multi 1.00 import weight 0.00
Epoch 8 Iter 7 subLoss 38001.8 multi 1.00 import weight 0.00
Epoch 8 Iter 8 subLoss 38970.4 multi 1.00 import weight 0.00
Epoch 8 Iter 9 subLoss 38805.7 multi 1.00 import weight 0.00
Epoch 8 Iter 10 subLoss 39589.7 multi 1.00 import weight 0.00
Epoch 8 Iter 11 subLoss 37784.1 multi 1.00 import weight 0.00
Epoch 8 Acc: 61.45 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 3778 train Loss: 38883.8 test Loss: 5919.9
Epoch 9 Iter 0 subLoss 38406.0 multi 1.00 import weight 0.00
Epoch 9 Iter 1 subLoss 37067.4 multi 1.00 import weight 0.00
Epoch 9 Iter 2 subLoss 36960.6 multi 1.00 import weight 0.00
Epoch 9 Iter 3 subLoss 35572.6 multi 1.00 import weight 0.00
Epoch 9 Iter 4 subLoss 35701.7 multi 1.00 import weight 0.00
Epoch 9 Iter 5 subLoss 35373.1 multi 1.00 import weight 0.00
Epoch 9 Iter 6 subLoss 37023.9 multi 1.00 import weight 0.00
Epoch 9 Iter 7 subLoss 36548.8 multi 1.00 import weight 0.00
Epoch 9 Iter 8 subLoss 37324.3 multi 1.00 import weight 0.00
Epoch 9 Iter 9 subLoss 36381.0 multi 1.00 import weight 0.00
Epoch 9 Iter 10 subLoss 35064.2 multi 1.00 import weight 0.00
Epoch 9 Iter 11 subLoss 34727.3 multi 1.00 import weight 0.00
Epoch 9 Acc: 70.34 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 3472 train Loss: 35505.1 test Loss: 5237.7
Epoch 10 Iter 0 subLoss 34723.9 multi 3.99 import weight 0.00
Epoch 10 Iter 1 subLoss 79947.1 multi 1.00 import weight 0.00
Epoch 10 Iter 2 subLoss 49052.3 multi 1.00 import weight 0.00
Epoch 10 Iter 3 subLoss 49274.5 multi 1.00 import weight 0.00
Epoch 10 Iter 4 subLoss 49328.6 multi 1.00 import weight 0.00
Epoch 10 Iter 5 subLoss 49133.6 multi 1.00 import weight 0.00
Epoch 10 Iter 6 subLoss 49170.2 multi 1.00 import weight 0.00
Epoch 10 Iter 7 subLoss 49099.5 multi 1.00 import weight 0.00
Epoch 10 Iter 8 subLoss 49383.0 multi 1.00 import weight 0.00
Epoch 10 Iter 9 subLoss 49101.5 multi -1.99 import weight 0.00
Epoch 10 Iter 10 subLoss 49240.1 multi 1.00 import weight 0.00
Epoch 10 Iter 11 subLoss 49253.3 multi -1.99 import weight 0.00
Epoch 10 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 4925 train Loss: 50182.3 test Loss: 8423.0
Epoch 11 Iter 0 subLoss 49137.8 multi 3.99 import weight 0.00
Epoch 11 Iter 1 subLoss 49106.3 multi 1.00 import weight 0.00
Epoch 11 Iter 2 subLoss 48930.1 multi 1.00 import weight 0.00
Epoch 11 Iter 3 subLoss 48827.1 multi -1.99 import weight 0.00
Epoch 11 Iter 4 subLoss 48953.6 multi 1.00 import weight 0.00
Epoch 11 Iter 5 subLoss 48884.2 multi 1.00 import weight 0.00
Epoch 11 Iter 6 subLoss 49429.4 multi 1.00 import weight 0.00
Epoch 11 Iter 7 subLoss 49129.4 multi 1.00 import weight 0.00
Epoch 11 Iter 8 subLoss 48919.1 multi 1.00 import weight 0.00
Epoch 11 Iter 9 subLoss 49213.3 multi 1.00 import weight 0.00
Epoch 11 Iter 10 subLoss 49026.6 multi 1.00 import weight 0.00
Epoch 11 Iter 11 subLoss 48838.7 multi -1.99 import weight 0.00
Epoch 11 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 4883 train Loss: 49912.0 test Loss: 8378.2
Epoch 12 Iter 0 subLoss 48876.3 multi 1.00 import weight 0.00
Epoch 12 Iter 1 subLoss 49106.2 multi 3.98 import weight 1.00
Epoch 12 Iter 2 subLoss 48545.8 multi 1.00 import weight 0.00
Epoch 12 Iter 3 subLoss 48579.6 multi -1.99 import weight 0.00
Epoch 12 Iter 4 subLoss 48544.6 multi 3.99 import weight 0.00
Epoch 12 Iter 5 subLoss 48414.1 multi 1.00 import weight 0.00
Epoch 12 Iter 6 subLoss 48329.4 multi 1.00 import weight 0.00
Epoch 12 Iter 7 subLoss 48216.8 multi -4.97 import weight 0.00
Epoch 12 Iter 8 subLoss 48710.5 multi 1.00 import weight 0.00
Epoch 12 Iter 9 subLoss 48519.7 multi 1.00 import weight 0.00
Epoch 12 Iter 10 subLoss 48530.9 multi 1.00 import weight 0.00
Epoch 12 Iter 11 subLoss 48795.5 multi 1.00 import weight 0.00
Epoch 12 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4879 train Loss: 49392.7 test Loss: 8261.7
Epoch 13 Iter 0 subLoss 48315.6 multi -1.99 import weight 0.00
Epoch 13 Iter 1 subLoss 48531.1 multi 3.99 import weight 0.00
Epoch 13 Iter 2 subLoss 48367.4 multi 3.99 import weight 0.00
Epoch 13 Iter 3 subLoss 47986.1 multi -1.99 import weight 0.00
Epoch 13 Iter 4 subLoss 48294.9 multi 3.99 import weight 0.00
Epoch 13 Iter 5 subLoss 47516.6 multi 1.00 import weight 0.00
Epoch 13 Iter 6 subLoss 47413.1 multi 1.00 import weight 0.00
Epoch 13 Iter 7 subLoss 47089.6 multi 1.00 import weight 0.00
Epoch 13 Iter 8 subLoss 46727.8 multi 1.00 import weight 0.00
Epoch 13 Iter 9 subLoss 46819.3 multi 1.00 import weight 0.00
Epoch 13 Iter 10 subLoss 46303.1 multi 1.00 import weight 0.00
Epoch 13 Iter 11 subLoss 45879.0 multi 1.00 import weight 0.00
Epoch 13 Acc: 40.05 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4587 train Loss: 46587.0 test Loss: 7668.2
Epoch 14 Iter 0 subLoss 45540.1 multi 1.00 import weight 0.00
Epoch 14 Iter 1 subLoss 45373.4 multi 1.00 import weight 0.00
Epoch 14 Iter 2 subLoss 44953.9 multi 1.00 import weight 0.00
Epoch 14 Iter 3 subLoss 44549.6 multi 3.99 import weight 0.00
Epoch 14 Iter 4 subLoss 43747.4 multi 1.00 import weight 0.00
Epoch 14 Iter 5 subLoss 43338.7 multi 1.00 import weight 0.00
Epoch 14 Iter 6 subLoss 42817.0 multi 3.99 import weight 0.00
Epoch 14 Iter 7 subLoss 42941.7 multi 1.00 import weight 0.00
Epoch 14 Iter 8 subLoss 42761.5 multi 1.00 import weight 0.00
Epoch 14 Iter 9 subLoss 42341.4 multi 1.00 import weight 0.00
Epoch 14 Iter 10 subLoss 41906.6 multi 1.00 import weight 0.00
Epoch 14 Iter 11 subLoss 42044.9 multi 1.00 import weight 0.00
Epoch 14 Acc: 42.89 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4204 train Loss: 42699.7 test Loss: 7010.9
Epoch 15 Iter 0 subLoss 41693.4 multi 1.00 import weight 0.00
Epoch 15 Iter 1 subLoss 41521.9 multi 1.00 import weight 0.00
Epoch 15 Iter 2 subLoss 41777.9 multi 3.99 import weight 0.00
Epoch 15 Iter 3 subLoss 52381.3 multi 1.00 import weight 0.00
Epoch 15 Iter 4 subLoss 48141.5 multi -1.99 import weight 0.00
Epoch 15 Iter 5 subLoss 49164.2 multi 1.00 import weight 0.00
Epoch 15 Iter 6 subLoss 48934.7 multi 3.99 import weight 0.00
Epoch 15 Iter 7 subLoss 48425.7 multi -1.99 import weight 0.00
Epoch 15 Iter 8 subLoss 48908.1 multi 1.00 import weight 0.00
Epoch 15 Iter 9 subLoss 48605.2 multi 1.00 import weight 0.00
Epoch 15 Iter 10 subLoss 48804.1 multi -1.99 import weight 0.00
Epoch 15 Iter 11 subLoss 49133.4 multi 3.98 import weight 1.00
Epoch 15 Acc: 22.36 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 3.98 Pidx 4913 train Loss: 49652.0 test Loss: 8255.3
Epoch 16 Iter 0 subLoss 48590.7 multi 1.00 import weight 0.00
Epoch 16 Iter 1 subLoss 48371.7 multi -4.97 import weight 0.00
Epoch 16 Iter 2 subLoss 49240.2 multi 3.99 import weight 0.00
Epoch 16 Iter 3 subLoss 48889.4 multi 1.00 import weight 0.00
Epoch 16 Iter 4 subLoss 49088.6 multi 1.00 import weight 0.00
Epoch 16 Iter 5 subLoss 48851.3 multi 1.00 import weight 0.00
Epoch 16 Iter 6 subLoss 48764.2 multi 1.00 import weight 0.00
Epoch 16 Iter 7 subLoss 48590.4 multi 3.99 import weight 0.00
Epoch 16 Iter 8 subLoss 48745.5 multi 1.00 import weight 0.00
Epoch 16 Iter 9 subLoss 49054.0 multi 3.99 import weight 0.00
Epoch 16 Iter 10 subLoss 48839.7 multi 1.00 import weight 0.00
Epoch 16 Iter 11 subLoss 48650.2 multi 1.00 import weight 0.00
Epoch 16 Acc: 22.36 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4865 train Loss: 49433.2 test Loss: 8230.2
Epoch 17 Iter 0 subLoss 48520.8 multi -4.97 import weight 0.00
Epoch 17 Iter 1 subLoss 48727.3 multi -1.99 import weight 0.00
Epoch 17 Iter 2 subLoss 49010.9 multi 1.00 import weight 0.00
Epoch 17 Iter 3 subLoss 49097.1 multi 1.00 import weight 0.00
Epoch 17 Iter 4 subLoss 48725.2 multi 1.00 import weight 0.00
Epoch 17 Iter 5 subLoss 48547.1 multi 1.00 import weight 1.00
Epoch 17 Iter 6 subLoss 48751.7 multi -1.99 import weight 0.00
Epoch 17 Iter 7 subLoss 48727.0 multi 3.98 import weight 1.00
Epoch 17 Iter 8 subLoss 48408.7 multi 1.00 import weight 0.00
Epoch 17 Iter 9 subLoss 48664.0 multi -1.99 import weight 0.00
Epoch 17 Iter 10 subLoss 48654.7 multi 3.99 import weight 0.00
Epoch 17 Iter 11 subLoss 49005.6 multi 1.00 import weight 0.00
Epoch 17 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4900 train Loss: 49626.6 test Loss: 8305.7
Epoch 18 Iter 0 subLoss 48712.9 multi 3.99 import weight 0.00
Epoch 18 Iter 1 subLoss 48654.2 multi 6.97 import weight 1.00
Epoch 18 Iter 2 subLoss 48111.7 multi 1.00 import weight 0.00
Epoch 18 Iter 3 subLoss 48182.9 multi 1.00 import weight 0.00
Epoch 18 Iter 4 subLoss 47645.1 multi 1.00 import weight 0.00
Epoch 18 Iter 5 subLoss 46980.2 multi 1.00 import weight 0.00
Epoch 18 Iter 6 subLoss 45686.5 multi 1.00 import weight 0.00
Epoch 18 Iter 7 subLoss 43503.4 multi 1.00 import weight 0.00
Epoch 18 Iter 8 subLoss 42131.1 multi 1.00 import weight 0.00
Epoch 18 Iter 9 subLoss 41806.6 multi -1.99 import weight 0.00
Epoch 18 Iter 10 subLoss 41978.8 multi 1.00 import weight 0.00
Epoch 18 Iter 11 subLoss 41817.5 multi -1.99 import weight 0.00
Epoch 18 Acc: 44.19 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 4181 train Loss: 43027.8 test Loss: 7069.9
Epoch 19 Iter 0 subLoss 42363.4 multi 1.00 import weight 0.00
Epoch 19 Iter 1 subLoss 41893.0 multi 1.00 import weight 0.00
Epoch 19 Iter 2 subLoss 41680.0 multi 1.00 import weight 0.00
Epoch 19 Iter 3 subLoss 41689.0 multi -1.99 import weight 0.00
Epoch 19 Iter 4 subLoss 42042.9 multi 3.99 import weight 0.00
Epoch 19 Iter 5 subLoss 42089.5 multi 1.00 import weight 0.00
Epoch 19 Iter 6 subLoss 41612.5 multi 1.00 import weight 0.00
Epoch 19 Iter 7 subLoss 41329.0 multi 1.00 import weight 0.00
Epoch 19 Iter 8 subLoss 41344.8 multi 1.00 import weight 0.00
Epoch 19 Iter 9 subLoss 41434.6 multi 1.00 import weight 0.00
Epoch 19 Iter 10 subLoss 40984.2 multi 1.00 import weight 0.00
Epoch 19 Iter 11 subLoss 41174.3 multi 1.00 import weight 0.00
Epoch 19 Acc: 42.97 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4117 train Loss: 41912.9 test Loss: 6905.8
Epoch 20 Iter 0 subLoss 41220.4 multi 3.99 import weight 0.00
Epoch 20 Iter 1 subLoss 41089.1 multi 1.00 import weight 0.00
Epoch 20 Iter 2 subLoss 40809.8 multi 1.00 import weight 0.00
Epoch 20 Iter 3 subLoss 40899.3 multi 1.00 import weight 0.00
Epoch 20 Iter 4 subLoss 40735.6 multi 1.00 import weight 0.00
Epoch 20 Iter 5 subLoss 40978.9 multi 1.00 import weight 0.00
Epoch 20 Iter 6 subLoss 40983.0 multi 1.00 import weight 0.00
Epoch 20 Iter 7 subLoss 40670.8 multi -1.99 import weight 0.00
Epoch 20 Iter 8 subLoss 42102.8 multi 1.00 import weight 0.00
Epoch 20 Iter 9 subLoss 42057.8 multi -4.97 import weight 0.00
Epoch 20 Iter 10 subLoss 48785.1 multi 1.00 import weight 0.00
Epoch 20 Iter 11 subLoss 49036.2 multi -1.99 import weight 0.00
Epoch 20 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 4903 train Loss: 49934.3 test Loss: 8379.2
Epoch 21 Iter 0 subLoss 49015.5 multi 1.00 import weight 0.00
Epoch 21 Iter 1 subLoss 48922.5 multi -1.99 import weight 0.00
Epoch 21 Iter 2 subLoss 48874.9 multi 3.99 import weight 0.00
Epoch 21 Iter 3 subLoss 48994.6 multi 1.00 import weight 0.00
Epoch 21 Iter 4 subLoss 48948.9 multi -4.97 import weight 0.00
Epoch 21 Iter 5 subLoss 48759.3 multi 1.00 import weight 0.00
Epoch 21 Iter 6 subLoss 48795.6 multi 1.00 import weight 0.00
Epoch 21 Iter 7 subLoss 48856.9 multi 3.99 import weight 0.00
Epoch 21 Iter 8 subLoss 49028.5 multi -1.98 import weight 0.00
Epoch 21 Iter 9 subLoss 48830.0 multi 3.98 import weight 1.00
Epoch 21 Iter 10 subLoss 49061.8 multi -4.97 import weight 0.00
Epoch 21 Iter 11 subLoss 49001.2 multi 1.00 import weight 0.00
Epoch 21 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4900 train Loss: 49893.3 test Loss: 8373.1
Epoch 22 Iter 0 subLoss 48791.2 multi 3.98 import weight 1.00
Epoch 22 Iter 1 subLoss 48724.9 multi 3.99 import weight 1.00
Epoch 22 Iter 2 subLoss 48903.9 multi 3.99 import weight 0.00
Epoch 22 Iter 3 subLoss 49011.1 multi 1.00 import weight 0.00
Epoch 22 Iter 4 subLoss 48674.4 multi -1.99 import weight 0.00
Epoch 22 Iter 5 subLoss 48903.3 multi 6.97 import weight 0.00
Epoch 22 Iter 6 subLoss 48592.4 multi 6.97 import weight 0.00
Epoch 22 Iter 7 subLoss 48578.9 multi 1.00 import weight 0.00
Epoch 22 Iter 8 subLoss 48420.5 multi 1.00 import weight 0.00
Epoch 22 Iter 9 subLoss 48598.6 multi 9.96 import weight 1.00
Epoch 22 Iter 10 subLoss 48403.7 multi 3.99 import weight 0.00
Epoch 22 Iter 11 subLoss 48546.9 multi 3.99 import weight 1.00
Epoch 22 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 3.99 Pidx 4854 train Loss: 49397.8 test Loss: 8285.8
Epoch 23 Iter 0 subLoss 48519.0 multi 3.98 import weight 0.00
Epoch 23 Iter 1 subLoss 48609.9 multi -7.96 import weight 0.00
Epoch 23 Iter 2 subLoss 48353.6 multi 1.00 import weight 0.00
Epoch 23 Iter 3 subLoss 48542.4 multi 6.97 import weight 1.00
Epoch 23 Iter 4 subLoss 48323.6 multi 1.00 import weight 0.00
Epoch 23 Iter 5 subLoss 48323.5 multi 3.98 import weight 0.00
Epoch 23 Iter 6 subLoss 48346.5 multi 1.00 import weight 0.00
Epoch 23 Iter 7 subLoss 48423.1 multi 3.98 import weight 0.00
Epoch 23 Iter 8 subLoss 48365.3 multi 3.98 import weight 0.00
Epoch 23 Iter 9 subLoss 48446.5 multi -4.97 import weight 0.00
Epoch 23 Iter 10 subLoss 48266.5 multi 1.00 import weight 0.00
Epoch 23 Iter 11 subLoss 48344.7 multi 3.99 import weight 0.00
Epoch 23 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 4834 train Loss: 49306.5 test Loss: 8262.3
Epoch 24 Iter 0 subLoss 48352.7 multi -1.98 import weight 0.00
Epoch 24 Iter 1 subLoss 48393.8 multi 1.00 import weight 0.00
Epoch 24 Iter 2 subLoss 48350.6 multi 1.00 import weight 0.00
Epoch 24 Iter 3 subLoss 48299.1 multi 6.97 import weight 0.00
Epoch 24 Iter 4 subLoss 48305.5 multi -4.97 import weight 0.00
Epoch 24 Iter 5 subLoss 48401.3 multi 3.98 import weight 0.00
Epoch 24 Iter 6 subLoss 48321.1 multi 6.97 import weight 0.00
Epoch 24 Iter 7 subLoss 48146.3 multi 1.00 import weight 0.00
Epoch 24 Iter 8 subLoss 48321.8 multi 9.96 import weight 1.00
Epoch 24 Iter 9 subLoss 48137.3 multi 3.99 import weight 0.00
Epoch 24 Iter 10 subLoss 48018.2 multi 1.00 import weight 0.00
Epoch 24 Iter 11 subLoss 47931.3 multi 1.00 import weight 0.00
Epoch 24 Acc: 23.45 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4793 train Loss: 48697.1 test Loss: 8081.6
Epoch 25 Iter 0 subLoss 47777.3 multi 1.00 import weight 0.00
Epoch 25 Iter 1 subLoss 47561.2 multi 1.00 import weight 0.00
Epoch 25 Iter 2 subLoss 47121.4 multi 1.00 import weight 0.00
Epoch 25 Iter 3 subLoss 46714.4 multi 1.00 import weight 0.00
Epoch 25 Iter 4 subLoss 45821.9 multi 6.97 import weight 0.00
Epoch 25 Iter 5 subLoss 69878.7 multi 1.00 import weight 0.00
Epoch 25 Iter 6 subLoss 48188.3 multi 3.99 import weight 0.00
Epoch 25 Iter 7 subLoss 48298.7 multi 9.96 import weight 0.00
Epoch 25 Iter 8 subLoss 47487.6 multi 1.00 import weight 0.00
Epoch 25 Iter 9 subLoss 47024.2 multi 1.00 import weight 0.00
Epoch 25 Iter 10 subLoss 46674.8 multi 1.00 import weight 0.00
Epoch 25 Iter 11 subLoss 45980.9 multi 1.00 import weight 0.00
Epoch 25 Acc: 41.93 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4598 train Loss: 45846.3 test Loss: 7502.6
Epoch 26 Iter 0 subLoss 44880.0 multi 1.00 import weight 0.00
Epoch 26 Iter 1 subLoss 43800.8 multi 1.00 import weight 0.00
Epoch 26 Iter 2 subLoss 42710.5 multi 1.00 import weight 0.00
Epoch 26 Iter 3 subLoss 42293.6 multi 1.00 import weight 0.00
Epoch 26 Iter 4 subLoss 42511.5 multi 1.00 import weight 0.00
Epoch 26 Iter 5 subLoss 42568.1 multi 1.00 import weight 0.00
Epoch 26 Iter 6 subLoss 42185.7 multi 1.00 import weight 0.00
Epoch 26 Iter 7 subLoss 42242.4 multi 1.00 import weight 0.00
Epoch 26 Iter 8 subLoss 41912.4 multi -1.99 import weight 0.00
Epoch 26 Iter 9 subLoss 42097.0 multi -1.99 import weight 0.00
Epoch 26 Iter 10 subLoss 42430.9 multi 1.00 import weight 0.00
Epoch 26 Iter 11 subLoss 42309.1 multi -1.99 import weight 0.00
Epoch 26 Acc: 42.27 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 4230 train Loss: 43260.8 test Loss: 7089.6
Epoch 27 Iter 0 subLoss 42508.0 multi 1.00 import weight 0.00
Epoch 27 Iter 1 subLoss 42289.2 multi 1.00 import weight 0.00
Epoch 27 Iter 2 subLoss 42035.1 multi 1.00 import weight 0.00
Epoch 27 Iter 3 subLoss 42206.1 multi 1.00 import weight 0.00
Epoch 27 Iter 4 subLoss 41994.9 multi 1.00 import weight 0.00
Epoch 27 Iter 5 subLoss 41804.0 multi 1.00 import weight 0.00
Epoch 27 Iter 6 subLoss 42162.2 multi 1.00 import weight 0.00
Epoch 27 Iter 7 subLoss 41784.8 multi -4.97 import weight 0.00
Epoch 27 Iter 8 subLoss 42337.0 multi 1.00 import weight 0.00
Epoch 27 Iter 9 subLoss 42192.6 multi -1.99 import weight 0.00
Epoch 27 Iter 10 subLoss 42466.1 multi 1.00 import weight 0.00
Epoch 27 Iter 11 subLoss 42600.7 multi 1.00 import weight 0.00
Epoch 27 Acc: 41.97 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4260 train Loss: 43021.9 test Loss: 7058.2
Epoch 28 Iter 0 subLoss 42518.2 multi 1.00 import weight 0.00
Epoch 28 Iter 1 subLoss 42035.2 multi 3.99 import weight 0.00
Epoch 28 Iter 2 subLoss 41845.8 multi 1.00 import weight 0.00
Epoch 28 Iter 3 subLoss 41678.2 multi 3.99 import weight 0.00
Epoch 28 Iter 4 subLoss 41218.7 multi 1.00 import weight 0.00
Epoch 28 Iter 5 subLoss 41304.2 multi 1.00 import weight 0.00
Epoch 28 Iter 6 subLoss 41320.9 multi 3.99 import weight 0.00
Epoch 28 Iter 7 subLoss 41007.0 multi 1.00 import weight 0.00
Epoch 28 Iter 8 subLoss 40826.3 multi 1.00 import weight 0.00
Epoch 28 Iter 9 subLoss 41053.8 multi 1.00 import weight 0.00
Epoch 28 Iter 10 subLoss 41187.0 multi -1.99 import weight 0.00
Epoch 28 Iter 11 subLoss 41534.1 multi -1.99 import weight 0.00
Epoch 28 Acc: 40.44 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 4153 train Loss: 44639.4 test Loss: 7411.7
Epoch 29 Iter 0 subLoss 44079.6 multi 1.00 import weight 0.00
Epoch 29 Iter 1 subLoss 41942.0 multi 1.00 import weight 0.00
Epoch 29 Iter 2 subLoss 41042.8 multi 1.00 import weight 0.00
Epoch 29 Iter 3 subLoss 40818.3 multi -1.99 import weight 0.00
Epoch 29 Iter 4 subLoss 41142.6 multi 3.99 import weight 0.00
Epoch 29 Iter 5 subLoss 41201.1 multi 1.00 import weight 0.00
Epoch 29 Iter 6 subLoss 40657.4 multi 1.00 import weight 0.00
Epoch 29 Iter 7 subLoss 40721.4 multi 1.00 import weight 0.00
Epoch 29 Iter 8 subLoss 40733.9 multi 1.00 import weight 0.00
Epoch 29 Iter 9 subLoss 40767.5 multi 3.99 import weight 0.00
Epoch 29 Iter 10 subLoss 40740.9 multi -4.97 import weight 0.00
Epoch 29 Iter 11 subLoss 46096.6 multi -1.99 import weight 0.00
Epoch 29 Acc: 19.07 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 4609 train Loss: 282002.9 test Loss: 50124.6
Epoch 30 Iter 0 subLoss 278680.1 multi 1.00 import weight 0.00
Epoch 30 Iter 1 subLoss 48700.1 multi 1.00 import weight 0.00
Epoch 30 Iter 2 subLoss 48573.0 multi 3.98 import weight 0.00
Epoch 30 Iter 3 subLoss 48651.6 multi 9.96 import weight 0.00
Epoch 30 Iter 4 subLoss 48553.4 multi -10.94 import weight 0.00
Epoch 30 Iter 5 subLoss 48568.1 multi -1.98 import weight 0.00
Epoch 30 Iter 6 subLoss 48672.2 multi 1.00 import weight 0.00
Epoch 30 Iter 7 subLoss 48711.0 multi 3.98 import weight 0.00
Epoch 30 Iter 8 subLoss 48784.3 multi 3.99 import weight 0.00
Epoch 30 Iter 9 subLoss 48557.6 multi -7.96 import weight 0.00
Epoch 30 Iter 10 subLoss 48668.1 multi -7.96 import weight 0.00
Epoch 30 Iter 11 subLoss 48829.5 multi 1.00 import weight 0.00
Epoch 30 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4882 train Loss: 49703.0 test Loss: 8346.2
Epoch 31 Iter 0 subLoss 48708.3 multi 3.99 import weight 0.00
Epoch 31 Iter 1 subLoss 48556.8 multi -4.97 import weight 0.00
Epoch 31 Iter 2 subLoss 48748.4 multi 3.99 import weight 0.00
Epoch 31 Iter 3 subLoss 48732.2 multi -10.94 import weight 0.00
Epoch 31 Iter 4 subLoss 49072.6 multi -1.99 import weight 0.00
Epoch 31 Iter 5 subLoss 48875.1 multi 6.97 import weight 0.00
Epoch 31 Iter 6 subLoss 48785.0 multi 6.97 import weight 0.00
Epoch 31 Iter 7 subLoss 48649.9 multi 1.00 import weight 0.00
Epoch 31 Iter 8 subLoss 48659.3 multi 9.96 import weight 1.00
Epoch 31 Iter 9 subLoss 48516.7 multi 6.97 import weight 0.00
Epoch 31 Iter 10 subLoss 48584.5 multi -7.96 import weight 0.00
Epoch 31 Iter 11 subLoss 48420.9 multi 6.97 import weight 0.00
Epoch 31 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 4842 train Loss: 49493.7 test Loss: 8310.9
Epoch 32 Iter 0 subLoss 48457.4 multi -1.99 import weight 0.00
Epoch 32 Iter 1 subLoss 48606.2 multi -4.97 import weight 0.00
Epoch 32 Iter 2 subLoss 48600.3 multi -1.99 import weight 0.00
Epoch 32 Iter 3 subLoss 48539.4 multi 3.98 import weight 0.00
Epoch 32 Iter 4 subLoss 48520.1 multi -7.96 import weight 0.00
Epoch 32 Iter 5 subLoss 48616.2 multi -10.94 import weight 0.00
Epoch 32 Iter 6 subLoss 48982.4 multi 1.00 import weight 0.00
Epoch 32 Iter 7 subLoss 48680.8 multi -4.97 import weight 0.00
Epoch 32 Iter 8 subLoss 48879.1 multi 9.96 import weight 0.00
Epoch 32 Iter 9 subLoss 48707.4 multi 6.97 import weight 0.00
Epoch 32 Iter 10 subLoss 48438.6 multi -4.97 import weight 0.00
Epoch 32 Iter 11 subLoss 48594.7 multi 9.96 import weight 1.00
Epoch 32 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 9.96 Pidx 4859 train Loss: 49505.3 test Loss: 8313.3
Epoch 33 Iter 0 subLoss 48481.6 multi 6.97 import weight 0.00
Epoch 33 Iter 1 subLoss 48330.6 multi -13.93 import weight 0.00
Epoch 33 Iter 2 subLoss 48515.3 multi 9.96 import weight 1.00
Epoch 33 Iter 3 subLoss 48537.9 multi 3.99 import weight 0.00
Epoch 33 Iter 4 subLoss 48597.5 multi 12.94 import weight 1.00
Epoch 33 Iter 5 subLoss 48441.0 multi -4.97 import weight 0.00
Epoch 33 Iter 6 subLoss 48467.9 multi 3.98 import weight 0.00
Epoch 33 Iter 7 subLoss 48317.4 multi -1.98 import weight 0.00
Epoch 33 Iter 8 subLoss 48388.3 multi -1.99 import weight 0.00
Epoch 33 Iter 9 subLoss 48384.9 multi 1.00 import weight 0.00
Epoch 33 Iter 10 subLoss 48364.8 multi 1.00 import weight 0.00
Epoch 33 Iter 11 subLoss 48510.8 multi 12.94 import weight 1.00
Epoch 33 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 12.94 Pidx 4851 train Loss: 49304.0 test Loss: 8280.7
Epoch 34 Iter 0 subLoss 48364.6 multi 3.99 import weight 0.00
Epoch 34 Iter 1 subLoss 48368.7 multi 6.97 import weight 1.00
Epoch 34 Iter 2 subLoss 48312.6 multi 1.00 import weight 0.00
Epoch 34 Iter 3 subLoss 48396.2 multi -1.98 import weight 0.00
Epoch 34 Iter 4 subLoss 48362.7 multi 9.96 import weight 1.00
Epoch 34 Iter 5 subLoss 48279.6 multi 1.00 import weight 0.00
Epoch 34 Iter 6 subLoss 48232.1 multi 1.00 import weight 0.00
Epoch 34 Iter 7 subLoss 48314.8 multi 3.99 import weight 0.00
Epoch 34 Iter 8 subLoss 48324.6 multi 3.98 import weight 0.00
Epoch 34 Iter 9 subLoss 48304.1 multi -4.97 import weight 0.00
Epoch 34 Iter 10 subLoss 48210.7 multi -1.98 import weight 0.00
Epoch 34 Iter 11 subLoss 48223.2 multi -4.97 import weight 0.00
Epoch 34 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 4822 train Loss: 49253.8 test Loss: 8271.8
Epoch 35 Iter 0 subLoss 48412.4 multi -4.97 import weight 0.00
Epoch 35 Iter 1 subLoss 48320.2 multi 6.97 import weight 1.00
Epoch 35 Iter 2 subLoss 48349.7 multi 3.98 import weight 0.00
Epoch 35 Iter 3 subLoss 48269.9 multi 3.99 import weight 0.00
Epoch 35 Iter 4 subLoss 48258.8 multi 1.00 import weight 0.00
Epoch 35 Iter 5 subLoss 48306.4 multi -1.99 import weight 0.00
Epoch 35 Iter 6 subLoss 48211.7 multi 1.00 import weight 0.00
Epoch 35 Iter 7 subLoss 48343.7 multi 6.97 import weight 0.00
Epoch 35 Iter 8 subLoss 48260.9 multi 3.98 import weight 0.00
Epoch 35 Iter 9 subLoss 48239.9 multi 1.00 import weight 0.00
Epoch 35 Iter 10 subLoss 48261.6 multi 6.97 import weight 0.00
Epoch 35 Iter 11 subLoss 48188.2 multi 6.97 import weight 0.00
Epoch 35 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 4818 train Loss: 49224.5 test Loss: 8267.0
Epoch 36 Iter 0 subLoss 48228.7 multi -4.97 import weight 0.00
Epoch 36 Iter 1 subLoss 48285.5 multi -4.97 import weight 0.00
Epoch 36 Iter 2 subLoss 48248.1 multi -4.97 import weight 0.00
Epoch 36 Iter 3 subLoss 48280.7 multi -1.98 import weight 0.00
Epoch 36 Iter 4 subLoss 48290.7 multi 6.97 import weight 0.00
Epoch 36 Iter 5 subLoss 48282.8 multi 1.00 import weight 0.00
Epoch 36 Iter 6 subLoss 48406.0 multi 3.99 import weight 0.00
Epoch 36 Iter 7 subLoss 48310.1 multi 1.00 import weight 0.00
Epoch 36 Iter 8 subLoss 48197.5 multi -7.96 import weight 0.00
Epoch 36 Iter 9 subLoss 48207.8 multi 3.98 import weight 0.00
Epoch 36 Iter 10 subLoss 48272.5 multi -4.97 import weight 0.00
Epoch 36 Iter 11 subLoss 48229.6 multi -1.99 import weight 0.00
Epoch 36 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 4822 train Loss: 49230.9 test Loss: 8267.6
Epoch 37 Iter 0 subLoss 48187.3 multi 9.96 import weight 0.00
Epoch 37 Iter 1 subLoss 48229.0 multi 1.00 import weight 0.00
Epoch 37 Iter 2 subLoss 48345.9 multi 9.96 import weight 0.00
Epoch 37 Iter 3 subLoss 48144.6 multi 1.00 import weight 0.00
Epoch 37 Iter 4 subLoss 48210.4 multi 1.00 import weight 0.00
Epoch 37 Iter 5 subLoss 48323.4 multi 6.97 import weight 1.00
Epoch 37 Iter 6 subLoss 48291.8 multi 6.97 import weight 0.00
Epoch 37 Iter 7 subLoss 48280.3 multi 1.00 import weight 0.00
Epoch 37 Iter 8 subLoss 48248.0 multi -1.98 import weight 0.00
Epoch 37 Iter 9 subLoss 48253.9 multi -1.98 import weight 0.00
Epoch 37 Iter 10 subLoss 48301.1 multi -4.97 import weight 0.00
Epoch 37 Iter 11 subLoss 48285.2 multi 3.99 import weight 0.00
Epoch 37 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 4828 train Loss: 49211.5 test Loss: 8264.8
Epoch 38 Iter 0 subLoss 48203.5 multi 6.97 import weight 0.00
Epoch 38 Iter 1 subLoss 48230.6 multi -4.97 import weight 0.00
Epoch 38 Iter 2 subLoss 48273.6 multi -1.99 import weight 0.00
Epoch 38 Iter 3 subLoss 48284.9 multi 3.98 import weight 0.00
Epoch 38 Iter 4 subLoss 48212.2 multi 1.00 import weight 0.00
Epoch 38 Iter 5 subLoss 48288.5 multi 6.97 import weight 0.00
Epoch 38 Iter 6 subLoss 48276.9 multi 1.00 import weight 0.00
Epoch 38 Iter 7 subLoss 48225.9 multi -1.98 import weight 0.00
Epoch 38 Iter 8 subLoss 48288.7 multi 6.97 import weight 1.00
Epoch 38 Iter 9 subLoss 48306.5 multi -1.99 import weight 0.00
Epoch 38 Iter 10 subLoss 48191.2 multi -7.96 import weight 0.00
Epoch 38 Iter 11 subLoss 48218.5 multi 3.98 import weight 0.00
Epoch 38 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 4821 train Loss: 49205.2 test Loss: 8263.9
Epoch 39 Iter 0 subLoss 48276.8 multi 3.98 import weight 0.00
Epoch 39 Iter 1 subLoss 48274.6 multi 6.97 import weight 0.00
Epoch 39 Iter 2 subLoss 48271.3 multi 9.96 import weight 1.00
Epoch 39 Iter 3 subLoss 48228.5 multi -1.99 import weight 0.00
Epoch 39 Iter 4 subLoss 48262.9 multi 6.97 import weight 0.00
Epoch 39 Iter 5 subLoss 48247.8 multi -1.99 import weight 0.00
Epoch 39 Iter 6 subLoss 48238.2 multi -7.96 import weight 0.00
Epoch 39 Iter 7 subLoss 48172.2 multi 1.00 import weight 0.00
Epoch 39 Iter 8 subLoss 48216.2 multi 6.97 import weight 0.00
Epoch 39 Iter 9 subLoss 48275.4 multi 9.96 import weight 1.00
Epoch 39 Iter 10 subLoss 48261.2 multi 9.96 import weight 0.00
Epoch 39 Iter 11 subLoss 48225.9 multi -1.99 import weight 0.00
Epoch 39 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 4822 train Loss: 49201.4 test Loss: 8263.6
Epoch 40 Iter 0 subLoss 48273.0 multi 9.96 import weight 1.00
Epoch 40 Iter 1 subLoss 48249.1 multi -1.99 import weight 0.00
Epoch 40 Iter 2 subLoss 48280.6 multi -4.97 import weight 0.00
Epoch 40 Iter 3 subLoss 48244.2 multi 1.00 import weight 0.00
Epoch 40 Iter 4 subLoss 48241.1 multi 3.98 import weight 0.00
Epoch 40 Iter 5 subLoss 48268.2 multi 12.94 import weight 0.00
Epoch 40 Iter 6 subLoss 48216.1 multi 9.96 import weight 0.00
Epoch 40 Iter 7 subLoss 48198.5 multi -4.97 import weight 0.00
Epoch 40 Iter 8 subLoss 48202.5 multi 3.99 import weight 0.00
Epoch 40 Iter 9 subLoss 48241.7 multi 6.97 import weight 0.00
Epoch 40 Iter 10 subLoss 48250.6 multi -13.93 import weight 0.00
Epoch 40 Iter 11 subLoss 48267.5 multi 12.94 import weight 0.00
Epoch 40 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 4826 train Loss: 49202.2 test Loss: 8263.6
Epoch 41 Iter 0 subLoss 48315.9 multi -1.99 import weight 0.00
Epoch 41 Iter 1 subLoss 48263.6 multi 15.93 import weight 0.00
Epoch 41 Iter 2 subLoss 48229.5 multi -1.98 import weight 0.00
Epoch 41 Iter 3 subLoss 48245.7 multi 9.96 import weight 0.00
Epoch 41 Iter 4 subLoss 48207.9 multi 6.97 import weight 0.00
Epoch 41 Iter 5 subLoss 48207.6 multi 9.96 import weight 0.00
Epoch 41 Iter 6 subLoss 48248.2 multi 12.94 import weight 0.00
Epoch 41 Iter 7 subLoss 48214.6 multi 3.98 import weight 0.00
Epoch 41 Iter 8 subLoss 48215.9 multi 6.97 import weight 1.00
Epoch 41 Iter 9 subLoss 48258.5 multi -16.91 import weight 0.00
Epoch 41 Iter 10 subLoss 48274.8 multi 3.99 import weight 1.00
Epoch 41 Iter 11 subLoss 48248.8 multi 15.93 import weight 0.00
Epoch 41 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 15.93 Pidx 4824 train Loss: 49201.6 test Loss: 8263.9
Epoch 42 Iter 0 subLoss 48211.8 multi 9.96 import weight 1.00
Epoch 42 Iter 1 subLoss 48201.6 multi 12.94 import weight 0.00
Epoch 42 Iter 2 subLoss 48275.1 multi 6.97 import weight 1.00
Epoch 42 Iter 3 subLoss 48215.3 multi 9.96 import weight 1.00
Epoch 42 Iter 4 subLoss 48231.5 multi -10.94 import weight 0.00
Epoch 42 Iter 5 subLoss 48296.8 multi -7.96 import weight 0.00
Epoch 42 Iter 6 subLoss 48213.4 multi 12.94 import weight 1.00
Epoch 42 Iter 7 subLoss 48242.2 multi 15.93 import weight 0.00
Epoch 42 Iter 8 subLoss 48231.1 multi -7.96 import weight 0.00
Epoch 42 Iter 9 subLoss 48279.4 multi 9.96 import weight 1.00
Epoch 42 Iter 10 subLoss 48239.4 multi -4.97 import weight 0.00
Epoch 42 Iter 11 subLoss 48275.5 multi 12.94 import weight 1.00
Epoch 42 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 12.94 Pidx 4827 train Loss: 49197.5 test Loss: 8261.2
Epoch 43 Iter 0 subLoss 48242.7 multi 12.94 import weight 0.00
Epoch 43 Iter 1 subLoss 48251.1 multi -22.88 import weight 0.00
Epoch 43 Iter 2 subLoss 48240.4 multi 15.93 import weight 0.00
Epoch 43 Iter 3 subLoss 48264.2 multi 12.94 import weight 0.00
Epoch 43 Iter 4 subLoss 48259.1 multi -22.88 import weight 0.00
Epoch 43 Iter 5 subLoss 48271.5 multi 12.94 import weight 1.00
Epoch 43 Iter 6 subLoss 48289.8 multi -16.91 import weight 0.00
Epoch 43 Iter 7 subLoss 48246.2 multi 18.91 import weight 0.00
Epoch 43 Iter 8 subLoss 48248.9 multi 21.90 import weight 1.00
Epoch 43 Iter 9 subLoss 48260.0 multi -25.87 import weight 0.00
Epoch 43 Iter 10 subLoss 48182.5 multi 9.96 import weight 0.00
Epoch 43 Iter 11 subLoss 48193.2 multi -4.97 import weight 0.00
Epoch 43 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 4819 train Loss: 49205.6 test Loss: 8264.7
Epoch 44 Iter 0 subLoss 48211.4 multi 15.93 import weight 0.00
Epoch 44 Iter 1 subLoss 48291.2 multi -7.96 import weight 0.00
Epoch 44 Iter 2 subLoss 48237.1 multi -1.98 import weight 0.00
Epoch 44 Iter 3 subLoss 48253.5 multi -22.88 import weight 0.00
Epoch 44 Iter 4 subLoss 48206.2 multi 12.94 import weight 0.00
Epoch 44 Iter 5 subLoss 48232.1 multi 1.00 import weight 0.00
Epoch 44 Iter 6 subLoss 48291.6 multi -4.97 import weight 0.00
Epoch 44 Iter 7 subLoss 48314.4 multi 1.00 import weight 0.00
Epoch 44 Iter 8 subLoss 48220.9 multi -16.91 import weight 0.00
Epoch 44 Iter 9 subLoss 48232.8 multi 1.00 import weight 0.00
Epoch 44 Iter 10 subLoss 48287.0 multi -13.93 import weight 0.00
Epoch 44 Iter 11 subLoss 48312.5 multi 3.99 import weight 0.00
Epoch 44 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 4831 train Loss: 49226.2 test Loss: 8267.6
Epoch 45 Iter 0 subLoss 48283.6 multi -10.94 import weight 0.00
Epoch 45 Iter 1 subLoss 48241.7 multi 15.93 import weight 1.00
Epoch 45 Iter 2 subLoss 48245.4 multi 18.91 import weight 1.00
Epoch 45 Iter 3 subLoss 48319.3 multi 6.97 import weight 0.00
Epoch 45 Iter 4 subLoss 48236.1 multi 3.99 import weight 0.00
Epoch 45 Iter 5 subLoss 48221.6 multi -13.93 import weight 0.00
Epoch 45 Iter 6 subLoss 48286.0 multi -7.96 import weight 0.00
Epoch 45 Iter 7 subLoss 48263.1 multi 6.97 import weight 0.00
Epoch 45 Iter 8 subLoss 48251.5 multi -25.87 import weight 0.00
Epoch 45 Iter 9 subLoss 48202.3 multi 15.93 import weight 0.00
Epoch 45 Iter 10 subLoss 48275.4 multi 12.94 import weight 0.00
Epoch 45 Iter 11 subLoss 48337.6 multi -19.90 import weight 0.00
Epoch 45 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -19.90 Pidx 4833 train Loss: 49269.3 test Loss: 8270.5
Epoch 46 Iter 0 subLoss 48311.1 multi 9.96 import weight 0.00
Epoch 46 Iter 1 subLoss 48365.7 multi 12.94 import weight 0.00
Epoch 46 Iter 2 subLoss 48214.4 multi 12.94 import weight 0.00
Epoch 46 Iter 3 subLoss 48296.5 multi -10.94 import weight 0.00
Epoch 46 Iter 4 subLoss 48308.5 multi -10.94 import weight 0.00
Epoch 46 Iter 5 subLoss 48284.5 multi -7.96 import weight 0.00
Epoch 46 Iter 6 subLoss 48267.4 multi 6.97 import weight 0.00
Epoch 46 Iter 7 subLoss 48227.7 multi -13.93 import weight 0.00
Epoch 46 Iter 8 subLoss 48284.9 multi -4.97 import weight 0.00
Epoch 46 Iter 9 subLoss 48295.5 multi -13.93 import weight 0.00
Epoch 46 Iter 10 subLoss 48412.9 multi -4.97 import weight 0.00
Epoch 46 Iter 11 subLoss 48381.7 multi 3.98 import weight 0.00
Epoch 46 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 4838 train Loss: 49300.9 test Loss: 8275.0
Epoch 47 Iter 0 subLoss 48248.5 multi 18.91 import weight 1.00
Epoch 47 Iter 1 subLoss 48305.7 multi -10.94 import weight 0.00
Epoch 47 Iter 2 subLoss 48299.5 multi -10.94 import weight 0.00
Epoch 47 Iter 3 subLoss 48373.7 multi -19.90 import weight 0.00
Epoch 47 Iter 4 subLoss 48446.4 multi -1.99 import weight 0.00
Epoch 47 Iter 5 subLoss 48466.7 multi 6.97 import weight 0.00
Epoch 47 Iter 6 subLoss 48400.1 multi 6.97 import weight 0.00
Epoch 47 Iter 7 subLoss 48421.1 multi 3.99 import weight 0.00
Epoch 47 Iter 8 subLoss 48384.7 multi 3.99 import weight 0.00
Epoch 47 Iter 9 subLoss 48356.9 multi -4.97 import weight 0.00
Epoch 47 Iter 10 subLoss 48280.5 multi -1.99 import weight 0.00
Epoch 47 Iter 11 subLoss 48325.3 multi -4.97 import weight 0.00
Epoch 47 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 4832 train Loss: 49325.7 test Loss: 8279.3
Epoch 48 Iter 0 subLoss 48294.8 multi -10.94 import weight 0.00
Epoch 48 Iter 1 subLoss 48455.3 multi -4.97 import weight 0.00
Epoch 48 Iter 2 subLoss 48436.1 multi -4.97 import weight 0.00
Epoch 48 Iter 3 subLoss 48245.6 multi 21.90 import weight 1.00
Epoch 48 Iter 4 subLoss 48539.3 multi 6.97 import weight 0.00
Epoch 48 Iter 5 subLoss 48399.2 multi -4.97 import weight 0.00
Epoch 48 Iter 6 subLoss 48308.1 multi -13.93 import weight 0.00
Epoch 48 Iter 7 subLoss 48318.4 multi 3.99 import weight 0.00
Epoch 48 Iter 8 subLoss 48435.0 multi -1.98 import weight 0.00
Epoch 48 Iter 9 subLoss 48518.1 multi 15.93 import weight 0.00
Epoch 48 Iter 10 subLoss 48314.3 multi 6.97 import weight 0.00
Epoch 48 Iter 11 subLoss 48253.0 multi -28.85 import weight 0.00
Epoch 48 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -28.85 Pidx 4825 train Loss: 49319.4 test Loss: 8278.4
Epoch 49 Iter 0 subLoss 48374.7 multi -16.91 import weight 0.00
Epoch 49 Iter 1 subLoss 48381.0 multi 3.99 import weight 0.00
Epoch 49 Iter 2 subLoss 48431.2 multi 1.00 import weight 0.00
Epoch 49 Iter 3 subLoss 48294.6 multi -7.96 import weight 0.00
Epoch 49 Iter 4 subLoss 48296.4 multi -4.97 import weight 0.00
Epoch 49 Iter 5 subLoss 48419.8 multi -4.97 import weight 0.00
Epoch 49 Iter 6 subLoss 48467.5 multi 6.97 import weight 0.00
Epoch 49 Iter 7 subLoss 48389.1 multi 6.97 import weight 0.00
Epoch 49 Iter 8 subLoss 48487.6 multi 9.96 import weight 0.00
Epoch 49 Iter 9 subLoss 48460.0 multi 9.96 import weight 0.00
Epoch 49 Iter 10 subLoss 48378.4 multi -13.93 import weight 0.00
Epoch 49 Iter 11 subLoss 48270.2 multi 12.94 import weight 0.00
Epoch 49 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 4827 train Loss: 49285.1 test Loss: 8273.4
Epoch 50 Iter 0 subLoss 48232.5 multi 1.00 import weight 0.00
Epoch 50 Iter 1 subLoss 48298.0 multi -1.99 import weight 0.00
Epoch 50 Iter 2 subLoss 48326.0 multi -7.96 import weight 0.00
Epoch 50 Iter 3 subLoss 48344.0 multi 9.96 import weight 0.00
Epoch 50 Iter 4 subLoss 48348.3 multi 12.94 import weight 0.00
Epoch 50 Iter 5 subLoss 48172.0 multi 3.99 import weight 0.00
Epoch 50 Iter 6 subLoss 48392.9 multi -7.96 import weight 0.00
Epoch 50 Iter 7 subLoss 48375.8 multi -10.94 import weight 0.00
Epoch 50 Iter 8 subLoss 48306.9 multi -19.90 import weight 0.00
Epoch 50 Iter 9 subLoss 48454.6 multi -1.99 import weight 0.00
Epoch 50 Iter 10 subLoss 48462.3 multi 9.96 import weight 0.00
Epoch 50 Iter 11 subLoss 48241.3 multi 21.90 import weight 1.00
Epoch 50 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 21.90 Pidx 4824 train Loss: 49271.3 test Loss: 8271.8
Epoch 51 Iter 0 subLoss 48406.3 multi 3.98 import weight 0.00
Epoch 51 Iter 1 subLoss 48317.3 multi 6.97 import weight 0.00
Epoch 51 Iter 2 subLoss 48268.2 multi 6.97 import weight 0.00
Epoch 51 Iter 3 subLoss 48299.0 multi 1.00 import weight 0.00
Epoch 51 Iter 4 subLoss 48309.7 multi -19.90 import weight 0.00
Epoch 51 Iter 5 subLoss 48315.1 multi 6.97 import weight 0.00
Epoch 51 Iter 6 subLoss 48273.9 multi 12.94 import weight 0.00
Epoch 51 Iter 7 subLoss 48339.5 multi -22.88 import weight 0.00
Epoch 51 Iter 8 subLoss 48258.4 multi -28.85 import weight 0.00
Epoch 51 Iter 9 subLoss 48295.0 multi 3.98 import weight 0.00
Epoch 51 Iter 10 subLoss 48417.4 multi -4.97 import weight 0.00
Epoch 51 Iter 11 subLoss 48255.3 multi -25.87 import weight 0.00
Epoch 51 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -25.87 Pidx 4825 train Loss: 49408.1 test Loss: 8294.1
Epoch 52 Iter 0 subLoss 48407.8 multi 6.97 import weight 0.00
Epoch 52 Iter 1 subLoss 48382.3 multi 3.99 import weight 0.00
Epoch 52 Iter 2 subLoss 48277.9 multi 15.93 import weight 0.00
Epoch 52 Iter 3 subLoss 48453.6 multi 1.00 import weight 0.00
Epoch 52 Iter 4 subLoss 48370.2 multi -7.96 import weight 0.00
Epoch 52 Iter 5 subLoss 48227.2 multi -10.94 import weight 0.00
Epoch 52 Iter 6 subLoss 48435.7 multi 3.99 import weight 0.00
Epoch 52 Iter 7 subLoss 48443.4 multi -10.94 import weight 0.00
Epoch 52 Iter 8 subLoss 48425.9 multi 1.00 import weight 0.00
Epoch 52 Iter 9 subLoss 48393.3 multi -7.96 import weight 0.00
Epoch 52 Iter 10 subLoss 48518.1 multi 18.91 import weight 0.00
Epoch 52 Iter 11 subLoss 48453.2 multi 1.00 import weight 0.00
Epoch 52 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4845 train Loss: 49314.0 test Loss: 8279.5
Epoch 53 Iter 0 subLoss 48359.9 multi -7.96 import weight 0.00
Epoch 53 Iter 1 subLoss 48296.7 multi 6.97 import weight 0.00
Epoch 53 Iter 2 subLoss 48388.5 multi 3.99 import weight 0.00
Epoch 53 Iter 3 subLoss 48301.2 multi -22.88 import weight 0.00
Epoch 53 Iter 4 subLoss 48367.6 multi 9.96 import weight 0.00
Epoch 53 Iter 5 subLoss 48268.3 multi 3.99 import weight 0.00
Epoch 53 Iter 6 subLoss 48434.4 multi 3.99 import weight 0.00
Epoch 53 Iter 7 subLoss 48398.6 multi -7.96 import weight 0.00
Epoch 53 Iter 8 subLoss 48349.8 multi 12.94 import weight 0.00
Epoch 53 Iter 9 subLoss 48452.7 multi 3.98 import weight 0.00
Epoch 53 Iter 10 subLoss 48361.0 multi 12.94 import weight 0.00
Epoch 53 Iter 11 subLoss 48267.8 multi 6.97 import weight 0.00
Epoch 53 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 4826 train Loss: 49247.0 test Loss: 8269.1
Epoch 54 Iter 0 subLoss 48295.1 multi 9.96 import weight 1.00
Epoch 54 Iter 1 subLoss 48279.8 multi 12.94 import weight 1.00
Epoch 54 Iter 2 subLoss 48295.5 multi 12.94 import weight 1.00
Epoch 54 Iter 3 subLoss 48269.9 multi 9.96 import weight 0.00
Epoch 54 Iter 4 subLoss 48266.9 multi 12.94 import weight 0.00
Epoch 54 Iter 5 subLoss 48253.5 multi -22.88 import weight 0.00
Epoch 54 Iter 6 subLoss 48232.8 multi 1.00 import weight 0.00
Epoch 54 Iter 7 subLoss 48281.6 multi -10.94 import weight 0.00
Epoch 54 Iter 8 subLoss 48217.8 multi 15.93 import weight 0.00
Epoch 54 Iter 9 subLoss 48303.6 multi -25.87 import weight 0.00
Epoch 54 Iter 10 subLoss 48228.3 multi -10.94 import weight 0.00
Epoch 54 Iter 11 subLoss 48330.6 multi -19.90 import weight 0.00
Epoch 54 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -19.90 Pidx 4833 train Loss: 49291.3 test Loss: 8274.4
Epoch 55 Iter 0 subLoss 48420.0 multi -4.97 import weight 0.00
Epoch 55 Iter 1 subLoss 48358.3 multi -7.96 import weight 0.00
Epoch 55 Iter 2 subLoss 48292.3 multi 12.94 import weight 1.00
Epoch 55 Iter 3 subLoss 48558.5 multi -1.98 import weight 0.00
Epoch 55 Iter 4 subLoss 48266.1 multi 12.94 import weight 0.00
Epoch 55 Iter 5 subLoss 48349.0 multi 12.94 import weight 0.00
Epoch 55 Iter 6 subLoss 48200.4 multi 18.91 import weight 0.00
Epoch 55 Iter 7 subLoss 48270.3 multi 6.97 import weight 0.00
Epoch 55 Iter 8 subLoss 48315.7 multi 3.98 import weight 0.00
Epoch 55 Iter 9 subLoss 48216.9 multi 15.93 import weight 0.00
Epoch 55 Iter 10 subLoss 48299.6 multi 15.93 import weight 1.00
Epoch 55 Iter 11 subLoss 48215.6 multi 18.91 import weight 0.00
Epoch 55 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 18.91 Pidx 4821 train Loss: 49213.9 test Loss: 8264.6
Epoch 56 Iter 0 subLoss 48251.8 multi -19.90 import weight 0.00
Epoch 56 Iter 1 subLoss 48257.4 multi -16.91 import weight 0.00
Epoch 56 Iter 2 subLoss 48193.8 multi -1.98 import weight 0.00
Epoch 56 Iter 3 subLoss 48315.2 multi 6.97 import weight 0.00
Epoch 56 Iter 4 subLoss 48218.9 multi 21.90 import weight 0.00
Epoch 56 Iter 5 subLoss 48263.1 multi 9.96 import weight 0.00
Epoch 56 Iter 6 subLoss 48209.9 multi 18.91 import weight 0.00
Epoch 56 Iter 7 subLoss 48246.2 multi 21.90 import weight 0.00
Epoch 56 Iter 8 subLoss 48334.9 multi -16.91 import weight 0.00
Epoch 56 Iter 9 subLoss 48203.2 multi 21.90 import weight 0.00
Epoch 56 Iter 10 subLoss 48355.0 multi -7.96 import weight 0.00
Epoch 56 Iter 11 subLoss 48312.0 multi 9.96 import weight 0.00
Epoch 56 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 4831 train Loss: 49220.5 test Loss: 8265.7
Epoch 57 Iter 0 subLoss 48258.8 multi -16.91 import weight 0.00
Epoch 57 Iter 1 subLoss 48301.5 multi -28.85 import weight 0.00
Epoch 57 Iter 2 subLoss 48242.5 multi 24.88 import weight 0.00
Epoch 57 Iter 3 subLoss 48287.8 multi -10.94 import weight 0.00
Epoch 57 Iter 4 subLoss 48198.8 multi 1.00 import weight 0.00
Epoch 57 Iter 5 subLoss 48206.0 multi 21.90 import weight 0.00
Epoch 57 Iter 6 subLoss 48306.3 multi -25.87 import weight 0.00
Epoch 57 Iter 7 subLoss 48346.4 multi 12.94 import weight 0.00
Epoch 57 Iter 8 subLoss 48349.5 multi 15.93 import weight 0.00
Epoch 57 Iter 9 subLoss 48174.6 multi 6.97 import weight 0.00
Epoch 57 Iter 10 subLoss 48255.8 multi -16.91 import weight 0.00
Epoch 57 Iter 11 subLoss 48399.5 multi -4.97 import weight 0.00
Epoch 57 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 4839 train Loss: 49244.2 test Loss: 8270.7
Epoch 58 Iter 0 subLoss 48280.6 multi -7.96 import weight 0.00
Epoch 58 Iter 1 subLoss 48287.4 multi -4.97 import weight 0.00
Epoch 58 Iter 2 subLoss 48199.5 multi 3.99 import weight 0.00
Epoch 58 Iter 3 subLoss 48292.6 multi 9.96 import weight 1.00
Epoch 58 Iter 4 subLoss 48324.0 multi -19.90 import weight 0.00
Epoch 58 Iter 5 subLoss 48309.6 multi -25.87 import weight 0.00
Epoch 58 Iter 6 subLoss 48397.4 multi -1.98 import weight 0.00
Epoch 58 Iter 7 subLoss 48403.7 multi -1.98 import weight 0.00
Epoch 58 Iter 8 subLoss 48269.5 multi 6.97 import weight 0.00
Epoch 58 Iter 9 subLoss 48340.7 multi 18.91 import weight 0.00
Epoch 58 Iter 10 subLoss 48358.7 multi -13.93 import weight 0.00
Epoch 58 Iter 11 subLoss 48445.3 multi -10.94 import weight 0.00
Epoch 58 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -10.94 Pidx 4844 train Loss: 49357.8 test Loss: 8289.5
Epoch 59 Iter 0 subLoss 48557.5 multi 1.00 import weight 0.00
Epoch 59 Iter 1 subLoss 48468.6 multi 3.99 import weight 0.00
Epoch 59 Iter 2 subLoss 48259.7 multi -13.93 import weight 0.00
Epoch 59 Iter 3 subLoss 48357.2 multi -10.94 import weight 0.00
Epoch 59 Iter 4 subLoss 48419.0 multi -4.97 import weight 0.00
Epoch 59 Iter 5 subLoss 48530.4 multi 9.96 import weight 0.00
Epoch 59 Iter 6 subLoss 48382.0 multi 6.97 import weight 0.00
Epoch 59 Iter 7 subLoss 48472.7 multi -22.88 import weight 0.00
Epoch 59 Iter 8 subLoss 48559.0 multi 3.99 import weight 0.00
Epoch 59 Iter 9 subLoss 48248.2 multi 27.87 import weight 0.00
Epoch 59 Iter 10 subLoss 48337.0 multi -16.91 import weight 0.00
Epoch 59 Iter 11 subLoss 48557.7 multi 6.97 import weight 0.00
Epoch 59 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 4855 train Loss: 49381.5 test Loss: 8292.4
Epoch 60 Iter 0 subLoss 48488.5 multi 9.96 import weight 0.00
Epoch 60 Iter 1 subLoss 48277.1 multi 3.99 import weight 0.00
Epoch 60 Iter 2 subLoss 48410.6 multi -1.98 import weight 0.00
Epoch 60 Iter 3 subLoss 48297.2 multi 12.94 import weight 1.00
Epoch 60 Iter 4 subLoss 48386.5 multi 9.96 import weight 0.00
Epoch 60 Iter 5 subLoss 48489.1 multi 12.94 import weight 0.00
Epoch 60 Iter 6 subLoss 48353.8 multi -7.96 import weight 0.00
Epoch 60 Iter 7 subLoss 48259.8 multi -13.93 import weight 0.00
Epoch 60 Iter 8 subLoss 48249.2 multi 30.85 import weight 0.00
Epoch 60 Iter 9 subLoss 48269.4 multi 3.98 import weight 0.00
Epoch 60 Iter 10 subLoss 48298.3 multi 15.93 import weight 1.00
Epoch 60 Iter 11 subLoss 48159.8 multi -7.96 import weight 0.00
Epoch 60 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 4815 train Loss: 49221.9 test Loss: 8266.2
Epoch 61 Iter 0 subLoss 48257.2 multi -13.93 import weight 0.00
Epoch 61 Iter 1 subLoss 48401.8 multi 1.00 import weight 0.00
Epoch 61 Iter 2 subLoss 48233.9 multi 1.00 import weight 0.00
Epoch 61 Iter 3 subLoss 48258.0 multi -10.94 import weight 0.00
Epoch 61 Iter 4 subLoss 48280.2 multi -4.97 import weight 0.00
Epoch 61 Iter 5 subLoss 48187.1 multi 6.97 import weight 0.00
Epoch 61 Iter 6 subLoss 48252.1 multi -7.96 import weight 0.00
Epoch 61 Iter 7 subLoss 48374.1 multi -10.94 import weight 0.00
Epoch 61 Iter 8 subLoss 48211.5 multi 15.93 import weight 0.00
Epoch 61 Iter 9 subLoss 48373.2 multi -7.96 import weight 0.00
Epoch 61 Iter 10 subLoss 48216.7 multi 18.91 import weight 0.00
Epoch 61 Iter 11 subLoss 48269.0 multi -1.99 import weight 0.00
Epoch 61 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 4826 train Loss: 49249.4 test Loss: 8271.8
Epoch 62 Iter 0 subLoss 48254.8 multi -4.97 import weight 0.00
Epoch 62 Iter 1 subLoss 48290.4 multi 15.93 import weight 1.00
Epoch 62 Iter 2 subLoss 48234.8 multi 3.98 import weight 0.00
Epoch 62 Iter 3 subLoss 48179.0 multi 9.96 import weight 0.00
Epoch 62 Iter 4 subLoss 48309.2 multi -31.84 import weight 0.00
Epoch 62 Iter 5 subLoss 48346.0 multi 18.91 import weight 0.00
Epoch 62 Iter 6 subLoss 48347.3 multi 21.90 import weight 0.00
Epoch 62 Iter 7 subLoss 48203.6 multi 21.90 import weight 0.00
Epoch 62 Iter 8 subLoss 48281.9 multi -1.99 import weight 0.00
Epoch 62 Iter 9 subLoss 48246.5 multi 27.87 import weight 0.00
Epoch 62 Iter 10 subLoss 48216.9 multi 18.91 import weight 0.00
Epoch 62 Iter 11 subLoss 48288.8 multi 1.00 import weight 0.00
Epoch 62 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4828 train Loss: 49190.8 test Loss: 8254.6
Epoch 63 Iter 0 subLoss 48242.5 multi 30.85 import weight 0.00
Epoch 63 Iter 1 subLoss 48222.7 multi -25.87 import weight 0.00
Epoch 63 Iter 2 subLoss 50168.9 multi 1.00 import weight 0.00
Epoch 63 Iter 3 subLoss 49092.7 multi 3.98 import weight 0.00
Epoch 63 Iter 4 subLoss 48008.0 multi 1.00 import weight 0.00
Epoch 63 Iter 5 subLoss 48004.3 multi 3.99 import weight 0.00
Epoch 63 Iter 6 subLoss 47854.5 multi 1.00 import weight 0.00
Epoch 63 Iter 7 subLoss 47834.2 multi 1.00 import weight 0.00
Epoch 63 Iter 8 subLoss 47920.6 multi 1.00 import weight 0.00
Epoch 63 Iter 9 subLoss 47804.2 multi 3.99 import weight 0.00
Epoch 63 Iter 10 subLoss 47802.9 multi 6.97 import weight 0.00
Epoch 63 Iter 11 subLoss 47479.0 multi 1.00 import weight 0.00
Epoch 63 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4747 train Loss: 48456.3 test Loss: 8092.3
Epoch 64 Iter 0 subLoss 47569.5 multi 3.99 import weight 0.00
Epoch 64 Iter 1 subLoss 47429.7 multi -1.99 import weight 0.00
Epoch 64 Iter 2 subLoss 47476.0 multi 3.99 import weight 0.00
Epoch 64 Iter 3 subLoss 47156.2 multi 1.00 import weight 0.00
Epoch 64 Iter 4 subLoss 47524.6 multi -1.99 import weight 0.00
Epoch 64 Iter 5 subLoss 47329.4 multi 1.00 import weight 0.00
Epoch 64 Iter 6 subLoss 47185.4 multi 1.00 import weight 0.00
Epoch 64 Iter 7 subLoss 47257.9 multi 1.00 import weight 0.00
Epoch 64 Iter 8 subLoss 47228.0 multi 1.00 import weight 0.00
Epoch 64 Iter 9 subLoss 47167.1 multi -1.99 import weight 0.00
Epoch 64 Iter 10 subLoss 46993.7 multi -1.99 import weight 0.00
Epoch 64 Iter 11 subLoss 47171.5 multi -1.99 import weight 0.00
Epoch 64 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 4717 train Loss: 48371.8 test Loss: 8073.3
Epoch 65 Iter 0 subLoss 47429.6 multi 1.00 import weight 0.00
Epoch 65 Iter 1 subLoss 47447.5 multi 1.00 import weight 0.00
Epoch 65 Iter 2 subLoss 47180.6 multi 1.00 import weight 0.00
Epoch 65 Iter 3 subLoss 47425.8 multi 3.98 import weight 0.00
Epoch 65 Iter 4 subLoss 47076.1 multi 1.00 import weight 0.00
Epoch 65 Iter 5 subLoss 46885.4 multi -1.99 import weight 0.00
Epoch 65 Iter 6 subLoss 47303.3 multi 3.99 import weight 0.00
Epoch 65 Iter 7 subLoss 47053.5 multi 3.99 import weight 0.00
Epoch 65 Iter 8 subLoss 46697.3 multi 1.00 import weight 0.00
Epoch 65 Iter 9 subLoss 46628.0 multi 1.00 import weight 0.00
Epoch 65 Iter 10 subLoss 46603.7 multi 1.00 import weight 0.00
Epoch 65 Iter 11 subLoss 46588.9 multi -1.99 import weight 0.00
Epoch 65 Acc: 22.38 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 4658 train Loss: 47568.5 test Loss: 7896.6
Epoch 66 Iter 0 subLoss 46680.2 multi -1.99 import weight 0.00
Epoch 66 Iter 1 subLoss 46784.0 multi 1.00 import weight 0.00
Epoch 66 Iter 2 subLoss 46732.1 multi -1.99 import weight 0.00
Epoch 66 Iter 3 subLoss 46903.9 multi 3.99 import weight 0.00
Epoch 66 Iter 4 subLoss 46849.3 multi -1.99 import weight 0.00
Epoch 66 Iter 5 subLoss 46776.4 multi 1.00 import weight 0.00
Epoch 66 Iter 6 subLoss 46799.5 multi -1.99 import weight 0.00
Epoch 66 Iter 7 subLoss 46670.5 multi 3.99 import weight 0.00
Epoch 66 Iter 8 subLoss 46320.9 multi 1.00 import weight 0.00
Epoch 66 Iter 9 subLoss 46301.6 multi 3.99 import weight 0.00
Epoch 66 Iter 10 subLoss 46200.6 multi 1.00 import weight 0.00
Epoch 66 Iter 11 subLoss 45723.0 multi 1.00 import weight 0.00
Epoch 66 Acc: 24.52 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4572 train Loss: 46680.3 test Loss: 7695.0
Epoch 67 Iter 0 subLoss 45788.1 multi 1.00 import weight 0.00
Epoch 67 Iter 1 subLoss 45800.7 multi 1.00 import weight 0.00
Epoch 67 Iter 2 subLoss 45532.1 multi 1.00 import weight 0.00
Epoch 67 Iter 3 subLoss 45022.3 multi 1.00 import weight 0.00
Epoch 67 Iter 4 subLoss 45211.5 multi 1.00 import weight 0.00
Epoch 67 Iter 5 subLoss 45103.0 multi -1.99 import weight 0.00
Epoch 67 Iter 6 subLoss 45457.6 multi 1.00 import weight 0.00
Epoch 67 Iter 7 subLoss 44738.2 multi 1.00 import weight 0.00
Epoch 67 Iter 8 subLoss 44750.8 multi 1.00 import weight 0.00
Epoch 67 Iter 9 subLoss 44500.9 multi 1.00 import weight 0.00
Epoch 67 Iter 10 subLoss 44677.6 multi 3.99 import weight 0.00
Epoch 67 Iter 11 subLoss 43857.7 multi 1.00 import weight 0.00
Epoch 67 Acc: 36.91 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4385 train Loss: 43936.1 test Loss: 7210.5
Epoch 68 Iter 0 subLoss 42732.5 multi 1.00 import weight 0.00
Epoch 68 Iter 1 subLoss 43031.5 multi 1.00 import weight 0.00
Epoch 68 Iter 2 subLoss 42120.5 multi 1.00 import weight 0.00
Epoch 68 Iter 3 subLoss 41052.8 multi 1.00 import weight 0.00
Epoch 68 Iter 4 subLoss 39820.3 multi 1.00 import weight 0.00
Epoch 68 Iter 5 subLoss 38980.5 multi -1.99 import weight 0.00
Epoch 68 Iter 6 subLoss 40292.6 multi 1.00 import weight 0.00
Epoch 68 Iter 7 subLoss 39397.6 multi 1.00 import weight 0.00
Epoch 68 Iter 8 subLoss 38861.4 multi 1.00 import weight 0.00
Epoch 68 Iter 9 subLoss 37863.8 multi 1.00 import weight 0.00
Epoch 68 Iter 10 subLoss 37931.7 multi 1.00 import weight 0.00
Epoch 68 Iter 11 subLoss 37001.0 multi 1.00 import weight 0.00
Epoch 68 Acc: 40.03 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 3700 train Loss: 37634.2 test Loss: 6078.1
Epoch 69 Iter 0 subLoss 36671.4 multi 1.00 import weight 0.00
Epoch 69 Iter 1 subLoss 36740.4 multi 1.00 import weight 0.00
Epoch 69 Iter 2 subLoss 36670.8 multi 3.99 import weight 0.00
Epoch 69 Iter 3 subLoss 40715.3 multi 1.00 import weight 0.00
Epoch 69 Iter 4 subLoss 38208.9 multi 1.00 import weight 0.00
Epoch 69 Iter 5 subLoss 36764.4 multi 1.00 import weight 0.00
Epoch 69 Iter 6 subLoss 35356.2 multi 1.00 import weight 0.00
Epoch 69 Iter 7 subLoss 34579.1 multi 1.00 import weight 0.00
Epoch 69 Iter 8 subLoss 33604.6 multi 1.00 import weight 0.00
Epoch 69 Iter 9 subLoss 33408.9 multi 1.00 import weight 0.00
Epoch 69 Iter 10 subLoss 32878.1 multi 1.00 import weight 0.00
Epoch 69 Iter 11 subLoss 32955.5 multi 1.00 import weight 0.00
Epoch 69 Acc: 53.82 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 3295 train Loss: 33289.6 test Loss: 5231.6
Epoch 70 Iter 0 subLoss 32241.1 multi 1.00 import weight 0.00
Epoch 70 Iter 1 subLoss 31866.0 multi 1.00 import weight 0.00
Epoch 70 Iter 2 subLoss 31530.9 multi 1.00 import weight 0.00
Epoch 70 Iter 3 subLoss 30328.2 multi 1.00 import weight 0.00
Epoch 70 Iter 4 subLoss 29749.0 multi 1.00 import weight 0.00
Epoch 70 Iter 5 subLoss 28755.9 multi 1.00 import weight 0.00
Epoch 70 Iter 6 subLoss 27662.6 multi 1.00 import weight 0.00
Epoch 70 Iter 7 subLoss 27302.6 multi 1.00 import weight 0.00
Epoch 70 Iter 8 subLoss 27599.4 multi 1.00 import weight 0.00
Epoch 70 Iter 9 subLoss 26417.9 multi 1.00 import weight 0.00
Epoch 70 Iter 10 subLoss 25424.9 multi 1.00 import weight 0.00
Epoch 70 Iter 11 subLoss 26010.9 multi 1.00 import weight 0.00
Epoch 70 Acc: 78.34 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2601 train Loss: 26081.2 test Loss: 3707.3
Epoch 71 Iter 0 subLoss 25197.9 multi 1.00 import weight 0.00
Epoch 71 Iter 1 subLoss 26173.6 multi 1.00 import weight 0.00
Epoch 71 Iter 2 subLoss 27683.9 multi 1.00 import weight 0.00
Epoch 71 Iter 3 subLoss 34070.4 multi 1.00 import weight 0.00
Epoch 71 Iter 4 subLoss 39823.3 multi 3.99 import weight 0.00
Epoch 71 Iter 5 subLoss 463442.7 multi 1.00 import weight 0.00
Epoch 71 Iter 6 subLoss 49206.0 multi 1.00 import weight 0.00
Epoch 71 Iter 7 subLoss 48205.1 multi 24.88 import weight 0.00
Epoch 71 Iter 8 subLoss 46157.5 multi 1.00 import weight 0.00
Epoch 71 Iter 9 subLoss 44998.7 multi 1.00 import weight 0.00
Epoch 71 Iter 10 subLoss 44767.0 multi -1.99 import weight 0.00
Epoch 71 Iter 11 subLoss 45934.6 multi 1.00 import weight 0.00
Epoch 71 Acc: 28.37 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4593 train Loss: 46207.8 test Loss: 7379.0
Epoch 72 Iter 0 subLoss 45431.4 multi 1.00 import weight 0.00
Epoch 72 Iter 1 subLoss 44683.4 multi -4.97 import weight 0.00
Epoch 72 Iter 2 subLoss 47185.8 multi 3.98 import weight 0.00
Epoch 72 Iter 3 subLoss 46531.6 multi 1.00 import weight 0.00
Epoch 72 Iter 4 subLoss 46075.2 multi 1.00 import weight 0.00
Epoch 72 Iter 5 subLoss 45743.8 multi 1.00 import weight 0.00
Epoch 72 Iter 6 subLoss 45577.6 multi 1.00 import weight 0.00
Epoch 72 Iter 7 subLoss 45270.7 multi 1.00 import weight 0.00
Epoch 72 Iter 8 subLoss 44529.4 multi 1.00 import weight 0.00
Epoch 72 Iter 9 subLoss 43819.1 multi -1.99 import weight 0.00
Epoch 72 Iter 10 subLoss 45086.2 multi -1.99 import weight 0.00
Epoch 72 Iter 11 subLoss 46122.5 multi 1.00 import weight 0.00
Epoch 72 Acc: 26.17 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4612 train Loss: 46598.2 test Loss: 7515.5
Epoch 73 Iter 0 subLoss 45879.4 multi 3.99 import weight 0.00
Epoch 73 Iter 1 subLoss 44250.5 multi 1.00 import weight 0.00
Epoch 73 Iter 2 subLoss 43886.4 multi 3.99 import weight 0.00
Epoch 73 Iter 3 subLoss 41382.9 multi 1.00 import weight 0.00
Epoch 73 Iter 4 subLoss 40801.7 multi 3.99 import weight 0.00
Epoch 73 Iter 5 subLoss 38372.9 multi 1.00 import weight 0.00
Epoch 73 Iter 6 subLoss 37929.7 multi 1.00 import weight 0.00
Epoch 73 Iter 7 subLoss 36898.0 multi 1.00 import weight 0.00
Epoch 73 Iter 8 subLoss 36833.1 multi 1.00 import weight 0.00
Epoch 73 Iter 9 subLoss 36224.9 multi 1.00 import weight 0.00
Epoch 73 Iter 10 subLoss 36100.4 multi 1.00 import weight 0.00
Epoch 73 Iter 11 subLoss 34972.5 multi 1.00 import weight 0.00
Epoch 73 Acc: 63.67 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 3497 train Loss: 35558.2 test Loss: 5026.0
Epoch 74 Iter 0 subLoss 34126.8 multi 1.00 import weight 0.00
Epoch 74 Iter 1 subLoss 34021.1 multi 1.00 import weight 0.00
Epoch 74 Iter 2 subLoss 34582.7 multi -1.99 import weight 0.00
Epoch 74 Iter 3 subLoss 59220.1 multi 1.00 import weight 0.00
Epoch 74 Iter 4 subLoss 39336.6 multi 1.00 import weight 0.00
Epoch 74 Iter 5 subLoss 36933.2 multi 1.00 import weight 0.00
Epoch 74 Iter 6 subLoss 35515.5 multi 1.00 import weight 0.00
Epoch 74 Iter 7 subLoss 34496.6 multi 1.00 import weight 0.00
Epoch 74 Iter 8 subLoss 34224.7 multi 1.00 import weight 0.00
Epoch 74 Iter 9 subLoss 33976.7 multi 1.00 import weight 0.00
Epoch 74 Iter 10 subLoss 33147.8 multi 1.00 import weight 0.00
Epoch 74 Iter 11 subLoss 33570.6 multi 1.00 import weight 0.00
Epoch 74 Acc: 74.94 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 3357 train Loss: 33038.4 test Loss: 4578.0
Epoch 75 Iter 0 subLoss 32326.2 multi 1.00 import weight 0.00
Epoch 75 Iter 1 subLoss 31873.3 multi -1.99 import weight 0.00
Epoch 75 Iter 2 subLoss 34317.4 multi 1.00 import weight 0.00
Epoch 75 Iter 3 subLoss 33292.5 multi 1.00 import weight 0.00
Epoch 75 Iter 4 subLoss 32017.6 multi 1.00 import weight 0.00
Epoch 75 Iter 5 subLoss 31116.6 multi 1.00 import weight 0.00
Epoch 75 Iter 6 subLoss 31381.0 multi 1.00 import weight 0.00
Epoch 75 Iter 7 subLoss 30256.4 multi 1.00 import weight 0.00
Epoch 75 Iter 8 subLoss 30481.4 multi 1.00 import weight 0.00
Epoch 75 Iter 9 subLoss 31059.7 multi 1.00 import weight 0.00
Epoch 75 Iter 10 subLoss 33146.1 multi 3.99 import weight 0.00
Epoch 75 Iter 11 subLoss 53839.2 multi 1.00 import weight 0.00
Epoch 75 Acc: 44.31 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 5383 train Loss: 45942.4 test Loss: 7494.7
Epoch 76 Iter 0 subLoss 45222.4 multi -1.99 import weight 0.00
Epoch 76 Iter 1 subLoss 53927.5 multi 1.00 import weight 0.00
Epoch 76 Iter 2 subLoss 47190.8 multi -7.96 import weight 0.00
Epoch 76 Iter 3 subLoss 66807.9 multi 1.00 import weight 0.00
Epoch 76 Iter 4 subLoss 49598.9 multi 1.00 import weight 0.00
Epoch 76 Iter 5 subLoss 49249.6 multi 6.97 import weight 0.00
Epoch 76 Iter 6 subLoss 48422.2 multi -4.97 import weight 0.00
Epoch 76 Iter 7 subLoss 48400.1 multi 3.99 import weight 0.00
Epoch 76 Iter 8 subLoss 48416.7 multi -4.97 import weight 0.00
Epoch 76 Iter 9 subLoss 48444.6 multi -7.96 import weight 0.00
Epoch 76 Iter 10 subLoss 48530.0 multi 12.94 import weight 0.00
Epoch 76 Iter 11 subLoss 48391.1 multi -4.97 import weight 0.00
Epoch 76 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 4839 train Loss: 49382.7 test Loss: 8300.4
Epoch 77 Iter 0 subLoss 48369.5 multi 1.00 import weight 0.00
Epoch 77 Iter 1 subLoss 48285.5 multi 3.98 import weight 0.00
Epoch 77 Iter 2 subLoss 48377.5 multi -7.96 import weight 0.00
Epoch 77 Iter 3 subLoss 48335.2 multi -13.93 import weight 0.00
Epoch 77 Iter 4 subLoss 48517.8 multi 21.90 import weight 0.00
Epoch 77 Iter 5 subLoss 48403.3 multi 3.99 import weight 0.00
Epoch 77 Iter 6 subLoss 48331.4 multi -10.94 import weight 0.00
Epoch 77 Iter 7 subLoss 48495.1 multi -7.96 import weight 0.00
Epoch 77 Iter 8 subLoss 48588.6 multi -4.97 import weight 0.00
Epoch 77 Iter 9 subLoss 48445.7 multi -4.97 import weight 0.00
Epoch 77 Iter 10 subLoss 48760.9 multi -1.98 import weight 0.00
Epoch 77 Iter 11 subLoss 48381.6 multi 3.99 import weight 0.00
Epoch 77 Acc: 21.95 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 4838 train Loss: 49486.1 test Loss: 8315.5
Epoch 78 Iter 0 subLoss 48448.9 multi -1.98 import weight 0.00
Epoch 78 Iter 1 subLoss 48585.8 multi -1.99 import weight 0.00
Epoch 78 Iter 2 subLoss 48778.1 multi -4.97 import weight 0.00
Epoch 78 Iter 3 subLoss 48689.5 multi -1.98 import weight 0.00
Epoch 78 Iter 4 subLoss 48499.8 multi -4.97 import weight 0.00
Epoch 78 Iter 5 subLoss 48806.3 multi -4.97 import weight 0.00
Epoch 78 Iter 6 subLoss 49031.2 multi -1.98 import weight 0.00
Epoch 78 Iter 7 subLoss 49248.6 multi 9.96 import weight 0.00
Epoch 78 Iter 8 subLoss 48637.1 multi -1.99 import weight 0.00
Epoch 78 Iter 9 subLoss 48493.8 multi -1.99 import weight 0.00
Epoch 78 Iter 10 subLoss 48600.4 multi -4.97 import weight 0.00
Epoch 78 Iter 11 subLoss 48549.4 multi -4.97 import weight 0.00
Epoch 78 Acc: 17.81 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 4854 train Loss: 49782.2 test Loss: 8373.0
Epoch 79 Iter 0 subLoss 48907.2 multi 9.96 import weight 0.00
Epoch 79 Iter 1 subLoss 48565.8 multi -16.91 import weight 0.00
Epoch 79 Iter 2 subLoss 48813.7 multi -1.98 import weight 0.00
Epoch 79 Iter 3 subLoss 48837.2 multi 3.99 import weight 0.00
Epoch 79 Iter 4 subLoss 48785.8 multi 6.97 import weight 0.00
Epoch 79 Iter 5 subLoss 48718.9 multi 1.00 import weight 0.00
Epoch 79 Iter 6 subLoss 48508.8 multi -13.93 import weight 0.00
Epoch 79 Iter 7 subLoss 48920.7 multi 1.00 import weight 0.00
Epoch 79 Iter 8 subLoss 48887.8 multi -4.97 import weight 0.00
Epoch 79 Iter 9 subLoss 48895.5 multi -7.96 import weight 0.00
Epoch 79 Iter 10 subLoss 48887.9 multi -1.99 import weight 0.00
Epoch 79 Iter 11 subLoss 49295.1 multi 1.00 import weight 0.00
Epoch 79 Acc: 19.11 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4929 train Loss: 50157.3 test Loss: 8450.2
Epoch 80 Iter 0 subLoss 49220.8 multi -1.99 import weight 0.00
Epoch 80 Iter 1 subLoss 49178.6 multi 1.00 import weight 0.00
Epoch 80 Iter 2 subLoss 49255.7 multi -7.96 import weight 0.00
Epoch 80 Iter 3 subLoss 49765.4 multi 1.00 import weight 0.00
Epoch 80 Iter 4 subLoss 49508.2 multi 1.00 import weight 0.00
Epoch 80 Iter 5 subLoss 49662.1 multi 1.00 import weight 0.00
Epoch 80 Iter 6 subLoss 49651.7 multi 1.00 import weight 0.00
Epoch 80 Iter 7 subLoss 49494.7 multi 1.00 import weight 0.00
Epoch 80 Iter 8 subLoss 49287.8 multi -1.99 import weight 0.00
Epoch 80 Iter 9 subLoss 49625.2 multi 1.00 import weight 0.00
Epoch 80 Iter 10 subLoss 49215.5 multi 1.00 import weight 0.00
Epoch 80 Iter 11 subLoss 49363.0 multi 1.00 import weight 0.00
Epoch 80 Acc: 19.11 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4936 train Loss: 50209.3 test Loss: 8460.9
Epoch 81 Iter 0 subLoss 49158.6 multi 1.00 import weight 0.00
Epoch 81 Iter 1 subLoss 49203.6 multi 3.99 import weight 0.00
Epoch 81 Iter 2 subLoss 49090.1 multi 6.97 import weight 0.00
Epoch 81 Iter 3 subLoss 48965.0 multi -1.99 import weight 0.00
Epoch 81 Iter 4 subLoss 48924.1 multi 3.98 import weight 0.00
Epoch 81 Iter 5 subLoss 48894.0 multi -7.96 import weight 0.00
Epoch 81 Iter 6 subLoss 48861.5 multi -4.97 import weight 0.00
Epoch 81 Iter 7 subLoss 48815.8 multi 1.00 import weight 0.00
Epoch 81 Iter 8 subLoss 48903.1 multi 6.97 import weight 0.00
Epoch 81 Iter 9 subLoss 48933.8 multi -1.99 import weight 0.00
Epoch 81 Iter 10 subLoss 48893.8 multi -4.97 import weight 0.00
Epoch 81 Iter 11 subLoss 48852.6 multi 6.97 import weight 0.00
Epoch 81 Acc: 19.11 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 4885 train Loss: 49824.7 test Loss: 8382.7
Epoch 82 Iter 0 subLoss 48880.6 multi 1.00 import weight 0.00
Epoch 82 Iter 1 subLoss 48699.5 multi -4.97 import weight 0.00
Epoch 82 Iter 2 subLoss 48883.9 multi 3.98 import weight 0.00
Epoch 82 Iter 3 subLoss 48961.3 multi 1.00 import weight 0.00
Epoch 82 Iter 4 subLoss 48954.4 multi 1.00 import weight 0.00
Epoch 82 Iter 5 subLoss 48682.1 multi 1.00 import weight 0.00
Epoch 82 Iter 6 subLoss 48947.1 multi -4.97 import weight 0.00
Epoch 82 Iter 7 subLoss 48848.7 multi -10.94 import weight 0.00
Epoch 82 Iter 8 subLoss 49208.6 multi 6.97 import weight 0.00
Epoch 82 Iter 9 subLoss 48888.0 multi 6.97 import weight 0.00
Epoch 82 Iter 10 subLoss 48787.5 multi 9.96 import weight 0.00
Epoch 82 Iter 11 subLoss 48580.4 multi 1.00 import weight 0.00
Epoch 82 Acc: 14.36 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4858 train Loss: 49592.2 test Loss: 8337.6
Epoch 83 Iter 0 subLoss 48668.2 multi -7.96 import weight 0.00
Epoch 83 Iter 1 subLoss 48623.7 multi 1.00 import weight 0.00
Epoch 83 Iter 2 subLoss 48598.8 multi 6.97 import weight 0.00
Epoch 83 Iter 3 subLoss 48781.1 multi 12.94 import weight 0.00
Epoch 83 Iter 4 subLoss 48376.9 multi -4.97 import weight 0.00
Epoch 83 Iter 5 subLoss 48356.5 multi -10.94 import weight 0.00
Epoch 83 Iter 6 subLoss 48630.7 multi -1.98 import weight 0.00
Epoch 83 Iter 7 subLoss 48583.0 multi 3.99 import weight 0.00
Epoch 83 Iter 8 subLoss 48557.9 multi 6.97 import weight 0.00
Epoch 83 Iter 9 subLoss 48460.8 multi 6.97 import weight 0.00
Epoch 83 Iter 10 subLoss 48642.0 multi -1.98 import weight 0.00
Epoch 83 Iter 11 subLoss 48527.3 multi -19.90 import weight 0.00
Epoch 83 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -19.90 Pidx 4852 train Loss: 49572.6 test Loss: 8333.5
Epoch 84 Iter 0 subLoss 48660.4 multi -4.97 import weight 0.00
Epoch 84 Iter 1 subLoss 48866.3 multi -4.97 import weight 0.00
Epoch 84 Iter 2 subLoss 48821.6 multi -1.99 import weight 0.00
Epoch 84 Iter 3 subLoss 48618.7 multi -10.94 import weight 0.00
Epoch 84 Iter 4 subLoss 49069.2 multi -1.98 import weight 0.00
Epoch 84 Iter 5 subLoss 48675.1 multi -4.97 import weight 0.00
Epoch 84 Iter 6 subLoss 48773.1 multi -1.98 import weight 0.00
Epoch 84 Iter 7 subLoss 48844.9 multi -7.96 import weight 0.00
Epoch 84 Iter 8 subLoss 49232.4 multi -1.99 import weight 0.00
Epoch 84 Iter 9 subLoss 49300.9 multi -1.99 import weight 0.00
Epoch 84 Iter 10 subLoss 49356.2 multi 1.00 import weight 0.00
Epoch 84 Iter 11 subLoss 49375.1 multi -1.99 import weight 0.00
Epoch 84 Acc: 17.65 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 4937 train Loss: 50353.9 test Loss: 8485.4
Epoch 85 Iter 0 subLoss 49528.1 multi 1.00 import weight 0.00
Epoch 85 Iter 1 subLoss 49536.2 multi -1.99 import weight 0.00
Epoch 85 Iter 2 subLoss 49347.5 multi 1.00 import weight 0.00
Epoch 85 Iter 3 subLoss 49377.4 multi 1.00 import weight 0.00
Epoch 85 Iter 4 subLoss 49320.2 multi 3.99 import weight 0.00
Epoch 85 Iter 5 subLoss 49002.3 multi 3.98 import weight 0.00
Epoch 85 Iter 6 subLoss 49137.7 multi 6.97 import weight 0.00
Epoch 85 Iter 7 subLoss 49010.5 multi 1.00 import weight 0.00
Epoch 85 Iter 8 subLoss 48789.4 multi 12.94 import weight 0.00
Epoch 85 Iter 9 subLoss 48599.6 multi 6.97 import weight 0.00
Epoch 85 Iter 10 subLoss 48598.2 multi 9.96 import weight 0.00
Epoch 85 Iter 11 subLoss 48630.0 multi 1.00 import weight 0.00
Epoch 85 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4862 train Loss: 49516.8 test Loss: 8322.6
Epoch 86 Iter 0 subLoss 48615.9 multi -7.96 import weight 0.00
Epoch 86 Iter 1 subLoss 48532.6 multi 12.94 import weight 0.00
Epoch 86 Iter 2 subLoss 48454.7 multi -4.97 import weight 0.00
Epoch 86 Iter 3 subLoss 48607.7 multi -10.94 import weight 0.00
Epoch 86 Iter 4 subLoss 48675.4 multi -1.99 import weight 0.00
Epoch 86 Iter 5 subLoss 48771.9 multi 1.00 import weight 0.00
Epoch 86 Iter 6 subLoss 48505.7 multi -10.94 import weight 0.00
Epoch 86 Iter 7 subLoss 48677.2 multi 1.00 import weight 0.00
Epoch 86 Iter 8 subLoss 48709.0 multi 6.97 import weight 0.00
Epoch 86 Iter 9 subLoss 48623.0 multi 1.00 import weight 0.00
Epoch 86 Iter 10 subLoss 48804.8 multi -1.99 import weight 0.00
Epoch 86 Iter 11 subLoss 48633.0 multi -4.97 import weight 0.00
Epoch 86 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 4863 train Loss: 49681.0 test Loss: 8351.8
Epoch 87 Iter 0 subLoss 48881.5 multi 9.96 import weight 0.00
Epoch 87 Iter 1 subLoss 48522.5 multi -16.91 import weight 0.00
Epoch 87 Iter 2 subLoss 48599.5 multi 12.94 import weight 0.00
Epoch 87 Iter 3 subLoss 48475.1 multi -22.88 import weight 0.00
Epoch 87 Iter 4 subLoss 48904.5 multi 6.97 import weight 0.00
Epoch 87 Iter 5 subLoss 48643.2 multi -1.99 import weight 0.00
Epoch 87 Iter 6 subLoss 48727.5 multi 1.00 import weight 0.00
Epoch 87 Iter 7 subLoss 48627.4 multi 3.99 import weight 0.00
Epoch 87 Iter 8 subLoss 48720.9 multi 3.98 import weight 0.00
Epoch 87 Iter 9 subLoss 48610.1 multi -7.96 import weight 0.00
Epoch 87 Iter 10 subLoss 48736.3 multi -13.93 import weight 0.00
Epoch 87 Iter 11 subLoss 49002.1 multi 6.97 import weight 0.00
Epoch 87 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 4900 train Loss: 49734.3 test Loss: 8362.0
Epoch 88 Iter 0 subLoss 48771.5 multi 3.99 import weight 0.00
Epoch 88 Iter 1 subLoss 48620.3 multi 3.98 import weight 0.00
Epoch 88 Iter 2 subLoss 49079.6 multi -1.98 import weight 0.00
Epoch 88 Iter 3 subLoss 48883.4 multi 12.94 import weight 0.00
Epoch 88 Iter 4 subLoss 48448.5 multi 1.00 import weight 0.00
Epoch 88 Iter 5 subLoss 48555.0 multi 9.96 import weight 0.00
Epoch 88 Iter 6 subLoss 48420.5 multi -4.97 import weight 0.00
Epoch 88 Iter 7 subLoss 48440.7 multi 3.99 import weight 0.00
Epoch 88 Iter 8 subLoss 48410.0 multi 6.97 import weight 0.00
Epoch 88 Iter 9 subLoss 48516.7 multi 18.91 import weight 0.00
Epoch 88 Iter 10 subLoss 48313.9 multi 1.00 import weight 0.00
Epoch 88 Iter 11 subLoss 48324.2 multi -19.90 import weight 0.00
Epoch 88 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -19.90 Pidx 4832 train Loss: 49378.7 test Loss: 8298.2
Epoch 89 Iter 0 subLoss 48349.0 multi 18.91 import weight 0.00
Epoch 89 Iter 1 subLoss 48234.3 multi 3.99 import weight 0.00
Epoch 89 Iter 2 subLoss 48336.3 multi -10.94 import weight 0.00
Epoch 89 Iter 3 subLoss 48487.0 multi 12.94 import weight 0.00
Epoch 89 Iter 4 subLoss 48301.4 multi -28.85 import weight 0.00
Epoch 89 Iter 5 subLoss 48350.7 multi -10.94 import weight 0.00
Epoch 89 Iter 6 subLoss 48498.5 multi -1.99 import weight 0.00
Epoch 89 Iter 7 subLoss 48418.7 multi -7.96 import weight 0.00
Epoch 89 Iter 8 subLoss 48462.7 multi 6.97 import weight 0.00
Epoch 89 Iter 9 subLoss 48458.5 multi -7.96 import weight 0.00
Epoch 89 Iter 10 subLoss 48506.4 multi -10.94 import weight 0.00
Epoch 89 Iter 11 subLoss 48545.2 multi -4.97 import weight 0.00
Epoch 89 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 4854 train Loss: 49543.4 test Loss: 8324.5
Epoch 90 Iter 0 subLoss 48577.9 multi 1.00 import weight 0.00
Epoch 90 Iter 1 subLoss 48603.8 multi -10.94 import weight 0.00
Epoch 90 Iter 2 subLoss 48662.2 multi -1.98 import weight 0.00
Epoch 90 Iter 3 subLoss 48737.4 multi -10.94 import weight 0.00
Epoch 90 Iter 4 subLoss 48837.7 multi 3.99 import weight 0.00
Epoch 90 Iter 5 subLoss 48519.1 multi 18.91 import weight 0.00
Epoch 90 Iter 6 subLoss 48708.3 multi 9.96 import weight 0.00
Epoch 90 Iter 7 subLoss 48533.3 multi 12.94 import weight 0.00
Epoch 90 Iter 8 subLoss 48436.3 multi 1.00 import weight 0.00
Epoch 90 Iter 9 subLoss 48441.3 multi 3.99 import weight 0.00
Epoch 90 Iter 10 subLoss 48412.7 multi -4.97 import weight 0.00
Epoch 90 Iter 11 subLoss 48375.1 multi -1.98 import weight 0.00
Epoch 90 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 4837 train Loss: 49391.5 test Loss: 8298.0
Epoch 91 Iter 0 subLoss 48372.4 multi 1.00 import weight 0.00
Epoch 91 Iter 1 subLoss 48503.7 multi -7.96 import weight 0.00
Epoch 91 Iter 2 subLoss 48406.4 multi 9.96 import weight 0.00
Epoch 91 Iter 3 subLoss 48351.6 multi -7.96 import weight 0.00
Epoch 91 Iter 4 subLoss 48379.8 multi 3.99 import weight 0.00
Epoch 91 Iter 5 subLoss 48433.3 multi 3.99 import weight 0.00
Epoch 91 Iter 6 subLoss 48250.5 multi -7.96 import weight 0.00
Epoch 91 Iter 7 subLoss 48501.2 multi -4.97 import weight 0.00
Epoch 91 Iter 8 subLoss 48601.1 multi -7.96 import weight 0.00
Epoch 91 Iter 9 subLoss 48589.5 multi 3.98 import weight 0.00
Epoch 91 Iter 10 subLoss 48620.4 multi 6.97 import weight 0.00
Epoch 91 Iter 11 subLoss 48506.1 multi -1.99 import weight 0.00
Epoch 91 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 4850 train Loss: 49425.9 test Loss: 8304.1
Epoch 92 Iter 0 subLoss 48439.5 multi 6.97 import weight 0.00
Epoch 92 Iter 1 subLoss 48448.3 multi 1.00 import weight 0.00
Epoch 92 Iter 2 subLoss 48456.8 multi -10.94 import weight 0.00
Epoch 92 Iter 3 subLoss 48590.3 multi 12.94 import weight 0.00
Epoch 92 Iter 4 subLoss 48409.0 multi 12.94 import weight 0.00
Epoch 92 Iter 5 subLoss 48368.4 multi -4.97 import weight 0.00
Epoch 92 Iter 6 subLoss 48319.1 multi 1.00 import weight 0.00
Epoch 92 Iter 7 subLoss 48457.5 multi -7.96 import weight 0.00
Epoch 92 Iter 8 subLoss 48304.1 multi -25.87 import weight 0.00
Epoch 92 Iter 9 subLoss 48422.5 multi -7.96 import weight 0.00
Epoch 92 Iter 10 subLoss 48484.8 multi 15.93 import weight 0.00
Epoch 92 Iter 11 subLoss 48438.2 multi 6.97 import weight 0.00
Epoch 92 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 4843 train Loss: 49365.7 test Loss: 8292.8
Epoch 93 Iter 0 subLoss 48522.9 multi -19.90 import weight 0.00
Epoch 93 Iter 1 subLoss 48337.1 multi -7.96 import weight 0.00
Epoch 93 Iter 2 subLoss 48749.0 multi -1.99 import weight 0.00
Epoch 93 Iter 3 subLoss 48567.0 multi -19.90 import weight 0.00
Epoch 93 Iter 4 subLoss 48866.3 multi -1.99 import weight 0.00
Epoch 93 Iter 5 subLoss 48904.1 multi 9.96 import weight 0.00
Epoch 93 Iter 6 subLoss 48686.2 multi -4.97 import weight 0.00
Epoch 93 Iter 7 subLoss 48741.0 multi 1.00 import weight 0.00
Epoch 93 Iter 8 subLoss 48559.7 multi 9.96 import weight 0.00
Epoch 93 Iter 9 subLoss 48478.9 multi -22.88 import weight 0.00
Epoch 93 Iter 10 subLoss 48661.9 multi 1.00 import weight 0.00
Epoch 93 Iter 11 subLoss 48704.6 multi 12.94 import weight 0.00
Epoch 93 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 4870 train Loss: 49602.8 test Loss: 8336.0
Epoch 94 Iter 0 subLoss 48563.7 multi -19.90 import weight 0.00
Epoch 94 Iter 1 subLoss 48891.2 multi -16.91 import weight 0.00
Epoch 94 Iter 2 subLoss 49141.3 multi -10.94 import weight 0.00
Epoch 94 Iter 3 subLoss 49423.2 multi 3.99 import weight 0.00
Epoch 94 Iter 4 subLoss 49329.0 multi 6.97 import weight 0.00
Epoch 94 Iter 5 subLoss 49190.4 multi 1.00 import weight 0.00
Epoch 94 Iter 6 subLoss 49102.2 multi -1.99 import weight 0.00
Epoch 94 Iter 7 subLoss 49015.9 multi 1.00 import weight 0.00
Epoch 94 Iter 8 subLoss 49037.3 multi 1.00 import weight 0.00
Epoch 94 Iter 9 subLoss 49152.6 multi 1.00 import weight 0.00
Epoch 94 Iter 10 subLoss 49072.0 multi 1.00 import weight 0.00
Epoch 94 Iter 11 subLoss 48999.6 multi 1.00 import weight 0.00
Epoch 94 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4899 train Loss: 49990.5 test Loss: 8405.0
Epoch 95 Iter 0 subLoss 48788.6 multi 9.96 import weight 0.00
Epoch 95 Iter 1 subLoss 48862.4 multi 1.00 import weight 0.00
Epoch 95 Iter 2 subLoss 48828.7 multi 1.00 import weight 0.00
Epoch 95 Iter 3 subLoss 48732.8 multi -7.96 import weight 0.00
Epoch 95 Iter 4 subLoss 48938.2 multi 1.00 import weight 0.00
Epoch 95 Iter 5 subLoss 49000.3 multi 6.97 import weight 0.00
Epoch 95 Iter 6 subLoss 49017.9 multi 1.00 import weight 0.00
Epoch 95 Iter 7 subLoss 48639.3 multi -10.94 import weight 0.00
Epoch 95 Iter 8 subLoss 48923.3 multi 6.97 import weight 0.00
Epoch 95 Iter 9 subLoss 48804.2 multi 1.00 import weight 0.00
Epoch 95 Iter 10 subLoss 48928.3 multi 9.96 import weight 0.00
Epoch 95 Iter 11 subLoss 48638.6 multi -7.96 import weight 0.00
Epoch 95 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 4863 train Loss: 49701.7 test Loss: 8353.1
Epoch 96 Iter 0 subLoss 48800.2 multi 3.99 import weight 0.00
Epoch 96 Iter 1 subLoss 48662.8 multi 3.99 import weight 0.00
Epoch 96 Iter 2 subLoss 48566.2 multi -16.91 import weight 0.00
Epoch 96 Iter 3 subLoss 48776.6 multi 6.97 import weight 0.00
Epoch 96 Iter 4 subLoss 48741.9 multi 1.00 import weight 0.00
Epoch 96 Iter 5 subLoss 48642.0 multi -4.97 import weight 0.00
Epoch 96 Iter 6 subLoss 48803.1 multi 6.97 import weight 0.00
Epoch 96 Iter 7 subLoss 48638.0 multi -4.97 import weight 0.00
Epoch 96 Iter 8 subLoss 48509.7 multi 1.00 import weight 0.00
Epoch 96 Iter 9 subLoss 48811.0 multi -7.96 import weight 0.00
Epoch 96 Iter 10 subLoss 49105.4 multi 1.00 import weight 0.00
Epoch 96 Iter 11 subLoss 48774.9 multi 9.96 import weight 0.00
Epoch 96 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 4877 train Loss: 49644.6 test Loss: 8343.1
Epoch 97 Iter 0 subLoss 48765.8 multi 1.00 import weight 0.00
Epoch 97 Iter 1 subLoss 48644.4 multi -4.97 import weight 0.00
Epoch 97 Iter 2 subLoss 48841.2 multi -7.96 import weight 0.00
Epoch 97 Iter 3 subLoss 49019.2 multi 3.99 import weight 0.00
Epoch 97 Iter 4 subLoss 48567.1 multi -13.93 import weight 0.00
Epoch 97 Iter 5 subLoss 48963.2 multi 1.00 import weight 0.00
Epoch 97 Iter 6 subLoss 48915.2 multi -16.91 import weight 0.00
Epoch 97 Iter 7 subLoss 49148.5 multi -7.96 import weight 0.00
Epoch 97 Iter 8 subLoss 49414.9 multi 1.00 import weight 0.00
Epoch 97 Iter 9 subLoss 49431.8 multi -4.97 import weight 0.00
Epoch 97 Iter 10 subLoss 49618.4 multi 1.00 import weight 0.00
Epoch 97 Iter 11 subLoss 49439.4 multi -1.98 import weight 0.00
Epoch 97 Acc: 21.79 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 4943 train Loss: 50641.3 test Loss: 8524.2
Epoch 98 Iter 0 subLoss 49689.5 multi 1.00 import weight 0.00
Epoch 98 Iter 1 subLoss 49795.5 multi 1.00 import weight 0.00
Epoch 98 Iter 2 subLoss 49656.3 multi 3.99 import weight 0.00
Epoch 98 Iter 3 subLoss 49423.8 multi 3.98 import weight 0.00
Epoch 98 Iter 4 subLoss 49247.6 multi 9.96 import weight 0.00
Epoch 98 Iter 5 subLoss 48997.9 multi 3.98 import weight 0.00
Epoch 98 Iter 6 subLoss 49006.1 multi 6.97 import weight 0.00
Epoch 98 Iter 7 subLoss 48619.4 multi -10.94 import weight 0.00
Epoch 98 Iter 8 subLoss 48927.6 multi 9.96 import weight 0.00
Epoch 98 Iter 9 subLoss 48693.8 multi -7.96 import weight 0.00
Epoch 98 Iter 10 subLoss 49173.6 multi 3.98 import weight 0.00
Epoch 98 Iter 11 subLoss 48746.8 multi 3.98 import weight 0.00
Epoch 98 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 4874 train Loss: 49752.1 test Loss: 8362.1
Epoch 99 Iter 0 subLoss 48608.3 multi -7.96 import weight 0.00
Epoch 99 Iter 1 subLoss 49113.2 multi -13.93 import weight 0.00
Epoch 99 Iter 2 subLoss 49373.1 multi 3.98 import weight 0.00
Epoch 99 Iter 3 subLoss 49196.9 multi 3.99 import weight 0.00
Epoch 99 Iter 4 subLoss 48758.0 multi -10.94 import weight 0.00
Epoch 99 Iter 5 subLoss 49144.7 multi -4.97 import weight 0.00
Epoch 99 Iter 6 subLoss 49428.2 multi 6.97 import weight 0.00
Epoch 99 Iter 7 subLoss 49078.9 multi 3.99 import weight 0.00
Epoch 99 Iter 8 subLoss 49096.7 multi 9.96 import weight 0.00
Epoch 99 Iter 9 subLoss 48731.5 multi -4.97 import weight 0.00
Epoch 99 Iter 10 subLoss 48883.4 multi 15.93 import weight 0.00
Epoch 99 Iter 11 subLoss 48493.1 multi -1.98 import weight 0.00
Epoch 99 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 4849 train Loss: 49640.7 test Loss: 8341.4
Epoch 100 Iter 0 subLoss 48486.1 multi 15.93 import weight 0.00
Epoch 100 Iter 1 subLoss 48544.8 multi -4.97 import weight 0.00
Epoch 100 Iter 2 subLoss 48666.8 multi 6.97 import weight 0.00
Epoch 100 Iter 3 subLoss 48607.8 multi -4.97 import weight 0.00
Epoch 100 Iter 4 subLoss 48758.5 multi -7.96 import weight 0.00
Epoch 100 Iter 5 subLoss 48523.3 multi -16.91 import weight 0.00
Epoch 100 Iter 6 subLoss 48955.3 multi 1.00 import weight 0.00
Epoch 100 Iter 7 subLoss 48801.6 multi 9.96 import weight 0.00
Epoch 100 Iter 8 subLoss 48720.5 multi 6.97 import weight 0.00
Epoch 100 Iter 9 subLoss 48646.3 multi -1.99 import weight 0.00
Epoch 100 Iter 10 subLoss 48393.7 multi -4.97 import weight 0.00
Epoch 100 Iter 11 subLoss 48519.4 multi 9.96 import weight 0.00
Epoch 100 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 4851 train Loss: 49527.0 test Loss: 8320.7
Epoch 101 Iter 0 subLoss 48511.5 multi 12.94 import weight 0.00
Epoch 101 Iter 1 subLoss 48435.5 multi 9.96 import weight 0.00
Epoch 101 Iter 2 subLoss 48604.3 multi -1.98 import weight 0.00
Epoch 101 Iter 3 subLoss 48552.7 multi 9.96 import weight 0.00
Epoch 101 Iter 4 subLoss 48317.3 multi 1.00 import weight 0.00
Epoch 101 Iter 5 subLoss 48451.5 multi -4.97 import weight 0.00
Epoch 101 Iter 6 subLoss 48260.7 multi -4.97 import weight 0.00
Epoch 101 Iter 7 subLoss 48384.0 multi -4.97 import weight 0.00
Epoch 101 Iter 8 subLoss 48483.7 multi 18.91 import weight 0.00
Epoch 101 Iter 9 subLoss 48365.3 multi -1.99 import weight 0.00
Epoch 101 Iter 10 subLoss 48244.5 multi 30.85 import weight 1.00
Epoch 101 Iter 11 subLoss 48347.7 multi 15.93 import weight 0.00
Epoch 101 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 15.93 Pidx 4834 train Loss: 49251.9 test Loss: 8273.6
Epoch 102 Iter 0 subLoss 48337.6 multi -4.97 import weight 0.00
Epoch 102 Iter 1 subLoss 48336.5 multi -1.99 import weight 0.00
Epoch 102 Iter 2 subLoss 48287.9 multi 6.97 import weight 0.00
Epoch 102 Iter 3 subLoss 48351.9 multi -7.96 import weight 0.00
Epoch 102 Iter 4 subLoss 48260.5 multi -1.99 import weight 0.00
Epoch 102 Iter 5 subLoss 48308.8 multi -22.88 import weight 0.00
Epoch 102 Iter 6 subLoss 48265.0 multi 1.00 import weight 0.00
Epoch 102 Iter 7 subLoss 48401.5 multi 12.94 import weight 0.00
Epoch 102 Iter 8 subLoss 48276.9 multi -7.96 import weight 0.00
Epoch 102 Iter 9 subLoss 48312.4 multi 1.00 import weight 0.00
Epoch 102 Iter 10 subLoss 48277.0 multi -4.97 import weight 0.00
Epoch 102 Iter 11 subLoss 48431.6 multi 12.94 import weight 0.00
Epoch 102 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 4843 train Loss: 49268.7 test Loss: 8275.8
Epoch 103 Iter 0 subLoss 48328.5 multi -25.87 import weight 0.00
Epoch 103 Iter 1 subLoss 48246.8 multi 33.84 import weight 1.00
Epoch 103 Iter 2 subLoss 48315.1 multi 3.99 import weight 0.00
Epoch 103 Iter 3 subLoss 48262.1 multi 3.99 import weight 0.00
Epoch 103 Iter 4 subLoss 48355.0 multi -4.97 import weight 0.00
Epoch 103 Iter 5 subLoss 48351.5 multi -1.99 import weight 0.00
Epoch 103 Iter 6 subLoss 48206.7 multi 27.87 import weight 0.00
Epoch 103 Iter 7 subLoss 48300.9 multi -19.90 import weight 0.00
Epoch 103 Iter 8 subLoss 48357.4 multi 1.00 import weight 0.00
Epoch 103 Iter 9 subLoss 48320.7 multi -25.87 import weight 0.00
Epoch 103 Iter 10 subLoss 48271.0 multi -4.97 import weight 0.00
Epoch 103 Iter 11 subLoss 48531.9 multi 9.96 import weight 0.00
Epoch 103 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 4853 train Loss: 49304.5 test Loss: 8286.1
Epoch 104 Iter 0 subLoss 48246.7 multi 36.82 import weight 1.00
Epoch 104 Iter 1 subLoss 48234.6 multi 6.97 import weight 0.00
Epoch 104 Iter 2 subLoss 48360.8 multi -10.94 import weight 0.00
Epoch 104 Iter 3 subLoss 48315.2 multi 3.99 import weight 0.00
Epoch 104 Iter 4 subLoss 48302.7 multi -16.91 import weight 0.00
Epoch 104 Iter 5 subLoss 48301.7 multi -13.93 import weight 0.00
Epoch 104 Iter 6 subLoss 48464.9 multi -1.98 import weight 0.00
Epoch 104 Iter 7 subLoss 48394.6 multi -4.97 import weight 0.00
Epoch 104 Iter 8 subLoss 48473.8 multi -22.88 import weight 0.00
Epoch 104 Iter 9 subLoss 48593.7 multi 15.93 import weight 0.00
Epoch 104 Iter 10 subLoss 48251.4 multi -13.93 import weight 0.00
Epoch 104 Iter 11 subLoss 48421.5 multi -4.97 import weight 0.00
Epoch 104 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 4842 train Loss: 49421.1 test Loss: 8306.3
Epoch 105 Iter 0 subLoss 48463.5 multi 1.00 import weight 0.00
Epoch 105 Iter 1 subLoss 48627.2 multi 6.97 import weight 0.00
Epoch 105 Iter 2 subLoss 48411.4 multi -10.94 import weight 0.00
Epoch 105 Iter 3 subLoss 48381.0 multi -1.99 import weight 0.00
Epoch 105 Iter 4 subLoss 48523.5 multi -19.90 import weight 0.00
Epoch 105 Iter 5 subLoss 48709.5 multi 12.94 import weight 0.00
Epoch 105 Iter 6 subLoss 48505.6 multi 1.00 import weight 0.00
Epoch 105 Iter 7 subLoss 48232.3 multi 9.96 import weight 0.00
Epoch 105 Iter 8 subLoss 48473.0 multi -22.88 import weight 0.00
Epoch 105 Iter 9 subLoss 48607.0 multi -1.99 import weight 0.00
Epoch 105 Iter 10 subLoss 48527.7 multi -16.91 import weight 0.00
Epoch 105 Iter 11 subLoss 48714.7 multi -7.96 import weight 0.00
Epoch 105 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 4871 train Loss: 49799.1 test Loss: 8373.7
Epoch 106 Iter 0 subLoss 48899.2 multi -16.91 import weight 0.00
Epoch 106 Iter 1 subLoss 48957.3 multi 3.99 import weight 0.00
Epoch 106 Iter 2 subLoss 49051.4 multi 6.97 import weight 0.00
Epoch 106 Iter 3 subLoss 49183.5 multi -7.96 import weight 0.00
Epoch 106 Iter 4 subLoss 49017.2 multi 3.99 import weight 0.00
Epoch 106 Iter 5 subLoss 48840.3 multi -4.97 import weight 0.00
Epoch 106 Iter 6 subLoss 48965.6 multi -1.99 import weight 0.00
Epoch 106 Iter 7 subLoss 49249.6 multi 12.94 import weight 0.00
Epoch 106 Iter 8 subLoss 48947.7 multi -4.97 import weight 0.00
Epoch 106 Iter 9 subLoss 48581.1 multi 6.97 import weight 0.00
Epoch 106 Iter 10 subLoss 48723.6 multi 6.97 import weight 0.00
Epoch 106 Iter 11 subLoss 48847.3 multi -1.98 import weight 0.00
Epoch 106 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 4884 train Loss: 49739.7 test Loss: 8363.3
Epoch 107 Iter 0 subLoss 48683.8 multi -1.98 import weight 0.00
Epoch 107 Iter 1 subLoss 48723.3 multi 9.96 import weight 0.00
Epoch 107 Iter 2 subLoss 48791.7 multi -13.93 import weight 0.00
Epoch 107 Iter 3 subLoss 48606.0 multi 1.00 import weight 0.00
Epoch 107 Iter 4 subLoss 48777.4 multi 9.96 import weight 0.00
Epoch 107 Iter 5 subLoss 48590.1 multi 15.93 import weight 0.00
Epoch 107 Iter 6 subLoss 48551.5 multi 12.94 import weight 0.00
Epoch 107 Iter 7 subLoss 48661.1 multi 9.96 import weight 0.00
Epoch 107 Iter 8 subLoss 48503.2 multi 3.99 import weight 0.00
Epoch 107 Iter 9 subLoss 48370.0 multi -1.98 import weight 0.00
Epoch 107 Iter 10 subLoss 48461.2 multi 3.99 import weight 0.00
Epoch 107 Iter 11 subLoss 48465.0 multi 6.97 import weight 0.00
Epoch 107 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 4846 train Loss: 49331.3 test Loss: 8290.5
Epoch 108 Iter 0 subLoss 48353.1 multi 3.98 import weight 0.00
Epoch 108 Iter 1 subLoss 48414.5 multi -7.96 import weight 0.00
Epoch 108 Iter 2 subLoss 48320.1 multi -25.87 import weight 0.00
Epoch 108 Iter 3 subLoss 48392.7 multi -4.97 import weight 0.00
Epoch 108 Iter 4 subLoss 48385.7 multi -1.98 import weight 0.00
Epoch 108 Iter 5 subLoss 48445.5 multi -4.97 import weight 0.00
Epoch 108 Iter 6 subLoss 48590.9 multi 18.91 import weight 0.00
Epoch 108 Iter 7 subLoss 48380.5 multi 1.00 import weight 0.00
Epoch 108 Iter 8 subLoss 48342.4 multi 12.94 import weight 0.00
Epoch 108 Iter 9 subLoss 48411.4 multi -4.97 import weight 0.00
Epoch 108 Iter 10 subLoss 48565.1 multi -16.91 import weight 0.00
Epoch 108 Iter 11 subLoss 48427.4 multi -10.94 import weight 0.00
Epoch 108 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -10.94 Pidx 4842 train Loss: 49494.1 test Loss: 8320.8
Epoch 109 Iter 0 subLoss 48552.0 multi 15.93 import weight 0.00
Epoch 109 Iter 1 subLoss 48486.8 multi 15.93 import weight 0.00
Epoch 109 Iter 2 subLoss 48364.8 multi -10.94 import weight 0.00
Epoch 109 Iter 3 subLoss 48422.5 multi -7.96 import weight 0.00
Epoch 109 Iter 4 subLoss 48339.3 multi -7.96 import weight 0.00
Epoch 109 Iter 5 subLoss 48429.7 multi -4.97 import weight 0.00
Epoch 109 Iter 6 subLoss 48401.1 multi 9.96 import weight 0.00
Epoch 109 Iter 7 subLoss 48442.8 multi -1.98 import weight 0.00
Epoch 109 Iter 8 subLoss 48434.7 multi 3.98 import weight 0.00
Epoch 109 Iter 9 subLoss 48564.4 multi -16.91 import weight 0.00
Epoch 109 Iter 10 subLoss 48450.4 multi -7.96 import weight 0.00
Epoch 109 Iter 11 subLoss 48543.3 multi -4.97 import weight 0.00
Epoch 109 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 4854 train Loss: 49575.2 test Loss: 8334.7
Epoch 110 Iter 0 subLoss 48548.1 multi -1.99 import weight 0.00
Epoch 110 Iter 1 subLoss 48582.4 multi 9.96 import weight 0.00
Epoch 110 Iter 2 subLoss 48554.4 multi 12.94 import weight 0.00
Epoch 110 Iter 3 subLoss 48511.5 multi 9.96 import weight 0.00
Epoch 110 Iter 4 subLoss 48472.1 multi -25.87 import weight 0.00
Epoch 110 Iter 5 subLoss 48693.9 multi -7.96 import weight 0.00
Epoch 110 Iter 6 subLoss 48370.3 multi -1.99 import weight 0.00
Epoch 110 Iter 7 subLoss 48737.8 multi -10.94 import weight 0.00
Epoch 110 Iter 8 subLoss 48721.9 multi 12.94 import weight 0.00
Epoch 110 Iter 9 subLoss 48519.1 multi 12.94 import weight 0.00
Epoch 110 Iter 10 subLoss 48549.1 multi 1.00 import weight 0.00
Epoch 110 Iter 11 subLoss 48418.5 multi -4.97 import weight 0.00
Epoch 110 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 4841 train Loss: 49482.7 test Loss: 8317.5
Epoch 111 Iter 0 subLoss 48521.7 multi -19.90 import weight 0.00
Epoch 111 Iter 1 subLoss 48459.2 multi -4.97 import weight 0.00
Epoch 111 Iter 2 subLoss 48568.3 multi -16.91 import weight 0.00
Epoch 111 Iter 3 subLoss 48889.0 multi 18.91 import weight 0.00
Epoch 111 Iter 4 subLoss 48682.7 multi 1.00 import weight 0.00
Epoch 111 Iter 5 subLoss 48957.7 multi 3.99 import weight 0.00
Epoch 111 Iter 6 subLoss 48660.8 multi 12.94 import weight 0.00
Epoch 111 Iter 7 subLoss 48321.4 multi -22.88 import weight 0.00
Epoch 111 Iter 8 subLoss 48589.7 multi 12.94 import weight 0.00
Epoch 111 Iter 9 subLoss 48355.8 multi 3.99 import weight 0.00
Epoch 111 Iter 10 subLoss 48536.5 multi 3.99 import weight 0.00
Epoch 111 Iter 11 subLoss 48484.1 multi 15.93 import weight 0.00
Epoch 111 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 15.93 Pidx 4848 train Loss: 49311.6 test Loss: 8286.4
Epoch 112 Iter 0 subLoss 48186.8 multi 6.97 import weight 0.00
Epoch 112 Iter 1 subLoss 48489.5 multi 18.91 import weight 0.00
Epoch 112 Iter 2 subLoss 48345.7 multi 12.94 import weight 0.00
Epoch 112 Iter 3 subLoss 48210.0 multi 30.85 import weight 0.00
Epoch 112 Iter 4 subLoss 48308.1 multi -10.94 import weight 0.00
Epoch 112 Iter 5 subLoss 48225.9 multi -22.88 import weight 0.00
Epoch 112 Iter 6 subLoss 48255.5 multi -10.94 import weight 0.00
Epoch 112 Iter 7 subLoss 48267.7 multi 1.00 import weight 0.00
Epoch 112 Iter 8 subLoss 48295.2 multi 6.97 import weight 0.00
Epoch 112 Iter 9 subLoss 48296.5 multi 9.96 import weight 1.00
Epoch 112 Iter 10 subLoss 48192.3 multi 1.00 import weight 0.00
Epoch 112 Iter 11 subLoss 48351.2 multi 3.99 import weight 0.00
Epoch 112 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 4835 train Loss: 49219.3 test Loss: 8267.8
Epoch 113 Iter 0 subLoss 48220.9 multi -19.90 import weight 0.00
Epoch 113 Iter 1 subLoss 48284.0 multi 1.00 import weight 0.00
Epoch 113 Iter 2 subLoss 48297.4 multi 9.96 import weight 1.00
Epoch 113 Iter 3 subLoss 48196.2 multi 3.98 import weight 0.00
Epoch 113 Iter 4 subLoss 48232.5 multi 6.97 import weight 0.00
Epoch 113 Iter 5 subLoss 48278.4 multi -4.97 import weight 0.00
Epoch 113 Iter 6 subLoss 48240.5 multi 30.85 import weight 1.00
Epoch 113 Iter 7 subLoss 48298.6 multi 12.94 import weight 1.00
Epoch 113 Iter 8 subLoss 48273.5 multi -1.99 import weight 0.00
Epoch 113 Iter 9 subLoss 48246.8 multi 33.84 import weight 1.00
Epoch 113 Iter 10 subLoss 48233.1 multi 9.96 import weight 0.00
Epoch 113 Iter 11 subLoss 48252.6 multi -13.93 import weight 0.00
Epoch 113 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -13.93 Pidx 4825 train Loss: 49206.6 test Loss: 8265.1
Epoch 114 Iter 0 subLoss 48293.6 multi 15.93 import weight 1.00
Epoch 114 Iter 1 subLoss 48242.2 multi 33.84 import weight 1.00
Epoch 114 Iter 2 subLoss 48267.0 multi 1.00 import weight 0.00
Epoch 114 Iter 3 subLoss 48261.9 multi 3.99 import weight 0.00
Epoch 114 Iter 4 subLoss 48260.1 multi 6.97 import weight 0.00
Epoch 114 Iter 5 subLoss 48283.2 multi -1.99 import weight 0.00
Epoch 114 Iter 6 subLoss 48282.3 multi 1.00 import weight 0.00
Epoch 114 Iter 7 subLoss 48166.3 multi -1.99 import weight 0.00
Epoch 114 Iter 8 subLoss 48225.3 multi -16.91 import weight 0.00
Epoch 114 Iter 9 subLoss 48243.8 multi 36.82 import weight 1.00
Epoch 114 Iter 10 subLoss 48199.8 multi 6.97 import weight 0.00
Epoch 114 Iter 11 subLoss 48190.7 multi 9.96 import weight 0.00
Epoch 114 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 4819 train Loss: 49158.5 test Loss: 8255.7
Epoch 115 Iter 0 subLoss 48228.5 multi -13.93 import weight 0.00
Epoch 115 Iter 1 subLoss 48263.6 multi 9.96 import weight 0.00
Epoch 115 Iter 2 subLoss 48255.5 multi -16.91 import weight 0.00
Epoch 115 Iter 3 subLoss 48132.3 multi 6.97 import weight 0.00
Epoch 115 Iter 4 subLoss 48299.6 multi 12.94 import weight 1.00
Epoch 115 Iter 5 subLoss 48221.1 multi -10.94 import weight 0.00
Epoch 115 Iter 6 subLoss 48229.7 multi -7.96 import weight 0.00
Epoch 115 Iter 7 subLoss 48221.1 multi -4.97 import weight 0.00
Epoch 115 Iter 8 subLoss 48292.7 multi 15.93 import weight 1.00
Epoch 115 Iter 9 subLoss 48163.3 multi 1.00 import weight 0.00
Epoch 115 Iter 10 subLoss 48271.9 multi -10.94 import weight 0.00
Epoch 115 Iter 11 subLoss 48236.7 multi -1.99 import weight 0.00
Epoch 115 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 4823 train Loss: 49198.0 test Loss: 8264.8
Epoch 116 Iter 0 subLoss 48258.4 multi -13.93 import weight 0.00
Epoch 116 Iter 1 subLoss 48215.5 multi 12.94 import weight 0.00
Epoch 116 Iter 2 subLoss 48256.3 multi -10.94 import weight 0.00
Epoch 116 Iter 3 subLoss 48244.4 multi 36.82 import weight 1.00
Epoch 116 Iter 4 subLoss 48240.9 multi 39.81 import weight 1.00
Epoch 116 Iter 5 subLoss 48252.2 multi -13.93 import weight 0.00
Epoch 116 Iter 6 subLoss 48265.3 multi 1.00 import weight 0.00
Epoch 116 Iter 7 subLoss 48194.9 multi 12.94 import weight 0.00
Epoch 116 Iter 8 subLoss 48215.8 multi 15.93 import weight 0.00
Epoch 116 Iter 9 subLoss 48233.3 multi 1.00 import weight 0.00
Epoch 116 Iter 10 subLoss 48224.7 multi -7.96 import weight 0.00
Epoch 116 Iter 11 subLoss 48216.2 multi 18.91 import weight 0.00
Epoch 116 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 18.91 Pidx 4821 train Loss: 49175.1 test Loss: 8261.2
Epoch 117 Iter 0 subLoss 48190.6 multi 15.93 import weight 0.00
Epoch 117 Iter 1 subLoss 48191.5 multi 18.91 import weight 0.00
Epoch 117 Iter 2 subLoss 48116.4 multi 3.99 import weight 0.00
Epoch 117 Iter 3 subLoss 48095.0 multi 1.00 import weight 0.00
Epoch 117 Iter 4 subLoss 48075.3 multi 1.00 import weight 0.00
Epoch 117 Iter 5 subLoss 48040.2 multi -4.97 import weight 0.00
Epoch 117 Iter 6 subLoss 48035.5 multi 3.98 import weight 0.00
Epoch 117 Iter 7 subLoss 48034.2 multi 6.97 import weight 0.00
Epoch 117 Iter 8 subLoss 47981.9 multi 1.00 import weight 0.00
Epoch 117 Iter 9 subLoss 47952.9 multi -1.99 import weight 0.00
Epoch 117 Iter 10 subLoss 47968.0 multi 1.00 import weight 0.00
Epoch 117 Iter 11 subLoss 48029.4 multi 1.00 import weight 0.00
Epoch 117 Acc: 22.36 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4802 train Loss: 48933.9 test Loss: 8173.6
Epoch 118 Iter 0 subLoss 48013.1 multi -1.98 import weight 0.00
Epoch 118 Iter 1 subLoss 47985.7 multi 3.98 import weight 0.00
Epoch 118 Iter 2 subLoss 47937.1 multi 1.00 import weight 0.00
Epoch 118 Iter 3 subLoss 47959.1 multi 1.00 import weight 0.00
Epoch 118 Iter 4 subLoss 47935.6 multi 3.98 import weight 0.00
Epoch 118 Iter 5 subLoss 47832.4 multi 3.99 import weight 0.00
Epoch 118 Iter 6 subLoss 47809.6 multi 9.96 import weight 0.00
Epoch 118 Iter 7 subLoss 47533.1 multi -1.99 import weight 0.00
Epoch 118 Iter 8 subLoss 47689.6 multi 1.00 import weight 0.00
Epoch 118 Iter 9 subLoss 47625.4 multi 1.00 import weight 0.00
Epoch 118 Iter 10 subLoss 47601.7 multi 6.97 import weight 0.00
Epoch 118 Iter 11 subLoss 47311.9 multi -4.97 import weight 0.00
Epoch 118 Acc: 33.33 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 4731 train Loss: 48504.2 test Loss: 8038.4
Epoch 119 Iter 0 subLoss 47544.3 multi -1.99 import weight 0.00
Epoch 119 Iter 1 subLoss 47650.6 multi -1.99 import weight 0.00
Epoch 119 Iter 2 subLoss 47759.7 multi 1.00 import weight 0.00
Epoch 119 Iter 3 subLoss 47624.2 multi 3.99 import weight 0.00
Epoch 119 Iter 4 subLoss 47463.8 multi 1.00 import weight 0.00
Epoch 119 Iter 5 subLoss 47524.3 multi 1.00 import weight 0.00
Epoch 119 Iter 6 subLoss 47446.5 multi 3.99 import weight 0.00
Epoch 119 Iter 7 subLoss 47313.3 multi -1.98 import weight 0.00
Epoch 119 Iter 8 subLoss 47362.1 multi 1.00 import weight 0.00
Epoch 119 Iter 9 subLoss 47272.6 multi 3.99 import weight 0.00
Epoch 119 Iter 10 subLoss 47048.4 multi 1.00 import weight 0.00
Epoch 119 Iter 11 subLoss 46940.5 multi 1.00 import weight 0.00
Epoch 119 Acc: 29.71 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4694 train Loss: 47783.8 test Loss: 7858.0
Epoch 120 Iter 0 subLoss 46918.0 multi -4.97 import weight 0.00
Epoch 120 Iter 1 subLoss 47183.9 multi 6.97 import weight 0.00
Epoch 120 Iter 2 subLoss 46783.1 multi 1.00 import weight 0.00
Epoch 120 Iter 3 subLoss 46916.9 multi -1.98 import weight 0.00
Epoch 120 Iter 4 subLoss 47029.0 multi 3.99 import weight 0.00
Epoch 120 Iter 5 subLoss 46601.0 multi 3.99 import weight 0.00
Epoch 120 Iter 6 subLoss 46036.8 multi 1.00 import weight 0.00
Epoch 120 Iter 7 subLoss 45612.7 multi 1.00 import weight 0.00
Epoch 120 Iter 8 subLoss 45518.2 multi 1.00 import weight 0.00
Epoch 120 Iter 9 subLoss 44700.0 multi -1.99 import weight 0.00
Epoch 120 Iter 10 subLoss 46204.8 multi 3.99 import weight 0.00
Epoch 120 Iter 11 subLoss 45158.3 multi 1.00 import weight 0.00
Epoch 120 Acc: 30.98 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4515 train Loss: 45634.5 test Loss: 7369.5
Epoch 121 Iter 0 subLoss 44485.2 multi 1.00 import weight 0.00
Epoch 121 Iter 1 subLoss 43944.1 multi 1.00 import weight 0.00
Epoch 121 Iter 2 subLoss 42747.7 multi -1.99 import weight 0.00
Epoch 121 Iter 3 subLoss 45072.0 multi 3.99 import weight 0.00
Epoch 121 Iter 4 subLoss 43087.0 multi 1.00 import weight 0.00
Epoch 121 Iter 5 subLoss 41466.5 multi -1.99 import weight 0.00
Epoch 121 Iter 6 subLoss 44807.8 multi 1.00 import weight 0.00
Epoch 121 Iter 7 subLoss 43927.2 multi 3.99 import weight 0.00
Epoch 121 Iter 8 subLoss 40274.4 multi 1.00 import weight 0.00
Epoch 121 Iter 9 subLoss 38688.9 multi 1.00 import weight 0.00
Epoch 121 Iter 10 subLoss 37642.9 multi 1.00 import weight 0.00
Epoch 121 Iter 11 subLoss 36513.5 multi 1.00 import weight 0.00
Epoch 121 Acc: 62.42 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 3651 train Loss: 36012.7 test Loss: 5182.6
Epoch 122 Iter 0 subLoss 35339.9 multi 1.00 import weight 0.00
Epoch 122 Iter 1 subLoss 34589.7 multi 1.00 import weight 0.00
Epoch 122 Iter 2 subLoss 34373.6 multi 1.00 import weight 0.00
Epoch 122 Iter 3 subLoss 32993.5 multi 1.00 import weight 0.00
Epoch 122 Iter 4 subLoss 33071.4 multi 1.00 import weight 0.00
Epoch 122 Iter 5 subLoss 31950.5 multi 1.00 import weight 0.00
Epoch 122 Iter 6 subLoss 31426.1 multi 1.00 import weight 0.00
Epoch 122 Iter 7 subLoss 30630.5 multi 1.00 import weight 0.00
Epoch 122 Iter 8 subLoss 30125.1 multi 1.00 import weight 0.00
Epoch 122 Iter 9 subLoss 30010.1 multi 1.00 import weight 0.00
Epoch 122 Iter 10 subLoss 30867.8 multi 1.00 import weight 0.00
Epoch 122 Iter 11 subLoss 30292.0 multi 1.00 import weight 0.00
Epoch 122 Acc: 73.71 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 3029 train Loss: 31286.0 test Loss: 4078.0
Epoch 123 Iter 0 subLoss 30451.0 multi 1.00 import weight 0.00
Epoch 123 Iter 1 subLoss 34805.9 multi 1.00 import weight 0.00
Epoch 123 Iter 2 subLoss 29190.0 multi 1.00 import weight 0.00
Epoch 123 Iter 3 subLoss 29302.8 multi 1.00 import weight 0.00
Epoch 123 Iter 4 subLoss 27833.8 multi 1.00 import weight 0.00
Epoch 123 Iter 5 subLoss 27261.6 multi 1.00 import weight 0.00
Epoch 123 Iter 6 subLoss 28455.7 multi 1.00 import weight 0.00
Epoch 123 Iter 7 subLoss 30077.8 multi 1.00 import weight 0.00
Epoch 123 Iter 8 subLoss 28517.2 multi 1.00 import weight 0.00
Epoch 123 Iter 9 subLoss 27057.3 multi 1.00 import weight 0.00
Epoch 123 Iter 10 subLoss 25930.5 multi 1.00 import weight 0.00
Epoch 123 Iter 11 subLoss 26517.3 multi 1.00 import weight 0.00
Epoch 123 Acc: 86.22 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2651 train Loss: 25738.7 test Loss: 3229.6
Epoch 124 Iter 0 subLoss 25890.7 multi 1.00 import weight 0.00
Epoch 124 Iter 1 subLoss 25490.5 multi 1.00 import weight 0.00
Epoch 124 Iter 2 subLoss 25956.5 multi 1.00 import weight 0.00
Epoch 124 Iter 3 subLoss 27510.7 multi 1.00 import weight 0.00
Epoch 124 Iter 4 subLoss 26365.2 multi 1.00 import weight 0.00
Epoch 124 Iter 5 subLoss 26966.5 multi 1.00 import weight 0.00
Epoch 124 Iter 6 subLoss 23821.1 multi 1.00 import weight 0.00
Epoch 124 Iter 7 subLoss 22774.8 multi 1.00 import weight 0.00
Epoch 124 Iter 8 subLoss 22197.1 multi 1.00 import weight 0.00
Epoch 124 Iter 9 subLoss 21305.3 multi 1.00 import weight 0.00
Epoch 124 Iter 10 subLoss 21925.5 multi 1.00 import weight 0.00
Epoch 124 Iter 11 subLoss 23136.9 multi 1.00 import weight 0.00
Epoch 124 Acc: 87.53 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2313 train Loss: 24017.9 test Loss: 2793.3
Epoch 125 Iter 0 subLoss 23745.3 multi 1.00 import weight 0.00
Epoch 125 Iter 1 subLoss 29876.4 multi 1.00 import weight 0.00
Epoch 125 Iter 2 subLoss 22824.8 multi 1.00 import weight 0.00
Epoch 125 Iter 3 subLoss 22303.6 multi 1.00 import weight 0.00
Epoch 125 Iter 4 subLoss 20083.4 multi 1.00 import weight 0.00
Epoch 125 Iter 5 subLoss 20478.3 multi 1.00 import weight 0.00
Epoch 125 Iter 6 subLoss 20800.4 multi 1.00 import weight 0.00
Epoch 125 Iter 7 subLoss 21501.7 multi 1.00 import weight 0.00
Epoch 125 Iter 8 subLoss 20331.8 multi 1.00 import weight 0.00
Epoch 125 Iter 9 subLoss 22609.5 multi 1.00 import weight 0.00
Epoch 125 Iter 10 subLoss 20300.5 multi 1.00 import weight 0.00
Epoch 125 Iter 11 subLoss 21867.2 multi 1.00 import weight 0.00
Epoch 125 Acc: 90.33 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2186 train Loss: 19397.6 test Loss: 2031.8
Epoch 126 Iter 0 subLoss 18609.7 multi 1.00 import weight 0.00
Epoch 126 Iter 1 subLoss 18880.2 multi 1.00 import weight 0.00
Epoch 126 Iter 2 subLoss 18504.6 multi 1.00 import weight 0.00
Epoch 126 Iter 3 subLoss 18871.6 multi 1.00 import weight 0.00
Epoch 126 Iter 4 subLoss 17169.9 multi 1.00 import weight 0.00
Epoch 126 Iter 5 subLoss 18397.8 multi 1.00 import weight 0.00
Epoch 126 Iter 6 subLoss 17367.5 multi 1.00 import weight 0.00
Epoch 126 Iter 7 subLoss 19385.6 multi 1.00 import weight 0.00
Epoch 126 Iter 8 subLoss 16872.8 multi 1.00 import weight 0.00
Epoch 126 Iter 9 subLoss 18028.6 multi 1.00 import weight 0.00
Epoch 126 Iter 10 subLoss 17871.6 multi 1.00 import weight 0.00
Epoch 126 Iter 11 subLoss 17651.9 multi 1.00 import weight 0.00
Epoch 126 Acc: 86.26 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1765 train Loss: 16087.9 test Loss: 2062.3
Epoch 127 Iter 0 subLoss 15571.0 multi 1.00 import weight 0.00
Epoch 127 Iter 1 subLoss 14472.7 multi 1.00 import weight 0.00
Epoch 127 Iter 2 subLoss 14134.1 multi 1.00 import weight 0.00
Epoch 127 Iter 3 subLoss 13791.7 multi 1.00 import weight 0.00
Epoch 127 Iter 4 subLoss 12918.6 multi 1.00 import weight 0.00
Epoch 127 Iter 5 subLoss 14394.1 multi 1.00 import weight 0.00
Epoch 127 Iter 6 subLoss 16011.7 multi 1.00 import weight 0.00
Epoch 127 Iter 7 subLoss 25717.6 multi 1.00 import weight 0.00
Epoch 127 Iter 8 subLoss 26566.8 multi 1.00 import weight 0.00
Epoch 127 Iter 9 subLoss 35158.5 multi 1.00 import weight 0.00
Epoch 127 Iter 10 subLoss 17726.8 multi 1.00 import weight 0.00
Epoch 127 Iter 11 subLoss 14530.5 multi 1.00 import weight 0.00
Epoch 127 Acc: 93.29 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1453 train Loss: 13807.7 test Loss: 1458.9
Epoch 128 Iter 0 subLoss 13138.2 multi 1.00 import weight 0.00
Epoch 128 Iter 1 subLoss 13445.6 multi 1.00 import weight 0.00
Epoch 128 Iter 2 subLoss 12514.3 multi 1.00 import weight 0.00
Epoch 128 Iter 3 subLoss 11458.7 multi 1.00 import weight 0.00
Epoch 128 Iter 4 subLoss 10902.1 multi 1.00 import weight 0.00
Epoch 128 Iter 5 subLoss 9996.8 multi 1.00 import weight 0.00
Epoch 128 Iter 6 subLoss 10733.4 multi 1.00 import weight 0.00
Epoch 128 Iter 7 subLoss 10119.7 multi 1.00 import weight 0.00
Epoch 128 Iter 8 subLoss 10030.7 multi 1.00 import weight 0.00
Epoch 128 Iter 9 subLoss 10910.3 multi -1.99 import weight 0.00
Epoch 128 Iter 10 subLoss 18693.0 multi 1.00 import weight 0.00
Epoch 128 Iter 11 subLoss 21512.8 multi -1.99 import weight 0.00
Epoch 128 Acc: 22.57 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 2151 train Loss: 454751.1 test Loss: 77926.0
Epoch 129 Iter 0 subLoss 448521.8 multi 1.00 import weight 0.00
Epoch 129 Iter 1 subLoss 48689.2 multi 3.99 import weight 0.00
Epoch 129 Iter 2 subLoss 45095.5 multi 1.00 import weight 0.00
Epoch 129 Iter 3 subLoss 43993.5 multi 1.00 import weight 0.00
Epoch 129 Iter 4 subLoss 43081.1 multi 3.99 import weight 0.00
Epoch 129 Iter 5 subLoss 41479.5 multi -1.99 import weight 0.00
Epoch 129 Iter 6 subLoss 49547.5 multi -1.99 import weight 0.00
Epoch 129 Iter 7 subLoss 161137.6 multi 1.00 import weight 0.00
Epoch 129 Iter 8 subLoss 47344.1 multi 1.00 import weight 0.00
Epoch 129 Iter 9 subLoss 46314.1 multi -4.97 import weight 0.00
Epoch 129 Iter 10 subLoss 48659.4 multi -1.99 import weight 0.00
Epoch 129 Iter 11 subLoss 49344.5 multi 3.99 import weight 0.00
Epoch 129 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 4934 train Loss: 49116.4 test Loss: 8024.3
Epoch 130 Iter 0 subLoss 48078.2 multi 3.98 import weight 0.00
Epoch 130 Iter 1 subLoss 47346.4 multi 3.99 import weight 0.00
Epoch 130 Iter 2 subLoss 46529.7 multi 1.00 import weight 0.00
Epoch 130 Iter 3 subLoss 46370.9 multi 1.00 import weight 0.00
Epoch 130 Iter 4 subLoss 45681.1 multi 3.99 import weight 0.00
Epoch 130 Iter 5 subLoss 44007.9 multi -1.99 import weight 0.00
Epoch 130 Iter 6 subLoss 45518.4 multi 3.99 import weight 0.00
Epoch 130 Iter 7 subLoss 43319.6 multi 1.00 import weight 0.00
Epoch 130 Iter 8 subLoss 42345.8 multi 1.00 import weight 0.00
Epoch 130 Iter 9 subLoss 41841.0 multi 3.99 import weight 0.00
Epoch 130 Iter 10 subLoss 39828.8 multi 6.97 import weight 0.00
Epoch 130 Iter 11 subLoss 34892.7 multi 1.00 import weight 0.00
Epoch 130 Acc: 65.95 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 3489 train Loss: 34303.9 test Loss: 4793.2
Epoch 131 Iter 0 subLoss 33620.5 multi 1.00 import weight 0.00
Epoch 131 Iter 1 subLoss 32546.0 multi 1.00 import weight 0.00
Epoch 131 Iter 2 subLoss 31988.4 multi 1.00 import weight 0.00
Epoch 131 Iter 3 subLoss 31979.1 multi 1.00 import weight 0.00
Epoch 131 Iter 4 subLoss 30399.4 multi 1.00 import weight 0.00
Epoch 131 Iter 5 subLoss 29842.2 multi 1.00 import weight 0.00
Epoch 131 Iter 6 subLoss 29158.5 multi 1.00 import weight 0.00
Epoch 131 Iter 7 subLoss 28579.2 multi 1.00 import weight 0.00
Epoch 131 Iter 8 subLoss 27879.5 multi 1.00 import weight 0.00
Epoch 131 Iter 9 subLoss 26688.6 multi 1.00 import weight 0.00
Epoch 131 Iter 10 subLoss 25107.1 multi 1.00 import weight 0.00
Epoch 131 Iter 11 subLoss 25876.0 multi 1.00 import weight 0.00
Epoch 131 Acc: 74.78 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2587 train Loss: 24922.8 test Loss: 3153.7
Epoch 132 Iter 0 subLoss 25517.2 multi 1.00 import weight 0.00
Epoch 132 Iter 1 subLoss 23308.3 multi 1.00 import weight 0.00
Epoch 132 Iter 2 subLoss 22646.8 multi 1.00 import weight 0.00
Epoch 132 Iter 3 subLoss 22133.6 multi 1.00 import weight 0.00
Epoch 132 Iter 4 subLoss 22143.6 multi -1.99 import weight 0.00
Epoch 132 Iter 5 subLoss 23000.0 multi 1.00 import weight 0.00
Epoch 132 Iter 6 subLoss 21310.9 multi -1.99 import weight 0.00
Epoch 132 Iter 7 subLoss 24463.2 multi 1.00 import weight 0.00
Epoch 132 Iter 8 subLoss 22861.9 multi 1.00 import weight 0.00
Epoch 132 Iter 9 subLoss 22306.4 multi 3.99 import weight 0.00
Epoch 132 Iter 10 subLoss 20228.5 multi 1.00 import weight 0.00
Epoch 132 Iter 11 subLoss 20136.9 multi 1.00 import weight 0.00
Epoch 132 Acc: 87.43 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2013 train Loss: 19077.2 test Loss: 1985.5
Epoch 133 Iter 0 subLoss 19100.7 multi 1.00 import weight 0.00
Epoch 133 Iter 1 subLoss 18503.8 multi 3.99 import weight 0.00
Epoch 133 Iter 2 subLoss 16850.1 multi 1.00 import weight 0.00
Epoch 133 Iter 3 subLoss 16718.1 multi 1.00 import weight 0.00
Epoch 133 Iter 4 subLoss 15830.7 multi 1.00 import weight 0.00
Epoch 133 Iter 5 subLoss 15739.0 multi 1.00 import weight 0.00
Epoch 133 Iter 6 subLoss 14970.2 multi 1.00 import weight 0.00
Epoch 133 Iter 7 subLoss 15456.3 multi 1.00 import weight 0.00
Epoch 133 Iter 8 subLoss 16208.2 multi 1.00 import weight 0.00
Epoch 133 Iter 9 subLoss 16580.2 multi 1.00 import weight 0.00
Epoch 133 Iter 10 subLoss 18919.1 multi 1.00 import weight 0.00
Epoch 133 Iter 11 subLoss 25993.8 multi 1.00 import weight 0.00
Epoch 133 Acc: 75.31 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2599 train Loss: 26891.3 test Loss: 3407.7
Epoch 134 Iter 0 subLoss 25001.3 multi 1.00 import weight 0.00
Epoch 134 Iter 1 subLoss 24225.0 multi 1.00 import weight 0.00
Epoch 134 Iter 2 subLoss 17403.2 multi 1.00 import weight 0.00
Epoch 134 Iter 3 subLoss 15551.1 multi 1.00 import weight 0.00
Epoch 134 Iter 4 subLoss 15303.0 multi 1.00 import weight 0.00
Epoch 134 Iter 5 subLoss 14980.7 multi -1.99 import weight 0.00
Epoch 134 Iter 6 subLoss 17656.9 multi 3.99 import weight 0.00
Epoch 134 Iter 7 subLoss 77649.1 multi 1.00 import weight 0.00
Epoch 134 Iter 8 subLoss 37606.5 multi 1.00 import weight 0.00
Epoch 134 Iter 9 subLoss 31570.8 multi 1.00 import weight 0.00
Epoch 134 Iter 10 subLoss 28735.8 multi 1.00 import weight 0.00
Epoch 134 Iter 11 subLoss 27388.7 multi 1.00 import weight 0.00
Epoch 134 Acc: 73.65 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2738 train Loss: 27107.5 test Loss: 3743.2
Epoch 135 Iter 0 subLoss 26409.5 multi 1.00 import weight 0.00
Epoch 135 Iter 1 subLoss 25533.9 multi 1.00 import weight 0.00
Epoch 135 Iter 2 subLoss 24769.1 multi 1.00 import weight 0.00
Epoch 135 Iter 3 subLoss 23035.8 multi 1.00 import weight 0.00
Epoch 135 Iter 4 subLoss 22190.1 multi 3.99 import weight 0.00
Epoch 135 Iter 5 subLoss 18606.2 multi 3.99 import weight 0.00
Epoch 135 Iter 6 subLoss 15172.2 multi 1.00 import weight 0.00
Epoch 135 Iter 7 subLoss 15068.4 multi 1.00 import weight 0.00
Epoch 135 Iter 8 subLoss 14952.1 multi 1.00 import weight 0.00
Epoch 135 Iter 9 subLoss 14394.0 multi 3.99 import weight 0.00
Epoch 135 Iter 10 subLoss 13767.0 multi 1.00 import weight 0.00
Epoch 135 Iter 11 subLoss 12783.2 multi 1.00 import weight 0.00
Epoch 135 Acc: 91.75 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1278 train Loss: 12972.1 test Loss: 1421.7
Epoch 136 Iter 0 subLoss 12666.0 multi 1.00 import weight 0.00
Epoch 136 Iter 1 subLoss 12158.7 multi 1.00 import weight 0.00
Epoch 136 Iter 2 subLoss 11714.0 multi 1.00 import weight 0.00
Epoch 136 Iter 3 subLoss 11705.7 multi 1.00 import weight 0.00
Epoch 136 Iter 4 subLoss 12325.3 multi 1.00 import weight 0.00
Epoch 136 Iter 5 subLoss 11522.3 multi 1.00 import weight 0.00
Epoch 136 Iter 6 subLoss 12344.5 multi 1.00 import weight 0.00
Epoch 136 Iter 7 subLoss 11658.7 multi 1.00 import weight 0.00
Epoch 136 Iter 8 subLoss 12243.2 multi 1.00 import weight 0.00
Epoch 136 Iter 9 subLoss 11397.4 multi 1.00 import weight 0.00
Epoch 136 Iter 10 subLoss 11010.3 multi 1.00 import weight 0.00
Epoch 136 Iter 11 subLoss 11417.0 multi 1.00 import weight 0.00
Epoch 136 Acc: 91.94 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1141 train Loss: 11461.5 test Loss: 1278.6
Epoch 137 Iter 0 subLoss 11828.7 multi 1.00 import weight 0.00
Epoch 137 Iter 1 subLoss 10970.1 multi 1.00 import weight 0.00
Epoch 137 Iter 2 subLoss 12113.5 multi 1.00 import weight 0.00
Epoch 137 Iter 3 subLoss 11755.2 multi 1.00 import weight 0.00
Epoch 137 Iter 4 subLoss 12243.2 multi 3.99 import weight 0.00
Epoch 137 Iter 5 subLoss 123957.5 multi 1.00 import weight 0.00
Epoch 137 Iter 6 subLoss 35942.7 multi 1.00 import weight 0.00
Epoch 137 Iter 7 subLoss 21847.1 multi 1.00 import weight 0.00
Epoch 137 Iter 8 subLoss 19039.4 multi 1.00 import weight 0.00
Epoch 137 Iter 9 subLoss 17643.4 multi 1.00 import weight 0.00
Epoch 137 Iter 10 subLoss 16510.6 multi 1.00 import weight 0.00
Epoch 137 Iter 11 subLoss 15624.7 multi 1.00 import weight 0.00
Epoch 137 Acc: 84.00 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1562 train Loss: 15250.3 test Loss: 1893.1
Epoch 138 Iter 0 subLoss 14557.3 multi 1.00 import weight 0.00
Epoch 138 Iter 1 subLoss 14899.8 multi 1.00 import weight 0.00
Epoch 138 Iter 2 subLoss 13664.0 multi 1.00 import weight 0.00
Epoch 138 Iter 3 subLoss 12691.6 multi 1.00 import weight 0.00
Epoch 138 Iter 4 subLoss 12224.8 multi 1.00 import weight 0.00
Epoch 138 Iter 5 subLoss 11544.9 multi 1.00 import weight 0.00
Epoch 138 Iter 6 subLoss 11674.9 multi 1.00 import weight 0.00
Epoch 138 Iter 7 subLoss 10958.8 multi 1.00 import weight 0.00
Epoch 138 Iter 8 subLoss 10011.5 multi 1.00 import weight 0.00
Epoch 138 Iter 9 subLoss 10895.4 multi 1.00 import weight 0.00
Epoch 138 Iter 10 subLoss 10109.1 multi 1.00 import weight 0.00
Epoch 138 Iter 11 subLoss 9675.0 multi 1.00 import weight 0.00
Epoch 138 Acc: 94.38 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 967 train Loss: 9778.0 test Loss: 1089.1
Epoch 139 Iter 0 subLoss 8791.7 multi 1.00 import weight 0.00
Epoch 139 Iter 1 subLoss 10177.6 multi 1.00 import weight 0.00
Epoch 139 Iter 2 subLoss 8860.3 multi 1.00 import weight 0.00
Epoch 139 Iter 3 subLoss 9618.8 multi 1.00 import weight 0.00
Epoch 139 Iter 4 subLoss 10037.2 multi 3.99 import weight 0.00
Epoch 139 Iter 5 subLoss 11295.3 multi 1.00 import weight 0.00
Epoch 139 Iter 6 subLoss 9170.0 multi 1.00 import weight 0.00
Epoch 139 Iter 7 subLoss 8984.0 multi 1.00 import weight 0.00
Epoch 139 Iter 8 subLoss 8513.1 multi 1.00 import weight 0.00
Epoch 139 Iter 9 subLoss 8450.8 multi 1.00 import weight 0.00
Epoch 139 Iter 10 subLoss 8420.2 multi 1.00 import weight 0.00
Epoch 139 Iter 11 subLoss 8016.2 multi 1.00 import weight 0.00
Epoch 139 Acc: 95.17 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 801 train Loss: 8163.1 test Loss: 889.0
Epoch 140 Iter 0 subLoss 8083.8 multi 1.00 import weight 0.00
Epoch 140 Iter 1 subLoss 8600.5 multi 1.00 import weight 0.00
Epoch 140 Iter 2 subLoss 7765.6 multi 1.00 import weight 0.00
Epoch 140 Iter 3 subLoss 7290.0 multi 1.00 import weight 0.00
Epoch 140 Iter 4 subLoss 7434.1 multi 1.00 import weight 0.00
Epoch 140 Iter 5 subLoss 7222.4 multi 1.00 import weight 0.00
Epoch 140 Iter 6 subLoss 7896.9 multi 1.00 import weight 0.00
Epoch 140 Iter 7 subLoss 7378.7 multi 1.00 import weight 0.00
Epoch 140 Iter 8 subLoss 8061.7 multi 1.00 import weight 0.00
Epoch 140 Iter 9 subLoss 7161.2 multi 1.00 import weight 0.00
Epoch 140 Iter 10 subLoss 7634.2 multi 1.00 import weight 0.00
Epoch 140 Iter 11 subLoss 7719.0 multi 1.00 import weight 0.00
Epoch 140 Acc: 95.15 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 771 train Loss: 7526.9 test Loss: 841.5
Epoch 141 Iter 0 subLoss 7469.4 multi 1.00 import weight 0.00
Epoch 141 Iter 1 subLoss 7171.0 multi -1.99 import weight 0.00
Epoch 141 Iter 2 subLoss 25313.4 multi 1.00 import weight 0.00
Epoch 141 Iter 3 subLoss 59099.9 multi 1.00 import weight 0.00
Epoch 141 Iter 4 subLoss 37622.9 multi 1.00 import weight 0.00
Epoch 141 Iter 5 subLoss 15229.4 multi 1.00 import weight 0.00
Epoch 141 Iter 6 subLoss 11939.6 multi 1.00 import weight 0.00
Epoch 141 Iter 7 subLoss 10921.0 multi -1.99 import weight 0.00
Epoch 141 Iter 8 subLoss 13765.1 multi 3.99 import weight 0.00
Epoch 141 Iter 9 subLoss 9626.6 multi -1.99 import weight 0.00
Epoch 141 Iter 10 subLoss 13234.5 multi 1.00 import weight 0.00
Epoch 141 Iter 11 subLoss 9699.7 multi 1.00 import weight 0.00
Epoch 141 Acc: 93.99 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 969 train Loss: 9752.8 test Loss: 1094.8
Epoch 142 Iter 0 subLoss 8983.9 multi 3.99 import weight 0.00
Epoch 142 Iter 1 subLoss 8249.7 multi 1.00 import weight 0.00
Epoch 142 Iter 2 subLoss 8519.0 multi 3.99 import weight 0.00
Epoch 142 Iter 3 subLoss 8681.2 multi 1.00 import weight 0.00
Epoch 142 Iter 4 subLoss 7610.5 multi 1.00 import weight 0.00
Epoch 142 Iter 5 subLoss 7705.4 multi 1.00 import weight 0.00
Epoch 142 Iter 6 subLoss 7387.7 multi -1.99 import weight 0.00
Epoch 142 Iter 7 subLoss 7428.2 multi 1.00 import weight 0.00
Epoch 142 Iter 8 subLoss 7387.9 multi 1.00 import weight 0.00
Epoch 142 Iter 9 subLoss 7441.7 multi -1.99 import weight 0.00
Epoch 142 Iter 10 subLoss 8171.8 multi 1.00 import weight 0.00
Epoch 142 Iter 11 subLoss 7945.8 multi 1.00 import weight 0.00
Epoch 142 Acc: 95.31 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 794 train Loss: 7618.4 test Loss: 826.6
Epoch 143 Iter 0 subLoss 7735.4 multi 1.00 import weight 0.00
Epoch 143 Iter 1 subLoss 7323.6 multi 1.00 import weight 0.00
Epoch 143 Iter 2 subLoss 7480.6 multi 1.00 import weight 0.00
Epoch 143 Iter 3 subLoss 6715.4 multi 1.00 import weight 0.00
Epoch 143 Iter 4 subLoss 6908.1 multi 1.00 import weight 0.00
Epoch 143 Iter 5 subLoss 6815.1 multi 1.00 import weight 0.00
Epoch 143 Iter 6 subLoss 7404.7 multi 1.00 import weight 0.00
Epoch 143 Iter 7 subLoss 7118.8 multi 1.00 import weight 0.00
Epoch 143 Iter 8 subLoss 7210.8 multi 1.00 import weight 0.00
Epoch 143 Iter 9 subLoss 6369.7 multi 1.00 import weight 0.00
Epoch 143 Iter 10 subLoss 6953.9 multi 1.00 import weight 0.00
Epoch 143 Iter 11 subLoss 6397.7 multi 1.00 import weight 0.00
Epoch 143 Acc: 96.11 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 639 train Loss: 6656.2 test Loss: 708.7
Epoch 144 Iter 0 subLoss 6269.9 multi 1.00 import weight 0.00
Epoch 144 Iter 1 subLoss 6081.8 multi 1.00 import weight 0.00
Epoch 144 Iter 2 subLoss 6536.9 multi 1.00 import weight 0.00
Epoch 144 Iter 3 subLoss 6314.4 multi 1.00 import weight 0.00
Epoch 144 Iter 4 subLoss 6346.4 multi 1.00 import weight 0.00
Epoch 144 Iter 5 subLoss 7174.1 multi 1.00 import weight 0.00
Epoch 144 Iter 6 subLoss 6747.8 multi 1.00 import weight 0.00
Epoch 144 Iter 7 subLoss 6422.4 multi 1.00 import weight 0.00
Epoch 144 Iter 8 subLoss 6292.7 multi 1.00 import weight 0.00
Epoch 144 Iter 9 subLoss 6283.0 multi 1.00 import weight 0.00
Epoch 144 Iter 10 subLoss 6008.5 multi 1.00 import weight 0.00
Epoch 144 Iter 11 subLoss 5689.4 multi 1.00 import weight 0.00
Epoch 144 Acc: 96.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 568 train Loss: 6203.6 test Loss: 673.9
Epoch 145 Iter 0 subLoss 6306.1 multi -1.99 import weight 0.00
Epoch 145 Iter 1 subLoss 6710.9 multi 3.99 import weight 0.00
Epoch 145 Iter 2 subLoss 31257.2 multi 1.00 import weight 0.00
Epoch 145 Iter 3 subLoss 19791.1 multi 1.00 import weight 0.00
Epoch 145 Iter 4 subLoss 13928.5 multi 1.00 import weight 0.00
Epoch 145 Iter 5 subLoss 6988.0 multi 1.00 import weight 0.00
Epoch 145 Iter 6 subLoss 6760.8 multi 1.00 import weight 0.00
Epoch 145 Iter 7 subLoss 6607.0 multi 1.00 import weight 0.00
Epoch 145 Iter 8 subLoss 7246.3 multi 1.00 import weight 0.00
Epoch 145 Iter 9 subLoss 6088.7 multi 3.99 import weight 0.00
Epoch 145 Iter 10 subLoss 6430.2 multi -1.99 import weight 0.00
Epoch 145 Iter 11 subLoss 8501.4 multi 1.00 import weight 0.00
Epoch 145 Acc: 94.88 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 850 train Loss: 7082.0 test Loss: 775.5
Epoch 146 Iter 0 subLoss 6890.0 multi 1.00 import weight 0.00
Epoch 146 Iter 1 subLoss 7315.1 multi 1.00 import weight 0.00
Epoch 146 Iter 2 subLoss 6474.1 multi 1.00 import weight 0.00
Epoch 146 Iter 3 subLoss 6238.7 multi 1.00 import weight 0.00
Epoch 146 Iter 4 subLoss 5721.9 multi 1.00 import weight 0.00
Epoch 146 Iter 5 subLoss 6096.3 multi -4.97 import weight 0.00
Epoch 146 Iter 6 subLoss 6833.3 multi 1.00 import weight 0.00
Epoch 146 Iter 7 subLoss 6554.8 multi 1.00 import weight 0.00
Epoch 146 Iter 8 subLoss 5409.4 multi 1.00 import weight 0.00
Epoch 146 Iter 9 subLoss 5971.7 multi 1.00 import weight 0.00
Epoch 146 Iter 10 subLoss 5891.5 multi 1.00 import weight 0.00
Epoch 146 Iter 11 subLoss 5912.5 multi 1.00 import weight 0.00
Epoch 146 Acc: 96.34 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 591 train Loss: 6051.9 test Loss: 647.6
Epoch 147 Iter 0 subLoss 6138.8 multi 1.00 import weight 0.00
Epoch 147 Iter 1 subLoss 5616.8 multi 1.00 import weight 0.00
Epoch 147 Iter 2 subLoss 5935.7 multi 1.00 import weight 0.00
Epoch 147 Iter 3 subLoss 6094.7 multi -1.98 import weight 0.00
Epoch 147 Iter 4 subLoss 6520.7 multi 1.00 import weight 0.00
Epoch 147 Iter 5 subLoss 6727.1 multi -4.97 import weight 0.00
Epoch 147 Iter 6 subLoss 24910.3 multi 1.00 import weight 0.00
Epoch 147 Iter 7 subLoss 23881.5 multi 1.00 import weight 0.00
Epoch 147 Iter 8 subLoss 8092.1 multi -1.99 import weight 0.00
Epoch 147 Iter 9 subLoss 20549.4 multi 1.00 import weight 0.00
Epoch 147 Iter 10 subLoss 15638.9 multi -1.99 import weight 0.00
Epoch 147 Iter 11 subLoss 100496.7 multi 1.00 import weight 0.00
Epoch 147 Acc: 67.27 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 10049 train Loss: 28444.2 test Loss: 3855.2
Epoch 148 Iter 0 subLoss 28429.0 multi 1.00 import weight 0.00
Epoch 148 Iter 1 subLoss 18434.4 multi 1.00 import weight 0.00
Epoch 148 Iter 2 subLoss 16319.4 multi 1.00 import weight 0.00
Epoch 148 Iter 3 subLoss 14124.8 multi 1.00 import weight 0.00
Epoch 148 Iter 4 subLoss 12906.2 multi 1.00 import weight 0.00
Epoch 148 Iter 5 subLoss 12988.8 multi 1.00 import weight 0.00
Epoch 148 Iter 6 subLoss 12250.5 multi -4.97 import weight 0.00
Epoch 148 Iter 7 subLoss 16019.6 multi 3.99 import weight 0.00
Epoch 148 Iter 8 subLoss 12494.7 multi 1.00 import weight 0.00
Epoch 148 Iter 9 subLoss 11062.4 multi 1.00 import weight 0.00
Epoch 148 Iter 10 subLoss 10126.5 multi -1.99 import weight 0.00
Epoch 148 Iter 11 subLoss 11979.2 multi 1.00 import weight 0.00
Epoch 148 Acc: 92.00 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1197 train Loss: 11293.3 test Loss: 1429.2
Epoch 149 Iter 0 subLoss 10688.6 multi 1.00 import weight 0.00
Epoch 149 Iter 1 subLoss 11010.8 multi 3.99 import weight 0.00
Epoch 149 Iter 2 subLoss 8652.1 multi 1.00 import weight 0.00
Epoch 149 Iter 3 subLoss 8139.8 multi 1.00 import weight 0.00
Epoch 149 Iter 4 subLoss 7503.5 multi 1.00 import weight 0.00
Epoch 149 Iter 5 subLoss 7047.3 multi 1.00 import weight 0.00
Epoch 149 Iter 6 subLoss 7591.9 multi 1.00 import weight 0.00
Epoch 149 Iter 7 subLoss 7290.1 multi -1.99 import weight 0.00
Epoch 149 Iter 8 subLoss 6990.8 multi -1.99 import weight 0.00
Epoch 149 Iter 9 subLoss 8136.4 multi 3.99 import weight 0.00
Epoch 149 Iter 10 subLoss 8531.2 multi 1.00 import weight 0.00
Epoch 149 Iter 11 subLoss 7633.2 multi 3.99 import weight 0.00
Epoch 149 Acc: 95.82 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 763 train Loss: 7245.1 test Loss: 826.3
Epoch 150 Iter 0 subLoss 7165.2 multi 3.99 import weight 0.00
Epoch 150 Iter 1 subLoss 9448.5 multi 1.00 import weight 0.00
Epoch 150 Iter 2 subLoss 5752.3 multi 1.00 import weight 0.00
Epoch 150 Iter 3 subLoss 5888.3 multi 1.00 import weight 0.00
Epoch 150 Iter 4 subLoss 6018.4 multi -1.99 import weight 0.00
Epoch 150 Iter 5 subLoss 5800.8 multi 1.00 import weight 0.00
Epoch 150 Iter 6 subLoss 5980.1 multi -1.99 import weight 0.00
Epoch 150 Iter 7 subLoss 6664.8 multi 1.00 import weight 0.00
Epoch 150 Iter 8 subLoss 6153.4 multi 1.00 import weight 0.00
Epoch 150 Iter 9 subLoss 6326.0 multi -1.99 import weight 0.00
Epoch 150 Iter 10 subLoss 6372.5 multi -1.99 import weight 0.00
Epoch 150 Iter 11 subLoss 6848.4 multi -1.99 import weight 0.00
Epoch 150 Acc: 94.05 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 684 train Loss: 7541.5 test Loss: 952.3
Epoch 151 Iter 0 subLoss 7299.3 multi 1.00 import weight 0.00
Epoch 151 Iter 1 subLoss 6562.0 multi -1.99 import weight 0.00
Epoch 151 Iter 2 subLoss 7381.2 multi 3.98 import weight 0.00
Epoch 151 Iter 3 subLoss 9557.5 multi 1.00 import weight 0.00
Epoch 151 Iter 4 subLoss 6701.8 multi 1.00 import weight 0.00
Epoch 151 Iter 5 subLoss 5700.4 multi 1.00 import weight 0.00
Epoch 151 Iter 6 subLoss 6013.3 multi 1.00 import weight 0.00
Epoch 151 Iter 7 subLoss 6347.2 multi 3.99 import weight 0.00
Epoch 151 Iter 8 subLoss 6252.1 multi 1.00 import weight 0.00
Epoch 151 Iter 9 subLoss 6499.0 multi 1.00 import weight 0.00
Epoch 151 Iter 10 subLoss 6336.7 multi -1.99 import weight 0.00
Epoch 151 Iter 11 subLoss 6153.0 multi 3.99 import weight 0.00
Epoch 151 Acc: 95.66 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 615 train Loss: 7413.0 test Loss: 764.7
Epoch 152 Iter 0 subLoss 7257.3 multi -1.99 import weight 0.00
Epoch 152 Iter 1 subLoss 27972.3 multi 1.00 import weight 0.00
Epoch 152 Iter 2 subLoss 17482.0 multi 1.00 import weight 0.00
Epoch 152 Iter 3 subLoss 7085.1 multi 1.00 import weight 0.00
Epoch 152 Iter 4 subLoss 6672.8 multi -1.99 import weight 0.00
Epoch 152 Iter 5 subLoss 6983.1 multi 3.99 import weight 0.00
Epoch 152 Iter 6 subLoss 7367.0 multi 1.00 import weight 0.00
Epoch 152 Iter 7 subLoss 6475.1 multi 3.99 import weight 0.00
Epoch 152 Iter 8 subLoss 6610.7 multi -1.99 import weight 0.00
Epoch 152 Iter 9 subLoss 8160.0 multi 1.00 import weight 0.00
Epoch 152 Iter 10 subLoss 6322.4 multi 1.00 import weight 0.00
Epoch 152 Iter 11 subLoss 6151.5 multi 6.97 import weight 0.00
Epoch 152 Acc: 92.18 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 615 train Loss: 8974.9 test Loss: 1160.3
Epoch 153 Iter 0 subLoss 9218.2 multi 1.00 import weight 0.00
Epoch 153 Iter 1 subLoss 6033.7 multi 1.00 import weight 0.00
Epoch 153 Iter 2 subLoss 5466.5 multi 1.00 import weight 0.00
Epoch 153 Iter 3 subLoss 5891.4 multi 1.00 import weight 0.00
Epoch 153 Iter 4 subLoss 5227.2 multi 1.00 import weight 0.00
Epoch 153 Iter 5 subLoss 5978.8 multi 3.99 import weight 0.00
Epoch 153 Iter 6 subLoss 5013.3 multi 1.00 import weight 0.00
Epoch 153 Iter 7 subLoss 4912.2 multi 1.00 import weight 0.00
Epoch 153 Iter 8 subLoss 6217.4 multi 1.00 import weight 0.00
Epoch 153 Iter 9 subLoss 5647.5 multi 1.00 import weight 0.00
Epoch 153 Iter 10 subLoss 5536.6 multi 1.00 import weight 0.00
Epoch 153 Iter 11 subLoss 4794.5 multi 1.00 import weight 0.00
Epoch 153 Acc: 96.63 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 479 train Loss: 5257.6 test Loss: 571.5
Epoch 154 Iter 0 subLoss 5117.0 multi 1.00 import weight 0.00
Epoch 154 Iter 1 subLoss 5292.6 multi 1.00 import weight 0.00
Epoch 154 Iter 2 subLoss 5289.6 multi 1.00 import weight 0.00
Epoch 154 Iter 3 subLoss 4633.6 multi 1.00 import weight 0.00
Epoch 154 Iter 4 subLoss 5105.4 multi 1.00 import weight 0.00
Epoch 154 Iter 5 subLoss 5223.2 multi 3.99 import weight 0.00
Epoch 154 Iter 6 subLoss 5102.5 multi 3.99 import weight 0.00
Epoch 154 Iter 7 subLoss 18286.0 multi 1.00 import weight 0.00
Epoch 154 Iter 8 subLoss 14433.6 multi 1.00 import weight 0.00
Epoch 154 Iter 9 subLoss 6870.7 multi 1.00 import weight 0.00
Epoch 154 Iter 10 subLoss 5393.7 multi 1.00 import weight 0.00
Epoch 154 Iter 11 subLoss 5942.7 multi -1.99 import weight 0.00
Epoch 154 Acc: 96.17 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 594 train Loss: 5723.0 test Loss: 657.5
Epoch 155 Iter 0 subLoss 5127.2 multi -1.99 import weight 0.00
Epoch 155 Iter 1 subLoss 6087.4 multi 6.97 import weight 0.00
Epoch 155 Iter 2 subLoss 7873.4 multi 1.00 import weight 0.00
Epoch 155 Iter 3 subLoss 5358.8 multi 1.00 import weight 0.00
Epoch 155 Iter 4 subLoss 5053.0 multi 1.00 import weight 0.00
Epoch 155 Iter 5 subLoss 5344.0 multi 1.00 import weight 0.00
Epoch 155 Iter 6 subLoss 5489.7 multi 1.00 import weight 0.00
Epoch 155 Iter 7 subLoss 4970.3 multi 1.00 import weight 0.00
Epoch 155 Iter 8 subLoss 5518.2 multi 1.00 import weight 0.00
Epoch 155 Iter 9 subLoss 5529.3 multi -1.99 import weight 0.00
Epoch 155 Iter 10 subLoss 5071.0 multi 1.00 import weight 0.00
Epoch 155 Iter 11 subLoss 5302.8 multi -1.99 import weight 0.00
Epoch 155 Acc: 96.52 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 530 train Loss: 5160.4 test Loss: 583.1
Epoch 156 Iter 0 subLoss 5579.6 multi 1.00 import weight 0.00
Epoch 156 Iter 1 subLoss 5100.3 multi 6.97 import weight 0.00
Epoch 156 Iter 2 subLoss 5876.0 multi 1.00 import weight 0.00
Epoch 156 Iter 3 subLoss 4937.6 multi 1.00 import weight 0.00
Epoch 156 Iter 4 subLoss 5037.0 multi 1.00 import weight 0.00
Epoch 156 Iter 5 subLoss 5024.0 multi -1.99 import weight 0.00
Epoch 156 Iter 6 subLoss 4882.2 multi 1.00 import weight 0.00
Epoch 156 Iter 7 subLoss 5288.1 multi 3.99 import weight 0.00
Epoch 156 Iter 8 subLoss 4695.6 multi 1.00 import weight 0.00
Epoch 156 Iter 9 subLoss 4230.7 multi 1.00 import weight 0.00
Epoch 156 Iter 10 subLoss 4970.5 multi 3.99 import weight 0.00
Epoch 156 Iter 11 subLoss 5227.9 multi 6.97 import weight 0.00
Epoch 156 Acc: 80.35 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 522 train Loss: 23545.6 test Loss: 4029.4
Epoch 157 Iter 0 subLoss 21847.6 multi 3.99 import weight 0.00
Epoch 157 Iter 1 subLoss 137104.2 multi 1.00 import weight 0.00
Epoch 157 Iter 2 subLoss 55162.8 multi 1.00 import weight 0.00
Epoch 157 Iter 3 subLoss 33453.9 multi 1.00 import weight 0.00
Epoch 157 Iter 4 subLoss 29584.1 multi 1.00 import weight 0.00
Epoch 157 Iter 5 subLoss 26549.4 multi 1.00 import weight 0.00
Epoch 157 Iter 6 subLoss 23144.6 multi -1.99 import weight 0.00
Epoch 157 Iter 7 subLoss 29211.8 multi 1.00 import weight 0.00
Epoch 157 Iter 8 subLoss 26935.1 multi 1.00 import weight 0.00
Epoch 157 Iter 9 subLoss 23542.3 multi 1.00 import weight 0.00
Epoch 157 Iter 10 subLoss 20876.5 multi 1.00 import weight 0.00
Epoch 157 Iter 11 subLoss 18889.8 multi 1.00 import weight 0.00
Epoch 157 Acc: 86.57 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1888 train Loss: 17177.3 test Loss: 2115.7
Epoch 158 Iter 0 subLoss 16741.7 multi 1.00 import weight 0.00
Epoch 158 Iter 1 subLoss 15617.8 multi 1.00 import weight 0.00
Epoch 158 Iter 2 subLoss 14054.0 multi 1.00 import weight 0.00
Epoch 158 Iter 3 subLoss 13481.3 multi 1.00 import weight 0.00
Epoch 158 Iter 4 subLoss 12856.5 multi 1.00 import weight 0.00
Epoch 158 Iter 5 subLoss 12700.4 multi -1.99 import weight 0.00
Epoch 158 Iter 6 subLoss 13648.8 multi 1.00 import weight 0.00
Epoch 158 Iter 7 subLoss 13296.3 multi 1.00 import weight 0.00
Epoch 158 Iter 8 subLoss 12748.6 multi 1.00 import weight 0.00
Epoch 158 Iter 9 subLoss 12145.8 multi 1.00 import weight 0.00
Epoch 158 Iter 10 subLoss 11649.7 multi 1.00 import weight 0.00
Epoch 158 Iter 11 subLoss 11021.1 multi -4.97 import weight 0.00
Epoch 158 Acc: 82.84 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 1102 train Loss: 17447.0 test Loss: 2086.0
Epoch 159 Iter 0 subLoss 17781.8 multi 1.00 import weight 0.00
Epoch 159 Iter 1 subLoss 12995.1 multi -1.99 import weight 0.00
Epoch 159 Iter 2 subLoss 31344.1 multi 1.00 import weight 0.00
Epoch 159 Iter 3 subLoss 20153.2 multi 1.00 import weight 0.00
Epoch 159 Iter 4 subLoss 15193.2 multi 1.00 import weight 0.00
Epoch 159 Iter 5 subLoss 12869.9 multi -1.99 import weight 0.00
Epoch 159 Iter 6 subLoss 14531.6 multi 3.99 import weight 0.00
Epoch 159 Iter 7 subLoss 12606.8 multi 1.00 import weight 0.00
Epoch 159 Iter 8 subLoss 11487.6 multi 1.00 import weight 0.00
Epoch 159 Iter 9 subLoss 10965.3 multi -1.99 import weight 0.00
Epoch 159 Iter 10 subLoss 11413.5 multi 3.99 import weight 0.00
Epoch 159 Iter 11 subLoss 10510.9 multi 1.00 import weight 0.00
Epoch 159 Acc: 93.60 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1051 train Loss: 10318.8 test Loss: 1155.5
Epoch 160 Iter 0 subLoss 9485.6 multi 1.00 import weight 0.00
Epoch 160 Iter 1 subLoss 9645.8 multi 1.00 import weight 0.00
Epoch 160 Iter 2 subLoss 9723.3 multi 1.00 import weight 0.00
Epoch 160 Iter 3 subLoss 9390.7 multi 1.00 import weight 0.00
Epoch 160 Iter 4 subLoss 9005.0 multi 1.00 import weight 0.00
Epoch 160 Iter 5 subLoss 9543.6 multi 1.00 import weight 0.00
Epoch 160 Iter 6 subLoss 8958.9 multi 1.00 import weight 0.00
Epoch 160 Iter 7 subLoss 9187.0 multi -1.99 import weight 0.00
Epoch 160 Iter 8 subLoss 9042.5 multi 1.00 import weight 0.00
Epoch 160 Iter 9 subLoss 8980.3 multi 6.97 import weight 0.00
Epoch 160 Iter 10 subLoss 8817.3 multi 1.00 import weight 0.00
Epoch 160 Iter 11 subLoss 8366.9 multi 1.00 import weight 0.00
Epoch 160 Acc: 93.71 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 836 train Loss: 8232.9 test Loss: 949.7
Epoch 161 Iter 0 subLoss 8373.2 multi -1.99 import weight 0.00
Epoch 161 Iter 1 subLoss 8507.2 multi 3.99 import weight 0.00
Epoch 161 Iter 2 subLoss 9375.6 multi 1.00 import weight 0.00
Epoch 161 Iter 3 subLoss 8248.3 multi 3.99 import weight 0.00
Epoch 161 Iter 4 subLoss 25427.5 multi 3.99 import weight 0.00
Epoch 161 Iter 5 subLoss 241838.6 multi 1.00 import weight 0.00
Epoch 161 Iter 6 subLoss 73927.4 multi 1.00 import weight 0.00
Epoch 161 Iter 7 subLoss 44076.4 multi 3.99 import weight 0.00
Epoch 161 Iter 8 subLoss 38232.6 multi 1.00 import weight 0.00
Epoch 161 Iter 9 subLoss 36615.8 multi 1.00 import weight 0.00
Epoch 161 Iter 10 subLoss 36464.8 multi 1.00 import weight 0.00
Epoch 161 Iter 11 subLoss 34878.1 multi 1.00 import weight 0.00
Epoch 161 Acc: 59.51 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 3487 train Loss: 33657.2 test Loss: 5374.5
Epoch 162 Iter 0 subLoss 33098.5 multi 1.00 import weight 0.00
Epoch 162 Iter 1 subLoss 31533.7 multi 3.99 import weight 0.00
Epoch 162 Iter 2 subLoss 23600.6 multi 1.00 import weight 0.00
Epoch 162 Iter 3 subLoss 22214.3 multi 1.00 import weight 0.00
Epoch 162 Iter 4 subLoss 20332.6 multi 3.99 import weight 0.00
Epoch 162 Iter 5 subLoss 15435.7 multi 1.00 import weight 0.00
Epoch 162 Iter 6 subLoss 13558.6 multi 1.00 import weight 0.00
Epoch 162 Iter 7 subLoss 13372.9 multi 1.00 import weight 0.00
Epoch 162 Iter 8 subLoss 12803.2 multi 1.00 import weight 0.00
Epoch 162 Iter 9 subLoss 12572.4 multi 1.00 import weight 0.00
Epoch 162 Iter 10 subLoss 11887.3 multi 1.00 import weight 0.00
Epoch 162 Iter 11 subLoss 11071.8 multi -1.99 import weight 0.00
Epoch 162 Acc: 93.70 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 1107 train Loss: 12507.8 test Loss: 1244.5
Epoch 163 Iter 0 subLoss 12478.6 multi 1.00 import weight 0.00
Epoch 163 Iter 1 subLoss 11811.4 multi 1.00 import weight 0.00
Epoch 163 Iter 2 subLoss 11313.8 multi 1.00 import weight 0.00
Epoch 163 Iter 3 subLoss 10585.5 multi 1.00 import weight 0.00
Epoch 163 Iter 4 subLoss 10289.5 multi 1.00 import weight 0.00
Epoch 163 Iter 5 subLoss 10692.8 multi -1.99 import weight 0.00
Epoch 163 Iter 6 subLoss 11405.8 multi -1.99 import weight 0.00
Epoch 163 Iter 7 subLoss 19020.1 multi 1.00 import weight 0.00
Epoch 163 Iter 8 subLoss 15690.2 multi 1.00 import weight 0.00
Epoch 163 Iter 9 subLoss 12011.8 multi 1.00 import weight 0.00
Epoch 163 Iter 10 subLoss 10301.5 multi 1.00 import weight 0.00
Epoch 163 Iter 11 subLoss 9867.8 multi 1.00 import weight 0.00
Epoch 163 Acc: 95.10 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 986 train Loss: 10428.3 test Loss: 967.5
Epoch 164 Iter 0 subLoss 9832.5 multi 1.00 import weight 0.00
Epoch 164 Iter 1 subLoss 10407.3 multi 1.00 import weight 0.00
Epoch 164 Iter 2 subLoss 10065.9 multi 1.00 import weight 0.00
Epoch 164 Iter 3 subLoss 9289.8 multi 1.00 import weight 0.00
Epoch 164 Iter 4 subLoss 9711.0 multi 1.00 import weight 0.00
Epoch 164 Iter 5 subLoss 9203.3 multi 1.00 import weight 0.00
Epoch 164 Iter 6 subLoss 9469.7 multi 1.00 import weight 0.00
Epoch 164 Iter 7 subLoss 8659.5 multi 3.99 import weight 0.00
Epoch 164 Iter 8 subLoss 8496.4 multi 1.00 import weight 0.00
Epoch 164 Iter 9 subLoss 9281.6 multi 3.99 import weight 0.00
Epoch 164 Iter 10 subLoss 10537.4 multi 1.00 import weight 0.00
Epoch 164 Iter 11 subLoss 8545.9 multi -1.99 import weight 0.00
Epoch 164 Acc: 81.73 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 854 train Loss: 18228.2 test Loss: 2350.5
Epoch 165 Iter 0 subLoss 17246.4 multi 1.00 import weight 0.00
Epoch 165 Iter 1 subLoss 10368.2 multi 1.00 import weight 0.00
Epoch 165 Iter 2 subLoss 7795.3 multi 1.00 import weight 0.00
Epoch 165 Iter 3 subLoss 8759.5 multi 1.00 import weight 0.00
Epoch 165 Iter 4 subLoss 8152.7 multi 1.00 import weight 0.00
Epoch 165 Iter 5 subLoss 8006.4 multi 1.00 import weight 0.00
Epoch 165 Iter 6 subLoss 7679.0 multi 1.00 import weight 0.00
Epoch 165 Iter 7 subLoss 8218.2 multi 1.00 import weight 0.00
Epoch 165 Iter 8 subLoss 8243.1 multi 6.97 import weight 0.00
Epoch 165 Iter 9 subLoss 7554.5 multi 1.00 import weight 0.00
Epoch 165 Iter 10 subLoss 7146.4 multi 1.00 import weight 0.00
Epoch 165 Iter 11 subLoss 7069.7 multi 1.00 import weight 0.00
Epoch 165 Acc: 95.87 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 706 train Loss: 7343.4 test Loss: 667.2
Epoch 166 Iter 0 subLoss 7347.9 multi 1.00 import weight 0.00
Epoch 166 Iter 1 subLoss 7535.4 multi 1.00 import weight 0.00
Epoch 166 Iter 2 subLoss 6842.4 multi 1.00 import weight 0.00
Epoch 166 Iter 3 subLoss 7265.9 multi -1.99 import weight 0.00
Epoch 166 Iter 4 subLoss 9050.4 multi -1.99 import weight 0.00
Epoch 166 Iter 5 subLoss 45150.5 multi 3.99 import weight 0.00
Epoch 166 Iter 6 subLoss 846968.4 multi 1.00 import weight 0.00
Epoch 166 Iter 7 subLoss 49240.8 multi 15.93 import weight 0.00
Epoch 166 Iter 8 subLoss 46114.6 multi 1.00 import weight 0.00
Epoch 166 Iter 9 subLoss 46177.2 multi 3.99 import weight 0.00
Epoch 166 Iter 10 subLoss 44091.9 multi 1.00 import weight 0.00
Epoch 166 Iter 11 subLoss 43512.9 multi -1.99 import weight 0.00
Epoch 166 Acc: 39.13 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 4351 train Loss: 45244.7 test Loss: 7269.4
Epoch 167 Iter 0 subLoss 43546.2 multi 1.00 import weight 0.00
Epoch 167 Iter 1 subLoss 43699.0 multi 1.00 import weight 0.00
Epoch 167 Iter 2 subLoss 43393.7 multi 1.00 import weight 0.00
Epoch 167 Iter 3 subLoss 43024.2 multi 1.00 import weight 0.00
Epoch 167 Iter 4 subLoss 42946.2 multi 3.99 import weight 0.00
Epoch 167 Iter 5 subLoss 41329.2 multi 6.97 import weight 0.00
Epoch 167 Iter 6 subLoss 54695.2 multi 1.00 import weight 0.00
Epoch 167 Iter 7 subLoss 43307.8 multi 1.00 import weight 0.00
Epoch 167 Iter 8 subLoss 42020.1 multi 1.00 import weight 0.00
Epoch 167 Iter 9 subLoss 40829.7 multi 1.00 import weight 0.00
Epoch 167 Iter 10 subLoss 39732.1 multi 1.00 import weight 0.00
Epoch 167 Iter 11 subLoss 39489.2 multi 1.00 import weight 0.00
Epoch 167 Acc: 55.63 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 3948 train Loss: 39659.6 test Loss: 5742.5
Epoch 168 Iter 0 subLoss 38375.2 multi 3.99 import weight 0.00
Epoch 168 Iter 1 subLoss 37723.9 multi 1.00 import weight 0.00
Epoch 168 Iter 2 subLoss 37302.4 multi 1.00 import weight 0.00
Epoch 168 Iter 3 subLoss 37412.3 multi 1.00 import weight 0.00
Epoch 168 Iter 4 subLoss 36434.4 multi 1.00 import weight 0.00
Epoch 168 Iter 5 subLoss 36279.8 multi 1.00 import weight 0.00
Epoch 168 Iter 6 subLoss 36269.6 multi 1.00 import weight 0.00
Epoch 168 Iter 7 subLoss 35356.6 multi 3.99 import weight 0.00
Epoch 168 Iter 8 subLoss 34798.7 multi 1.00 import weight 0.00
Epoch 168 Iter 9 subLoss 34881.9 multi -1.99 import weight 0.00
Epoch 168 Iter 10 subLoss 36269.9 multi 3.99 import weight 0.00
Epoch 168 Iter 11 subLoss 43383.3 multi 1.00 import weight 0.00
Epoch 168 Acc: 62.93 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4338 train Loss: 36078.8 test Loss: 4728.7
Epoch 169 Iter 0 subLoss 35389.8 multi -1.99 import weight 0.00
Epoch 169 Iter 1 subLoss 39344.8 multi -1.99 import weight 0.00
Epoch 169 Iter 2 subLoss 53585.3 multi 1.00 import weight 0.00
Epoch 169 Iter 3 subLoss 40927.1 multi 1.00 import weight 0.00
Epoch 169 Iter 4 subLoss 39238.2 multi 1.00 import weight 0.00
Epoch 169 Iter 5 subLoss 38246.9 multi -1.99 import weight 0.00
Epoch 169 Iter 6 subLoss 39163.2 multi 1.00 import weight 0.00
Epoch 169 Iter 7 subLoss 38649.2 multi 3.99 import weight 0.00
Epoch 169 Iter 8 subLoss 37112.3 multi 1.00 import weight 0.00
Epoch 169 Iter 9 subLoss 36283.5 multi -1.99 import weight 0.00
Epoch 169 Iter 10 subLoss 38133.7 multi 1.00 import weight 0.00
Epoch 169 Iter 11 subLoss 36554.5 multi -1.99 import weight 0.00
Epoch 169 Acc: 61.30 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 3655 train Loss: 38172.4 test Loss: 5029.9
Epoch 170 Iter 0 subLoss 36925.2 multi 1.00 import weight 0.00
Epoch 170 Iter 1 subLoss 36657.2 multi 1.00 import weight 0.00
Epoch 170 Iter 2 subLoss 37040.3 multi 1.00 import weight 0.00
Epoch 170 Iter 3 subLoss 36296.1 multi -1.99 import weight 0.00
Epoch 170 Iter 4 subLoss 36811.5 multi 1.00 import weight 0.00
Epoch 170 Iter 5 subLoss 36918.0 multi 1.00 import weight 0.00
Epoch 170 Iter 6 subLoss 36834.4 multi 3.99 import weight 0.00
Epoch 170 Iter 7 subLoss 34681.3 multi 1.00 import weight 0.00
Epoch 170 Iter 8 subLoss 33954.7 multi 1.00 import weight 0.00
Epoch 170 Iter 9 subLoss 33184.4 multi 1.00 import weight 0.00
Epoch 170 Iter 10 subLoss 32781.2 multi 1.00 import weight 0.00
Epoch 170 Iter 11 subLoss 31779.2 multi 1.00 import weight 0.00
Epoch 170 Acc: 64.51 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 3177 train Loss: 32164.6 test Loss: 4149.8
Epoch 171 Iter 0 subLoss 31456.7 multi 1.00 import weight 0.00
Epoch 171 Iter 1 subLoss 30944.6 multi 1.00 import weight 0.00
Epoch 171 Iter 2 subLoss 31057.5 multi 3.99 import weight 0.00
Epoch 171 Iter 3 subLoss 29403.3 multi 1.00 import weight 0.00
Epoch 171 Iter 4 subLoss 28780.9 multi 1.00 import weight 0.00
Epoch 171 Iter 5 subLoss 28123.1 multi 1.00 import weight 0.00
Epoch 171 Iter 6 subLoss 27641.5 multi 1.00 import weight 0.00
Epoch 171 Iter 7 subLoss 27555.8 multi 1.00 import weight 0.00
Epoch 171 Iter 8 subLoss 26963.9 multi 3.99 import weight 0.00
Epoch 171 Iter 9 subLoss 24720.9 multi 1.00 import weight 0.00
Epoch 171 Iter 10 subLoss 23504.7 multi 1.00 import weight 0.00
Epoch 171 Iter 11 subLoss 23833.9 multi -1.99 import weight 0.00
Epoch 171 Acc: 76.84 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 2383 train Loss: 25145.3 test Loss: 3336.2
Epoch 172 Iter 0 subLoss 24802.6 multi 1.00 import weight 0.00
Epoch 172 Iter 1 subLoss 23792.3 multi 1.00 import weight 0.00
Epoch 172 Iter 2 subLoss 24210.9 multi 1.00 import weight 0.00
Epoch 172 Iter 3 subLoss 23830.7 multi 1.00 import weight 0.00
Epoch 172 Iter 4 subLoss 23277.7 multi 1.00 import weight 0.00
Epoch 172 Iter 5 subLoss 22104.7 multi 1.00 import weight 0.00
Epoch 172 Iter 6 subLoss 21664.9 multi 1.00 import weight 0.00
Epoch 172 Iter 7 subLoss 22171.3 multi 1.00 import weight 0.00
Epoch 172 Iter 8 subLoss 21716.9 multi 1.00 import weight 0.00
Epoch 172 Iter 9 subLoss 20669.3 multi 1.00 import weight 0.00
Epoch 172 Iter 10 subLoss 20720.9 multi 1.00 import weight 0.00
Epoch 172 Iter 11 subLoss 20493.3 multi 1.00 import weight 0.00
Epoch 172 Acc: 80.89 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2049 train Loss: 20569.7 test Loss: 2642.8
Epoch 173 Iter 0 subLoss 20056.7 multi 1.00 import weight 0.00
Epoch 173 Iter 1 subLoss 20053.5 multi 3.99 import weight 0.00
Epoch 173 Iter 2 subLoss 28011.8 multi 1.00 import weight 0.00
Epoch 173 Iter 3 subLoss 29380.0 multi 1.00 import weight 0.00
Epoch 173 Iter 4 subLoss 20788.7 multi 1.00 import weight 0.00
Epoch 173 Iter 5 subLoss 18522.2 multi 1.00 import weight 0.00
Epoch 173 Iter 6 subLoss 18268.0 multi 1.00 import weight 0.00
Epoch 173 Iter 7 subLoss 17574.1 multi 1.00 import weight 0.00
Epoch 173 Iter 8 subLoss 16766.2 multi 1.00 import weight 0.00
Epoch 173 Iter 9 subLoss 16839.4 multi 1.00 import weight 0.00
Epoch 173 Iter 10 subLoss 16614.6 multi 1.00 import weight 0.00
Epoch 173 Iter 11 subLoss 16789.5 multi 1.00 import weight 0.00
Epoch 173 Acc: 85.13 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1678 train Loss: 16953.6 test Loss: 2136.4
Epoch 174 Iter 0 subLoss 16398.5 multi 1.00 import weight 0.00
Epoch 174 Iter 1 subLoss 16187.7 multi 1.00 import weight 0.00
Epoch 174 Iter 2 subLoss 16353.9 multi 1.00 import weight 0.00
Epoch 174 Iter 3 subLoss 16081.1 multi 1.00 import weight 0.00
Epoch 174 Iter 4 subLoss 16228.3 multi 1.00 import weight 0.00
Epoch 174 Iter 5 subLoss 16424.0 multi 1.00 import weight 0.00
Epoch 174 Iter 6 subLoss 18428.5 multi 1.00 import weight 0.00
Epoch 174 Iter 7 subLoss 18545.5 multi 1.00 import weight 0.00
Epoch 174 Iter 8 subLoss 20177.1 multi 1.00 import weight 0.00
Epoch 174 Iter 9 subLoss 18031.3 multi -1.99 import weight 0.00
Epoch 174 Iter 10 subLoss 75632.5 multi 1.00 import weight 0.00
Epoch 174 Iter 11 subLoss 28309.4 multi 1.00 import weight 0.00
Epoch 174 Acc: 76.18 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2830 train Loss: 22851.5 test Loss: 3000.0
Epoch 175 Iter 0 subLoss 22151.3 multi -1.99 import weight 0.00
Epoch 175 Iter 1 subLoss 31243.7 multi 1.00 import weight 0.00
Epoch 175 Iter 2 subLoss 23360.2 multi 1.00 import weight 0.00
Epoch 175 Iter 3 subLoss 20997.3 multi 1.00 import weight 0.00
Epoch 175 Iter 4 subLoss 21236.3 multi 1.00 import weight 0.00
Epoch 175 Iter 5 subLoss 18825.0 multi 1.00 import weight 0.00
Epoch 175 Iter 6 subLoss 19731.7 multi 1.00 import weight 0.00
Epoch 175 Iter 7 subLoss 17275.6 multi 1.00 import weight 0.00
Epoch 175 Iter 8 subLoss 17188.5 multi 1.00 import weight 0.00
Epoch 175 Iter 9 subLoss 17185.5 multi 3.99 import weight 0.00
Epoch 175 Iter 10 subLoss 14797.7 multi 1.00 import weight 0.00
Epoch 175 Iter 11 subLoss 14317.2 multi 1.00 import weight 0.00
Epoch 175 Acc: 91.57 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1431 train Loss: 14338.7 test Loss: 1611.4
Epoch 176 Iter 0 subLoss 13696.6 multi 1.00 import weight 0.00
Epoch 176 Iter 1 subLoss 13682.5 multi 1.00 import weight 0.00
Epoch 176 Iter 2 subLoss 13880.3 multi 1.00 import weight 0.00
Epoch 176 Iter 3 subLoss 13423.7 multi 1.00 import weight 0.00
Epoch 176 Iter 4 subLoss 13090.9 multi 1.00 import weight 0.00
Epoch 176 Iter 5 subLoss 12757.9 multi -1.99 import weight 0.00
Epoch 176 Iter 6 subLoss 13472.1 multi 1.00 import weight 0.00
Epoch 176 Iter 7 subLoss 13433.8 multi -1.99 import weight 0.00
Epoch 176 Iter 8 subLoss 15026.6 multi 1.00 import weight 0.00
Epoch 176 Iter 9 subLoss 13694.7 multi 1.00 import weight 0.00
Epoch 176 Iter 10 subLoss 13476.7 multi 3.99 import weight 0.00
Epoch 176 Iter 11 subLoss 25552.4 multi 1.00 import weight 0.00
Epoch 176 Acc: 87.29 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2555 train Loss: 19676.3 test Loss: 2121.2
Epoch 177 Iter 0 subLoss 19511.9 multi 1.00 import weight 0.00
Epoch 177 Iter 1 subLoss 17371.9 multi -1.99 import weight 0.00
Epoch 177 Iter 2 subLoss 90941.7 multi 1.00 import weight 0.00
Epoch 177 Iter 3 subLoss 29144.3 multi 1.00 import weight 0.00
Epoch 177 Iter 4 subLoss 21003.6 multi -1.99 import weight 0.00
Epoch 177 Iter 5 subLoss 30837.9 multi 1.00 import weight 0.00
Epoch 177 Iter 6 subLoss 23459.9 multi 1.00 import weight 0.00
Epoch 177 Iter 7 subLoss 19842.5 multi 1.00 import weight 0.00
Epoch 177 Iter 8 subLoss 17968.9 multi 1.00 import weight 0.00
Epoch 177 Iter 9 subLoss 16669.3 multi 1.00 import weight 0.00
Epoch 177 Iter 10 subLoss 15659.9 multi 1.00 import weight 0.00
Epoch 177 Iter 11 subLoss 14583.9 multi 1.00 import weight 0.00
Epoch 177 Acc: 92.47 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1458 train Loss: 14712.7 test Loss: 1497.1
Epoch 178 Iter 0 subLoss 14604.6 multi 1.00 import weight 0.00
Epoch 178 Iter 1 subLoss 13830.3 multi 1.00 import weight 0.00
Epoch 178 Iter 2 subLoss 13432.6 multi 1.00 import weight 0.00
Epoch 178 Iter 3 subLoss 12807.4 multi 3.99 import weight 0.00
Epoch 178 Iter 4 subLoss 11782.1 multi 1.00 import weight 0.00
Epoch 178 Iter 5 subLoss 12135.0 multi 1.00 import weight 0.00
Epoch 178 Iter 6 subLoss 11452.1 multi 3.99 import weight 0.00
Epoch 178 Iter 7 subLoss 15265.4 multi 1.00 import weight 0.00
Epoch 178 Iter 8 subLoss 15682.9 multi 1.00 import weight 0.00
Epoch 178 Iter 9 subLoss 13645.6 multi 3.99 import weight 0.00
Epoch 178 Iter 10 subLoss 89035.2 multi 1.00 import weight 0.00
Epoch 178 Iter 11 subLoss 27222.2 multi 1.00 import weight 0.00
Epoch 178 Acc: 82.12 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2722 train Loss: 21050.1 test Loss: 2690.4
Epoch 179 Iter 0 subLoss 20600.6 multi 1.00 import weight 0.00
Epoch 179 Iter 1 subLoss 18937.6 multi 1.00 import weight 0.00
Epoch 179 Iter 2 subLoss 18105.8 multi 1.00 import weight 0.00
Epoch 179 Iter 3 subLoss 17613.2 multi 1.00 import weight 0.00
Epoch 179 Iter 4 subLoss 16612.7 multi 3.99 import weight 0.00
Epoch 179 Iter 5 subLoss 14085.0 multi 1.00 import weight 0.00
Epoch 179 Iter 6 subLoss 13361.5 multi 1.00 import weight 0.00
Epoch 179 Iter 7 subLoss 12598.5 multi 1.00 import weight 0.00
Epoch 179 Iter 8 subLoss 12105.3 multi 1.00 import weight 0.00
Epoch 179 Iter 9 subLoss 11664.9 multi -1.99 import weight 0.00
Epoch 179 Iter 10 subLoss 12209.7 multi 1.00 import weight 0.00
Epoch 179 Iter 11 subLoss 12309.2 multi 1.00 import weight 0.00
Epoch 179 Acc: 94.36 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1230 train Loss: 11908.3 test Loss: 1205.0
Epoch 180 Iter 0 subLoss 11522.3 multi 3.99 import weight 0.00
Epoch 180 Iter 1 subLoss 10918.2 multi 1.00 import weight 0.00
Epoch 180 Iter 2 subLoss 9849.1 multi -1.99 import weight 0.00
Epoch 180 Iter 3 subLoss 13557.0 multi 3.99 import weight 0.00
Epoch 180 Iter 4 subLoss 40221.2 multi 1.00 import weight 0.00
Epoch 180 Iter 5 subLoss 18553.9 multi -1.99 import weight 0.00
Epoch 180 Iter 6 subLoss 32717.0 multi 1.00 import weight 0.00
Epoch 180 Iter 7 subLoss 20503.2 multi -1.99 import weight 0.00
Epoch 180 Iter 8 subLoss 33007.7 multi -1.99 import weight 0.00
Epoch 180 Iter 9 subLoss 64299.1 multi 1.00 import weight 0.00
Epoch 180 Iter 10 subLoss 34788.5 multi 1.00 import weight 0.00
Epoch 180 Iter 11 subLoss 28117.5 multi 1.00 import weight 0.00
Epoch 180 Acc: 76.12 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 2811 train Loss: 24355.9 test Loss: 4057.2
Epoch 181 Iter 0 subLoss 23982.6 multi 1.00 import weight 0.00
Epoch 181 Iter 1 subLoss 21198.2 multi 1.00 import weight 0.00
Epoch 181 Iter 2 subLoss 18221.0 multi 1.00 import weight 0.00
Epoch 181 Iter 3 subLoss 16262.3 multi 1.00 import weight 0.00
Epoch 181 Iter 4 subLoss 14643.3 multi 1.00 import weight 0.00
Epoch 181 Iter 5 subLoss 14230.1 multi 1.00 import weight 0.00
Epoch 181 Iter 6 subLoss 13549.0 multi 1.00 import weight 0.00
Epoch 181 Iter 7 subLoss 12840.0 multi 1.00 import weight 0.00
Epoch 181 Iter 8 subLoss 12838.3 multi 1.00 import weight 0.00
Epoch 181 Iter 9 subLoss 11914.4 multi 1.00 import weight 0.00
Epoch 181 Iter 10 subLoss 11990.0 multi 1.00 import weight 0.00
Epoch 181 Iter 11 subLoss 11422.7 multi -4.97 import weight 0.00
Epoch 181 Acc: 93.52 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 1142 train Loss: 13263.9 test Loss: 1468.9
Epoch 182 Iter 0 subLoss 12949.3 multi 1.00 import weight 0.00
Epoch 182 Iter 1 subLoss 12403.4 multi 1.00 import weight 0.00
Epoch 182 Iter 2 subLoss 12529.8 multi -1.99 import weight 0.00
Epoch 182 Iter 3 subLoss 12768.6 multi -1.99 import weight 0.00
Epoch 182 Iter 4 subLoss 14052.5 multi 3.99 import weight 0.00
Epoch 182 Iter 5 subLoss 12696.1 multi 3.99 import weight 0.00
Epoch 182 Iter 6 subLoss 15858.2 multi 1.00 import weight 0.00
Epoch 182 Iter 7 subLoss 11884.4 multi 3.99 import weight 0.00
Epoch 182 Iter 8 subLoss 12403.9 multi 3.99 import weight 0.00
Epoch 182 Iter 9 subLoss 23613.3 multi -1.99 import weight 0.00
Epoch 182 Iter 10 subLoss 135008.2 multi 1.00 import weight 0.00
Epoch 182 Iter 11 subLoss 25534.6 multi 3.99 import weight 0.00
Epoch 182 Acc: 62.68 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 2553 train Loss: 33771.3 test Loss: 4967.3
Epoch 183 Iter 0 subLoss 34166.0 multi 1.00 import weight 0.00
Epoch 183 Iter 1 subLoss 16485.5 multi 1.00 import weight 0.00
Epoch 183 Iter 2 subLoss 14755.7 multi 1.00 import weight 0.00
Epoch 183 Iter 3 subLoss 13250.1 multi 1.00 import weight 0.00
Epoch 183 Iter 4 subLoss 12994.1 multi 1.00 import weight 0.00
Epoch 183 Iter 5 subLoss 12123.0 multi -1.99 import weight 0.00
Epoch 183 Iter 6 subLoss 14003.7 multi 1.00 import weight 0.00
Epoch 183 Iter 7 subLoss 12928.7 multi -1.99 import weight 0.00
Epoch 183 Iter 8 subLoss 13859.8 multi 1.00 import weight 0.00
Epoch 183 Iter 9 subLoss 13511.6 multi 1.00 import weight 0.00
Epoch 183 Iter 10 subLoss 12357.2 multi -1.99 import weight 0.00
Epoch 183 Iter 11 subLoss 13215.1 multi 1.00 import weight 0.00
Epoch 183 Acc: 90.00 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 1321 train Loss: 13669.4 test Loss: 1443.3
Epoch 184 Iter 0 subLoss 13204.4 multi 1.00 import weight 0.00
Epoch 184 Iter 1 subLoss 12998.2 multi 3.98 import weight 0.00
Epoch 184 Iter 2 subLoss 11761.6 multi -1.99 import weight 0.00
Epoch 184 Iter 3 subLoss 12864.1 multi 1.00 import weight 0.00
Epoch 184 Iter 4 subLoss 11055.3 multi 1.00 import weight 0.00
Epoch 184 Iter 5 subLoss 10882.2 multi 1.00 import weight 0.00
Epoch 184 Iter 6 subLoss 10668.4 multi 1.00 import weight 0.00
Epoch 184 Iter 7 subLoss 11539.7 multi -4.97 import weight 0.00
Epoch 184 Iter 8 subLoss 13095.2 multi 3.99 import weight 0.00
Epoch 184 Iter 9 subLoss 13970.7 multi 1.00 import weight 0.00
Epoch 184 Iter 10 subLoss 12574.7 multi 3.99 import weight 0.00
Epoch 184 Iter 11 subLoss 11999.7 multi 3.99 import weight 0.00
Epoch 184 Acc: 78.79 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 1199 train Loss: 18438.6 test Loss: 2392.5
Epoch 185 Iter 0 subLoss 17520.5 multi 1.00 import weight 0.00
Epoch 185 Iter 1 subLoss 10804.5 multi 1.00 import weight 0.00
Epoch 185 Iter 2 subLoss 9670.4 multi 3.99 import weight 0.00
Epoch 185 Iter 3 subLoss 9623.3 multi 1.00 import weight 0.00
Epoch 185 Iter 4 subLoss 9123.1 multi 1.00 import weight 0.00
Epoch 185 Iter 5 subLoss 8345.5 multi 1.00 import weight 0.00
Epoch 185 Iter 6 subLoss 9120.0 multi 3.99 import weight 0.00
Epoch 185 Iter 7 subLoss 9088.8 multi 1.00 import weight 0.00
Epoch 185 Iter 8 subLoss 8189.2 multi -1.99 import weight 0.00
Epoch 185 Iter 9 subLoss 9249.3 multi 1.00 import weight 0.00
Epoch 185 Iter 10 subLoss 8376.4 multi 1.00 import weight 0.00
Epoch 185 Iter 11 subLoss 8961.3 multi -1.99 import weight 0.00
Epoch 185 Acc: 95.29 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 896 train Loss: 8720.0 test Loss: 816.5
Epoch 186 Iter 0 subLoss 8299.3 multi 1.00 import weight 0.00
Epoch 186 Iter 1 subLoss 7773.3 multi -1.99 import weight 0.00
Epoch 186 Iter 2 subLoss 8242.1 multi 9.96 import weight 0.00
Epoch 186 Iter 3 subLoss 48631.1 multi -4.97 import weight 0.00
Epoch 186 Iter 4 subLoss 24439454.0 multi 1.00 import weight 0.00
Epoch 186 Iter 5 subLoss 280798.8 multi 1.00 import weight 0.00
Epoch 186 Iter 6 subLoss 1745574.5 multi 1.00 import weight 0.00
Epoch 186 Iter 7 subLoss 30858176.0 multi 3.99 import weight 0.00
Epoch 186 Iter 8 subLoss 344555.4 multi 1.00 import weight 0.00
Epoch 186 Iter 9 subLoss 52919.9 multi 1.00 import weight 0.00
Epoch 186 Iter 10 subLoss 49127.4 multi 1.00 import weight 0.00
Epoch 186 Iter 11 subLoss 49049.2 multi -7.96 import weight 0.00
Epoch 186 Acc: 19.11 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 4904 train Loss: 50212.5 test Loss: 8439.8
Epoch 187 Iter 0 subLoss 49132.2 multi 6.97 import weight 0.00
Epoch 187 Iter 1 subLoss 48997.0 multi 6.97 import weight 0.00
Epoch 187 Iter 2 subLoss 49052.9 multi 6.97 import weight 0.00
Epoch 187 Iter 3 subLoss 48949.9 multi -1.99 import weight 0.00
Epoch 187 Iter 4 subLoss 48810.7 multi -7.96 import weight 0.00
Epoch 187 Iter 5 subLoss 49006.1 multi 6.97 import weight 0.00
Epoch 187 Iter 6 subLoss 48614.0 multi -22.88 import weight 0.00
Epoch 187 Iter 7 subLoss 49405.1 multi 1.00 import weight 0.00
Epoch 187 Iter 8 subLoss 49517.4 multi -1.99 import weight 0.00
Epoch 187 Iter 9 subLoss 49141.8 multi -4.97 import weight 0.00
Epoch 187 Iter 10 subLoss 49475.7 multi 1.00 import weight 0.00
Epoch 187 Iter 11 subLoss 49300.3 multi 1.00 import weight 0.00
Epoch 187 Acc: 19.11 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4930 train Loss: 50300.1 test Loss: 8454.6
Epoch 188 Iter 0 subLoss 49270.4 multi 3.99 import weight 0.00
Epoch 188 Iter 1 subLoss 49256.4 multi -13.93 import weight 0.00
Epoch 188 Iter 2 subLoss 49582.7 multi 1.00 import weight 0.00
Epoch 188 Iter 3 subLoss 49433.5 multi -4.97 import weight 0.00
Epoch 188 Iter 4 subLoss 49918.0 multi 1.00 import weight 0.00
Epoch 188 Iter 5 subLoss 49497.2 multi 3.99 import weight 0.00
Epoch 188 Iter 6 subLoss 49496.7 multi 6.97 import weight 0.00
Epoch 188 Iter 7 subLoss 49456.9 multi 1.00 import weight 0.00
Epoch 188 Iter 8 subLoss 49305.9 multi 3.98 import weight 0.00
Epoch 188 Iter 9 subLoss 49132.1 multi 9.96 import weight 0.00
Epoch 188 Iter 10 subLoss 49322.0 multi 9.96 import weight 0.00
Epoch 188 Iter 11 subLoss 48883.8 multi 21.90 import weight 0.00
Epoch 188 Acc: 19.11 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 21.90 Pidx 4888 train Loss: 49541.1 test Loss: 8324.2
Epoch 189 Iter 0 subLoss 48690.5 multi -10.94 import weight 0.00
Epoch 189 Iter 1 subLoss 48642.0 multi -1.99 import weight 0.00
Epoch 189 Iter 2 subLoss 48686.0 multi 6.97 import weight 0.00
Epoch 189 Iter 3 subLoss 48728.5 multi 15.93 import weight 0.00
Epoch 189 Iter 4 subLoss 48341.7 multi 15.93 import weight 0.00
Epoch 189 Iter 5 subLoss 48437.0 multi 6.97 import weight 0.00
Epoch 189 Iter 6 subLoss 48465.1 multi 3.98 import weight 0.00
Epoch 189 Iter 7 subLoss 48480.5 multi 21.90 import weight 0.00
Epoch 189 Iter 8 subLoss 48309.8 multi -28.85 import weight 0.00
Epoch 189 Iter 9 subLoss 48311.8 multi -4.97 import weight 0.00
Epoch 189 Iter 10 subLoss 48377.6 multi 1.00 import weight 0.00
Epoch 189 Iter 11 subLoss 48279.8 multi -10.94 import weight 0.00
Epoch 189 Acc: 19.11 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -10.94 Pidx 4827 train Loss: 49357.6 test Loss: 8291.8
Epoch 190 Iter 0 subLoss 48360.2 multi -13.93 import weight 0.00
Epoch 190 Iter 1 subLoss 48453.8 multi -1.98 import weight 0.00
Epoch 190 Iter 2 subLoss 48441.4 multi -4.97 import weight 0.00
Epoch 190 Iter 3 subLoss 48524.9 multi -16.91 import weight 0.00
Epoch 190 Iter 4 subLoss 48710.7 multi -4.97 import weight 0.00
Epoch 190 Iter 5 subLoss 48641.4 multi 1.00 import weight 0.00
Epoch 190 Iter 6 subLoss 48512.3 multi 15.93 import weight 0.00
Epoch 190 Iter 7 subLoss 48535.6 multi 3.98 import weight 0.00
Epoch 190 Iter 8 subLoss 48546.9 multi -1.99 import weight 0.00
Epoch 190 Iter 9 subLoss 48450.1 multi -1.99 import weight 0.00
Epoch 190 Iter 10 subLoss 48457.1 multi 1.00 import weight 0.00
Epoch 190 Iter 11 subLoss 48593.1 multi 15.93 import weight 0.00
Epoch 190 Acc: 19.11 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 15.93 Pidx 4859 train Loss: 49368.1 test Loss: 8293.3
Epoch 191 Iter 0 subLoss 48411.4 multi -1.99 import weight 0.00
Epoch 191 Iter 1 subLoss 48407.1 multi 12.94 import weight 0.00
Epoch 191 Iter 2 subLoss 48358.5 multi 3.98 import weight 0.00
Epoch 191 Iter 3 subLoss 48373.6 multi 1.00 import weight 0.00
Epoch 191 Iter 4 subLoss 48362.5 multi -13.93 import weight 0.00
Epoch 191 Iter 5 subLoss 48414.9 multi -1.98 import weight 0.00
Epoch 191 Iter 6 subLoss 48449.6 multi -1.99 import weight 0.00
Epoch 191 Iter 7 subLoss 48469.6 multi -1.99 import weight 0.00
Epoch 191 Iter 8 subLoss 48349.3 multi 18.91 import weight 0.00
Epoch 191 Iter 9 subLoss 48289.7 multi -1.98 import weight 0.00
Epoch 191 Iter 10 subLoss 48328.1 multi -22.88 import weight 0.00
Epoch 191 Iter 11 subLoss 48432.8 multi 9.96 import weight 0.00
Epoch 191 Acc: 19.11 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 4843 train Loss: 49348.7 test Loss: 8290.2
Epoch 192 Iter 0 subLoss 48329.3 multi -19.90 import weight 0.00
Epoch 192 Iter 1 subLoss 48327.3 multi -16.91 import weight 0.00
Epoch 192 Iter 2 subLoss 48532.1 multi 6.97 import weight 0.00
Epoch 192 Iter 3 subLoss 48495.3 multi -16.91 import weight 0.00
Epoch 192 Iter 4 subLoss 48584.8 multi 15.93 import weight 0.00
Epoch 192 Iter 5 subLoss 48674.3 multi -13.93 import weight 0.00
Epoch 192 Iter 6 subLoss 48549.1 multi -1.99 import weight 0.00
Epoch 192 Iter 7 subLoss 48584.2 multi 18.91 import weight 0.00
Epoch 192 Iter 8 subLoss 48420.8 multi -10.94 import weight 0.00
Epoch 192 Iter 9 subLoss 48512.8 multi 18.91 import weight 0.00
Epoch 192 Iter 10 subLoss 48396.9 multi -7.96 import weight 0.00
Epoch 192 Iter 11 subLoss 48406.3 multi 12.94 import weight 0.00
Epoch 192 Acc: 19.11 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 4840 train Loss: 49342.2 test Loss: 8288.7
Epoch 193 Iter 0 subLoss 48310.8 multi -1.99 import weight 0.00
Epoch 193 Iter 1 subLoss 48375.8 multi 1.00 import weight 0.00
Epoch 193 Iter 2 subLoss 48440.5 multi -1.98 import weight 0.00
Epoch 193 Iter 3 subLoss 48364.5 multi -10.94 import weight 0.00
Epoch 193 Iter 4 subLoss 48472.5 multi -28.85 import weight 0.00
Epoch 193 Iter 5 subLoss 48422.1 multi -7.96 import weight 0.00
Epoch 193 Iter 6 subLoss 48697.1 multi -10.94 import weight 0.00
Epoch 193 Iter 7 subLoss 48955.0 multi 3.98 import weight 0.00
Epoch 193 Iter 8 subLoss 48734.8 multi -13.93 import weight 0.00
Epoch 193 Iter 9 subLoss 48979.5 multi -10.94 import weight 0.00
Epoch 193 Iter 10 subLoss 49229.1 multi -1.98 import weight 0.00
Epoch 193 Iter 11 subLoss 49087.3 multi -7.96 import weight 0.00
Epoch 193 Acc: 19.11 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 4908 train Loss: 50347.0 test Loss: 8459.6
Epoch 194 Iter 0 subLoss 49237.8 multi -1.98 import weight 0.00
Epoch 194 Iter 1 subLoss 49347.6 multi 6.97 import weight 0.00
Epoch 194 Iter 2 subLoss 49165.3 multi -1.98 import weight 0.00
Epoch 194 Iter 3 subLoss 49073.6 multi 6.97 import weight 0.00
Epoch 194 Iter 4 subLoss 49333.9 multi -10.94 import weight 0.00
Epoch 194 Iter 5 subLoss 49436.8 multi -1.99 import weight 0.00
Epoch 194 Iter 6 subLoss 49496.1 multi 9.96 import weight 0.00
Epoch 194 Iter 7 subLoss 49250.6 multi -10.94 import weight 0.00
Epoch 194 Iter 8 subLoss 49314.8 multi -7.96 import weight 0.00
Epoch 194 Iter 9 subLoss 49759.1 multi 1.00 import weight 0.00
Epoch 194 Iter 10 subLoss 49465.3 multi -1.99 import weight 0.00
Epoch 194 Iter 11 subLoss 49972.7 multi 1.00 import weight 0.00
Epoch 194 Acc: 19.11 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4997 train Loss: 50656.2 test Loss: 8512.4
Epoch 195 Iter 0 subLoss 49875.8 multi 1.00 import weight 0.00
Epoch 195 Iter 1 subLoss 49865.0 multi 1.00 import weight 0.00
Epoch 195 Iter 2 subLoss 49394.1 multi -1.99 import weight 0.00
Epoch 195 Iter 3 subLoss 49624.7 multi 1.00 import weight 0.00
Epoch 195 Iter 4 subLoss 49276.7 multi 6.97 import weight 0.00
Epoch 195 Iter 5 subLoss 49599.2 multi 1.00 import weight 0.00
Epoch 195 Iter 6 subLoss 49535.3 multi 1.00 import weight 0.00
Epoch 195 Iter 7 subLoss 49496.6 multi 12.94 import weight 0.00
Epoch 195 Iter 8 subLoss 48957.2 multi 6.97 import weight 0.00
Epoch 195 Iter 9 subLoss 48805.9 multi 9.96 import weight 0.00
Epoch 195 Iter 10 subLoss 48657.2 multi -4.97 import weight 0.00
Epoch 195 Iter 11 subLoss 48699.3 multi -7.96 import weight 0.00
Epoch 195 Acc: 19.11 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 4869 train Loss: 49871.2 test Loss: 8379.4
Epoch 196 Iter 0 subLoss 49056.8 multi 9.96 import weight 0.00
Epoch 196 Iter 1 subLoss 48801.0 multi 12.94 import weight 0.00
Epoch 196 Iter 2 subLoss 48694.5 multi -4.97 import weight 0.00
Epoch 196 Iter 3 subLoss 48614.6 multi -19.90 import weight 0.00
Epoch 196 Iter 4 subLoss 48990.8 multi 9.96 import weight 0.00
Epoch 196 Iter 5 subLoss 48680.8 multi 6.97 import weight 0.00
Epoch 196 Iter 6 subLoss 48548.0 multi 1.00 import weight 0.00
Epoch 196 Iter 7 subLoss 48447.0 multi 1.00 import weight 0.00
Epoch 196 Iter 8 subLoss 48498.8 multi -13.93 import weight 0.00
Epoch 196 Iter 9 subLoss 48747.7 multi -1.99 import weight 0.00
Epoch 196 Iter 10 subLoss 48688.0 multi 9.96 import weight 0.00
Epoch 196 Iter 11 subLoss 48649.1 multi 3.98 import weight 0.00
Epoch 196 Acc: 19.11 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 4864 train Loss: 49566.4 test Loss: 8327.6
Epoch 197 Iter 0 subLoss 48635.3 multi -1.98 import weight 0.00
Epoch 197 Iter 1 subLoss 48566.1 multi -13.93 import weight 0.00
Epoch 197 Iter 2 subLoss 48748.9 multi 1.00 import weight 0.00
Epoch 197 Iter 3 subLoss 48730.2 multi -10.94 import weight 0.00
Epoch 197 Iter 4 subLoss 48972.0 multi -7.96 import weight 0.00
Epoch 197 Iter 5 subLoss 48760.1 multi -1.99 import weight 0.00
Epoch 197 Iter 6 subLoss 49086.6 multi -7.96 import weight 0.00
Epoch 197 Iter 7 subLoss 49119.2 multi -10.94 import weight 0.00
Epoch 197 Iter 8 subLoss 49442.9 multi -10.94 import weight 0.00
Epoch 197 Iter 9 subLoss 49788.4 multi 1.00 import weight 0.00
Epoch 197 Iter 10 subLoss 49884.4 multi -1.99 import weight 0.00
Epoch 197 Iter 11 subLoss 50131.3 multi 1.00 import weight 0.00
Epoch 197 Acc: 19.11 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 5013 train Loss: 50811.2 test Loss: 8538.9
Epoch 198 Iter 0 subLoss 49978.9 multi 3.99 import weight 0.00
Epoch 198 Iter 1 subLoss 49766.2 multi 1.00 import weight 0.00
Epoch 198 Iter 2 subLoss 49647.1 multi 1.00 import weight 0.00
Epoch 198 Iter 3 subLoss 49263.2 multi -10.94 import weight 0.00
Epoch 198 Iter 4 subLoss 50001.0 multi 1.00 import weight 0.00
Epoch 198 Iter 5 subLoss 50256.7 multi 1.00 import weight 0.00
Epoch 198 Iter 6 subLoss 49952.3 multi 1.00 import weight 0.00
Epoch 198 Iter 7 subLoss 49778.3 multi -4.97 import weight 0.00
Epoch 198 Iter 8 subLoss 49797.2 multi 1.00 import weight 0.00
Epoch 198 Iter 9 subLoss 49832.3 multi 1.00 import weight 0.00
Epoch 198 Iter 10 subLoss 49915.6 multi 3.99 import weight 0.00
Epoch 198 Iter 11 subLoss 49595.0 multi 3.98 import weight 0.00
Epoch 198 Acc: 19.11 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 4959 train Loss: 50589.7 test Loss: 8501.8
Epoch 199 Iter 0 subLoss 49716.4 multi 1.00 import weight 0.00
Epoch 199 Iter 1 subLoss 49519.8 multi 1.00 import weight 0.00
Epoch 199 Iter 2 subLoss 49380.6 multi -4.97 import weight 0.00
Epoch 199 Iter 3 subLoss 49823.0 multi 1.00 import weight 0.00
Epoch 199 Iter 4 subLoss 49781.4 multi 1.00 import weight 0.00
Epoch 199 Iter 5 subLoss 49344.1 multi 6.97 import weight 0.00
Epoch 199 Iter 6 subLoss 49484.9 multi -1.99 import weight 0.00
Epoch 199 Iter 7 subLoss 49703.9 multi 1.00 import weight 0.00
Epoch 199 Iter 8 subLoss 49154.0 multi -4.97 import weight 0.00
Epoch 199 Iter 9 subLoss 49745.9 multi 1.00 import weight 0.00
Epoch 199 Iter 10 subLoss 49633.0 multi -4.97 import weight 0.00
Epoch 199 Iter 11 subLoss 49589.4 multi 3.99 import weight 0.00
Epoch 199 Acc: 19.11 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 4958 train Loss: 50562.9 test Loss: 8497.5
Epoch 200 Iter 0 subLoss 50032.0 multi 1.00 import weight 0.00
Epoch 200 Iter 1 subLoss 49232.6 multi 1.00 import weight 0.00
Epoch 200 Iter 2 subLoss 49766.9 multi 3.98 import weight 0.00
Epoch 200 Iter 3 subLoss 49268.2 multi -7.96 import weight 0.00
Epoch 200 Iter 4 subLoss 49399.6 multi -1.98 import weight 0.00
Epoch 200 Iter 5 subLoss 49731.1 multi 1.00 import weight 0.00
Epoch 200 Iter 6 subLoss 49657.1 multi 3.98 import weight 0.00
Epoch 200 Iter 7 subLoss 49504.7 multi -10.94 import weight 0.00
Epoch 200 Iter 8 subLoss 49657.9 multi 6.97 import weight 0.00
Epoch 200 Iter 9 subLoss 49796.5 multi 1.00 import weight 0.00
Epoch 200 Iter 10 subLoss 49303.4 multi 6.97 import weight 0.00
Epoch 200 Iter 11 subLoss 49450.9 multi 1.00 import weight 0.00
Epoch 200 Acc: 19.11 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4945 train Loss: 50328.4 test Loss: 8457.8
Epoch 201 Iter 0 subLoss 49266.1 multi -4.97 import weight 0.00
Epoch 201 Iter 1 subLoss 49614.4 multi 3.99 import weight 0.00
Epoch 201 Iter 2 subLoss 49314.2 multi -7.96 import weight 0.00
Epoch 201 Iter 3 subLoss 49407.4 multi -1.98 import weight 0.00
Epoch 201 Iter 4 subLoss 49745.1 multi 1.00 import weight 0.00
Epoch 201 Iter 5 subLoss 49722.2 multi -1.99 import weight 0.00
Epoch 201 Iter 6 subLoss 49615.7 multi 6.97 import weight 0.00
Epoch 201 Iter 7 subLoss 49382.3 multi -1.99 import weight 0.00
Epoch 201 Iter 8 subLoss 49389.6 multi 1.00 import weight 0.00
Epoch 201 Iter 9 subLoss 49419.1 multi -1.98 import weight 0.00
Epoch 201 Iter 10 subLoss 49863.9 multi 3.99 import weight 0.00
Epoch 201 Iter 11 subLoss 49279.7 multi 1.00 import weight 0.00
Epoch 201 Acc: 19.11 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4927 train Loss: 50336.7 test Loss: 8459.3
Epoch 202 Iter 0 subLoss 49272.9 multi 3.99 import weight 0.00
Epoch 202 Iter 1 subLoss 49094.0 multi 6.97 import weight 0.00
Epoch 202 Iter 2 subLoss 49295.0 multi 1.00 import weight 0.00
Epoch 202 Iter 3 subLoss 48923.0 multi 12.94 import weight 0.00
Epoch 202 Iter 4 subLoss 48782.6 multi 3.98 import weight 0.00
Epoch 202 Iter 5 subLoss 48766.0 multi 1.00 import weight 0.00
Epoch 202 Iter 6 subLoss 48773.8 multi 6.97 import weight 0.00
Epoch 202 Iter 7 subLoss 48782.4 multi 3.99 import weight 0.00
Epoch 202 Iter 8 subLoss 48759.7 multi -10.94 import weight 0.00
Epoch 202 Iter 9 subLoss 48903.9 multi 6.97 import weight 0.00
Epoch 202 Iter 10 subLoss 48736.6 multi -7.96 import weight 0.00
Epoch 202 Iter 11 subLoss 48766.4 multi 1.00 import weight 0.00
Epoch 202 Acc: 19.11 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4876 train Loss: 49752.1 test Loss: 8359.7
Epoch 203 Iter 0 subLoss 48741.8 multi -1.99 import weight 0.00
Epoch 203 Iter 1 subLoss 48775.6 multi 6.97 import weight 0.00
Epoch 203 Iter 2 subLoss 48657.2 multi -4.97 import weight 0.00
Epoch 203 Iter 3 subLoss 48763.8 multi 3.99 import weight 0.00
Epoch 203 Iter 4 subLoss 48807.0 multi 15.93 import weight 0.00
Epoch 203 Iter 5 subLoss 48594.9 multi 12.94 import weight 0.00
Epoch 203 Iter 6 subLoss 48443.0 multi 3.99 import weight 0.00
Epoch 203 Iter 7 subLoss 48492.8 multi -10.94 import weight 0.00
Epoch 203 Iter 8 subLoss 48441.5 multi 6.97 import weight 0.00
Epoch 203 Iter 9 subLoss 48519.9 multi 21.90 import weight 0.00
Epoch 203 Iter 10 subLoss 48394.8 multi -4.97 import weight 0.00
Epoch 203 Iter 11 subLoss 48324.1 multi -16.91 import weight 0.00
Epoch 203 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -16.91 Pidx 4832 train Loss: 49369.7 test Loss: 8295.1
Epoch 204 Iter 0 subLoss 48441.6 multi 9.96 import weight 0.00
Epoch 204 Iter 1 subLoss 48384.9 multi -7.96 import weight 0.00
Epoch 204 Iter 2 subLoss 48391.4 multi -4.97 import weight 0.00
Epoch 204 Iter 3 subLoss 48429.1 multi -4.97 import weight 0.00
Epoch 204 Iter 4 subLoss 48420.7 multi -1.98 import weight 0.00
Epoch 204 Iter 5 subLoss 48414.5 multi -1.99 import weight 0.00
Epoch 204 Iter 6 subLoss 48474.4 multi -25.87 import weight 0.00
Epoch 204 Iter 7 subLoss 48482.3 multi 18.91 import weight 0.00
Epoch 204 Iter 8 subLoss 48396.4 multi -1.99 import weight 0.00
Epoch 204 Iter 9 subLoss 48600.1 multi -7.96 import weight 0.00
Epoch 204 Iter 10 subLoss 48654.8 multi -1.99 import weight 0.00
Epoch 204 Iter 11 subLoss 48418.2 multi 1.00 import weight 0.00
Epoch 204 Acc: 19.11 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4841 train Loss: 49514.0 test Loss: 8320.7
Epoch 205 Iter 0 subLoss 48596.9 multi 15.93 import weight 0.00
Epoch 205 Iter 1 subLoss 48431.3 multi 1.00 import weight 0.00
Epoch 205 Iter 2 subLoss 48482.2 multi 21.90 import weight 0.00
Epoch 205 Iter 3 subLoss 48296.8 multi 15.93 import weight 1.00
Epoch 205 Iter 4 subLoss 48235.3 multi 1.00 import weight 0.00
Epoch 205 Iter 5 subLoss 48283.3 multi 1.00 import weight 0.00
Epoch 205 Iter 6 subLoss 48305.0 multi -28.85 import weight 0.00
Epoch 205 Iter 7 subLoss 48392.1 multi 1.00 import weight 0.00
Epoch 205 Iter 8 subLoss 48349.4 multi 21.90 import weight 0.00
Epoch 205 Iter 9 subLoss 48308.9 multi -25.87 import weight 0.00
Epoch 205 Iter 10 subLoss 48399.3 multi 3.98 import weight 0.00
Epoch 205 Iter 11 subLoss 48435.4 multi 3.99 import weight 0.00
Epoch 205 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 4843 train Loss: 49296.1 test Loss: 8282.4
Epoch 206 Iter 0 subLoss 48246.3 multi 36.82 import weight 1.00
Epoch 206 Iter 1 subLoss 48160.2 multi 3.98 import weight 0.00
Epoch 206 Iter 2 subLoss 48370.4 multi 1.00 import weight 0.00
Epoch 206 Iter 3 subLoss 48302.9 multi -22.88 import weight 0.00
Epoch 206 Iter 4 subLoss 48404.5 multi 1.00 import weight 0.00
Epoch 206 Iter 5 subLoss 48419.9 multi 1.00 import weight 0.00
Epoch 206 Iter 6 subLoss 48332.3 multi -19.90 import weight 0.00
Epoch 206 Iter 7 subLoss 48343.9 multi 21.90 import weight 0.00
Epoch 206 Iter 8 subLoss 48340.0 multi 24.88 import weight 0.00
Epoch 206 Iter 9 subLoss 48233.0 multi 3.98 import weight 0.00
Epoch 206 Iter 10 subLoss 48332.0 multi -16.91 import weight 0.00
Epoch 206 Iter 11 subLoss 48265.9 multi 3.98 import weight 0.00
Epoch 206 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 4826 train Loss: 49269.7 test Loss: 8277.5
Epoch 207 Iter 0 subLoss 48238.8 multi 6.97 import weight 0.00
Epoch 207 Iter 1 subLoss 48285.7 multi 3.99 import weight 0.00
Epoch 207 Iter 2 subLoss 48300.7 multi -19.90 import weight 0.00
Epoch 207 Iter 3 subLoss 48403.6 multi 3.99 import weight 0.00
Epoch 207 Iter 4 subLoss 48236.9 multi 9.96 import weight 0.00
Epoch 207 Iter 5 subLoss 48398.0 multi 6.97 import weight 0.00
Epoch 207 Iter 6 subLoss 48277.7 multi -10.94 import weight 0.00
Epoch 207 Iter 7 subLoss 48286.0 multi 3.99 import weight 0.00
Epoch 207 Iter 8 subLoss 48326.9 multi -13.93 import weight 0.00
Epoch 207 Iter 9 subLoss 48427.5 multi -7.96 import weight 0.00
Epoch 207 Iter 10 subLoss 48360.8 multi -7.96 import weight 0.00
Epoch 207 Iter 11 subLoss 48414.6 multi 1.00 import weight 0.00
Epoch 207 Acc: 19.65 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4841 train Loss: 49345.2 test Loss: 8290.9
Epoch 208 Iter 0 subLoss 48267.0 multi 6.97 import weight 0.00
Epoch 208 Iter 1 subLoss 48403.9 multi 3.98 import weight 0.00
Epoch 208 Iter 2 subLoss 48390.9 multi 9.96 import weight 0.00
Epoch 208 Iter 3 subLoss 48332.0 multi -16.91 import weight 0.00
Epoch 208 Iter 4 subLoss 48321.5 multi -10.94 import weight 0.00
Epoch 208 Iter 5 subLoss 48367.8 multi -4.97 import weight 0.00
Epoch 208 Iter 6 subLoss 48418.5 multi 1.00 import weight 0.00
Epoch 208 Iter 7 subLoss 48404.8 multi 3.99 import weight 0.00
Epoch 208 Iter 8 subLoss 48474.3 multi -22.88 import weight 0.00
Epoch 208 Iter 9 subLoss 48441.9 multi 6.97 import weight 0.00
Epoch 208 Iter 10 subLoss 48557.2 multi 3.99 import weight 0.00
Epoch 208 Iter 11 subLoss 48533.6 multi 9.96 import weight 0.00
Epoch 208 Acc: 19.65 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 4853 train Loss: 49360.3 test Loss: 8294.8
Epoch 209 Iter 0 subLoss 48436.1 multi 3.99 import weight 0.00
Epoch 209 Iter 1 subLoss 48311.0 multi -10.94 import weight 0.00
Epoch 209 Iter 2 subLoss 48464.4 multi 1.00 import weight 0.00
Epoch 209 Iter 3 subLoss 48393.0 multi 12.94 import weight 0.00
Epoch 209 Iter 4 subLoss 48294.8 multi 9.96 import weight 1.00
Epoch 209 Iter 5 subLoss 48300.4 multi -19.90 import weight 0.00
Epoch 209 Iter 6 subLoss 48426.7 multi -10.94 import weight 0.00
Epoch 209 Iter 7 subLoss 48409.0 multi 3.99 import weight 0.00
Epoch 209 Iter 8 subLoss 48327.7 multi -10.94 import weight 0.00
Epoch 209 Iter 9 subLoss 48544.1 multi 1.00 import weight 0.00
Epoch 209 Iter 10 subLoss 48441.9 multi 6.97 import weight 0.00
Epoch 209 Iter 11 subLoss 48482.4 multi 21.90 import weight 0.00
Epoch 209 Acc: 19.65 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 21.90 Pidx 4848 train Loss: 49303.1 test Loss: 8284.6
Epoch 210 Iter 0 subLoss 48336.6 multi -19.90 import weight 0.00
Epoch 210 Iter 1 subLoss 48511.4 multi 24.88 import weight 0.00
Epoch 210 Iter 2 subLoss 48259.6 multi -13.93 import weight 0.00
Epoch 210 Iter 3 subLoss 48300.1 multi -16.91 import weight 0.00
Epoch 210 Iter 4 subLoss 48335.6 multi -16.91 import weight 0.00
Epoch 210 Iter 5 subLoss 48395.2 multi 15.93 import weight 0.00
Epoch 210 Iter 6 subLoss 48366.1 multi -1.99 import weight 0.00
Epoch 210 Iter 7 subLoss 48299.2 multi 12.94 import weight 1.00
Epoch 210 Iter 8 subLoss 48341.2 multi 15.93 import weight 0.00
Epoch 210 Iter 9 subLoss 48376.1 multi -4.97 import weight 0.00
Epoch 210 Iter 10 subLoss 48250.8 multi -10.94 import weight 0.00
Epoch 210 Iter 11 subLoss 48265.8 multi 3.99 import weight 0.00
Epoch 210 Acc: 19.65 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 4826 train Loss: 49260.7 test Loss: 8277.0
Epoch 211 Iter 0 subLoss 48340.5 multi 18.91 import weight 0.00
Epoch 211 Iter 1 subLoss 48280.3 multi 6.97 import weight 0.00
Epoch 211 Iter 2 subLoss 48278.4 multi -13.93 import weight 0.00
Epoch 211 Iter 3 subLoss 48306.1 multi -16.91 import weight 0.00
Epoch 211 Iter 4 subLoss 48280.0 multi 6.97 import weight 0.00
Epoch 211 Iter 5 subLoss 48236.9 multi 12.94 import weight 0.00
Epoch 211 Iter 6 subLoss 48287.1 multi 9.96 import weight 0.00
Epoch 211 Iter 7 subLoss 48247.4 multi 27.87 import weight 1.00
Epoch 211 Iter 8 subLoss 48237.0 multi 15.93 import weight 0.00
Epoch 211 Iter 9 subLoss 48265.1 multi 6.97 import weight 0.00
Epoch 211 Iter 10 subLoss 48212.3 multi 21.90 import weight 0.00
Epoch 211 Iter 11 subLoss 48285.6 multi 12.94 import weight 0.00
Epoch 211 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 4828 train Loss: 49208.7 test Loss: 8266.7
Epoch 212 Iter 0 subLoss 48270.5 multi -13.93 import weight 0.00
Epoch 212 Iter 1 subLoss 48186.7 multi 9.96 import weight 0.00
Epoch 212 Iter 2 subLoss 48148.8 multi 1.00 import weight 0.00
Epoch 212 Iter 3 subLoss 48288.2 multi 12.94 import weight 1.00
Epoch 212 Iter 4 subLoss 48255.3 multi -10.94 import weight 0.00
Epoch 212 Iter 5 subLoss 48259.4 multi -7.96 import weight 0.00
Epoch 212 Iter 6 subLoss 48290.1 multi 1.00 import weight 1.00
Epoch 212 Iter 7 subLoss 48296.5 multi 3.98 import weight 1.00
Epoch 212 Iter 8 subLoss 48275.8 multi -10.94 import weight 0.00
Epoch 212 Iter 9 subLoss 48221.0 multi -10.94 import weight 0.00
Epoch 212 Iter 10 subLoss 48290.5 multi 6.97 import weight 1.00
Epoch 212 Iter 11 subLoss 48252.1 multi -4.97 import weight 0.00
Epoch 212 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 4825 train Loss: 49210.4 test Loss: 8267.8
Epoch 213 Iter 0 subLoss 48269.4 multi 1.00 import weight 0.00
Epoch 213 Iter 1 subLoss 48193.2 multi 18.91 import weight 0.00
Epoch 213 Iter 2 subLoss 48265.9 multi 3.99 import weight 0.00
Epoch 213 Iter 3 subLoss 48239.2 multi 15.93 import weight 0.00
Epoch 213 Iter 4 subLoss 48264.6 multi 6.97 import weight 0.00
Epoch 213 Iter 5 subLoss 48251.8 multi -1.99 import weight 0.00
Epoch 213 Iter 6 subLoss 48285.4 multi 12.94 import weight 0.00
Epoch 213 Iter 7 subLoss 48289.2 multi 15.93 import weight 0.00
Epoch 213 Iter 8 subLoss 48261.0 multi 6.97 import weight 1.00
Epoch 213 Iter 9 subLoss 48271.9 multi -19.90 import weight 0.00
Epoch 213 Iter 10 subLoss 48214.6 multi 24.88 import weight 0.00
Epoch 213 Iter 11 subLoss 48218.2 multi 27.87 import weight 0.00
Epoch 213 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 27.87 Pidx 4821 train Loss: 49206.3 test Loss: 8266.4
Epoch 214 Iter 0 subLoss 48229.4 multi -13.93 import weight 0.00
Epoch 214 Iter 1 subLoss 48252.9 multi 1.00 import weight 0.00
Epoch 214 Iter 2 subLoss 48339.7 multi -13.93 import weight 0.00
Epoch 214 Iter 3 subLoss 48256.0 multi 3.98 import weight 0.00
Epoch 214 Iter 4 subLoss 48284.8 multi 15.93 import weight 1.00
Epoch 214 Iter 5 subLoss 48276.6 multi -16.91 import weight 0.00
Epoch 214 Iter 6 subLoss 48219.7 multi 30.85 import weight 0.00
Epoch 214 Iter 7 subLoss 48277.7 multi -13.93 import weight 0.00
Epoch 214 Iter 8 subLoss 48227.1 multi -13.93 import weight 0.00
Epoch 214 Iter 9 subLoss 48227.4 multi -10.94 import weight 0.00
Epoch 214 Iter 10 subLoss 48294.5 multi 1.00 import weight 1.00
Epoch 214 Iter 11 subLoss 48333.2 multi -10.94 import weight 0.00
Epoch 214 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -10.94 Pidx 4833 train Loss: 49276.7 test Loss: 8283.0
Epoch 215 Iter 0 subLoss 48325.6 multi -7.96 import weight 0.00
Epoch 215 Iter 1 subLoss 48418.5 multi -1.98 import weight 0.00
Epoch 215 Iter 2 subLoss 48337.6 multi -10.94 import weight 0.00
Epoch 215 Iter 3 subLoss 48412.4 multi 1.00 import weight 0.00
Epoch 215 Iter 4 subLoss 48380.8 multi -10.94 import weight 0.00
Epoch 215 Iter 5 subLoss 48354.8 multi -10.94 import weight 0.00
Epoch 215 Iter 6 subLoss 48469.6 multi 3.98 import weight 0.00
Epoch 215 Iter 7 subLoss 48432.3 multi 3.98 import weight 0.00
Epoch 215 Iter 8 subLoss 48283.6 multi 12.94 import weight 1.00
Epoch 215 Iter 9 subLoss 48379.6 multi -1.99 import weight 0.00
Epoch 215 Iter 10 subLoss 48292.9 multi 1.00 import weight 1.00
Epoch 215 Iter 11 subLoss 48338.7 multi -7.96 import weight 0.00
Epoch 215 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 4833 train Loss: 49352.4 test Loss: 8298.4
Epoch 216 Iter 0 subLoss 48390.3 multi 15.93 import weight 0.00
Epoch 216 Iter 1 subLoss 48414.7 multi 3.99 import weight 0.00
Epoch 216 Iter 2 subLoss 48325.0 multi -4.97 import weight 0.00
Epoch 216 Iter 3 subLoss 48306.2 multi -28.85 import weight 0.00
Epoch 216 Iter 4 subLoss 48452.8 multi -19.90 import weight 0.00
Epoch 216 Iter 5 subLoss 48482.9 multi 24.88 import weight 0.00
Epoch 216 Iter 6 subLoss 48435.6 multi 6.97 import weight 0.00
Epoch 216 Iter 7 subLoss 48345.6 multi 9.96 import weight 0.00
Epoch 216 Iter 8 subLoss 48331.6 multi -7.96 import weight 0.00
Epoch 216 Iter 9 subLoss 48288.8 multi 15.93 import weight 1.00
Epoch 216 Iter 10 subLoss 48247.2 multi 24.88 import weight 0.00
Epoch 216 Iter 11 subLoss 48323.8 multi -1.98 import weight 0.00
Epoch 216 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 4832 train Loss: 49255.6 test Loss: 8278.4
Epoch 217 Iter 0 subLoss 48333.7 multi -7.96 import weight 0.00
Epoch 217 Iter 1 subLoss 48294.8 multi 1.00 import weight 1.00
Epoch 217 Iter 2 subLoss 48385.4 multi -10.94 import weight 0.00
Epoch 217 Iter 3 subLoss 48351.8 multi -10.94 import weight 0.00
Epoch 217 Iter 4 subLoss 48360.2 multi -4.97 import weight 0.00
Epoch 217 Iter 5 subLoss 48290.5 multi 3.99 import weight 1.00
Epoch 217 Iter 6 subLoss 48472.5 multi -25.87 import weight 0.00
Epoch 217 Iter 7 subLoss 48257.0 multi 3.99 import weight 0.00
Epoch 217 Iter 8 subLoss 48522.2 multi -25.87 import weight 0.00
Epoch 217 Iter 9 subLoss 48420.2 multi -16.91 import weight 0.00
Epoch 217 Iter 10 subLoss 48887.1 multi 24.88 import weight 0.00
Epoch 217 Iter 11 subLoss 48517.9 multi 27.87 import weight 0.00
Epoch 217 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 27.87 Pidx 4851 train Loss: 49324.5 test Loss: 8292.8
Epoch 218 Iter 0 subLoss 48200.2 multi 9.96 import weight 0.00
Epoch 218 Iter 1 subLoss 48371.9 multi -1.99 import weight 0.00
Epoch 218 Iter 2 subLoss 48342.7 multi 6.97 import weight 0.00
Epoch 218 Iter 3 subLoss 48316.4 multi -19.90 import weight 0.00
Epoch 218 Iter 4 subLoss 48296.1 multi 6.97 import weight 1.00
Epoch 218 Iter 5 subLoss 48437.3 multi 6.97 import weight 0.00
Epoch 218 Iter 6 subLoss 48377.1 multi 1.00 import weight 0.00
Epoch 218 Iter 7 subLoss 48460.1 multi 3.99 import weight 0.00
Epoch 218 Iter 8 subLoss 48343.9 multi 9.96 import weight 0.00
Epoch 218 Iter 9 subLoss 48292.4 multi 9.96 import weight 1.00
Epoch 218 Iter 10 subLoss 48332.9 multi -4.97 import weight 0.00
Epoch 218 Iter 11 subLoss 48346.5 multi 9.96 import weight 0.00
Epoch 218 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 4834 train Loss: 49256.3 test Loss: 8278.8
Epoch 219 Iter 0 subLoss 48257.4 multi 6.97 import weight 0.00
Epoch 219 Iter 1 subLoss 48320.5 multi -1.99 import weight 0.00
Epoch 219 Iter 2 subLoss 48324.3 multi 1.00 import weight 0.00
Epoch 219 Iter 3 subLoss 48367.9 multi -1.98 import weight 0.00
Epoch 219 Iter 4 subLoss 48253.6 multi 9.96 import weight 0.00
Epoch 219 Iter 5 subLoss 48267.4 multi -4.97 import weight 0.00
Epoch 219 Iter 6 subLoss 48325.6 multi 3.99 import weight 0.00
Epoch 219 Iter 7 subLoss 48221.3 multi -7.96 import weight 0.00
Epoch 219 Iter 8 subLoss 48252.1 multi 12.94 import weight 0.00
Epoch 219 Iter 9 subLoss 48342.8 multi 12.94 import weight 0.00
Epoch 219 Iter 10 subLoss 48284.1 multi 18.91 import weight 0.00
Epoch 219 Iter 11 subLoss 48249.6 multi 27.87 import weight 0.00
Epoch 219 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 27.87 Pidx 4824 train Loss: 49210.4 test Loss: 8267.6
Epoch 220 Iter 0 subLoss 48275.3 multi -13.93 import weight 0.00
Epoch 220 Iter 1 subLoss 48257.5 multi 12.94 import weight 0.00
Epoch 220 Iter 2 subLoss 48244.7 multi 30.85 import weight 0.00
Epoch 220 Iter 3 subLoss 48217.1 multi 30.85 import weight 0.00
Epoch 220 Iter 4 subLoss 48227.9 multi -7.96 import weight 0.00
Epoch 220 Iter 5 subLoss 48281.6 multi 18.91 import weight 0.00
Epoch 220 Iter 6 subLoss 48194.5 multi 21.90 import weight 0.00
Epoch 220 Iter 7 subLoss 48181.0 multi 12.94 import weight 0.00
Epoch 220 Iter 8 subLoss 48261.8 multi -7.96 import weight 0.00
Epoch 220 Iter 9 subLoss 48268.6 multi -4.97 import weight 0.00
Epoch 220 Iter 10 subLoss 48281.2 multi 21.90 import weight 0.00
Epoch 220 Iter 11 subLoss 48267.8 multi -1.98 import weight 0.00
Epoch 220 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 4826 train Loss: 49204.2 test Loss: 8264.5
Epoch 221 Iter 0 subLoss 48260.5 multi 1.00 import weight 0.00
Epoch 221 Iter 1 subLoss 48327.3 multi 6.97 import weight 0.00
Epoch 221 Iter 2 subLoss 48238.4 multi 3.98 import weight 0.00
Epoch 221 Iter 3 subLoss 48255.1 multi 12.94 import weight 0.00
Epoch 221 Iter 4 subLoss 48246.1 multi 30.85 import weight 0.00
Epoch 221 Iter 5 subLoss 48216.9 multi 33.84 import weight 0.00
Epoch 221 Iter 6 subLoss 48228.4 multi -7.96 import weight 0.00
Epoch 221 Iter 7 subLoss 48255.3 multi 12.94 import weight 1.00
Epoch 221 Iter 8 subLoss 48229.1 multi -4.97 import weight 0.00
Epoch 221 Iter 9 subLoss 48250.7 multi 15.93 import weight 1.00
Epoch 221 Iter 10 subLoss 48262.7 multi -4.97 import weight 0.00
Epoch 221 Iter 11 subLoss 48224.0 multi -1.99 import weight 0.00
Epoch 221 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 4822 train Loss: 49210.5 test Loss: 8265.5
Epoch 222 Iter 0 subLoss 48240.0 multi 33.84 import weight 0.00
Epoch 222 Iter 1 subLoss 48254.7 multi 15.93 import weight 1.00
Epoch 222 Iter 2 subLoss 48209.2 multi 9.96 import weight 0.00
Epoch 222 Iter 3 subLoss 48250.4 multi 18.91 import weight 1.00
Epoch 222 Iter 4 subLoss 48266.8 multi -7.96 import weight 0.00
Epoch 222 Iter 5 subLoss 48230.3 multi -1.99 import weight 0.00
Epoch 222 Iter 6 subLoss 48217.8 multi 33.84 import weight 0.00
Epoch 222 Iter 7 subLoss 48216.1 multi 36.82 import weight 0.00
Epoch 222 Iter 8 subLoss 48264.6 multi -4.97 import weight 0.00
Epoch 222 Iter 9 subLoss 48252.8 multi 21.90 import weight 1.00
Epoch 222 Iter 10 subLoss 48277.1 multi -31.84 import weight 0.00
Epoch 222 Iter 11 subLoss 48375.1 multi 1.00 import weight 0.00
Epoch 222 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4837 train Loss: 49229.9 test Loss: 8270.7
Epoch 223 Iter 0 subLoss 48252.6 multi 24.88 import weight 1.00
Epoch 223 Iter 1 subLoss 48320.2 multi 9.96 import weight 0.00
Epoch 223 Iter 2 subLoss 48264.5 multi -7.96 import weight 0.00
Epoch 223 Iter 3 subLoss 48197.1 multi 21.90 import weight 0.00
Epoch 223 Iter 4 subLoss 48255.3 multi 27.87 import weight 1.00
Epoch 223 Iter 5 subLoss 48289.3 multi 21.90 import weight 0.00
Epoch 223 Iter 6 subLoss 48251.6 multi 30.85 import weight 1.00
Epoch 223 Iter 7 subLoss 48241.3 multi 33.84 import weight 0.00
Epoch 223 Iter 8 subLoss 48224.0 multi -4.97 import weight 0.00
Epoch 223 Iter 9 subLoss 48227.9 multi -1.99 import weight 0.00
Epoch 223 Iter 10 subLoss 48233.6 multi -4.97 import weight 0.00
Epoch 223 Iter 11 subLoss 48269.2 multi -10.94 import weight 0.00
Epoch 223 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -10.94 Pidx 4826 train Loss: 49202.4 test Loss: 8265.0
Epoch 224 Iter 0 subLoss 48245.6 multi 33.84 import weight 0.00
Epoch 224 Iter 1 subLoss 48305.8 multi -37.81 import weight 0.00
Epoch 224 Iter 2 subLoss 48199.4 multi 24.88 import weight 0.00
Epoch 224 Iter 3 subLoss 48321.1 multi 12.94 import weight 0.00
Epoch 224 Iter 4 subLoss 48277.0 multi -34.82 import weight 0.00
Epoch 224 Iter 5 subLoss 48267.5 multi -7.96 import weight 0.00
Epoch 224 Iter 6 subLoss 48293.3 multi 1.00 import weight 0.00
Epoch 224 Iter 7 subLoss 48280.1 multi 21.90 import weight 0.00
Epoch 224 Iter 8 subLoss 48214.1 multi 39.81 import weight 0.00
Epoch 224 Iter 9 subLoss 48245.1 multi 36.82 import weight 0.00
Epoch 224 Iter 10 subLoss 48264.6 multi -4.97 import weight 0.00
Epoch 224 Iter 11 subLoss 48282.1 multi 24.88 import weight 0.00
Epoch 224 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 24.88 Pidx 4828 train Loss: 49207.7 test Loss: 8267.1
Epoch 225 Iter 0 subLoss 48256.5 multi 24.88 import weight 1.00
Epoch 225 Iter 1 subLoss 48263.2 multi -4.97 import weight 0.00
Epoch 225 Iter 2 subLoss 48230.9 multi -1.99 import weight 0.00
Epoch 225 Iter 3 subLoss 48219.6 multi 42.79 import weight 0.00
Epoch 225 Iter 4 subLoss 48191.1 multi 27.87 import weight 0.00
Epoch 225 Iter 5 subLoss 48289.3 multi 27.87 import weight 0.00
Epoch 225 Iter 6 subLoss 48288.7 multi 30.85 import weight 0.00
Epoch 225 Iter 7 subLoss 48251.9 multi 27.87 import weight 1.00
Epoch 225 Iter 8 subLoss 48226.3 multi -4.97 import weight 0.00
Epoch 225 Iter 9 subLoss 48263.0 multi -4.97 import weight 0.00
Epoch 225 Iter 10 subLoss 48260.7 multi -1.99 import weight 1.00
Epoch 225 Iter 11 subLoss 48218.5 multi 45.78 import weight 0.00
Epoch 225 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 45.78 Pidx 4821 train Loss: 49211.6 test Loss: 8265.1
Epoch 226 Iter 0 subLoss 48308.0 multi -37.81 import weight 0.00
Epoch 226 Iter 1 subLoss 48317.2 multi -22.88 import weight 0.00
Epoch 226 Iter 2 subLoss 48302.8 multi -34.82 import weight 0.00
Epoch 226 Iter 3 subLoss 48309.5 multi -31.84 import weight 0.00
Epoch 226 Iter 4 subLoss 48455.5 multi -16.91 import weight 0.00
Epoch 226 Iter 5 subLoss 48489.8 multi 24.88 import weight 0.00
Epoch 226 Iter 6 subLoss 48339.6 multi -19.90 import weight 0.00
Epoch 226 Iter 7 subLoss 48626.2 multi 3.98 import weight 0.00
Epoch 226 Iter 8 subLoss 48552.2 multi 3.99 import weight 0.00
Epoch 226 Iter 9 subLoss 48472.3 multi -25.87 import weight 0.00
Epoch 226 Iter 10 subLoss 48727.8 multi 15.93 import weight 0.00
Epoch 226 Iter 11 subLoss 48499.0 multi -22.88 import weight 0.00
Epoch 226 Acc: 20.08 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -22.88 Pidx 4849 train Loss: 49615.0 test Loss: 8325.1
Epoch 227 Iter 0 subLoss 48655.4 multi 1.00 import weight 0.00
Epoch 227 Iter 1 subLoss 48732.1 multi -7.96 import weight 0.00
Epoch 227 Iter 2 subLoss 48728.0 multi 18.91 import weight 0.00
Epoch 227 Iter 3 subLoss 48479.7 multi -22.88 import weight 0.00
Epoch 227 Iter 4 subLoss 48621.2 multi 6.97 import weight 0.00
Epoch 227 Iter 5 subLoss 48598.5 multi 18.91 import weight 0.00
Epoch 227 Iter 6 subLoss 48504.2 multi -4.97 import weight 0.00
Epoch 227 Iter 7 subLoss 48554.0 multi 6.97 import weight 0.00
Epoch 227 Iter 8 subLoss 48442.7 multi 1.00 import weight 0.00
Epoch 227 Iter 9 subLoss 48378.4 multi 3.99 import weight 0.00
Epoch 227 Iter 10 subLoss 48408.0 multi 1.00 import weight 0.00
Epoch 227 Iter 11 subLoss 48581.2 multi 21.90 import weight 0.00
Epoch 227 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 21.90 Pidx 4858 train Loss: 49299.0 test Loss: 8276.8
Epoch 228 Iter 0 subLoss 48396.3 multi 15.93 import weight 0.00
Epoch 228 Iter 1 subLoss 48333.2 multi -16.91 import weight 0.00
Epoch 228 Iter 2 subLoss 48383.7 multi -19.90 import weight 0.00
Epoch 228 Iter 3 subLoss 48428.1 multi -13.93 import weight 0.00
Epoch 228 Iter 4 subLoss 48213.3 multi 48.76 import weight 0.00
Epoch 228 Iter 5 subLoss 48367.1 multi 1.00 import weight 0.00
Epoch 228 Iter 6 subLoss 48369.9 multi 3.99 import weight 0.00
Epoch 228 Iter 7 subLoss 48427.2 multi -10.94 import weight 0.00
Epoch 228 Iter 8 subLoss 48321.0 multi 12.94 import weight 0.00
Epoch 228 Iter 9 subLoss 48324.3 multi 15.93 import weight 0.00
Epoch 228 Iter 10 subLoss 48290.6 multi -7.96 import weight 0.00
Epoch 228 Iter 11 subLoss 48321.4 multi 18.91 import weight 0.00
Epoch 228 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 18.91 Pidx 4832 train Loss: 49256.2 test Loss: 8271.3
Epoch 229 Iter 0 subLoss 48292.3 multi -4.97 import weight 0.00
Epoch 229 Iter 1 subLoss 48307.9 multi -34.82 import weight 0.00
Epoch 229 Iter 2 subLoss 48420.1 multi -7.96 import weight 0.00
Epoch 229 Iter 3 subLoss 48428.8 multi -4.97 import weight 0.00
Epoch 229 Iter 4 subLoss 48508.1 multi -1.99 import weight 0.00
Epoch 229 Iter 5 subLoss 48352.7 multi -19.90 import weight 0.00
Epoch 229 Iter 6 subLoss 48412.8 multi 3.99 import weight 0.00
Epoch 229 Iter 7 subLoss 48346.1 multi 9.96 import weight 0.00
Epoch 229 Iter 8 subLoss 48385.9 multi -16.91 import weight 0.00
Epoch 229 Iter 9 subLoss 48678.0 multi -10.94 import weight 0.00
Epoch 229 Iter 10 subLoss 48669.8 multi 1.00 import weight 0.00
Epoch 229 Iter 11 subLoss 48577.2 multi -19.90 import weight 0.00
Epoch 229 Acc: 20.08 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -19.90 Pidx 4857 train Loss: 49741.0 test Loss: 8346.9
Epoch 230 Iter 0 subLoss 48959.7 multi 9.96 import weight 0.00
Epoch 230 Iter 1 subLoss 48548.7 multi 3.99 import weight 0.00
Epoch 230 Iter 2 subLoss 48624.0 multi 9.96 import weight 0.00
Epoch 230 Iter 3 subLoss 48432.0 multi -1.99 import weight 0.00
Epoch 230 Iter 4 subLoss 48547.3 multi 6.97 import weight 0.00
Epoch 230 Iter 5 subLoss 48570.7 multi -16.91 import weight 0.00
Epoch 230 Iter 6 subLoss 48445.9 multi 1.00 import weight 0.00
Epoch 230 Iter 7 subLoss 48760.8 multi 6.97 import weight 0.00
Epoch 230 Iter 8 subLoss 48542.3 multi 9.96 import weight 0.00
Epoch 230 Iter 9 subLoss 48502.6 multi 1.00 import weight 0.00
Epoch 230 Iter 10 subLoss 48471.4 multi -19.90 import weight 0.00
Epoch 230 Iter 11 subLoss 48469.0 multi 3.99 import weight 0.00
Epoch 230 Acc: 20.08 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 4846 train Loss: 49510.8 test Loss: 8310.7
Epoch 231 Iter 0 subLoss 48547.6 multi 12.94 import weight 0.00
Epoch 231 Iter 1 subLoss 48470.3 multi -19.90 import weight 0.00
Epoch 231 Iter 2 subLoss 48567.7 multi -19.90 import weight 0.00
Epoch 231 Iter 3 subLoss 48885.2 multi 27.87 import weight 0.00
Epoch 231 Iter 4 subLoss 48430.0 multi -4.97 import weight 0.00
Epoch 231 Iter 5 subLoss 48469.6 multi 6.97 import weight 0.00
Epoch 231 Iter 6 subLoss 48419.7 multi 6.97 import weight 0.00
Epoch 231 Iter 7 subLoss 48430.1 multi -1.99 import weight 0.00
Epoch 231 Iter 8 subLoss 48449.3 multi 1.00 import weight 0.00
Epoch 231 Iter 9 subLoss 48328.3 multi 21.90 import weight 0.00
Epoch 231 Iter 10 subLoss 48351.2 multi -19.90 import weight 0.00
Epoch 231 Iter 11 subLoss 48397.9 multi 12.94 import weight 0.00
Epoch 231 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 4839 train Loss: 49331.3 test Loss: 8282.6
Epoch 232 Iter 0 subLoss 48308.2 multi -31.84 import weight 0.00
Epoch 232 Iter 1 subLoss 48541.9 multi 15.93 import weight 0.00
Epoch 232 Iter 2 subLoss 48356.1 multi -16.91 import weight 0.00
Epoch 232 Iter 3 subLoss 48445.2 multi 3.98 import weight 0.00
Epoch 232 Iter 4 subLoss 48324.8 multi 24.88 import weight 0.00
Epoch 232 Iter 5 subLoss 48376.7 multi 1.00 import weight 0.00
Epoch 232 Iter 6 subLoss 48328.9 multi 27.87 import weight 0.00
Epoch 232 Iter 7 subLoss 48374.7 multi 3.98 import weight 0.00
Epoch 232 Iter 8 subLoss 48371.9 multi 6.97 import weight 0.00
Epoch 232 Iter 9 subLoss 48282.6 multi 33.84 import weight 0.00
Epoch 232 Iter 10 subLoss 48147.6 multi 3.99 import weight 0.00
Epoch 232 Iter 11 subLoss 48302.6 multi -28.85 import weight 0.00
Epoch 232 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -28.85 Pidx 4830 train Loss: 49256.0 test Loss: 8269.9
Epoch 233 Iter 0 subLoss 48291.9 multi -4.97 import weight 0.00
Epoch 233 Iter 1 subLoss 48287.6 multi 36.82 import weight 0.00
Epoch 233 Iter 2 subLoss 48237.9 multi -1.99 import weight 0.00
Epoch 233 Iter 3 subLoss 48305.1 multi -28.85 import weight 0.00
Epoch 233 Iter 4 subLoss 48391.0 multi 15.93 import weight 0.00
Epoch 233 Iter 5 subLoss 48334.6 multi -31.84 import weight 0.00
Epoch 233 Iter 6 subLoss 48290.8 multi -4.97 import weight 0.00
Epoch 233 Iter 7 subLoss 48436.7 multi 1.00 import weight 0.00
Epoch 233 Iter 8 subLoss 48346.8 multi 9.96 import weight 0.00
Epoch 233 Iter 9 subLoss 48329.8 multi 30.85 import weight 0.00
Epoch 233 Iter 10 subLoss 48262.1 multi 1.00 import weight 1.00
Epoch 233 Iter 11 subLoss 48314.3 multi -37.81 import weight 0.00
Epoch 233 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -37.81 Pidx 4831 train Loss: 49281.8 test Loss: 8272.9
Epoch 234 Iter 0 subLoss 48373.2 multi 9.96 import weight 0.00
Epoch 234 Iter 1 subLoss 48289.1 multi 39.81 import weight 0.00
Epoch 234 Iter 2 subLoss 48273.0 multi -49.75 import weight 0.00
Epoch 234 Iter 3 subLoss 48313.7 multi -34.82 import weight 0.00
Epoch 234 Iter 4 subLoss 48244.0 multi 33.84 import weight 0.00
Epoch 234 Iter 5 subLoss 48248.5 multi 36.82 import weight 0.00
Epoch 234 Iter 6 subLoss 48274.4 multi -46.76 import weight 0.00
Epoch 234 Iter 7 subLoss 48329.1 multi 27.87 import weight 0.00
Epoch 234 Iter 8 subLoss 48322.9 multi 30.85 import weight 0.00
Epoch 234 Iter 9 subLoss 48244.2 multi 39.81 import weight 0.00
Epoch 234 Iter 10 subLoss 48325.1 multi 33.84 import weight 0.00
Epoch 234 Iter 11 subLoss 48256.3 multi 21.90 import weight 1.00
Epoch 234 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 21.90 Pidx 4825 train Loss: 49203.8 test Loss: 8264.3
Epoch 235 Iter 0 subLoss 48254.7 multi 24.88 import weight 1.00
Epoch 235 Iter 1 subLoss 48245.3 multi 42.79 import weight 0.00
Epoch 235 Iter 2 subLoss 48255.2 multi 24.88 import weight 1.00
Epoch 235 Iter 3 subLoss 48246.3 multi 45.78 import weight 0.00
Epoch 235 Iter 4 subLoss 48207.1 multi 3.98 import weight 0.00
Epoch 235 Iter 5 subLoss 48229.6 multi -7.96 import weight 0.00
Epoch 235 Iter 6 subLoss 48255.9 multi 24.88 import weight 1.00
Epoch 235 Iter 7 subLoss 48222.0 multi -4.97 import weight 0.00
Epoch 235 Iter 8 subLoss 48205.4 multi 6.97 import weight 0.00
Epoch 235 Iter 9 subLoss 48278.8 multi -43.78 import weight 0.00
Epoch 235 Iter 10 subLoss 48255.2 multi 27.87 import weight 1.00
Epoch 235 Iter 11 subLoss 48264.6 multi -10.94 import weight 0.00
Epoch 235 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -10.94 Pidx 4826 train Loss: 49207.6 test Loss: 8265.5
Epoch 236 Iter 0 subLoss 48298.1 multi -4.97 import weight 0.00
Epoch 236 Iter 1 subLoss 48263.0 multi -7.96 import weight 0.00
Epoch 236 Iter 2 subLoss 48198.9 multi 30.85 import weight 0.00
Epoch 236 Iter 3 subLoss 48217.4 multi 45.78 import weight 0.00
Epoch 236 Iter 4 subLoss 48251.1 multi 30.85 import weight 1.00
Epoch 236 Iter 5 subLoss 48246.8 multi 48.76 import weight 0.00
Epoch 236 Iter 6 subLoss 48266.3 multi -7.96 import weight 0.00
Epoch 236 Iter 7 subLoss 48247.9 multi 51.75 import weight 0.00
Epoch 236 Iter 8 subLoss 48293.2 multi -1.98 import weight 0.00
Epoch 236 Iter 9 subLoss 48221.1 multi -4.97 import weight 0.00
Epoch 236 Iter 10 subLoss 48222.1 multi -1.98 import weight 0.00
Epoch 236 Iter 11 subLoss 48229.1 multi 1.00 import weight 0.00
Epoch 236 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4822 train Loss: 49202.9 test Loss: 8264.0
Epoch 237 Iter 0 subLoss 48234.1 multi -13.93 import weight 0.00
Epoch 237 Iter 1 subLoss 48218.1 multi 48.76 import weight 0.00
Epoch 237 Iter 2 subLoss 48229.0 multi 1.00 import weight 0.00
Epoch 237 Iter 3 subLoss 48306.6 multi -34.82 import weight 0.00
Epoch 237 Iter 4 subLoss 48291.9 multi 1.00 import weight 0.00
Epoch 237 Iter 5 subLoss 48293.6 multi 3.99 import weight 0.00
Epoch 237 Iter 6 subLoss 48270.7 multi -49.75 import weight 0.00
Epoch 237 Iter 7 subLoss 48396.2 multi 18.91 import weight 0.00
Epoch 237 Iter 8 subLoss 48271.9 multi -46.76 import weight 0.00
Epoch 237 Iter 9 subLoss 48279.2 multi -43.78 import weight 0.00
Epoch 237 Iter 10 subLoss 48515.7 multi 21.90 import weight 0.00
Epoch 237 Iter 11 subLoss 48338.7 multi -40.79 import weight 0.00
Epoch 237 Acc: 19.65 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -40.79 Pidx 4833 train Loss: 49506.6 test Loss: 8314.7
Epoch 238 Iter 0 subLoss 48364.8 multi -1.98 import weight 0.00
Epoch 238 Iter 1 subLoss 48635.7 multi -7.96 import weight 0.00
Epoch 238 Iter 2 subLoss 48670.7 multi -10.94 import weight 0.00
Epoch 238 Iter 3 subLoss 48843.0 multi 1.00 import weight 0.00
Epoch 238 Iter 4 subLoss 48914.3 multi -16.91 import weight 0.00
Epoch 238 Iter 5 subLoss 49102.7 multi -1.99 import weight 0.00
Epoch 238 Iter 6 subLoss 49180.4 multi -4.97 import weight 0.00
Epoch 238 Iter 7 subLoss 48944.7 multi 1.00 import weight 0.00
Epoch 238 Iter 8 subLoss 48849.8 multi 3.99 import weight 0.00
Epoch 238 Iter 9 subLoss 48796.9 multi -16.91 import weight 0.00
Epoch 238 Iter 10 subLoss 49488.2 multi 1.00 import weight 0.00
Epoch 238 Iter 11 subLoss 49496.5 multi 9.96 import weight 0.00
Epoch 238 Acc: 19.65 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 4949 train Loss: 50036.0 test Loss: 8404.3
Epoch 239 Iter 0 subLoss 49173.2 multi 3.99 import weight 0.00
Epoch 239 Iter 1 subLoss 48989.1 multi -1.98 import weight 0.00
Epoch 239 Iter 2 subLoss 48837.3 multi 3.98 import weight 0.00
Epoch 239 Iter 3 subLoss 48697.5 multi -7.96 import weight 0.00
Epoch 239 Iter 4 subLoss 49308.8 multi 6.97 import weight 0.00
Epoch 239 Iter 5 subLoss 48758.1 multi -10.94 import weight 0.00
Epoch 239 Iter 6 subLoss 49051.8 multi 12.94 import weight 0.00
Epoch 239 Iter 7 subLoss 48766.1 multi 6.97 import weight 0.00
Epoch 239 Iter 8 subLoss 48840.3 multi 3.99 import weight 0.00
Epoch 239 Iter 9 subLoss 48831.7 multi 6.97 import weight 0.00
Epoch 239 Iter 10 subLoss 48656.3 multi 3.99 import weight 0.00
Epoch 239 Iter 11 subLoss 48566.6 multi -16.91 import weight 0.00
Epoch 239 Acc: 19.65 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -16.91 Pidx 4856 train Loss: 49686.0 test Loss: 8344.3
Epoch 240 Iter 0 subLoss 48750.7 multi -7.96 import weight 0.00
Epoch 240 Iter 1 subLoss 63618868.0 multi 6.97 import weight 0.00
Epoch 240 Iter 2 subLoss 2661027328.0 multi 9.96 import weight 0.00
Epoch 240 Iter 3 subLoss 5386082304.0 multi 12.94 import weight 0.00
Epoch 240 Iter 4 subLoss 48395.0 multi 21.90 import weight 0.00
Epoch 240 Iter 5 subLoss 48341.8 multi 9.96 import weight 0.00
Epoch 240 Iter 6 subLoss 48288.5 multi 24.88 import weight 0.00
Epoch 240 Iter 7 subLoss 48253.6 multi 27.87 import weight 1.00
Epoch 240 Iter 8 subLoss 48288.2 multi 27.87 import weight 0.00
Epoch 240 Iter 9 subLoss 48225.6 multi 3.99 import weight 0.00
Epoch 240 Iter 10 subLoss 48182.0 multi 15.93 import weight 0.00
Epoch 240 Iter 11 subLoss 48280.5 multi 30.85 import weight 0.00
Epoch 240 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 30.85 Pidx 4828 train Loss: 185378454.3 test Loss: 8264.6
Epoch 241 Iter 0 subLoss 48248.5 multi 51.75 import weight 0.00
Epoch 241 Iter 1 subLoss 48264.6 multi -7.96 import weight 0.00
Epoch 241 Iter 2 subLoss 48183.3 multi 18.91 import weight 0.00
Epoch 241 Iter 3 subLoss 48219.3 multi 51.75 import weight 0.00
Epoch 241 Iter 4 subLoss 48273.0 multi -43.78 import weight 0.00
Epoch 241 Iter 5 subLoss 48256.4 multi 27.87 import weight 1.00
Epoch 241 Iter 6 subLoss 48231.5 multi -16.91 import weight 0.00
Epoch 241 Iter 7 subLoss 48314.6 multi -34.82 import weight 0.00
Epoch 241 Iter 8 subLoss 48345.9 multi 12.94 import weight 0.00
Epoch 241 Iter 9 subLoss 48271.7 multi -40.79 import weight 0.00
Epoch 241 Iter 10 subLoss 48351.9 multi -22.88 import weight 0.00
Epoch 241 Iter 11 subLoss 48369.3 multi -1.99 import weight 0.00
Epoch 241 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 4836 train Loss: 13872019.3 test Loss: 8286.1
Epoch 242 Iter 0 subLoss 48343.0 multi 15.93 import weight 0.00
Epoch 242 Iter 1 subLoss 48277.1 multi -37.81 import weight 0.00
Epoch 242 Iter 2 subLoss 48420.8 multi -4.97 import weight 0.00
Epoch 242 Iter 3 subLoss 48522.0 multi -28.85 import weight 0.00
Epoch 242 Iter 4 subLoss 48636.7 multi -4.97 import weight 0.00
Epoch 242 Iter 5 subLoss 48802.1 multi 15.93 import weight 0.00
Epoch 242 Iter 6 subLoss 48455.0 multi -25.87 import weight 0.00
Epoch 242 Iter 7 subLoss 48896.9 multi -25.87 import weight 0.00
Epoch 242 Iter 8 subLoss 48945.6 multi 3.98 import weight 0.00
Epoch 242 Iter 9 subLoss 49090.6 multi 9.96 import weight 0.00
Epoch 242 Iter 10 subLoss 49170.8 multi 6.97 import weight 0.00
Epoch 242 Iter 11 subLoss 47830872.0 multi 15.93 import weight 0.00
Epoch 242 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 15.93 Pidx 999999 train Loss: 49553.3 test Loss: 8315.7
Epoch 243 Iter 0 subLoss 48716.4 multi -1.99 import weight 0.00
Epoch 243 Iter 1 subLoss 48452.0 multi -22.88 import weight 0.00
Epoch 243 Iter 2 subLoss 48699.0 multi -4.97 import weight 0.00
Epoch 243 Iter 3 subLoss 48894.4 multi -22.88 import weight 0.00
Epoch 243 Iter 4 subLoss 49182.3 multi -7.96 import weight 0.00
Epoch 243 Iter 5 subLoss 49631.1 multi -1.98 import weight 0.00
Epoch 243 Iter 6 subLoss 49401.2 multi 1.00 import weight 0.00
Epoch 243 Iter 7 subLoss 49561.4 multi 1.00 import weight 0.00
Epoch 243 Iter 8 subLoss 49580.7 multi 6.97 import weight 0.00
Epoch 243 Iter 9 subLoss 48972.9 multi -4.97 import weight 0.00
Epoch 243 Iter 10 subLoss 49245.0 multi 12.94 import weight 0.00
Epoch 243 Iter 11 subLoss 49122.5 multi 1.00 import weight 0.00
Epoch 243 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4912 train Loss: 49986.5 test Loss: 8384.7
Epoch 244 Iter 0 subLoss 49258.1 multi -10.94 import weight 0.00
Epoch 244 Iter 1 subLoss 49383.4 multi 3.99 import weight 0.00
Epoch 244 Iter 2 subLoss 49162.7 multi -1.99 import weight 0.00
Epoch 244 Iter 3 subLoss 49021.9 multi -16.91 import weight 0.00
Epoch 244 Iter 4 subLoss 49325.0 multi 6.97 import weight 0.00
Epoch 244 Iter 5 subLoss 49379.0 multi 6.97 import weight 0.00
Epoch 244 Iter 6 subLoss 49122.3 multi 3.99 import weight 0.00
Epoch 244 Iter 7 subLoss 48992.4 multi 9.96 import weight 0.00
Epoch 244 Iter 8 subLoss 49032.3 multi 1.00 import weight 0.00
Epoch 244 Iter 9 subLoss 48830.9 multi 9.96 import weight 0.00
Epoch 244 Iter 10 subLoss 48806.2 multi 18.91 import weight 0.00
Epoch 244 Iter 11 subLoss 48692.7 multi -1.99 import weight 0.00
Epoch 244 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 4869 train Loss: 49557.8 test Loss: 8316.2
Epoch 245 Iter 0 subLoss 48727.5 multi 18.91 import weight 0.00
Epoch 245 Iter 1 subLoss 48463.2 multi 3.99 import weight 0.00
Epoch 245 Iter 2 subLoss 48466.2 multi 6.97 import weight 0.00
Epoch 245 Iter 3 subLoss 48438.4 multi 1.00 import weight 0.00
Epoch 245 Iter 4 subLoss 48336.2 multi -37.81 import weight 0.00
Epoch 245 Iter 5 subLoss 48605.6 multi -10.94 import weight 0.00
Epoch 245 Iter 6 subLoss 48525.2 multi -25.87 import weight 0.00
Epoch 245 Iter 7 subLoss 48867.3 multi 3.99 import weight 0.00
Epoch 245 Iter 8 subLoss 48612.3 multi -22.88 import weight 0.00
Epoch 245 Iter 9 subLoss 49020.6 multi -13.93 import weight 0.00
Epoch 245 Iter 10 subLoss 49344.8 multi 9.96 import weight 0.00
Epoch 245 Iter 11 subLoss 48707.2 multi -7.96 import weight 0.00
Epoch 245 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 4870 train Loss: 50143.2 test Loss: 8411.7
Epoch 246 Iter 0 subLoss 49377.1 multi 9.96 import weight 0.00
Epoch 246 Iter 1 subLoss 48847.0 multi 1.00 import weight 0.00
Epoch 246 Iter 2 subLoss 48926.5 multi 12.94 import weight 0.00
Epoch 246 Iter 3 subLoss 48660.4 multi 1.00 import weight 0.00
Epoch 246 Iter 4 subLoss 48844.7 multi 3.99 import weight 0.00
Epoch 246 Iter 5 subLoss 48734.4 multi -10.94 import weight 0.00
Epoch 246 Iter 6 subLoss 48875.7 multi -1.98 import weight 0.00
Epoch 246 Iter 7 subLoss 48855.4 multi -19.90 import weight 0.00
Epoch 246 Iter 8 subLoss 49069.8 multi -10.94 import weight 0.00
Epoch 246 Iter 9 subLoss 49278.8 multi 6.97 import weight 0.00
Epoch 246 Iter 10 subLoss 49320.3 multi 9.96 import weight 0.00
Epoch 246 Iter 11 subLoss 48859.2 multi -16.91 import weight 0.00
Epoch 246 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -16.91 Pidx 4885 train Loss: 50283.8 test Loss: 8433.8
Epoch 247 Iter 0 subLoss 49446.0 multi -7.96 import weight 0.00
Epoch 247 Iter 1 subLoss 49197.6 multi -1.99 import weight 0.00
Epoch 247 Iter 2 subLoss 49451.8 multi 1.00 import weight 0.00
Epoch 247 Iter 3 subLoss 49680.4 multi 3.99 import weight 0.00
Epoch 247 Iter 4 subLoss 49567.4 multi 3.99 import weight 0.00
Epoch 247 Iter 5 subLoss 49424.8 multi 6.97 import weight 0.00
Epoch 247 Iter 6 subLoss 49104.1 multi -1.99 import weight 0.00
Epoch 247 Iter 7 subLoss 48901.8 multi 3.98 import weight 0.00
Epoch 247 Iter 8 subLoss 49245.4 multi 15.93 import weight 0.00
Epoch 247 Iter 9 subLoss 48876.6 multi 1.00 import weight 0.00
Epoch 247 Iter 10 subLoss 48759.5 multi -4.97 import weight 0.00
Epoch 247 Iter 11 subLoss 48891.2 multi -19.90 import weight 0.00
Epoch 247 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -19.90 Pidx 4889 train Loss: 50158.7 test Loss: 8412.7
Epoch 248 Iter 0 subLoss 49269.2 multi -4.97 import weight 0.00
Epoch 248 Iter 1 subLoss 49165.4 multi 1.00 import weight 0.00
Epoch 248 Iter 2 subLoss 49355.5 multi -10.94 import weight 0.00
Epoch 248 Iter 3 subLoss 49744.6 multi 3.98 import weight 0.00
Epoch 248 Iter 4 subLoss 48949.6 multi 6.97 import weight 0.00
Epoch 248 Iter 5 subLoss 49191.2 multi 1.00 import weight 0.00
Epoch 248 Iter 6 subLoss 49146.7 multi -4.97 import weight 0.00
Epoch 248 Iter 7 subLoss 49419.3 multi -1.99 import weight 0.00
Epoch 248 Iter 8 subLoss 49389.8 multi 1.00 import weight 0.00
Epoch 248 Iter 9 subLoss 49473.0 multi 1.00 import weight 0.00
Epoch 248 Iter 10 subLoss 49373.8 multi 12.94 import weight 0.00
Epoch 248 Iter 11 subLoss 49422.5 multi 6.97 import weight 0.00
Epoch 248 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 4942 train Loss: 49911.1 test Loss: 8373.2
Epoch 249 Iter 0 subLoss 48965.3 multi -10.94 import weight 0.00
Epoch 249 Iter 1 subLoss 48972.3 multi -4.97 import weight 0.00
Epoch 249 Iter 2 subLoss 49353.0 multi -7.96 import weight 0.00
Epoch 249 Iter 3 subLoss 49408.3 multi 3.99 import weight 0.00
Epoch 249 Iter 4 subLoss 49407.6 multi 6.97 import weight 0.00
Epoch 249 Iter 5 subLoss 49166.6 multi 3.99 import weight 0.00
Epoch 249 Iter 6 subLoss 49120.9 multi 6.97 import weight 0.00
Epoch 249 Iter 7 subLoss 48986.3 multi -4.97 import weight 0.00
Epoch 249 Iter 8 subLoss 48719.0 multi -1.98 import weight 0.00
Epoch 249 Iter 9 subLoss 48940.1 multi 9.96 import weight 0.00
Epoch 249 Iter 10 subLoss 48696.6 multi 1.00 import weight 0.00
Epoch 249 Iter 11 subLoss 49265.8 multi -1.98 import weight 0.00
Epoch 249 Acc: 22.09 BMA: 0.00 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 4926 train Loss: 49886.9 test Loss: 8369.3
Epoch 250 Iter 0 subLoss 48791.9 multi -13.93 import weight 0.00
Epoch 250 Iter 1 subLoss 49294.6 multi 3.98 import weight 0.00
Epoch 250 Iter 2 subLoss 49106.9 multi 1.00 import weight 0.00
Epoch 250 Iter 3 subLoss 49115.9 multi -16.91 import weight 0.00
Epoch 250 Iter 4 subLoss 48967.9 multi -7.96 import weight 0.00
Epoch 250 Iter 5 subLoss 49178.6 multi 1.00 import weight 0.00
Epoch 250 Iter 6 subLoss 49583.0 multi 9.96 import weight 0.00
Epoch 250 Iter 7 subLoss 49323.9 multi 12.94 import weight 0.00
Epoch 250 Iter 8 subLoss 49005.6 multi 3.99 import weight 0.00
Epoch 250 Iter 9 subLoss 49010.7 multi 1.00 import weight 0.00
Epoch 250 Iter 10 subLoss 48899.4 multi -16.91 import weight 0.00
Epoch 250 Iter 11 subLoss 49376.4 multi 15.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1612 / 0.04198 / 4.50
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 250 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 15.93 Pidx 4937 train Loss: 49811.7 test Loss: 8357.5
Epoch 251 Iter 0 subLoss 48940.4 multi 12.94 import weight 0.00
Epoch 251 Iter 1 subLoss 48615.9 multi -19.90 import weight 0.00
Epoch 251 Iter 2 subLoss 49151.7 multi -4.97 import weight 0.00
Epoch 251 Iter 3 subLoss 48840.2 multi 6.97 import weight 0.00
Epoch 251 Iter 4 subLoss 48608.5 multi -7.96 import weight 0.00
Epoch 251 Iter 5 subLoss 48640.1 multi -1.99 import weight 0.00
Epoch 251 Iter 6 subLoss 49234.4 multi 3.99 import weight 0.00
Epoch 251 Iter 7 subLoss 48781.7 multi 3.99 import weight 0.00
Epoch 251 Iter 8 subLoss 49118.1 multi -13.93 import weight 0.00
Epoch 251 Iter 9 subLoss 49067.3 multi -7.96 import weight 0.00
Epoch 251 Iter 10 subLoss 49239.8 multi 6.97 import weight 0.00
Epoch 251 Iter 11 subLoss 49082.2 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1617 / 0.04244 / 5.10
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 251 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 4908 train Loss: 50189.6 test Loss: 8419.0
Epoch 252 Iter 0 subLoss 49485.4 multi 1.00 import weight 0.00
Epoch 252 Iter 1 subLoss 49143.0 multi -1.99 import weight 0.00
Epoch 252 Iter 2 subLoss 49164.7 multi 3.98 import weight 0.00
Epoch 252 Iter 3 subLoss 49307.6 multi 6.97 import weight 0.00
Epoch 252 Iter 4 subLoss 48770.0 multi 3.99 import weight 0.00
Epoch 252 Iter 5 subLoss 48826.9 multi -1.98 import weight 0.00
Epoch 252 Iter 6 subLoss 48779.3 multi -1.99 import weight 0.00
Epoch 252 Iter 7 subLoss 49214.4 multi -1.99 import weight 0.00
Epoch 252 Iter 8 subLoss 48856.3 multi -16.91 import weight 0.00
Epoch 252 Iter 9 subLoss 49324.3 multi 15.93 import weight 0.00
Epoch 252 Iter 10 subLoss 48938.4 multi -10.94 import weight 0.00
Epoch 252 Iter 11 subLoss 49439.1 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1619 / 0.04266 / 5.40
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 252 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 4943 train Loss: 50266.1 test Loss: 8431.3
Epoch 253 Iter 0 subLoss 49151.7 multi -4.97 import weight 0.00
Epoch 253 Iter 1 subLoss 49771.9 multi -4.97 import weight 0.00
Epoch 253 Iter 2 subLoss 49245.0 multi 12.94 import weight 0.00
Epoch 253 Iter 3 subLoss 49283.9 multi -13.93 import weight 0.00
Epoch 253 Iter 4 subLoss 49842.1 multi -1.99 import weight 0.00
Epoch 253 Iter 5 subLoss 49927.7 multi -4.97 import weight 0.00
Epoch 253 Iter 6 subLoss 49895.4 multi -1.99 import weight 0.00
Epoch 253 Iter 7 subLoss 49679.0 multi -1.99 import weight 0.00
Epoch 253 Iter 8 subLoss 49578.2 multi -4.97 import weight 0.00
Epoch 253 Iter 9 subLoss 50454.3 multi 1.00 import weight 0.00
Epoch 253 Iter 10 subLoss 49774.2 multi -1.99 import weight 0.00
Epoch 253 Iter 11 subLoss 49870.4 multi -1.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1624 / 0.04329 / 6.30
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 253 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 4987 train Loss: 51203.7 test Loss: 8584.3
Epoch 254 Iter 0 subLoss 50123.4 multi 1.00 import weight 0.00
Epoch 254 Iter 1 subLoss 50229.2 multi 1.00 import weight 0.00
Epoch 254 Iter 2 subLoss 50382.7 multi 1.00 import weight 0.00
Epoch 254 Iter 3 subLoss 49862.3 multi 6.97 import weight 0.00
Epoch 254 Iter 4 subLoss 49847.5 multi 1.00 import weight 0.00
Epoch 254 Iter 5 subLoss 49853.3 multi -4.97 import weight 0.00
Epoch 254 Iter 6 subLoss 49863.0 multi 6.97 import weight 0.00
Epoch 254 Iter 7 subLoss 49641.7 multi -1.98 import weight 0.00
Epoch 254 Iter 8 subLoss 49948.4 multi 1.00 import weight 0.00
Epoch 254 Iter 9 subLoss 49511.6 multi 1.00 import weight 0.00
Epoch 254 Iter 10 subLoss 49634.7 multi 1.00 import weight 0.00
Epoch 254 Iter 11 subLoss 49899.4 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1625 / 0.04345 / 6.50
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 254 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4989 train Loss: 50645.6 test Loss: 8492.9
Epoch 255 Iter 0 subLoss 49868.2 multi 9.96 import weight 0.00
Epoch 255 Iter 1 subLoss 49185.7 multi -7.96 import weight 0.00
Epoch 255 Iter 2 subLoss 49504.9 multi -10.94 import weight 0.00
Epoch 255 Iter 3 subLoss 49739.5 multi 1.00 import weight 0.00
Epoch 255 Iter 4 subLoss 49920.6 multi -1.98 import weight 0.00
Epoch 255 Iter 5 subLoss 50006.0 multi 3.99 import weight 0.00
Epoch 255 Iter 6 subLoss 49766.2 multi 6.97 import weight 0.00
Epoch 255 Iter 7 subLoss 49613.6 multi 9.96 import weight 0.00
Epoch 255 Iter 8 subLoss 49071.9 multi 3.98 import weight 0.00
Epoch 255 Iter 9 subLoss 49505.2 multi -7.96 import weight 0.00
Epoch 255 Iter 10 subLoss 49139.0 multi 3.99 import weight 0.00
Epoch 255 Iter 11 subLoss 49197.7 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1625 / 0.04339 / 6.50
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 255 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4919 train Loss: 50249.5 test Loss: 8428.2
Epoch 256 Iter 0 subLoss 49438.6 multi -1.99 import weight 0.00
Epoch 256 Iter 1 subLoss 49376.8 multi 18.91 import weight 0.00
Epoch 256 Iter 2 subLoss 48975.4 multi -4.97 import weight 0.00
Epoch 256 Iter 3 subLoss 49039.3 multi 1.00 import weight 0.00
Epoch 256 Iter 4 subLoss 48818.9 multi -19.90 import weight 0.00
Epoch 256 Iter 5 subLoss 49483.8 multi 3.99 import weight 0.00
Epoch 256 Iter 6 subLoss 49151.8 multi -1.99 import weight 0.00
Epoch 256 Iter 7 subLoss 49194.2 multi 3.98 import weight 0.00
Epoch 256 Iter 8 subLoss 49006.5 multi 6.97 import weight 0.00
Epoch 256 Iter 9 subLoss 48838.7 multi 9.96 import weight 0.00
Epoch 256 Iter 10 subLoss 49148.1 multi -1.99 import weight 0.00
Epoch 256 Iter 11 subLoss 48798.6 multi -13.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1624 / 0.04331 / 6.40
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 256 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -13.93 Pidx 4879 train Loss: 50109.0 test Loss: 8406.0
Epoch 257 Iter 0 subLoss 49081.7 multi -4.97 import weight 0.00
Epoch 257 Iter 1 subLoss 49311.8 multi -10.94 import weight 0.00
Epoch 257 Iter 2 subLoss 49539.6 multi 3.98 import weight 0.00
Epoch 257 Iter 3 subLoss 49177.4 multi 1.00 import weight 0.00
Epoch 257 Iter 4 subLoss 49302.9 multi 9.96 import weight 0.00
Epoch 257 Iter 5 subLoss 49283.6 multi -10.94 import weight 0.00
Epoch 257 Iter 6 subLoss 49497.6 multi 6.97 import weight 0.00
Epoch 257 Iter 7 subLoss 49304.8 multi 12.94 import weight 0.00
Epoch 257 Iter 8 subLoss 49092.1 multi 6.97 import weight 0.00
Epoch 257 Iter 9 subLoss 48803.2 multi 15.93 import weight 0.00
Epoch 257 Iter 10 subLoss 48540.5 multi 18.91 import weight 0.00
Epoch 257 Iter 11 subLoss 48425.5 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1621 / 0.04295 / 6.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 257 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 4842 train Loss: 49477.0 test Loss: 8303.4
Epoch 258 Iter 0 subLoss 48506.4 multi 3.99 import weight 0.00
Epoch 258 Iter 1 subLoss 48474.8 multi -25.87 import weight 0.00
Epoch 258 Iter 2 subLoss 48469.4 multi 9.96 import weight 0.00
Epoch 258 Iter 3 subLoss 48466.2 multi 12.94 import weight 0.00
Epoch 258 Iter 4 subLoss 48497.8 multi -19.90 import weight 0.00
Epoch 258 Iter 5 subLoss 48671.8 multi -10.94 import weight 0.00
Epoch 258 Iter 6 subLoss 48816.3 multi -19.90 import weight 0.00
Epoch 258 Iter 7 subLoss 49071.5 multi 6.97 import weight 0.00
Epoch 258 Iter 8 subLoss 49037.6 multi 3.98 import weight 0.00
Epoch 258 Iter 9 subLoss 48711.0 multi 1.00 import weight 0.00
Epoch 258 Iter 10 subLoss 48998.8 multi 9.96 import weight 0.00
Epoch 258 Iter 11 subLoss 48720.0 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1619 / 0.04274 / 5.70
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.7, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 258 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 4871 train Loss: 49603.9 test Loss: 8322.6
Epoch 259 Iter 0 subLoss 48447.3 multi 1.00 import weight 0.00
Epoch 259 Iter 1 subLoss 48682.0 multi 3.99 import weight 0.00
Epoch 259 Iter 2 subLoss 48773.9 multi 1.00 import weight 0.00
Epoch 259 Iter 3 subLoss 48398.6 multi 24.88 import weight 0.00
Epoch 259 Iter 4 subLoss 48373.2 multi 6.97 import weight 0.00
Epoch 259 Iter 5 subLoss 48406.0 multi -13.93 import weight 0.00
Epoch 259 Iter 6 subLoss 48533.8 multi 3.98 import weight 0.00
Epoch 259 Iter 7 subLoss 48438.7 multi 1.00 import weight 0.00
Epoch 259 Iter 8 subLoss 48439.9 multi 3.99 import weight 0.00
Epoch 259 Iter 9 subLoss 48430.5 multi 6.97 import weight 0.00
Epoch 259 Iter 10 subLoss 48507.7 multi 3.98 import weight 0.00
Epoch 259 Iter 11 subLoss 48486.6 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1616 / 0.04243 / 5.30
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 259 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 4848 train Loss: 49302.9 test Loss: 8277.1
Epoch 260 Iter 0 subLoss 48313.9 multi -31.84 import weight 0.00
Epoch 260 Iter 1 subLoss 48484.8 multi 15.93 import weight 0.00
Epoch 260 Iter 2 subLoss 48383.0 multi -28.85 import weight 0.00
Epoch 260 Iter 3 subLoss 48257.9 multi 30.85 import weight 1.00
Epoch 260 Iter 4 subLoss 48292.6 multi -1.98 import weight 0.00
Epoch 260 Iter 5 subLoss 48367.9 multi 1.00 import weight 0.00
Epoch 260 Iter 6 subLoss 48508.2 multi 6.97 import weight 0.00
Epoch 260 Iter 7 subLoss 48335.1 multi -34.82 import weight 0.00
Epoch 260 Iter 8 subLoss 48392.2 multi 24.88 import weight 0.00
Epoch 260 Iter 9 subLoss 48424.6 multi 1.00 import weight 0.00
Epoch 260 Iter 10 subLoss 48385.4 multi -25.87 import weight 0.00
Epoch 260 Iter 11 subLoss 48565.1 multi -13.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1615 / 0.04224 / 5.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 27.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 260 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -13.93 Pidx 4856 train Loss: 49484.0 test Loss: 8304.5
Epoch 261 Iter 0 subLoss 48460.6 multi 15.93 import weight 0.00
Epoch 261 Iter 1 subLoss 48411.4 multi 6.97 import weight 0.00
Epoch 261 Iter 2 subLoss 48533.7 multi 6.97 import weight 0.00
Epoch 261 Iter 3 subLoss 48397.9 multi 24.88 import weight 0.00
Epoch 261 Iter 4 subLoss 48356.7 multi -22.88 import weight 0.00
Epoch 261 Iter 5 subLoss 48262.8 multi -10.94 import weight 0.00
Epoch 261 Iter 6 subLoss 48367.9 multi 1.00 import weight 0.00
Epoch 261 Iter 7 subLoss 48431.3 multi 6.97 import weight 0.00
Epoch 261 Iter 8 subLoss 48263.9 multi -7.96 import weight 0.00
Epoch 261 Iter 9 subLoss 48387.2 multi -22.88 import weight 0.00
Epoch 261 Iter 10 subLoss 48492.4 multi -22.88 import weight 0.00
Epoch 261 Iter 11 subLoss 48645.3 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1613 / 0.04210 / 4.70
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.7, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 261 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4864 train Loss: 49540.3 test Loss: 8312.2
Epoch 262 Iter 0 subLoss 48564.2 multi -10.94 import weight 0.00
Epoch 262 Iter 1 subLoss 48505.5 multi 6.97 import weight 0.00
Epoch 262 Iter 2 subLoss 48693.9 multi 1.00 import weight 0.00
Epoch 262 Iter 3 subLoss 48516.7 multi 12.94 import weight 0.00
Epoch 262 Iter 4 subLoss 48563.3 multi -7.96 import weight 0.00
Epoch 262 Iter 5 subLoss 48733.4 multi -7.96 import weight 0.00
Epoch 262 Iter 6 subLoss 48624.6 multi 6.97 import weight 0.00
Epoch 262 Iter 7 subLoss 48534.5 multi 9.96 import weight 0.00
Epoch 262 Iter 8 subLoss 48571.6 multi -28.85 import weight 0.00
Epoch 262 Iter 9 subLoss 48667.3 multi 3.99 import weight 0.00
Epoch 262 Iter 10 subLoss 48636.0 multi -4.97 import weight 0.00
Epoch 262 Iter 11 subLoss 48751.3 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1613 / 0.04202 / 4.60
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 262 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 4875 train Loss: 49730.5 test Loss: 8341.6
Epoch 263 Iter 0 subLoss 49016.7 multi 1.00 import weight 0.00
Epoch 263 Iter 1 subLoss 48780.3 multi 1.00 import weight 0.00
Epoch 263 Iter 2 subLoss 48693.0 multi 3.99 import weight 0.00
Epoch 263 Iter 3 subLoss 48561.7 multi -4.97 import weight 0.00
Epoch 263 Iter 4 subLoss 48464.4 multi 18.91 import weight 0.00
Epoch 263 Iter 5 subLoss 48557.9 multi -7.96 import weight 0.00
Epoch 263 Iter 6 subLoss 48388.3 multi -19.90 import weight 0.00
Epoch 263 Iter 7 subLoss 48950.7 multi -1.99 import weight 0.00
Epoch 263 Iter 8 subLoss 48901.4 multi 1.00 import weight 0.00
Epoch 263 Iter 9 subLoss 48972.5 multi -1.99 import weight 0.00
Epoch 263 Iter 10 subLoss 49231.9 multi 9.96 import weight 0.00
Epoch 263 Iter 11 subLoss 48479.9 multi -34.82 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1612 / 0.04197 / 4.50
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 263 Acc: 20.08 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -34.82 Pidx 4847 train Loss: 49989.8 test Loss: 8381.0
Epoch 264 Iter 0 subLoss 48778.8 multi 3.98 import weight 0.00
Epoch 264 Iter 1 subLoss 48986.9 multi -7.96 import weight 0.00
Epoch 264 Iter 2 subLoss 49074.1 multi 9.96 import weight 0.00
Epoch 264 Iter 3 subLoss 48847.1 multi 6.97 import weight 0.00
Epoch 264 Iter 4 subLoss 49037.2 multi 6.97 import weight 0.00
Epoch 264 Iter 5 subLoss 48680.4 multi 6.97 import weight 0.00
Epoch 264 Iter 6 subLoss 48543.4 multi 12.94 import weight 0.00
Epoch 264 Iter 7 subLoss 48562.4 multi -4.97 import weight 0.00
Epoch 264 Iter 8 subLoss 48704.4 multi -13.93 import weight 0.00
Epoch 264 Iter 9 subLoss 48770.5 multi 6.97 import weight 0.00
Epoch 264 Iter 10 subLoss 48645.5 multi 1.00 import weight 0.00
Epoch 264 Iter 11 subLoss 48804.5 multi 18.91 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1611 / 0.04186 / 4.30
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 264 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 18.91 Pidx 4880 train Loss: 49455.2 test Loss: 8298.5
Epoch 265 Iter 0 subLoss 48580.9 multi 15.93 import weight 0.00
Epoch 265 Iter 1 subLoss 48404.2 multi -16.91 import weight 0.00
Epoch 265 Iter 2 subLoss 48446.5 multi -7.96 import weight 0.00
Epoch 265 Iter 3 subLoss 48569.4 multi -1.99 import weight 0.00
Epoch 265 Iter 4 subLoss 48535.9 multi 12.94 import weight 0.00
Epoch 265 Iter 5 subLoss 48545.8 multi 12.94 import weight 0.00
Epoch 265 Iter 6 subLoss 48396.2 multi 21.90 import weight 0.00
Epoch 265 Iter 7 subLoss 48274.5 multi -40.79 import weight 0.00
Epoch 265 Iter 8 subLoss 48385.3 multi -16.91 import weight 0.00
Epoch 265 Iter 9 subLoss 48421.9 multi 1.00 import weight 0.00
Epoch 265 Iter 10 subLoss 48342.3 multi 12.94 import weight 0.00
Epoch 265 Iter 11 subLoss 48332.5 multi -31.84 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1610 / 0.04177 / 4.10
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 265 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -31.84 Pidx 4833 train Loss: 49458.1 test Loss: 8301.8
Epoch 266 Iter 0 subLoss 48343.0 multi 12.94 import weight 0.00
Epoch 266 Iter 1 subLoss 48338.1 multi -28.85 import weight 0.00
Epoch 266 Iter 2 subLoss 48717.8 multi 3.99 import weight 0.00
Epoch 266 Iter 3 subLoss 48528.7 multi -25.87 import weight 0.00
Epoch 266 Iter 4 subLoss 48659.7 multi -1.99 import weight 0.00
Epoch 266 Iter 5 subLoss 48580.3 multi 18.91 import weight 0.00
Epoch 266 Iter 6 subLoss 48560.8 multi 1.00 import weight 0.00
Epoch 266 Iter 7 subLoss 48626.8 multi 9.96 import weight 0.00
Epoch 266 Iter 8 subLoss 48631.1 multi -4.97 import weight 0.00
Epoch 266 Iter 9 subLoss 48566.9 multi 3.98 import weight 0.00
Epoch 266 Iter 10 subLoss 48602.8 multi -4.97 import weight 0.00
Epoch 266 Iter 11 subLoss 48656.3 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1610 / 0.04169 / 3.90
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 266 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4865 train Loss: 49518.1 test Loss: 8310.5
Epoch 267 Iter 0 subLoss 48500.5 multi 9.96 import weight 0.00
Epoch 267 Iter 1 subLoss 48539.9 multi 12.94 import weight 0.00
Epoch 267 Iter 2 subLoss 48486.7 multi 15.93 import weight 0.00
Epoch 267 Iter 3 subLoss 48431.6 multi 6.97 import weight 0.00
Epoch 267 Iter 4 subLoss 48350.4 multi -25.87 import weight 0.00
Epoch 267 Iter 5 subLoss 48376.3 multi 3.99 import weight 0.00
Epoch 267 Iter 6 subLoss 48452.3 multi -25.87 import weight 0.00
Epoch 267 Iter 7 subLoss 48416.9 multi 6.97 import weight 0.00
Epoch 267 Iter 8 subLoss 48390.9 multi 21.90 import weight 0.00
Epoch 267 Iter 9 subLoss 48482.9 multi 18.91 import weight 0.00
Epoch 267 Iter 10 subLoss 48290.1 multi 1.00 import weight 0.00
Epoch 267 Iter 11 subLoss 48312.9 multi -28.85 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1609 / 0.04158 / 3.70
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.7, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 267 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -28.85 Pidx 4831 train Loss: 49363.7 test Loss: 8287.4
Epoch 268 Iter 0 subLoss 48385.5 multi -16.91 import weight 0.00
Epoch 268 Iter 1 subLoss 48558.5 multi -10.94 import weight 0.00
Epoch 268 Iter 2 subLoss 48499.7 multi -25.87 import weight 0.00
Epoch 268 Iter 3 subLoss 48679.4 multi -10.94 import weight 0.00
Epoch 268 Iter 4 subLoss 48772.4 multi 9.96 import weight 0.00
Epoch 268 Iter 5 subLoss 48825.7 multi -4.97 import weight 0.00
Epoch 268 Iter 6 subLoss 48677.5 multi -7.96 import weight 0.00
Epoch 268 Iter 7 subLoss 48793.5 multi -13.93 import weight 0.00
Epoch 268 Iter 8 subLoss 49038.6 multi 9.96 import weight 0.00
Epoch 268 Iter 9 subLoss 48908.1 multi 3.99 import weight 0.00
Epoch 268 Iter 10 subLoss 48932.2 multi -7.96 import weight 0.00
Epoch 268 Iter 11 subLoss 48972.2 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1608 / 0.04152 / 3.40
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 268 Acc: 19.65 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4897 train Loss: 49919.7 test Loss: 8377.0
Epoch 269 Iter 0 subLoss 49038.8 multi 12.94 import weight 0.00
Epoch 269 Iter 1 subLoss 48962.0 multi -7.96 import weight 0.00
Epoch 269 Iter 2 subLoss 48778.0 multi 12.94 import weight 0.00
Epoch 269 Iter 3 subLoss 48635.4 multi -1.99 import weight 0.00
Epoch 269 Iter 4 subLoss 48826.3 multi -1.99 import weight 0.00
Epoch 269 Iter 5 subLoss 48765.8 multi 3.99 import weight 0.00
Epoch 269 Iter 6 subLoss 48638.0 multi 1.00 import weight 0.00
Epoch 269 Iter 7 subLoss 48583.5 multi 21.90 import weight 0.00
Epoch 269 Iter 8 subLoss 48610.0 multi -22.88 import weight 0.00
Epoch 269 Iter 9 subLoss 48639.6 multi 3.98 import weight 0.00
Epoch 269 Iter 10 subLoss 48621.9 multi 9.96 import weight 0.00
Epoch 269 Iter 11 subLoss 48754.6 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1608 / 0.04146 / 3.30
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 269 Acc: 19.65 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4875 train Loss: 49574.8 test Loss: 8320.8
Epoch 270 Iter 0 subLoss 48548.3 multi 12.94 import weight 0.00
Epoch 270 Iter 1 subLoss 48646.7 multi -7.96 import weight 0.00
Epoch 270 Iter 2 subLoss 48729.0 multi 9.96 import weight 0.00
Epoch 270 Iter 3 subLoss 48614.8 multi -19.90 import weight 0.00
Epoch 270 Iter 4 subLoss 48792.7 multi -10.94 import weight 0.00
Epoch 270 Iter 5 subLoss 48753.9 multi 3.99 import weight 0.00
Epoch 270 Iter 6 subLoss 48746.4 multi -7.96 import weight 0.00
Epoch 270 Iter 7 subLoss 48723.3 multi 12.94 import weight 0.00
Epoch 270 Iter 8 subLoss 48628.7 multi 9.96 import weight 0.00
Epoch 270 Iter 9 subLoss 48474.7 multi -31.84 import weight 0.00
Epoch 270 Iter 10 subLoss 48624.8 multi 12.94 import weight 0.00
Epoch 270 Iter 11 subLoss 48662.5 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1608 / 0.04141 / 3.10
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 270 Acc: 19.65 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4866 train Loss: 49681.1 test Loss: 8337.3
Epoch 271 Iter 0 subLoss 48746.0 multi -4.97 import weight 0.00
Epoch 271 Iter 1 subLoss 48737.3 multi -10.94 import weight 0.00
Epoch 271 Iter 2 subLoss 49005.7 multi 6.97 import weight 0.00
Epoch 271 Iter 3 subLoss 48738.9 multi -7.96 import weight 0.00
Epoch 271 Iter 4 subLoss 48986.8 multi -7.96 import weight 0.00
Epoch 271 Iter 5 subLoss 49161.3 multi 1.00 import weight 0.00
Epoch 271 Iter 6 subLoss 49038.4 multi 15.93 import weight 0.00
Epoch 271 Iter 7 subLoss 48620.7 multi 15.93 import weight 0.00
Epoch 271 Iter 8 subLoss 48629.5 multi 18.91 import weight 0.00
Epoch 271 Iter 9 subLoss 48463.1 multi 18.91 import weight 0.00
Epoch 271 Iter 10 subLoss 48420.0 multi 1.00 import weight 0.00
Epoch 271 Iter 11 subLoss 48306.2 multi -43.78 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1607 / 0.04135 / 2.90
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 271 Acc: 19.65 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -43.78 Pidx 4830 train Loss: 49468.8 test Loss: 8304.8
Epoch 272 Iter 0 subLoss 48535.8 multi 15.93 import weight 0.00
Epoch 272 Iter 1 subLoss 48493.2 multi -22.88 import weight 0.00
Epoch 272 Iter 2 subLoss 48520.9 multi -22.88 import weight 0.00
Epoch 272 Iter 3 subLoss 48746.5 multi -7.96 import weight 0.00
Epoch 272 Iter 4 subLoss 48773.9 multi 12.94 import weight 0.00
Epoch 272 Iter 5 subLoss 48572.9 multi -40.79 import weight 0.00
Epoch 272 Iter 6 subLoss 49057.2 multi 15.93 import weight 0.00
Epoch 272 Iter 7 subLoss 48737.8 multi -4.97 import weight 0.00
Epoch 272 Iter 8 subLoss 48815.5 multi -19.90 import weight 0.00
Epoch 272 Iter 9 subLoss 48977.5 multi 1.00 import weight 0.00
Epoch 272 Iter 10 subLoss 49261.3 multi 1.00 import weight 0.00
Epoch 272 Iter 11 subLoss 49202.8 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1607 / 0.04134 / 2.70
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.7, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 272 Acc: 20.08 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 4920 train Loss: 50240.7 test Loss: 8426.6
Epoch 273 Iter 0 subLoss 49352.5 multi -4.97 import weight 0.00
Epoch 273 Iter 1 subLoss 49367.1 multi -7.96 import weight 0.00
Epoch 273 Iter 2 subLoss 49389.4 multi -4.97 import weight 0.00
Epoch 273 Iter 3 subLoss 49601.5 multi -7.96 import weight 0.00
Epoch 273 Iter 4 subLoss 50118.2 multi 1.00 import weight 0.00
Epoch 273 Iter 5 subLoss 49948.4 multi 3.99 import weight 0.00
Epoch 273 Iter 6 subLoss 49794.6 multi 3.99 import weight 0.00
Epoch 273 Iter 7 subLoss 49578.4 multi -1.98 import weight 0.00
Epoch 273 Iter 8 subLoss 49682.5 multi 3.98 import weight 0.00
Epoch 273 Iter 9 subLoss 49692.7 multi -7.96 import weight 0.00
Epoch 273 Iter 10 subLoss 49763.8 multi 9.96 import weight 0.00
Epoch 273 Iter 11 subLoss 49578.2 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1607 / 0.04134 / 2.50
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 273 Acc: 20.08 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4957 train Loss: 50476.4 test Loss: 8464.6
Epoch 274 Iter 0 subLoss 50217.3 multi 1.00 import weight 0.00
Epoch 274 Iter 1 subLoss 49433.1 multi 1.00 import weight 0.00
Epoch 274 Iter 2 subLoss 49396.2 multi -13.93 import weight 0.00
Epoch 274 Iter 3 subLoss 49780.5 multi -1.99 import weight 0.00
Epoch 274 Iter 4 subLoss 50024.8 multi 1.00 import weight 0.00
Epoch 274 Iter 5 subLoss 49742.2 multi 3.99 import weight 0.00
Epoch 274 Iter 6 subLoss 49422.9 multi 9.96 import weight 0.00
Epoch 274 Iter 7 subLoss 49246.5 multi 12.94 import weight 0.00
Epoch 274 Iter 8 subLoss 49148.0 multi 1.00 import weight 0.00
Epoch 274 Iter 9 subLoss 49226.1 multi -1.99 import weight 0.00
Epoch 274 Iter 10 subLoss 49264.2 multi 3.99 import weight 0.00
Epoch 274 Iter 11 subLoss 48816.2 multi -16.91 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1607 / 0.04133 / 2.30
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 274 Acc: 20.08 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -16.91 Pidx 4881 train Loss: 50401.0 test Loss: 8452.6
Epoch 275 Iter 0 subLoss 49388.9 multi -1.98 import weight 0.00
Epoch 275 Iter 1 subLoss 49668.6 multi -7.96 import weight 0.00
Epoch 275 Iter 2 subLoss 49637.8 multi 3.99 import weight 0.00
Epoch 275 Iter 3 subLoss 49695.1 multi -4.97 import weight 0.00
Epoch 275 Iter 4 subLoss 49683.3 multi 6.97 import weight 0.00
Epoch 275 Iter 5 subLoss 49589.6 multi 3.99 import weight 0.00
Epoch 275 Iter 6 subLoss 49536.5 multi 6.97 import weight 0.00
Epoch 275 Iter 7 subLoss 49379.7 multi 18.91 import weight 0.00
Epoch 275 Iter 8 subLoss 48650.0 multi 1.00 import weight 0.00
Epoch 275 Iter 9 subLoss 48950.3 multi 1.00 import weight 0.00
Epoch 275 Iter 10 subLoss 48813.0 multi -13.93 import weight 0.00
Epoch 275 Iter 11 subLoss 48804.0 multi 15.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1607 / 0.04132 / 2.20
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 275 Acc: 20.08 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 15.93 Pidx 4880 train Loss: 49778.8 test Loss: 8352.4
Epoch 276 Iter 0 subLoss 48840.9 multi 9.96 import weight 0.00
Epoch 276 Iter 1 subLoss 48672.2 multi -7.96 import weight 0.00
Epoch 276 Iter 2 subLoss 48909.1 multi 6.97 import weight 0.00
Epoch 276 Iter 3 subLoss 48745.3 multi -7.96 import weight 0.00
Epoch 276 Iter 4 subLoss 48593.5 multi 9.96 import weight 0.00
Epoch 276 Iter 5 subLoss 48649.7 multi -4.97 import weight 0.00
Epoch 276 Iter 6 subLoss 48664.4 multi 1.00 import weight 0.00
Epoch 276 Iter 7 subLoss 48757.0 multi -4.97 import weight 0.00
Epoch 276 Iter 8 subLoss 48694.8 multi 3.99 import weight 0.00
Epoch 276 Iter 9 subLoss 48637.7 multi -7.96 import weight 0.00
Epoch 276 Iter 10 subLoss 48693.0 multi 6.97 import weight 0.00
Epoch 276 Iter 11 subLoss 48863.6 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1607 / 0.04130 / 2.10
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 276 Acc: 19.65 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 4886 train Loss: 49708.9 test Loss: 8341.6
Epoch 277 Iter 0 subLoss 48609.9 multi -4.97 import weight 0.00
Epoch 277 Iter 1 subLoss 48884.2 multi 24.88 import weight 0.00
Epoch 277 Iter 2 subLoss 48674.7 multi -7.96 import weight 0.00
Epoch 277 Iter 3 subLoss 48411.9 multi 9.96 import weight 0.00
Epoch 277 Iter 4 subLoss 48578.5 multi -37.81 import weight 0.00
Epoch 277 Iter 5 subLoss 48609.0 multi -1.99 import weight 0.00
Epoch 277 Iter 6 subLoss 49139.4 multi 6.97 import weight 0.00
Epoch 277 Iter 7 subLoss 48826.4 multi -7.96 import weight 0.00
Epoch 277 Iter 8 subLoss 48723.7 multi 15.93 import weight 0.00
Epoch 277 Iter 9 subLoss 48536.6 multi 15.93 import weight 0.00
Epoch 277 Iter 10 subLoss 48474.0 multi -31.84 import weight 0.00
Epoch 277 Iter 11 subLoss 49027.8 multi -16.91 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1607 / 0.04131 / 2.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 277 Acc: 20.08 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -16.91 Pidx 4902 train Loss: 49990.3 test Loss: 8384.5
Epoch 278 Iter 0 subLoss 49016.3 multi 1.00 import weight 0.00
Epoch 278 Iter 1 subLoss 48770.8 multi 15.93 import weight 0.00
Epoch 278 Iter 2 subLoss 48935.2 multi -4.97 import weight 0.00
Epoch 278 Iter 3 subLoss 48753.9 multi -1.99 import weight 0.00
Epoch 278 Iter 4 subLoss 49049.1 multi -25.87 import weight 0.00
Epoch 278 Iter 5 subLoss 49100.5 multi 1.00 import weight 0.00
Epoch 278 Iter 6 subLoss 49789.9 multi 1.00 import weight 0.00
Epoch 278 Iter 7 subLoss 48953.9 multi 3.99 import weight 0.00
Epoch 278 Iter 8 subLoss 49324.9 multi 15.93 import weight 0.00
Epoch 278 Iter 9 subLoss 48777.4 multi 18.91 import weight 0.00
Epoch 278 Iter 10 subLoss 48659.3 multi 1.00 import weight 0.00
Epoch 278 Iter 11 subLoss 48921.5 multi 15.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1607 / 0.04130 / 2.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 278 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 15.93 Pidx 4892 train Loss: 49512.2 test Loss: 8309.3
Epoch 279 Iter 0 subLoss 48571.5 multi -34.82 import weight 0.00
Epoch 279 Iter 1 subLoss 48521.5 multi -19.90 import weight 0.00
Epoch 279 Iter 2 subLoss 49045.6 multi -22.88 import weight 0.00
Epoch 279 Iter 3 subLoss 49338.0 multi -22.88 import weight 0.00
Epoch 279 Iter 4 subLoss 50182.3 multi 1.00 import weight 0.00
Epoch 279 Iter 5 subLoss 49959.9 multi -1.98 import weight 0.00
Epoch 279 Iter 6 subLoss 49848.5 multi 3.98 import weight 0.00
Epoch 279 Iter 7 subLoss 49935.5 multi -4.97 import weight 0.00
Epoch 279 Iter 8 subLoss 49636.1 multi 6.97 import weight 0.00
Epoch 279 Iter 9 subLoss 50015.4 multi -4.97 import weight 0.00
Epoch 279 Iter 10 subLoss 50107.1 multi 1.00 import weight 0.00
Epoch 279 Iter 11 subLoss 50181.6 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1608 / 0.04133 / 1.90
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 279 Acc: 20.08 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 5018 train Loss: 50789.9 test Loss: 8513.6
Epoch 280 Iter 0 subLoss 49879.1 multi -7.96 import weight 0.00
Epoch 280 Iter 1 subLoss 50387.5 multi 3.99 import weight 0.00
Epoch 280 Iter 2 subLoss 49688.9 multi 9.96 import weight 0.00
Epoch 280 Iter 3 subLoss 50036.7 multi 1.00 import weight 0.00
Epoch 280 Iter 4 subLoss 49550.5 multi -1.99 import weight 0.00
Epoch 280 Iter 5 subLoss 49704.2 multi -1.98 import weight 0.00
Epoch 280 Iter 6 subLoss 49691.4 multi -7.96 import weight 0.00
Epoch 280 Iter 7 subLoss 50266.6 multi -1.99 import weight 0.00
Epoch 280 Iter 8 subLoss 50174.6 multi -1.99 import weight 0.00
Epoch 280 Iter 9 subLoss 49632.8 multi 9.96 import weight 0.00
Epoch 280 Iter 10 subLoss 49652.2 multi 6.97 import weight 0.00
Epoch 280 Iter 11 subLoss 49194.0 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1608 / 0.04135 / 1.80
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 280 Acc: 20.08 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 4919 train Loss: 50454.5 test Loss: 8459.3
Epoch 281 Iter 0 subLoss 49502.3 multi -7.96 import weight 0.00
Epoch 281 Iter 1 subLoss 49375.7 multi 21.90 import weight 0.00
Epoch 281 Iter 2 subLoss 49569.0 multi 3.98 import weight 0.00
Epoch 281 Iter 3 subLoss 49210.7 multi -1.99 import weight 0.00
Epoch 281 Iter 4 subLoss 49250.7 multi -16.91 import weight 0.00
Epoch 281 Iter 5 subLoss 49441.3 multi -13.93 import weight 0.00
Epoch 281 Iter 6 subLoss 49888.0 multi -4.97 import weight 0.00
Epoch 281 Iter 7 subLoss 49688.1 multi 12.94 import weight 0.00
Epoch 281 Iter 8 subLoss 49621.0 multi -4.97 import weight 0.00
Epoch 281 Iter 9 subLoss 49760.5 multi 12.94 import weight 0.00
Epoch 281 Iter 10 subLoss 49258.1 multi -13.93 import weight 0.00
Epoch 281 Iter 11 subLoss 49514.5 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1608 / 0.04138 / 1.70
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.7, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 281 Acc: 20.08 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 4951 train Loss: 50802.7 test Loss: 8516.2
Epoch 282 Iter 0 subLoss 49637.9 multi 9.96 import weight 0.00
Epoch 282 Iter 1 subLoss 49569.1 multi 6.97 import weight 0.00
Epoch 282 Iter 2 subLoss 49511.3 multi -1.98 import weight 0.00
Epoch 282 Iter 3 subLoss 49347.0 multi 9.96 import weight 0.00
Epoch 282 Iter 4 subLoss 49151.4 multi -4.97 import weight 0.00
Epoch 282 Iter 5 subLoss 49480.8 multi 6.97 import weight 0.00
Epoch 282 Iter 6 subLoss 49304.1 multi 15.93 import weight 0.00
Epoch 282 Iter 7 subLoss 48756.9 multi 1.00 import weight 0.00
Epoch 282 Iter 8 subLoss 48961.9 multi -10.94 import weight 0.00
Epoch 282 Iter 9 subLoss 49092.5 multi 9.96 import weight 0.00
Epoch 282 Iter 10 subLoss 48839.1 multi 3.99 import weight 0.00
Epoch 282 Iter 11 subLoss 48895.2 multi -16.91 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1608 / 0.04139 / 1.60
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 282 Acc: 20.08 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -16.91 Pidx 4889 train Loss: 50044.5 test Loss: 8393.7
Epoch 283 Iter 0 subLoss 49046.9 multi -19.90 import weight 0.00
Epoch 283 Iter 1 subLoss 49253.0 multi -10.94 import weight 0.00
Epoch 283 Iter 2 subLoss 49521.2 multi -10.94 import weight 0.00
Epoch 283 Iter 3 subLoss 49905.4 multi -4.97 import weight 0.00
Epoch 283 Iter 4 subLoss 49847.5 multi 6.97 import weight 0.00
Epoch 283 Iter 5 subLoss 50114.4 multi 1.00 import weight 0.00
Epoch 283 Iter 6 subLoss 49694.4 multi -7.96 import weight 0.00
Epoch 283 Iter 7 subLoss 49813.3 multi 1.00 import weight 0.00
Epoch 283 Iter 8 subLoss 50346.9 multi 1.00 import weight 0.00
Epoch 283 Iter 9 subLoss 49907.8 multi -1.98 import weight 0.00
Epoch 283 Iter 10 subLoss 50041.7 multi -4.97 import weight 0.00
Epoch 283 Iter 11 subLoss 50705.3 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1609 / 0.04143 / 1.60
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 283 Acc: 20.08 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 5070 train Loss: 51170.6 test Loss: 8576.4
Epoch 284 Iter 0 subLoss 50118.2 multi 3.98 import weight 0.00
Epoch 284 Iter 1 subLoss 49807.9 multi -10.94 import weight 0.00
Epoch 284 Iter 2 subLoss 50337.5 multi 1.00 import weight 0.00
Epoch 284 Iter 3 subLoss 50415.8 multi 1.00 import weight 0.00
Epoch 284 Iter 4 subLoss 50395.3 multi -4.97 import weight 0.00
Epoch 284 Iter 5 subLoss 50683.0 multi 1.00 import weight 0.00
Epoch 284 Iter 6 subLoss 50203.6 multi 1.00 import weight 0.00
Epoch 284 Iter 7 subLoss 50754.9 multi 1.00 import weight 0.00
Epoch 284 Iter 8 subLoss 50099.2 multi 1.00 import weight 0.00
Epoch 284 Iter 9 subLoss 50609.0 multi 1.00 import weight 0.00
Epoch 284 Iter 10 subLoss 50430.7 multi 1.00 import weight 0.00
Epoch 284 Iter 11 subLoss 50029.3 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1609 / 0.04147 / 1.50
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 284 Acc: 20.08 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 5002 train Loss: 51218.0 test Loss: 8583.9
Epoch 285 Iter 0 subLoss 49842.8 multi 9.96 import weight 0.00
Epoch 285 Iter 1 subLoss 50209.0 multi 3.99 import weight 0.00
Epoch 285 Iter 2 subLoss 49955.5 multi 1.00 import weight 0.00
Epoch 285 Iter 3 subLoss 49566.2 multi 9.96 import weight 0.00
Epoch 285 Iter 4 subLoss 49513.6 multi 1.00 import weight 0.00
Epoch 285 Iter 5 subLoss 49315.4 multi -16.91 import weight 0.00
Epoch 285 Iter 6 subLoss 50164.4 multi 3.99 import weight 0.00
Epoch 285 Iter 7 subLoss 49750.1 multi -7.96 import weight 0.00
Epoch 285 Iter 8 subLoss 50009.6 multi 6.97 import weight 0.00
Epoch 285 Iter 9 subLoss 49764.0 multi 12.94 import weight 0.00
Epoch 285 Iter 10 subLoss 49480.8 multi 9.96 import weight 0.00
Epoch 285 Iter 11 subLoss 49269.1 multi -1.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1609 / 0.04149 / 1.40
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 285 Acc: 20.08 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 4926 train Loss: 50261.9 test Loss: 8429.4
Epoch 286 Iter 0 subLoss 49198.8 multi 9.96 import weight 0.00
Epoch 286 Iter 1 subLoss 49036.4 multi 15.93 import weight 0.00
Epoch 286 Iter 2 subLoss 49007.6 multi 9.96 import weight 0.00
Epoch 286 Iter 3 subLoss 48778.2 multi 21.90 import weight 0.00
Epoch 286 Iter 4 subLoss 48680.4 multi -1.99 import weight 0.00
Epoch 286 Iter 5 subLoss 48621.3 multi 21.90 import weight 0.00
Epoch 286 Iter 6 subLoss 48321.3 multi 27.87 import weight 0.00
Epoch 286 Iter 7 subLoss 48223.3 multi 3.98 import weight 0.00
Epoch 286 Iter 8 subLoss 48261.5 multi -4.97 import weight 0.00
Epoch 286 Iter 9 subLoss 48428.8 multi 1.00 import weight 0.00
Epoch 286 Iter 10 subLoss 48421.7 multi 3.99 import weight 0.00
Epoch 286 Iter 11 subLoss 48381.4 multi -13.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1609 / 0.04145 / 1.40
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 286 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -13.93 Pidx 4838 train Loss: 49336.6 test Loss: 8282.1
Epoch 287 Iter 0 subLoss 48254.5 multi 33.84 import weight 1.00
Epoch 287 Iter 1 subLoss 48207.9 multi 6.97 import weight 0.00
Epoch 287 Iter 2 subLoss 48395.5 multi 18.91 import weight 0.00
Epoch 287 Iter 3 subLoss 48272.0 multi -40.79 import weight 0.00
Epoch 287 Iter 4 subLoss 48354.4 multi -22.88 import weight 0.00
Epoch 287 Iter 5 subLoss 48496.7 multi -19.90 import weight 0.00
Epoch 287 Iter 6 subLoss 48437.6 multi 1.00 import weight 0.00
Epoch 287 Iter 7 subLoss 48558.2 multi -10.94 import weight 0.00
Epoch 287 Iter 8 subLoss 48487.3 multi 15.93 import weight 0.00
Epoch 287 Iter 9 subLoss 48536.8 multi 15.93 import weight 0.00
Epoch 287 Iter 10 subLoss 48346.3 multi 12.94 import weight 0.00
Epoch 287 Iter 11 subLoss 48327.5 multi 30.85 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1609 / 0.04141 / 1.40
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 287 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 30.85 Pidx 4832 train Loss: 49243.9 test Loss: 8268.9
Epoch 288 Iter 0 subLoss 48337.8 multi -31.84 import weight 0.00
Epoch 288 Iter 1 subLoss 48198.1 multi 27.87 import weight 0.00
Epoch 288 Iter 2 subLoss 48305.3 multi -40.79 import weight 0.00
Epoch 288 Iter 3 subLoss 48411.1 multi 12.94 import weight 0.00
Epoch 288 Iter 4 subLoss 48340.3 multi 12.94 import weight 0.00
Epoch 288 Iter 5 subLoss 48157.4 multi -10.94 import weight 0.00
Epoch 288 Iter 6 subLoss 48376.0 multi 6.97 import weight 0.00
Epoch 288 Iter 7 subLoss 48315.9 multi -31.84 import weight 0.00
Epoch 288 Iter 8 subLoss 48478.3 multi -28.85 import weight 0.00
Epoch 288 Iter 9 subLoss 48517.6 multi 12.94 import weight 0.00
Epoch 288 Iter 10 subLoss 48466.8 multi 21.90 import weight 0.00
Epoch 288 Iter 11 subLoss 48498.1 multi -19.90 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1608 / 0.04139 / 1.40
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 288 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -19.90 Pidx 4849 train Loss: 49393.0 test Loss: 8291.6
Epoch 289 Iter 0 subLoss 48551.4 multi -7.96 import weight 0.00
Epoch 289 Iter 1 subLoss 48492.2 multi -16.91 import weight 0.00
Epoch 289 Iter 2 subLoss 48303.6 multi -37.81 import weight 0.00
Epoch 289 Iter 3 subLoss 48546.2 multi 6.97 import weight 0.00
Epoch 289 Iter 4 subLoss 48829.8 multi -4.97 import weight 0.00
Epoch 289 Iter 5 subLoss 48902.7 multi 6.97 import weight 0.00
Epoch 289 Iter 6 subLoss 48653.6 multi 3.99 import weight 0.00
Epoch 289 Iter 7 subLoss 48676.3 multi -4.97 import weight 0.00
Epoch 289 Iter 8 subLoss 48968.9 multi -7.96 import weight 0.00
Epoch 289 Iter 9 subLoss 48708.2 multi -16.91 import weight 0.00
Epoch 289 Iter 10 subLoss 48906.3 multi 9.96 import weight 0.00
Epoch 289 Iter 11 subLoss 48880.2 multi 27.87 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1608 / 0.04138 / 1.40
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 289 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 27.87 Pidx 4888 train Loss: 49526.8 test Loss: 8311.9
Epoch 290 Iter 0 subLoss 48539.7 multi 18.91 import weight 0.00
Epoch 290 Iter 1 subLoss 48493.4 multi -13.93 import weight 0.00
Epoch 290 Iter 2 subLoss 48637.6 multi -7.96 import weight 0.00
Epoch 290 Iter 3 subLoss 48469.5 multi 24.88 import weight 0.00
Epoch 290 Iter 4 subLoss 48407.2 multi -22.88 import weight 0.00
Epoch 290 Iter 5 subLoss 48451.5 multi -22.88 import weight 0.00
Epoch 290 Iter 6 subLoss 48871.3 multi 1.00 import weight 0.00
Epoch 290 Iter 7 subLoss 48613.6 multi -22.88 import weight 0.00
Epoch 290 Iter 8 subLoss 49018.6 multi 1.00 import weight 0.00
Epoch 290 Iter 9 subLoss 48860.1 multi 1.00 import weight 0.00
Epoch 290 Iter 10 subLoss 48834.0 multi 3.99 import weight 0.00
Epoch 290 Iter 11 subLoss 48754.8 multi 3.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1608 / 0.04138 / 1.40
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 290 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 4875 train Loss: 49733.8 test Loss: 8345.8
Epoch 291 Iter 0 subLoss 48747.1 multi -4.97 import weight 0.00
Epoch 291 Iter 1 subLoss 48741.7 multi -1.99 import weight 0.00
Epoch 291 Iter 2 subLoss 48881.6 multi 27.87 import weight 0.00
Epoch 291 Iter 3 subLoss 48544.0 multi 6.97 import weight 0.00
Epoch 291 Iter 4 subLoss 48548.3 multi 9.96 import weight 0.00
Epoch 291 Iter 5 subLoss 48487.2 multi 15.93 import weight 0.00
Epoch 291 Iter 6 subLoss 48375.9 multi 9.96 import weight 0.00
Epoch 291 Iter 7 subLoss 48266.7 multi -4.97 import weight 0.00
Epoch 291 Iter 8 subLoss 48534.0 multi 21.90 import weight 0.00
Epoch 291 Iter 9 subLoss 48266.8 multi -1.98 import weight 1.00
Epoch 291 Iter 10 subLoss 48253.6 multi 36.82 import weight 1.00
Epoch 291 Iter 11 subLoss 48319.6 multi -31.84 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1608 / 0.04134 / 1.40
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 291 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -31.84 Pidx 4831 train Loss: 49262.9 test Loss: 8272.5
Epoch 292 Iter 0 subLoss 48252.1 multi 39.81 import weight 1.00
Epoch 292 Iter 1 subLoss 48287.4 multi 18.91 import weight 0.00
Epoch 292 Iter 2 subLoss 48317.0 multi -28.85 import weight 0.00
Epoch 292 Iter 3 subLoss 48269.5 multi -4.97 import weight 0.00
Epoch 292 Iter 4 subLoss 48330.2 multi -28.85 import weight 0.00
Epoch 292 Iter 5 subLoss 48419.6 multi 12.94 import weight 0.00
Epoch 292 Iter 6 subLoss 48242.7 multi 51.75 import weight 0.00
Epoch 292 Iter 7 subLoss 48201.2 multi 6.97 import weight 0.00
Epoch 292 Iter 8 subLoss 48260.7 multi -1.99 import weight 1.00
Epoch 292 Iter 9 subLoss 48264.0 multi 1.00 import weight 1.00
Epoch 292 Iter 10 subLoss 48284.5 multi 21.90 import weight 0.00
Epoch 292 Iter 11 subLoss 48200.6 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1608 / 0.04129 / 1.40
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 292 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 4820 train Loss: 49208.8 test Loss: 8266.4
Epoch 293 Iter 0 subLoss 48223.6 multi 6.97 import weight 0.00
Epoch 293 Iter 1 subLoss 48301.2 multi -34.82 import weight 0.00
Epoch 293 Iter 2 subLoss 48332.7 multi -25.87 import weight 0.00
Epoch 293 Iter 3 subLoss 48344.4 multi 9.96 import weight 0.00
Epoch 293 Iter 4 subLoss 48218.9 multi 45.78 import weight 0.00
Epoch 293 Iter 5 subLoss 48164.6 multi 3.99 import weight 0.00
Epoch 293 Iter 6 subLoss 48276.2 multi -52.73 import weight 0.00
Epoch 293 Iter 7 subLoss 48299.8 multi -1.99 import weight 0.00
Epoch 293 Iter 8 subLoss 48315.7 multi -28.85 import weight 0.00
Epoch 293 Iter 9 subLoss 48444.5 multi -10.94 import weight 0.00
Epoch 293 Iter 10 subLoss 48341.7 multi 12.94 import weight 0.00
Epoch 293 Iter 11 subLoss 48491.5 multi -13.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1607 / 0.04125 / 1.40
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 293 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -13.93 Pidx 4849 train Loss: 49427.2 test Loss: 8302.1
Epoch 294 Iter 0 subLoss 48413.4 multi 15.93 import weight 0.00
Epoch 294 Iter 1 subLoss 48441.5 multi -7.96 import weight 0.00
Epoch 294 Iter 2 subLoss 48459.3 multi -25.87 import weight 0.00
Epoch 294 Iter 3 subLoss 48663.1 multi -1.99 import weight 0.00
Epoch 294 Iter 4 subLoss 48673.1 multi -4.97 import weight 0.00
Epoch 294 Iter 5 subLoss 48526.9 multi -19.90 import weight 0.00
Epoch 294 Iter 6 subLoss 48800.9 multi 18.91 import weight 0.00
Epoch 294 Iter 7 subLoss 48577.1 multi -31.84 import weight 0.00
Epoch 294 Iter 8 subLoss 48803.9 multi 21.90 import weight 0.00
Epoch 294 Iter 9 subLoss 48501.6 multi -7.96 import weight 0.00
Epoch 294 Iter 10 subLoss 48586.6 multi 12.94 import weight 0.00
Epoch 294 Iter 11 subLoss 48672.9 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1607 / 0.04122 / 1.50
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 294 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 4867 train Loss: 49556.7 test Loss: 8325.2
Epoch 295 Iter 0 subLoss 48747.1 multi 1.00 import weight 0.00
Epoch 295 Iter 1 subLoss 48554.4 multi -13.93 import weight 0.00
Epoch 295 Iter 2 subLoss 48556.1 multi -10.94 import weight 0.00
Epoch 295 Iter 3 subLoss 48717.8 multi 3.98 import weight 0.00
Epoch 295 Iter 4 subLoss 48728.0 multi 15.93 import weight 0.00
Epoch 295 Iter 5 subLoss 48536.1 multi 21.90 import weight 0.00
Epoch 295 Iter 6 subLoss 48447.6 multi -4.97 import weight 0.00
Epoch 295 Iter 7 subLoss 48617.0 multi -19.90 import weight 0.00
Epoch 295 Iter 8 subLoss 48481.4 multi 18.91 import weight 0.00
Epoch 295 Iter 9 subLoss 48501.8 multi -4.97 import weight 0.00
Epoch 295 Iter 10 subLoss 48543.9 multi 6.97 import weight 0.00
Epoch 295 Iter 11 subLoss 48548.6 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1606 / 0.04118 / 1.50
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 295 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 4854 train Loss: 49372.1 test Loss: 8293.0
Epoch 296 Iter 0 subLoss 48515.5 multi 9.96 import weight 0.00
Epoch 296 Iter 1 subLoss 48270.0 multi 3.98 import weight 1.00
Epoch 296 Iter 2 subLoss 48304.0 multi -34.82 import weight 0.00
Epoch 296 Iter 3 subLoss 48477.4 multi -31.84 import weight 0.00
Epoch 296 Iter 4 subLoss 48684.7 multi -7.96 import weight 0.00
Epoch 296 Iter 5 subLoss 48593.5 multi 9.96 import weight 0.00
Epoch 296 Iter 6 subLoss 48722.0 multi 18.91 import weight 0.00
Epoch 296 Iter 7 subLoss 48385.2 multi -16.91 import weight 0.00
Epoch 296 Iter 8 subLoss 48669.5 multi 1.00 import weight 0.00
Epoch 296 Iter 9 subLoss 48609.0 multi -1.98 import weight 0.00
Epoch 296 Iter 10 subLoss 48488.4 multi 18.91 import weight 0.00
Epoch 296 Iter 11 subLoss 48465.9 multi 21.90 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1606 / 0.04115 / 1.50
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 296 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 21.90 Pidx 4846 train Loss: 49306.5 test Loss: 8281.9
Epoch 297 Iter 0 subLoss 48415.6 multi 18.91 import weight 0.00
Epoch 297 Iter 1 subLoss 48337.2 multi -22.88 import weight 0.00
Epoch 297 Iter 2 subLoss 48365.8 multi -1.99 import weight 0.00
Epoch 297 Iter 3 subLoss 48346.7 multi 12.94 import weight 0.00
Epoch 297 Iter 4 subLoss 48360.8 multi 1.00 import weight 0.00
Epoch 297 Iter 5 subLoss 48317.2 multi -28.85 import weight 0.00
Epoch 297 Iter 6 subLoss 48317.1 multi -25.87 import weight 0.00
Epoch 297 Iter 7 subLoss 48676.5 multi -1.98 import weight 0.00
Epoch 297 Iter 8 subLoss 48345.1 multi 15.93 import weight 0.00
Epoch 297 Iter 9 subLoss 48277.9 multi -52.73 import weight 0.00
Epoch 297 Iter 10 subLoss 48690.2 multi 3.99 import weight 0.00
Epoch 297 Iter 11 subLoss 48326.7 multi 15.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1606 / 0.04111 / 1.60
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 297 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 15.93 Pidx 4832 train Loss: 49455.5 test Loss: 8308.4
Epoch 298 Iter 0 subLoss 48520.0 multi 12.94 import weight 0.00
Epoch 298 Iter 1 subLoss 48390.6 multi 18.91 import weight 0.00
Epoch 298 Iter 2 subLoss 48437.3 multi 3.99 import weight 0.00
Epoch 298 Iter 3 subLoss 48184.9 multi 21.90 import weight 0.00
Epoch 298 Iter 4 subLoss 48263.1 multi 6.97 import weight 1.00
Epoch 298 Iter 5 subLoss 48352.5 multi -37.81 import weight 0.00
Epoch 298 Iter 6 subLoss 48473.1 multi -31.84 import weight 0.00
Epoch 298 Iter 7 subLoss 48583.0 multi 15.93 import weight 0.00
Epoch 298 Iter 8 subLoss 48341.6 multi 18.91 import weight 0.00
Epoch 298 Iter 9 subLoss 48354.4 multi -37.81 import weight 0.00
Epoch 298 Iter 10 subLoss 48416.2 multi 21.90 import weight 0.00
Epoch 298 Iter 11 subLoss 48682.7 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1605 / 0.04109 / 1.60
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 298 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 4868 train Loss: 49434.5 test Loss: 8307.3
Epoch 299 Iter 0 subLoss 48339.0 multi -22.88 import weight 0.00
Epoch 299 Iter 1 subLoss 48470.8 multi -28.85 import weight 0.00
Epoch 299 Iter 2 subLoss 48850.1 multi -19.90 import weight 0.00
Epoch 299 Iter 3 subLoss 49000.6 multi 12.94 import weight 0.00
Epoch 299 Iter 4 subLoss 48970.3 multi -1.99 import weight 0.00
Epoch 299 Iter 5 subLoss 49055.8 multi 9.96 import weight 0.00
Epoch 299 Iter 6 subLoss 48799.6 multi -7.96 import weight 0.00
Epoch 299 Iter 7 subLoss 48900.5 multi 12.94 import weight 0.00
Epoch 299 Iter 8 subLoss 48469.4 multi 24.88 import weight 0.00
Epoch 299 Iter 9 subLoss 48566.6 multi -7.96 import weight 0.00
Epoch 299 Iter 10 subLoss 48620.9 multi 18.91 import weight 0.00
Epoch 299 Iter 11 subLoss 48495.8 multi -16.91 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1605 / 0.04106 / 1.70
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.7, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 299 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -16.91 Pidx 4849 train Loss: 49475.8 test Loss: 8313.8
Epoch 300 Iter 0 subLoss 48646.9 multi -7.96 import weight 0.00
Epoch 300 Iter 1 subLoss 48675.1 multi 1.00 import weight 0.00
Epoch 300 Iter 2 subLoss 48491.8 multi -13.93 import weight 0.00
Epoch 300 Iter 3 subLoss 48614.2 multi -19.90 import weight 0.00
Epoch 300 Iter 4 subLoss 48796.0 multi -4.97 import weight 0.00
Epoch 300 Iter 5 subLoss 48872.2 multi 1.00 import weight 0.00
Epoch 300 Iter 6 subLoss 48922.5 multi 18.91 import weight 0.00
Epoch 300 Iter 7 subLoss 48647.4 multi -4.97 import weight 0.00
Epoch 300 Iter 8 subLoss 48693.4 multi 3.99 import weight 0.00
Epoch 300 Iter 9 subLoss 48806.2 multi 18.91 import weight 0.00
Epoch 300 Iter 10 subLoss 48484.3 multi 15.93 import weight 0.00
Epoch 300 Iter 11 subLoss 48356.8 multi -34.82 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1605 / 0.04103 / 1.70
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.7, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 300 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -34.82 Pidx 4835 train Loss: 49523.7 test Loss: 8321.1
Epoch 301 Iter 0 subLoss 48389.2 multi -13.93 import weight 0.00
Epoch 301 Iter 1 subLoss 48635.5 multi -7.96 import weight 0.00
Epoch 301 Iter 2 subLoss 48745.5 multi 3.99 import weight 0.00
Epoch 301 Iter 3 subLoss 48515.7 multi 15.93 import weight 0.00
Epoch 301 Iter 4 subLoss 48562.7 multi -4.97 import weight 0.00
Epoch 301 Iter 5 subLoss 48507.3 multi -7.96 import weight 0.00
Epoch 301 Iter 6 subLoss 48724.9 multi 21.90 import weight 0.00
Epoch 301 Iter 7 subLoss 48524.4 multi -25.87 import weight 0.00
Epoch 301 Iter 8 subLoss 48694.4 multi 6.97 import weight 0.00
Epoch 301 Iter 9 subLoss 48613.2 multi -16.91 import weight 0.00
Epoch 301 Iter 10 subLoss 48681.5 multi -7.96 import weight 0.00
Epoch 301 Iter 11 subLoss 48940.6 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1605 / 0.04102 / 1.70
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.7, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 301 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 4894 train Loss: 49658.4 test Loss: 8343.4
Epoch 302 Iter 0 subLoss 48858.2 multi -16.91 import weight 0.00
Epoch 302 Iter 1 subLoss 48869.1 multi -1.98 import weight 0.00
Epoch 302 Iter 2 subLoss 48903.2 multi 15.93 import weight 0.00
Epoch 302 Iter 3 subLoss 48772.1 multi 24.88 import weight 0.00
Epoch 302 Iter 4 subLoss 48263.8 multi 9.96 import weight 1.00
Epoch 302 Iter 5 subLoss 48445.8 multi -4.97 import weight 0.00
Epoch 302 Iter 6 subLoss 48393.7 multi 18.91 import weight 0.00
Epoch 302 Iter 7 subLoss 48488.9 multi 18.91 import weight 0.00
Epoch 302 Iter 8 subLoss 48300.7 multi -31.84 import weight 0.00
Epoch 302 Iter 9 subLoss 48431.7 multi 6.97 import weight 0.00
Epoch 302 Iter 10 subLoss 48411.9 multi 24.88 import weight 0.00
Epoch 302 Iter 11 subLoss 48259.6 multi 39.81 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1604 / 0.04099 / 1.70
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.7, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 302 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 39.81 Pidx 4825 train Loss: 49224.5 test Loss: 8268.0
Epoch 303 Iter 0 subLoss 48271.9 multi -55.72 import weight 0.00
Epoch 303 Iter 1 subLoss 48334.2 multi -19.90 import weight 0.00
Epoch 303 Iter 2 subLoss 48225.5 multi 6.97 import weight 0.00
Epoch 303 Iter 3 subLoss 48454.0 multi -28.85 import weight 0.00
Epoch 303 Iter 4 subLoss 48446.8 multi -4.97 import weight 0.00
Epoch 303 Iter 5 subLoss 48552.5 multi -13.93 import weight 0.00
Epoch 303 Iter 6 subLoss 48486.6 multi 21.90 import weight 0.00
Epoch 303 Iter 7 subLoss 48577.8 multi -34.82 import weight 0.00
Epoch 303 Iter 8 subLoss 48518.3 multi 15.93 import weight 0.00
Epoch 303 Iter 9 subLoss 48704.8 multi -22.88 import weight 0.00
Epoch 303 Iter 10 subLoss 48898.7 multi -19.90 import weight 0.00
Epoch 303 Iter 11 subLoss 49087.4 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1604 / 0.04099 / 1.80
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 303 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 4908 train Loss: 50227.2 test Loss: 8428.3
Epoch 304 Iter 0 subLoss 49518.8 multi 3.99 import weight 0.00
Epoch 304 Iter 1 subLoss 48980.5 multi -10.94 import weight 0.00
Epoch 304 Iter 2 subLoss 49476.4 multi 3.98 import weight 0.00
Epoch 304 Iter 3 subLoss 49363.5 multi -4.97 import weight 0.00
Epoch 304 Iter 4 subLoss 49350.5 multi -4.97 import weight 0.00
Epoch 304 Iter 5 subLoss 49614.6 multi 9.96 import weight 0.00
Epoch 304 Iter 6 subLoss 49439.1 multi 1.00 import weight 0.00
Epoch 304 Iter 7 subLoss 49177.6 multi 1.00 import weight 0.00
Epoch 304 Iter 8 subLoss 48768.4 multi -10.94 import weight 0.00
Epoch 304 Iter 9 subLoss 49474.3 multi 6.97 import weight 0.00
Epoch 304 Iter 10 subLoss 48994.3 multi 3.99 import weight 0.00
Epoch 304 Iter 11 subLoss 49156.8 multi -1.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1604 / 0.04098 / 1.80
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 304 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 4915 train Loss: 50156.5 test Loss: 8417.6
Epoch 305 Iter 0 subLoss 49481.7 multi 6.97 import weight 0.00
Epoch 305 Iter 1 subLoss 49142.9 multi 1.00 import weight 0.00
Epoch 305 Iter 2 subLoss 49116.4 multi -13.93 import weight 0.00
Epoch 305 Iter 3 subLoss 49108.5 multi 1.00 import weight 0.00
Epoch 305 Iter 4 subLoss 49395.9 multi -13.93 import weight 0.00
Epoch 305 Iter 5 subLoss 49689.6 multi 15.93 import weight 0.00
Epoch 305 Iter 6 subLoss 49366.0 multi -4.97 import weight 0.00
Epoch 305 Iter 7 subLoss 49081.3 multi -4.97 import weight 0.00
Epoch 305 Iter 8 subLoss 49470.1 multi 9.96 import weight 0.00
Epoch 305 Iter 9 subLoss 49180.4 multi -10.94 import weight 0.00
Epoch 305 Iter 10 subLoss 49101.6 multi 3.99 import weight 0.00
Epoch 305 Iter 11 subLoss 48733.5 multi -13.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1604 / 0.04098 / 1.90
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 305 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -13.93 Pidx 4873 train Loss: 50483.8 test Loss: 8471.4
Epoch 306 Iter 0 subLoss 49495.7 multi 1.00 import weight 0.00
Epoch 306 Iter 1 subLoss 49653.1 multi 9.96 import weight 0.00
Epoch 306 Iter 2 subLoss 49364.6 multi -1.98 import weight 0.00
Epoch 306 Iter 3 subLoss 49232.2 multi 9.96 import weight 0.00
Epoch 306 Iter 4 subLoss 49077.0 multi 12.94 import weight 0.00
Epoch 306 Iter 5 subLoss 48810.4 multi -22.88 import weight 0.00
Epoch 306 Iter 6 subLoss 49067.4 multi -10.94 import weight 0.00
Epoch 306 Iter 7 subLoss 49419.6 multi -4.97 import weight 0.00
Epoch 306 Iter 8 subLoss 49443.4 multi -13.93 import weight 0.00
Epoch 306 Iter 9 subLoss 49696.8 multi -7.96 import weight 0.00
Epoch 306 Iter 10 subLoss 50667.0 multi 1.00 import weight 0.00
Epoch 306 Iter 11 subLoss 49881.9 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1604 / 0.04099 / 2.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 306 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 4988 train Loss: 51155.9 test Loss: 8580.8
Epoch 307 Iter 0 subLoss 50574.4 multi 1.00 import weight 0.00
Epoch 307 Iter 1 subLoss 50030.7 multi 1.00 import weight 0.00
Epoch 307 Iter 2 subLoss 50021.4 multi 3.98 import weight 0.00
Epoch 307 Iter 3 subLoss 50177.7 multi -1.98 import weight 0.00
Epoch 307 Iter 4 subLoss 49961.5 multi -7.96 import weight 0.00
Epoch 307 Iter 5 subLoss 50702.5 multi 3.99 import weight 0.00
Epoch 307 Iter 6 subLoss 50136.0 multi 1.00 import weight 0.00
Epoch 307 Iter 7 subLoss 50135.4 multi 3.98 import weight 0.00
Epoch 307 Iter 8 subLoss 49665.2 multi -10.94 import weight 0.00
Epoch 307 Iter 9 subLoss 49999.7 multi 1.00 import weight 0.00
Epoch 307 Iter 10 subLoss 50051.7 multi -1.99 import weight 0.00
Epoch 307 Iter 11 subLoss 50214.8 multi -1.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1604 / 0.04101 / 2.10
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 307 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 5021 train Loss: 51411.2 test Loss: 8622.3
Epoch 308 Iter 0 subLoss 50189.9 multi 1.00 import weight 0.00
Epoch 308 Iter 1 subLoss 50896.2 multi 1.00 import weight 0.00
Epoch 308 Iter 2 subLoss 50247.7 multi 1.00 import weight 0.00
Epoch 308 Iter 3 subLoss 50317.1 multi 1.00 import weight 0.00
Epoch 308 Iter 4 subLoss 50196.6 multi -7.96 import weight 0.00
Epoch 308 Iter 5 subLoss 50703.1 multi 6.97 import weight 0.00
Epoch 308 Iter 6 subLoss 50420.8 multi -1.99 import weight 0.00
Epoch 308 Iter 7 subLoss 50160.7 multi 6.97 import weight 0.00
Epoch 308 Iter 8 subLoss 50251.1 multi 1.00 import weight 0.00
Epoch 308 Iter 9 subLoss 50107.3 multi 1.00 import weight 0.00
Epoch 308 Iter 10 subLoss 49694.5 multi -4.97 import weight 0.00
Epoch 308 Iter 11 subLoss 49936.7 multi -1.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1604 / 0.04102 / 2.20
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 308 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 4993 train Loss: 51231.1 test Loss: 8593.1
Epoch 309 Iter 0 subLoss 50651.8 multi 1.00 import weight 0.00
Epoch 309 Iter 1 subLoss 50956.6 multi 1.00 import weight 0.00
Epoch 309 Iter 2 subLoss 50086.5 multi 1.00 import weight 0.00
Epoch 309 Iter 3 subLoss 49808.2 multi -7.96 import weight 0.00
Epoch 309 Iter 4 subLoss 50490.9 multi 1.00 import weight 0.00
Epoch 309 Iter 5 subLoss 50130.2 multi 6.97 import weight 0.00
Epoch 309 Iter 6 subLoss 49913.9 multi 1.00 import weight 0.00
Epoch 309 Iter 7 subLoss 49784.1 multi 3.99 import weight 0.00
Epoch 309 Iter 8 subLoss 49876.7 multi -4.97 import weight 0.00
Epoch 309 Iter 9 subLoss 49997.5 multi 3.99 import weight 0.00
Epoch 309 Iter 10 subLoss 49971.2 multi 3.98 import weight 0.00
Epoch 309 Iter 11 subLoss 49806.3 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1604 / 0.04103 / 2.20
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 309 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 4980 train Loss: 50986.1 test Loss: 8552.8
Epoch 310 Iter 0 subLoss 50027.1 multi 6.97 import weight 0.00
Epoch 310 Iter 1 subLoss 49945.7 multi 1.00 import weight 0.00
Epoch 310 Iter 2 subLoss 49755.2 multi -4.97 import weight 0.00
Epoch 310 Iter 3 subLoss 49894.5 multi -1.99 import weight 0.00
Epoch 310 Iter 4 subLoss 50107.9 multi 3.98 import weight 0.00
Epoch 310 Iter 5 subLoss 49979.0 multi 6.97 import weight 0.00
Epoch 310 Iter 6 subLoss 49373.1 multi 15.93 import weight 0.00
Epoch 310 Iter 7 subLoss 49371.8 multi 18.91 import weight 0.00
Epoch 310 Iter 8 subLoss 48919.1 multi -37.81 import weight 0.00
Epoch 310 Iter 9 subLoss 49220.5 multi -1.99 import weight 0.00
Epoch 310 Iter 10 subLoss 49300.0 multi 1.00 import weight 0.00
Epoch 310 Iter 11 subLoss 49563.9 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1604 / 0.04103 / 2.30
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 310 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 4956 train Loss: 50181.3 test Loss: 8421.9
Epoch 311 Iter 0 subLoss 49179.8 multi 3.98 import weight 0.00
Epoch 311 Iter 1 subLoss 49203.9 multi -10.94 import weight 0.00
Epoch 311 Iter 2 subLoss 49315.0 multi -13.93 import weight 0.00
Epoch 311 Iter 3 subLoss 49597.9 multi -4.97 import weight 0.00
Epoch 311 Iter 4 subLoss 49696.0 multi -1.99 import weight 0.00
Epoch 311 Iter 5 subLoss 49575.3 multi -7.96 import weight 0.00
Epoch 311 Iter 6 subLoss 50241.6 multi 3.99 import weight 0.00
Epoch 311 Iter 7 subLoss 49911.8 multi 3.99 import weight 0.00
Epoch 311 Iter 8 subLoss 50136.1 multi 9.96 import weight 0.00
Epoch 311 Iter 9 subLoss 49444.7 multi -10.94 import weight 0.00
Epoch 311 Iter 10 subLoss 49821.5 multi 1.00 import weight 0.00
Epoch 311 Iter 11 subLoss 49779.9 multi -10.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1604 / 0.04105 / 2.40
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 311 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -10.94 Pidx 4977 train Loss: 51086.6 test Loss: 8569.5
Epoch 312 Iter 0 subLoss 50203.1 multi 3.98 import weight 0.00
Epoch 312 Iter 1 subLoss 49658.2 multi 12.94 import weight 0.00
Epoch 312 Iter 2 subLoss 49611.8 multi 12.94 import weight 0.00
Epoch 312 Iter 3 subLoss 49106.8 multi 6.97 import weight 0.00
Epoch 312 Iter 4 subLoss 49360.1 multi 1.00 import weight 0.00
Epoch 312 Iter 5 subLoss 49345.8 multi 12.94 import weight 0.00
Epoch 312 Iter 6 subLoss 48714.8 multi 3.99 import weight 0.00
Epoch 312 Iter 7 subLoss 48734.9 multi -10.94 import weight 0.00
Epoch 312 Iter 8 subLoss 49053.3 multi 12.94 import weight 0.00
Epoch 312 Iter 9 subLoss 48919.2 multi -34.82 import weight 0.00
Epoch 312 Iter 10 subLoss 49068.4 multi -10.94 import weight 0.00
Epoch 312 Iter 11 subLoss 49627.2 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1604 / 0.04106 / 2.40
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 312 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 4962 train Loss: 50705.3 test Loss: 8506.7
Epoch 313 Iter 0 subLoss 49865.5 multi 12.94 import weight 0.00
Epoch 313 Iter 1 subLoss 49303.4 multi 15.93 import weight 0.00
Epoch 313 Iter 2 subLoss 48996.6 multi 6.97 import weight 0.00
Epoch 313 Iter 3 subLoss 48748.5 multi 1.00 import weight 0.00
Epoch 313 Iter 4 subLoss 49015.8 multi 1.00 import weight 0.00
Epoch 313 Iter 5 subLoss 49069.6 multi -7.96 import weight 0.00
Epoch 313 Iter 6 subLoss 48971.3 multi 1.00 import weight 0.00
Epoch 313 Iter 7 subLoss 49138.9 multi 9.96 import weight 0.00
Epoch 313 Iter 8 subLoss 48560.1 multi -4.97 import weight 0.00
Epoch 313 Iter 9 subLoss 49203.9 multi -7.96 import weight 0.00
Epoch 313 Iter 10 subLoss 48986.7 multi -10.94 import weight 0.00
Epoch 313 Iter 11 subLoss 49209.1 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1604 / 0.04106 / 2.40
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 313 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 4920 train Loss: 50308.7 test Loss: 8442.3
Epoch 314 Iter 0 subLoss 49339.4 multi -19.90 import weight 0.00
Epoch 314 Iter 1 subLoss 49821.0 multi 3.98 import weight 0.00
Epoch 314 Iter 2 subLoss 49647.3 multi -13.93 import weight 0.00
Epoch 314 Iter 3 subLoss 50156.2 multi 1.00 import weight 0.00
Epoch 314 Iter 4 subLoss 50075.2 multi 1.00 import weight 0.00
Epoch 314 Iter 5 subLoss 49746.2 multi 6.97 import weight 0.00
Epoch 314 Iter 6 subLoss 49980.4 multi -10.94 import weight 0.00
Epoch 314 Iter 7 subLoss 49866.1 multi 15.93 import weight 0.00
Epoch 314 Iter 8 subLoss 49630.7 multi 9.96 import weight 0.00
Epoch 314 Iter 9 subLoss 49777.6 multi -7.96 import weight 0.00
Epoch 314 Iter 10 subLoss 49229.8 multi 1.00 import weight 0.00
Epoch 314 Iter 11 subLoss 49757.7 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1604 / 0.04107 / 2.50
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 314 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 4975 train Loss: 50712.8 test Loss: 8509.4
Epoch 315 Iter 0 subLoss 49318.6 multi -13.93 import weight 0.00
Epoch 315 Iter 1 subLoss 49496.2 multi 3.98 import weight 0.00
Epoch 315 Iter 2 subLoss 50559.1 multi 1.00 import weight 0.00
Epoch 315 Iter 3 subLoss 49996.9 multi 3.98 import weight 0.00
Epoch 315 Iter 4 subLoss 49880.3 multi -1.99 import weight 0.00
Epoch 315 Iter 5 subLoss 50048.3 multi -4.97 import weight 0.00
Epoch 315 Iter 6 subLoss 50327.3 multi -1.99 import weight 0.00
Epoch 315 Iter 7 subLoss 49888.8 multi 1.00 import weight 0.00
Epoch 315 Iter 8 subLoss 50047.4 multi -1.99 import weight 0.00
Epoch 315 Iter 9 subLoss 50167.4 multi 6.97 import weight 0.00
Epoch 315 Iter 10 subLoss 49870.7 multi -7.96 import weight 0.00
Epoch 315 Iter 11 subLoss 50088.5 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1604 / 0.04109 / 2.60
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 315 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 5008 train Loss: 51119.5 test Loss: 8576.4
Epoch 316 Iter 0 subLoss 49899.8 multi -4.97 import weight 0.00
Epoch 316 Iter 1 subLoss 50660.2 multi 1.00 import weight 0.00
Epoch 316 Iter 2 subLoss 50523.3 multi 1.00 import weight 0.00
Epoch 316 Iter 3 subLoss 50011.1 multi -4.97 import weight 0.00
Epoch 316 Iter 4 subLoss 50420.8 multi 1.00 import weight 0.00
Epoch 316 Iter 5 subLoss 50561.3 multi -1.99 import weight 0.00
Epoch 316 Iter 6 subLoss 50448.3 multi -1.99 import weight 0.00
Epoch 316 Iter 7 subLoss 50215.1 multi -1.99 import weight 0.00
Epoch 316 Iter 8 subLoss 50118.9 multi 1.00 import weight 0.00
Epoch 316 Iter 9 subLoss 50959.4 multi 3.99 import weight 0.00
Epoch 316 Iter 10 subLoss 50454.2 multi 1.00 import weight 0.00
Epoch 316 Iter 11 subLoss 50078.9 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1604 / 0.04111 / 2.60
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 316 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 5007 train Loss: 51180.8 test Loss: 8586.4
Epoch 317 Iter 0 subLoss 50005.9 multi 1.00 import weight 0.00
Epoch 317 Iter 1 subLoss 49996.8 multi 6.97 import weight 0.00
Epoch 317 Iter 2 subLoss 49974.3 multi 9.96 import weight 0.00
Epoch 317 Iter 3 subLoss 49591.2 multi -1.98 import weight 0.00
Epoch 317 Iter 4 subLoss 49513.9 multi 6.97 import weight 0.00
Epoch 317 Iter 5 subLoss 49620.0 multi -4.97 import weight 0.00
Epoch 317 Iter 6 subLoss 49583.1 multi 3.98 import weight 0.00
Epoch 317 Iter 7 subLoss 49579.2 multi -4.97 import weight 0.00
Epoch 317 Iter 8 subLoss 49662.6 multi -10.94 import weight 0.00
Epoch 317 Iter 9 subLoss 50029.9 multi 6.97 import weight 0.00
Epoch 317 Iter 10 subLoss 49614.0 multi 15.93 import weight 0.00
Epoch 317 Iter 11 subLoss 49628.8 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1604 / 0.04112 / 2.70
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.7, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 317 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 4962 train Loss: 50438.4 test Loss: 8464.6
Epoch 318 Iter 0 subLoss 49257.9 multi -7.96 import weight 0.00
Epoch 318 Iter 1 subLoss 49635.8 multi 6.97 import weight 0.00
Epoch 318 Iter 2 subLoss 49554.2 multi 1.00 import weight 0.00
Epoch 318 Iter 3 subLoss 49445.8 multi -7.96 import weight 0.00
Epoch 318 Iter 4 subLoss 49921.8 multi -4.97 import weight 0.00
Epoch 318 Iter 5 subLoss 49787.7 multi 1.00 import weight 0.00
Epoch 318 Iter 6 subLoss 49666.4 multi -7.96 import weight 0.00
Epoch 318 Iter 7 subLoss 49930.8 multi -1.99 import weight 0.00
Epoch 318 Iter 8 subLoss 50213.6 multi 1.00 import weight 0.00
Epoch 318 Iter 9 subLoss 49842.1 multi 12.94 import weight 0.00
Epoch 318 Iter 10 subLoss 49349.2 multi 12.94 import weight 0.00
Epoch 318 Iter 11 subLoss 49231.6 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1605 / 0.04112 / 2.70
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.7, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 318 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 4923 train Loss: 50164.2 test Loss: 8419.9
Epoch 319 Iter 0 subLoss 49345.5 multi 15.93 import weight 0.00
Epoch 319 Iter 1 subLoss 48705.1 multi -19.90 import weight 0.00
Epoch 319 Iter 2 subLoss 49006.5 multi 9.96 import weight 0.00
Epoch 319 Iter 3 subLoss 49083.7 multi -4.97 import weight 0.00
Epoch 319 Iter 4 subLoss 49100.4 multi 9.96 import weight 0.00
Epoch 319 Iter 5 subLoss 48829.2 multi -4.97 import weight 0.00
Epoch 319 Iter 6 subLoss 48901.5 multi 15.93 import weight 0.00
Epoch 319 Iter 7 subLoss 48820.2 multi -1.98 import weight 0.00
Epoch 319 Iter 8 subLoss 48989.0 multi -7.96 import weight 0.00
Epoch 319 Iter 9 subLoss 48864.7 multi 1.00 import weight 0.00
Epoch 319 Iter 10 subLoss 48998.6 multi 3.99 import weight 0.00
Epoch 319 Iter 11 subLoss 48831.6 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1604 / 0.04111 / 2.70
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.7, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 319 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4883 train Loss: 49806.2 test Loss: 8361.7
Epoch 320 Iter 0 subLoss 48756.9 multi -7.96 import weight 0.00
Epoch 320 Iter 1 subLoss 49026.9 multi -22.88 import weight 0.00
Epoch 320 Iter 2 subLoss 49237.8 multi 9.96 import weight 0.00
Epoch 320 Iter 3 subLoss 49289.4 multi -7.96 import weight 0.00
Epoch 320 Iter 4 subLoss 49150.2 multi -1.99 import weight 0.00
Epoch 320 Iter 5 subLoss 49224.0 multi 3.98 import weight 0.00
Epoch 320 Iter 6 subLoss 49179.0 multi 6.97 import weight 0.00
Epoch 320 Iter 7 subLoss 48900.1 multi 18.91 import weight 0.00
Epoch 320 Iter 8 subLoss 48943.7 multi 9.96 import weight 0.00
Epoch 320 Iter 9 subLoss 48790.4 multi -1.99 import weight 0.00
Epoch 320 Iter 10 subLoss 48744.9 multi 3.99 import weight 0.00
Epoch 320 Iter 11 subLoss 48708.7 multi -16.91 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1604 / 0.04111 / 2.70
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.7, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 320 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -16.91 Pidx 4870 train Loss: 49845.0 test Loss: 8369.0
Epoch 321 Iter 0 subLoss 48680.6 multi -4.97 import weight 0.00
Epoch 321 Iter 1 subLoss 49244.5 multi 6.97 import weight 0.00
Epoch 321 Iter 2 subLoss 48746.4 multi 6.97 import weight 0.00
Epoch 321 Iter 3 subLoss 48747.3 multi 9.96 import weight 0.00
Epoch 321 Iter 4 subLoss 48538.6 multi 21.90 import weight 0.00
Epoch 321 Iter 5 subLoss 48464.1 multi 24.88 import weight 0.00
Epoch 321 Iter 6 subLoss 48574.1 multi -34.82 import weight 0.00
Epoch 321 Iter 7 subLoss 48553.0 multi -10.94 import weight 0.00
Epoch 321 Iter 8 subLoss 48874.0 multi -1.99 import weight 0.00
Epoch 321 Iter 9 subLoss 48561.6 multi -4.97 import weight 0.00
Epoch 321 Iter 10 subLoss 48662.4 multi 3.98 import weight 0.00
Epoch 321 Iter 11 subLoss 48661.7 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1604 / 0.04110 / 2.70
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.7, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 321 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 4866 train Loss: 49619.9 test Loss: 8334.3
Epoch 322 Iter 0 subLoss 48533.9 multi 24.88 import weight 0.00
Epoch 322 Iter 1 subLoss 48451.2 multi -28.85 import weight 0.00
Epoch 322 Iter 2 subLoss 48736.7 multi -7.96 import weight 0.00
Epoch 322 Iter 3 subLoss 48771.0 multi 24.88 import weight 0.00
Epoch 322 Iter 4 subLoss 48473.7 multi -31.84 import weight 0.00
Epoch 322 Iter 5 subLoss 48889.8 multi 24.88 import weight 0.00
Epoch 322 Iter 6 subLoss 48353.0 multi -31.84 import weight 0.00
Epoch 322 Iter 7 subLoss 48679.0 multi -1.99 import weight 0.00
Epoch 322 Iter 8 subLoss 48757.2 multi -13.93 import weight 0.00
Epoch 322 Iter 9 subLoss 48892.5 multi -19.90 import weight 0.00
Epoch 322 Iter 10 subLoss 49107.6 multi 12.94 import weight 0.00
Epoch 322 Iter 11 subLoss 48982.0 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1604 / 0.04109 / 2.60
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 322 Acc: 19.65 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 4898 train Loss: 49950.0 test Loss: 8388.3
Epoch 323 Iter 0 subLoss 49019.9 multi 1.00 import weight 0.00
Epoch 323 Iter 1 subLoss 48841.4 multi 3.99 import weight 0.00
Epoch 323 Iter 2 subLoss 48837.9 multi 3.99 import weight 0.00
Epoch 323 Iter 3 subLoss 49021.9 multi -22.88 import weight 0.00
Epoch 323 Iter 4 subLoss 49166.9 multi -4.97 import weight 0.00
Epoch 323 Iter 5 subLoss 49214.7 multi -7.96 import weight 0.00
Epoch 323 Iter 6 subLoss 49413.8 multi -1.98 import weight 0.00
Epoch 323 Iter 7 subLoss 49751.3 multi -1.98 import weight 0.00
Epoch 323 Iter 8 subLoss 49460.1 multi -4.97 import weight 0.00
Epoch 323 Iter 9 subLoss 49642.2 multi -16.91 import weight 0.00
Epoch 323 Iter 10 subLoss 50190.6 multi -4.97 import weight 0.00
Epoch 323 Iter 11 subLoss 50530.8 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1604 / 0.04110 / 2.50
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 323 Acc: 19.65 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 5053 train Loss: 51461.6 test Loss: 8641.5
Epoch 324 Iter 0 subLoss 50775.1 multi 1.00 import weight 0.00
Epoch 324 Iter 1 subLoss 50365.6 multi 1.00 import weight 0.00
Epoch 324 Iter 2 subLoss 50768.7 multi -1.99 import weight 0.00
Epoch 324 Iter 3 subLoss 49891.6 multi -1.98 import weight 0.00
Epoch 324 Iter 4 subLoss 50793.6 multi 1.00 import weight 0.00
Epoch 324 Iter 5 subLoss 50397.5 multi -1.98 import weight 0.00
Epoch 324 Iter 6 subLoss 51141.3 multi 1.00 import weight 0.00
Epoch 324 Iter 7 subLoss 50645.4 multi 1.00 import weight 0.00
Epoch 324 Iter 8 subLoss 49999.0 multi 9.96 import weight 0.00
Epoch 324 Iter 9 subLoss 50051.1 multi -4.97 import weight 0.00
Epoch 324 Iter 10 subLoss 50364.6 multi 3.99 import weight 0.00
Epoch 324 Iter 11 subLoss 49782.9 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1604 / 0.04110 / 2.50
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 324 Acc: 19.65 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 4978 train Loss: 51015.5 test Loss: 8567.1
Epoch 325 Iter 0 subLoss 49941.9 multi 1.00 import weight 0.00
Epoch 325 Iter 1 subLoss 50178.7 multi -4.97 import weight 0.00
Epoch 325 Iter 2 subLoss 50116.6 multi 3.99 import weight 0.00
Epoch 325 Iter 3 subLoss 50195.4 multi -1.99 import weight 0.00
Epoch 325 Iter 4 subLoss 50292.2 multi 1.00 import weight 0.00
Epoch 325 Iter 5 subLoss 50203.2 multi 1.00 import weight 0.00
Epoch 325 Iter 6 subLoss 50233.4 multi -1.99 import weight 0.00
Epoch 325 Iter 7 subLoss 49659.3 multi 9.96 import weight 0.00
Epoch 325 Iter 8 subLoss 49853.3 multi -13.93 import weight 0.00
Epoch 325 Iter 9 subLoss 50260.5 multi -1.98 import weight 0.00
Epoch 325 Iter 10 subLoss 50589.9 multi -1.99 import weight 0.00
Epoch 325 Iter 11 subLoss 49678.4 multi -10.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1605 / 0.04110 / 2.40
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 325 Acc: 19.65 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -10.94 Pidx 4967 train Loss: 51798.8 test Loss: 8696.8
Epoch 326 Iter 0 subLoss 50818.7 multi 1.00 import weight 0.00
Epoch 326 Iter 1 subLoss 50725.9 multi 1.00 import weight 0.00
Epoch 326 Iter 2 subLoss 51032.2 multi 1.00 import weight 0.00
Epoch 326 Iter 3 subLoss 50275.0 multi -4.97 import weight 0.00
Epoch 326 Iter 4 subLoss 50971.7 multi 1.00 import weight 0.00
Epoch 326 Iter 5 subLoss 50526.7 multi 3.99 import weight 0.00
Epoch 326 Iter 6 subLoss 50630.6 multi 1.00 import weight 0.00
Epoch 326 Iter 7 subLoss 51021.4 multi 1.00 import weight 0.00
Epoch 326 Iter 8 subLoss 50242.6 multi 3.98 import weight 0.00
Epoch 326 Iter 9 subLoss 50022.9 multi 9.96 import weight 0.00
Epoch 326 Iter 10 subLoss 50102.5 multi 6.97 import weight 0.00
Epoch 326 Iter 11 subLoss 50151.2 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1605 / 0.04110 / 2.40
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 326 Acc: 19.65 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 5015 train Loss: 50686.5 test Loss: 8511.3
Epoch 327 Iter 0 subLoss 49485.8 multi 6.97 import weight 0.00
Epoch 327 Iter 1 subLoss 49540.5 multi -7.96 import weight 0.00
Epoch 327 Iter 2 subLoss 49923.7 multi -1.99 import weight 0.00
Epoch 327 Iter 3 subLoss 50089.4 multi 1.00 import weight 0.00
Epoch 327 Iter 4 subLoss 49291.4 multi 1.00 import weight 0.00
Epoch 327 Iter 5 subLoss 49809.1 multi -1.99 import weight 0.00
Epoch 327 Iter 6 subLoss 49516.2 multi 9.96 import weight 0.00
Epoch 327 Iter 7 subLoss 49640.9 multi -13.93 import weight 0.00
Epoch 327 Iter 8 subLoss 49844.6 multi 15.93 import weight 0.00
Epoch 327 Iter 9 subLoss 49643.8 multi -10.94 import weight 0.00
Epoch 327 Iter 10 subLoss 49619.3 multi 18.91 import weight 0.00
Epoch 327 Iter 11 subLoss 49491.1 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1605 / 0.04110 / 2.30
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 327 Acc: 19.65 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 4949 train Loss: 50179.2 test Loss: 8426.9
Epoch 328 Iter 0 subLoss 49084.3 multi -1.99 import weight 0.00
Epoch 328 Iter 1 subLoss 48988.3 multi -1.99 import weight 0.00
Epoch 328 Iter 2 subLoss 49536.2 multi 6.97 import weight 0.00
Epoch 328 Iter 3 subLoss 49058.0 multi 15.93 import weight 0.00
Epoch 328 Iter 4 subLoss 48831.2 multi 6.97 import weight 0.00
Epoch 328 Iter 5 subLoss 48876.5 multi 1.00 import weight 0.00
Epoch 328 Iter 6 subLoss 48693.8 multi 3.99 import weight 0.00
Epoch 328 Iter 7 subLoss 48863.9 multi 3.99 import weight 0.00
Epoch 328 Iter 8 subLoss 48556.9 multi -7.96 import weight 0.00
Epoch 328 Iter 9 subLoss 48900.7 multi 18.91 import weight 0.00
Epoch 328 Iter 10 subLoss 48462.5 multi 24.88 import weight 0.00
Epoch 328 Iter 11 subLoss 48578.1 multi -34.82 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1605 / 0.04110 / 2.30
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 328 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -34.82 Pidx 4857 train Loss: 49648.2 test Loss: 8336.7
Epoch 329 Iter 0 subLoss 48838.7 multi 9.96 import weight 0.00
Epoch 329 Iter 1 subLoss 48560.5 multi -4.97 import weight 0.00
Epoch 329 Iter 2 subLoss 48844.9 multi -1.99 import weight 0.00
Epoch 329 Iter 3 subLoss 48546.1 multi 6.97 import weight 0.00
Epoch 329 Iter 4 subLoss 48675.1 multi 1.00 import weight 0.00
Epoch 329 Iter 5 subLoss 48387.9 multi -10.94 import weight 0.00
Epoch 329 Iter 6 subLoss 48784.8 multi -25.87 import weight 0.00
Epoch 329 Iter 7 subLoss 49011.6 multi 3.98 import weight 0.00
Epoch 329 Iter 8 subLoss 48616.3 multi -13.93 import weight 0.00
Epoch 329 Iter 9 subLoss 48984.9 multi 1.00 import weight 0.00
Epoch 329 Iter 10 subLoss 48942.4 multi 12.94 import weight 0.00
Epoch 329 Iter 11 subLoss 48798.2 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1605 / 0.04109 / 2.30
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 329 Acc: 20.08 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 4879 train Loss: 49830.9 test Loss: 8366.6
Epoch 330 Iter 0 subLoss 48843.0 multi 1.00 import weight 0.00
Epoch 330 Iter 1 subLoss 49067.8 multi -7.96 import weight 0.00
Epoch 330 Iter 2 subLoss 48935.2 multi -7.96 import weight 0.00
Epoch 330 Iter 3 subLoss 49093.1 multi 1.00 import weight 0.00
Epoch 330 Iter 4 subLoss 48958.9 multi -1.99 import weight 0.00
Epoch 330 Iter 5 subLoss 49116.3 multi -25.87 import weight 0.00
Epoch 330 Iter 6 subLoss 48902.7 multi 21.90 import weight 0.00
Epoch 330 Iter 7 subLoss 49549.5 multi -7.96 import weight 0.00
Epoch 330 Iter 8 subLoss 49554.4 multi -1.99 import weight 0.00
Epoch 330 Iter 9 subLoss 49461.4 multi -1.99 import weight 0.00
Epoch 330 Iter 10 subLoss 49044.9 multi -19.90 import weight 0.00
Epoch 330 Iter 11 subLoss 49896.1 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1605 / 0.04110 / 2.30
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 330 Acc: 20.08 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4989 train Loss: 50778.2 test Loss: 8522.7
Epoch 331 Iter 0 subLoss 49563.0 multi 9.96 import weight 0.00
Epoch 331 Iter 1 subLoss 49490.9 multi 6.97 import weight 0.00
Epoch 331 Iter 2 subLoss 49058.5 multi 15.93 import weight 0.00
Epoch 331 Iter 3 subLoss 48945.8 multi 12.94 import weight 0.00
Epoch 331 Iter 4 subLoss 48890.2 multi -16.91 import weight 0.00
Epoch 331 Iter 5 subLoss 49166.6 multi -1.99 import weight 0.00
Epoch 331 Iter 6 subLoss 49329.7 multi 9.96 import weight 0.00
Epoch 331 Iter 7 subLoss 49223.6 multi 3.99 import weight 0.00
Epoch 331 Iter 8 subLoss 49038.3 multi 12.94 import weight 0.00
Epoch 331 Iter 9 subLoss 49083.9 multi 1.00 import weight 0.00
Epoch 331 Iter 10 subLoss 49025.6 multi -22.88 import weight 0.00
Epoch 331 Iter 11 subLoss 49040.9 multi -19.90 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1605 / 0.04111 / 2.20
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 331 Acc: 20.08 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -19.90 Pidx 4904 train Loss: 50455.2 test Loss: 8468.5
Epoch 332 Iter 0 subLoss 49403.6 multi 3.98 import weight 0.00
Epoch 332 Iter 1 subLoss 49229.2 multi 6.97 import weight 0.00
Epoch 332 Iter 2 subLoss 49216.4 multi -4.97 import weight 0.00
Epoch 332 Iter 3 subLoss 49675.1 multi -7.96 import weight 0.00
Epoch 332 Iter 4 subLoss 49513.8 multi 12.94 import weight 0.00
Epoch 332 Iter 5 subLoss 48991.9 multi -1.98 import weight 0.00
Epoch 332 Iter 6 subLoss 49411.9 multi -1.99 import weight 0.00
Epoch 332 Iter 7 subLoss 49020.5 multi -19.90 import weight 0.00
Epoch 332 Iter 8 subLoss 50230.0 multi -7.96 import weight 0.00
Epoch 332 Iter 9 subLoss 50296.8 multi 3.99 import weight 0.00
Epoch 332 Iter 10 subLoss 49975.1 multi 12.94 import weight 0.00
Epoch 332 Iter 11 subLoss 49060.1 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1605 / 0.04111 / 2.20
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 332 Acc: 20.08 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 4906 train Loss: 50628.8 test Loss: 8496.5
Epoch 333 Iter 0 subLoss 49365.1 multi 3.99 import weight 0.00
Epoch 333 Iter 1 subLoss 49651.3 multi 6.97 import weight 0.00
Epoch 333 Iter 2 subLoss 49710.5 multi -1.98 import weight 0.00
Epoch 333 Iter 3 subLoss 49370.3 multi 15.93 import weight 0.00
Epoch 333 Iter 4 subLoss 49223.8 multi 6.97 import weight 0.00
Epoch 333 Iter 5 subLoss 49100.2 multi 12.94 import weight 0.00
Epoch 333 Iter 6 subLoss 48893.2 multi -13.93 import weight 0.00
Epoch 333 Iter 7 subLoss 48703.4 multi -16.91 import weight 0.00
Epoch 333 Iter 8 subLoss 49170.5 multi 3.99 import weight 0.00
Epoch 333 Iter 9 subLoss 48981.0 multi 3.98 import weight 0.00
Epoch 333 Iter 10 subLoss 49087.6 multi 3.99 import weight 0.00
Epoch 333 Iter 11 subLoss 49067.0 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1605 / 0.04111 / 2.20
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 333 Acc: 20.08 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 4906 train Loss: 50064.4 test Loss: 8405.3
Epoch 334 Iter 0 subLoss 49189.6 multi -16.91 import weight 0.00
Epoch 334 Iter 1 subLoss 49368.1 multi 6.97 import weight 0.00
Epoch 334 Iter 2 subLoss 49382.9 multi -13.93 import weight 0.00
Epoch 334 Iter 3 subLoss 49726.2 multi -1.98 import weight 0.00
Epoch 334 Iter 4 subLoss 49306.5 multi 15.93 import weight 0.00
Epoch 334 Iter 5 subLoss 49421.0 multi 3.99 import weight 0.00
Epoch 334 Iter 6 subLoss 49214.9 multi -1.99 import weight 0.00
Epoch 334 Iter 7 subLoss 49120.5 multi -1.99 import weight 0.00
Epoch 334 Iter 8 subLoss 49307.0 multi 18.91 import weight 0.00
Epoch 334 Iter 9 subLoss 48927.0 multi 15.93 import weight 0.00
Epoch 334 Iter 10 subLoss 48673.0 multi 3.98 import weight 0.00
Epoch 334 Iter 11 subLoss 48543.8 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1605 / 0.04111 / 2.20
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 334 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 4854 train Loss: 49595.4 test Loss: 8328.0
Epoch 335 Iter 0 subLoss 48574.7 multi -34.82 import weight 0.00
Epoch 335 Iter 1 subLoss 48923.2 multi 18.91 import weight 0.00
Epoch 335 Iter 2 subLoss 48738.1 multi -4.97 import weight 0.00
Epoch 335 Iter 3 subLoss 48625.8 multi 12.94 import weight 0.00
Epoch 335 Iter 4 subLoss 48608.9 multi 1.00 import weight 0.00
Epoch 335 Iter 5 subLoss 48546.2 multi 12.94 import weight 0.00
Epoch 335 Iter 6 subLoss 48637.8 multi -7.96 import weight 0.00
Epoch 335 Iter 7 subLoss 48620.7 multi 15.93 import weight 0.00
Epoch 335 Iter 8 subLoss 48501.1 multi -4.97 import weight 0.00
Epoch 335 Iter 9 subLoss 48529.5 multi -25.87 import weight 0.00
Epoch 335 Iter 10 subLoss 48628.3 multi 18.91 import weight 0.00
Epoch 335 Iter 11 subLoss 48629.9 multi 21.90 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1605 / 0.04110 / 2.20
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 335 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 21.90 Pidx 4862 train Loss: 49364.9 test Loss: 8290.8
Epoch 336 Iter 0 subLoss 48400.6 multi -25.87 import weight 0.00
Epoch 336 Iter 1 subLoss 48404.3 multi -22.88 import weight 0.00
Epoch 336 Iter 2 subLoss 48608.4 multi 3.99 import weight 0.00
Epoch 336 Iter 3 subLoss 48686.8 multi -10.94 import weight 0.00
Epoch 336 Iter 4 subLoss 48659.3 multi 1.00 import weight 0.00
Epoch 336 Iter 5 subLoss 48605.2 multi 6.97 import weight 0.00
Epoch 336 Iter 6 subLoss 48548.1 multi 15.93 import weight 0.00
Epoch 336 Iter 7 subLoss 48523.3 multi -22.88 import weight 0.00
Epoch 336 Iter 8 subLoss 48723.8 multi 21.90 import weight 0.00
Epoch 336 Iter 9 subLoss 48350.7 multi -28.85 import weight 0.00
Epoch 336 Iter 10 subLoss 48847.9 multi 3.99 import weight 0.00
Epoch 336 Iter 11 subLoss 48651.4 multi 3.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1605 / 0.04109 / 2.10
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 336 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 4865 train Loss: 49543.5 test Loss: 8321.3
Epoch 337 Iter 0 subLoss 48388.8 multi -7.96 import weight 0.00
Epoch 337 Iter 1 subLoss 48660.6 multi 3.99 import weight 0.00
Epoch 337 Iter 2 subLoss 48712.1 multi -1.98 import weight 0.00
Epoch 337 Iter 3 subLoss 48649.2 multi -7.96 import weight 0.00
Epoch 337 Iter 4 subLoss 48786.2 multi -22.88 import weight 0.00
Epoch 337 Iter 5 subLoss 48649.9 multi -4.97 import weight 0.00
Epoch 337 Iter 6 subLoss 48702.9 multi -13.93 import weight 0.00
Epoch 337 Iter 7 subLoss 49155.5 multi 1.00 import weight 0.00
Epoch 337 Iter 8 subLoss 49090.7 multi -1.98 import weight 0.00
Epoch 337 Iter 9 subLoss 49303.1 multi 21.90 import weight 0.00
Epoch 337 Iter 10 subLoss 48744.4 multi 6.97 import weight 0.00
Epoch 337 Iter 11 subLoss 48902.6 multi 18.91 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1605 / 0.04108 / 2.10
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 337 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 18.91 Pidx 4890 train Loss: 49506.5 test Loss: 8313.7
Epoch 338 Iter 0 subLoss 48474.7 multi -31.84 import weight 0.00
Epoch 338 Iter 1 subLoss 48583.0 multi 6.97 import weight 0.00
Epoch 338 Iter 2 subLoss 48627.7 multi 24.88 import weight 0.00
Epoch 338 Iter 3 subLoss 48663.5 multi 6.97 import weight 0.00
Epoch 338 Iter 4 subLoss 48389.5 multi -4.97 import weight 0.00
Epoch 338 Iter 5 subLoss 48602.4 multi 9.96 import weight 0.00
Epoch 338 Iter 6 subLoss 48503.0 multi -1.98 import weight 0.00
Epoch 338 Iter 7 subLoss 48531.8 multi 21.90 import weight 0.00
Epoch 338 Iter 8 subLoss 48205.6 multi 12.94 import weight 0.00
Epoch 338 Iter 9 subLoss 48371.0 multi 6.97 import weight 0.00
Epoch 338 Iter 10 subLoss 48281.5 multi 15.93 import weight 0.00
Epoch 338 Iter 11 subLoss 48283.5 multi 18.91 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1605 / 0.04107 / 2.10
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 338 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 18.91 Pidx 4828 train Loss: 49233.4 test Loss: 8269.9
Epoch 339 Iter 0 subLoss 48244.7 multi 54.73 import weight 0.00
Epoch 339 Iter 1 subLoss 48246.1 multi 57.72 import weight 0.00
Epoch 339 Iter 2 subLoss 48269.4 multi 9.96 import weight 1.00
Epoch 339 Iter 3 subLoss 48226.2 multi 9.96 import weight 0.00
Epoch 339 Iter 4 subLoss 48250.0 multi 36.82 import weight 0.00
Epoch 339 Iter 5 subLoss 48244.4 multi 60.70 import weight 0.00
Epoch 339 Iter 6 subLoss 48238.0 multi -25.87 import weight 0.00
Epoch 339 Iter 7 subLoss 48272.1 multi -55.72 import weight 0.00
Epoch 339 Iter 8 subLoss 48356.8 multi -25.87 import weight 0.00
Epoch 339 Iter 9 subLoss 48214.5 multi 45.78 import weight 0.00
Epoch 339 Iter 10 subLoss 48295.9 multi -4.97 import weight 0.00
Epoch 339 Iter 11 subLoss 48416.0 multi 21.90 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1604 / 0.04105 / 2.10
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 339 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 21.90 Pidx 4841 train Loss: 49213.8 test Loss: 8268.2
Epoch 340 Iter 0 subLoss 48304.9 multi -31.84 import weight 0.00
Epoch 340 Iter 1 subLoss 48409.5 multi -19.90 import weight 0.00
Epoch 340 Iter 2 subLoss 48253.0 multi 36.82 import weight 0.00
Epoch 340 Iter 3 subLoss 48315.5 multi -28.85 import weight 0.00
Epoch 340 Iter 4 subLoss 48218.7 multi 48.76 import weight 0.00
Epoch 340 Iter 5 subLoss 48293.4 multi -1.99 import weight 0.00
Epoch 340 Iter 6 subLoss 48366.7 multi -13.93 import weight 0.00
Epoch 340 Iter 7 subLoss 48199.7 multi 27.87 import weight 0.00
Epoch 340 Iter 8 subLoss 48284.6 multi 18.91 import weight 0.00
Epoch 340 Iter 9 subLoss 48201.8 multi 12.94 import weight 0.00
Epoch 340 Iter 10 subLoss 48236.4 multi -22.88 import weight 0.00
Epoch 340 Iter 11 subLoss 48326.9 multi 15.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1604 / 0.04103 / 2.10
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 340 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 15.93 Pidx 4832 train Loss: 49230.4 test Loss: 8271.9
Epoch 341 Iter 0 subLoss 48320.7 multi 18.91 import weight 0.00
Epoch 341 Iter 1 subLoss 48317.8 multi -25.87 import weight 0.00
Epoch 341 Iter 2 subLoss 48187.9 multi 24.88 import weight 0.00
Epoch 341 Iter 3 subLoss 48274.4 multi -52.73 import weight 0.00
Epoch 341 Iter 4 subLoss 48198.7 multi 27.87 import weight 0.00
Epoch 341 Iter 5 subLoss 48363.6 multi -10.94 import weight 0.00
Epoch 341 Iter 6 subLoss 48316.7 multi -22.88 import weight 0.00
Epoch 341 Iter 7 subLoss 48240.8 multi 57.72 import weight 0.00
Epoch 341 Iter 8 subLoss 48415.1 multi 21.90 import weight 0.00
Epoch 341 Iter 9 subLoss 48181.5 multi 27.87 import weight 0.00
Epoch 341 Iter 10 subLoss 48289.4 multi 18.91 import weight 0.00
Epoch 341 Iter 11 subLoss 48222.3 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1604 / 0.04102 / 2.10
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 341 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 4822 train Loss: 49203.1 test Loss: 8264.6
Epoch 342 Iter 0 subLoss 48237.1 multi -22.88 import weight 0.00
Epoch 342 Iter 1 subLoss 48294.0 multi -4.97 import weight 0.00
Epoch 342 Iter 2 subLoss 48238.5 multi -19.90 import weight 0.00
Epoch 342 Iter 3 subLoss 48254.6 multi 36.82 import weight 0.00
Epoch 342 Iter 4 subLoss 48255.1 multi 39.81 import weight 1.00
Epoch 342 Iter 5 subLoss 48214.7 multi 48.76 import weight 0.00
Epoch 342 Iter 6 subLoss 48331.9 multi -22.88 import weight 0.00
Epoch 342 Iter 7 subLoss 48164.4 multi 6.97 import weight 0.00
Epoch 342 Iter 8 subLoss 48295.1 multi -1.98 import weight 0.00
Epoch 342 Iter 9 subLoss 48294.0 multi 1.00 import weight 0.00
Epoch 342 Iter 10 subLoss 48280.4 multi 21.90 import weight 0.00
Epoch 342 Iter 11 subLoss 48215.4 multi 51.75 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1604 / 0.04100 / 2.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 342 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 51.75 Pidx 4821 train Loss: 49206.5 test Loss: 8265.2
Epoch 343 Iter 0 subLoss 48252.7 multi 42.79 import weight 1.00
Epoch 343 Iter 1 subLoss 48231.5 multi -16.91 import weight 0.00
Epoch 343 Iter 2 subLoss 48260.0 multi -1.98 import weight 1.00
Epoch 343 Iter 3 subLoss 48299.6 multi 1.00 import weight 0.00
Epoch 343 Iter 4 subLoss 48258.4 multi 45.78 import weight 1.00
Epoch 343 Iter 5 subLoss 48270.7 multi -52.73 import weight 0.00
Epoch 343 Iter 6 subLoss 48358.8 multi -22.88 import weight 0.00
Epoch 343 Iter 7 subLoss 48292.4 multi 3.99 import weight 0.00
Epoch 343 Iter 8 subLoss 48332.7 multi -19.90 import weight 0.00
Epoch 343 Iter 9 subLoss 48419.8 multi 24.88 import weight 0.00
Epoch 343 Iter 10 subLoss 48274.1 multi -49.75 import weight 0.00
Epoch 343 Iter 11 subLoss 48422.5 multi -19.90 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1604 / 0.04098 / 2.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 343 Acc: 19.65 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -19.90 Pidx 4842 train Loss: 49506.9 test Loss: 8322.6
Epoch 344 Iter 0 subLoss 48568.1 multi -1.99 import weight 0.00
Epoch 344 Iter 1 subLoss 48538.7 multi 24.88 import weight 0.00
Epoch 344 Iter 2 subLoss 48467.7 multi 27.87 import weight 0.00
Epoch 344 Iter 3 subLoss 48305.7 multi -46.76 import weight 0.00
Epoch 344 Iter 4 subLoss 48370.0 multi 3.99 import weight 0.00
Epoch 344 Iter 5 subLoss 48348.8 multi 9.96 import weight 0.00
Epoch 344 Iter 6 subLoss 48341.5 multi 12.94 import weight 0.00
Epoch 344 Iter 7 subLoss 48346.5 multi 15.93 import weight 0.00
Epoch 344 Iter 8 subLoss 48308.8 multi -43.78 import weight 0.00
Epoch 344 Iter 9 subLoss 48334.5 multi -16.91 import weight 0.00
Epoch 344 Iter 10 subLoss 48473.4 multi -31.84 import weight 0.00
Epoch 344 Iter 11 subLoss 48618.4 multi -22.88 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1604 / 0.04096 / 1.90
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 344 Acc: 19.65 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -22.88 Pidx 4861 train Loss: 49842.7 test Loss: 8378.5
Epoch 345 Iter 0 subLoss 48918.0 multi -46.76 import weight 0.00
Epoch 345 Iter 1 subLoss 49658.6 multi 9.96 import weight 0.00
Epoch 345 Iter 2 subLoss 49308.9 multi 24.88 import weight 0.00
Epoch 345 Iter 3 subLoss 48820.1 multi 1.00 import weight 0.00
Epoch 345 Iter 4 subLoss 48864.3 multi 6.97 import weight 0.00
Epoch 345 Iter 5 subLoss 48719.7 multi -1.99 import weight 0.00
Epoch 345 Iter 6 subLoss 48874.3 multi -1.98 import weight 0.00
Epoch 345 Iter 7 subLoss 48976.8 multi 3.99 import weight 0.00
Epoch 345 Iter 8 subLoss 48642.2 multi -1.99 import weight 0.00
Epoch 345 Iter 9 subLoss 48784.7 multi -19.90 import weight 0.00
Epoch 345 Iter 10 subLoss 49085.8 multi 6.97 import weight 0.00
Epoch 345 Iter 11 subLoss 49034.3 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1604 / 0.04093 / 1.90
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 345 Acc: 19.65 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 4903 train Loss: 49740.2 test Loss: 8359.9
Epoch 346 Iter 0 subLoss 48671.9 multi 1.00 import weight 0.00
Epoch 346 Iter 1 subLoss 48843.7 multi 6.97 import weight 0.00
Epoch 346 Iter 2 subLoss 48740.3 multi 9.96 import weight 0.00
Epoch 346 Iter 3 subLoss 48419.4 multi 27.87 import weight 0.00
Epoch 346 Iter 4 subLoss 48457.8 multi -25.87 import weight 0.00
Epoch 346 Iter 5 subLoss 48586.7 multi 9.96 import weight 0.00
Epoch 346 Iter 6 subLoss 48371.3 multi 6.97 import weight 0.00
Epoch 346 Iter 7 subLoss 48463.5 multi 27.87 import weight 0.00
Epoch 346 Iter 8 subLoss 48299.7 multi 6.97 import weight 0.00
Epoch 346 Iter 9 subLoss 48287.2 multi 18.91 import weight 0.00
Epoch 346 Iter 10 subLoss 48339.0 multi -13.93 import weight 0.00
Epoch 346 Iter 11 subLoss 48399.9 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1603 / 0.04092 / 1.90
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 346 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 4839 train Loss: 49242.8 test Loss: 8271.5
Epoch 347 Iter 0 subLoss 48230.6 multi -13.93 import weight 0.00
Epoch 347 Iter 1 subLoss 48328.6 multi 15.93 import weight 0.00
Epoch 347 Iter 2 subLoss 48293.6 multi 6.97 import weight 0.00
Epoch 347 Iter 3 subLoss 48289.7 multi 21.90 import weight 0.00
Epoch 347 Iter 4 subLoss 48262.7 multi -1.99 import weight 1.00
Epoch 347 Iter 5 subLoss 48293.0 multi 6.97 import weight 0.00
Epoch 347 Iter 6 subLoss 48214.9 multi 54.73 import weight 0.00
Epoch 347 Iter 7 subLoss 48232.5 multi -10.94 import weight 0.00
Epoch 347 Iter 8 subLoss 48254.8 multi 48.76 import weight 1.00
Epoch 347 Iter 9 subLoss 48290.5 multi 9.96 import weight 0.00
Epoch 347 Iter 10 subLoss 48194.0 multi 27.87 import weight 0.00
Epoch 347 Iter 11 subLoss 48282.0 multi 24.88 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1603 / 0.04091 / 1.90
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 347 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 24.88 Pidx 4828 train Loss: 49204.8 test Loss: 8263.2
Epoch 348 Iter 0 subLoss 48203.2 multi 9.96 import weight 0.00
Epoch 348 Iter 1 subLoss 48224.1 multi 1.00 import weight 0.00
Epoch 348 Iter 2 subLoss 48246.6 multi 45.78 import weight 0.00
Epoch 348 Iter 3 subLoss 48297.9 multi 9.96 import weight 0.00
Epoch 348 Iter 4 subLoss 48203.5 multi 12.94 import weight 0.00
Epoch 348 Iter 5 subLoss 48236.5 multi -10.94 import weight 0.00
Epoch 348 Iter 6 subLoss 48233.2 multi -7.96 import weight 0.00
Epoch 348 Iter 7 subLoss 48312.0 multi -25.87 import weight 0.00
Epoch 348 Iter 8 subLoss 48290.6 multi 12.94 import weight 0.00
Epoch 348 Iter 9 subLoss 48223.6 multi 3.98 import weight 0.00
Epoch 348 Iter 10 subLoss 48270.1 multi -49.75 import weight 0.00
Epoch 348 Iter 11 subLoss 48218.0 multi 51.75 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1603 / 0.04090 / 1.80
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 348 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 51.75 Pidx 4821 train Loss: 49213.6 test Loss: 8267.4
Epoch 349 Iter 0 subLoss 48210.1 multi 54.73 import weight 0.00
Epoch 349 Iter 1 subLoss 48252.7 multi 48.76 import weight 1.00
Epoch 349 Iter 2 subLoss 48229.1 multi 1.00 import weight 0.00
Epoch 349 Iter 3 subLoss 48235.2 multi -10.94 import weight 0.00
Epoch 349 Iter 4 subLoss 48265.9 multi -4.97 import weight 0.00
Epoch 349 Iter 5 subLoss 48262.2 multi -1.98 import weight 1.00
Epoch 349 Iter 6 subLoss 48229.2 multi 3.99 import weight 0.00
Epoch 349 Iter 7 subLoss 48238.0 multi -10.94 import weight 0.00
Epoch 349 Iter 8 subLoss 48303.3 multi -58.70 import weight 0.00
Epoch 349 Iter 9 subLoss 48377.9 multi 9.96 import weight 0.00
Epoch 349 Iter 10 subLoss 48386.3 multi -13.93 import weight 0.00
Epoch 349 Iter 11 subLoss 48374.2 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1603 / 0.04088 / 1.80
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 349 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 4837 train Loss: 49260.5 test Loss: 8275.9
Epoch 350 Iter 0 subLoss 48264.4 multi 1.00 import weight 1.00
Epoch 350 Iter 1 subLoss 48387.3 multi -13.93 import weight 0.00
Epoch 350 Iter 2 subLoss 48227.4 multi 6.97 import weight 0.00
Epoch 350 Iter 3 subLoss 48240.6 multi 36.82 import weight 0.00
Epoch 350 Iter 4 subLoss 48315.2 multi -25.87 import weight 0.00
Epoch 350 Iter 5 subLoss 48393.6 multi 9.96 import weight 0.00
Epoch 350 Iter 6 subLoss 48313.6 multi -22.88 import weight 0.00
Epoch 350 Iter 7 subLoss 48416.4 multi 30.85 import weight 0.00
Epoch 350 Iter 8 subLoss 48304.9 multi -55.72 import weight 0.00
Epoch 350 Iter 9 subLoss 48352.5 multi -28.85 import weight 0.00
Epoch 350 Iter 10 subLoss 48271.5 multi -55.72 import weight 0.00
Epoch 350 Iter 11 subLoss 48753.2 multi -16.91 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1603 / 0.04087 / 1.80
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 350 Acc: 19.07 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -16.91 Pidx 4875 train Loss: 49937.2 test Loss: 8390.8
Epoch 351 Iter 0 subLoss 49234.0 multi 1.00 import weight 0.00
Epoch 351 Iter 1 subLoss 48922.2 multi 18.91 import weight 0.00
Epoch 351 Iter 2 subLoss 48610.8 multi -19.90 import weight 0.00
Epoch 351 Iter 3 subLoss 48852.6 multi -28.85 import weight 0.00
Epoch 351 Iter 4 subLoss 49462.8 multi 1.00 import weight 0.00
Epoch 351 Iter 5 subLoss 49402.2 multi 6.97 import weight 0.00
Epoch 351 Iter 6 subLoss 49112.5 multi -25.87 import weight 0.00
Epoch 351 Iter 7 subLoss 49722.7 multi 1.00 import weight 0.00
Epoch 351 Iter 8 subLoss 49657.5 multi 12.94 import weight 0.00
Epoch 351 Iter 9 subLoss 49294.6 multi 3.98 import weight 0.00
Epoch 351 Iter 10 subLoss 49499.7 multi 9.96 import weight 0.00
Epoch 351 Iter 11 subLoss 49028.1 multi -16.91 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1603 / 0.04085 / 1.80
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 351 Acc: 19.07 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -16.91 Pidx 4902 train Loss: 50376.9 test Loss: 8466.2
Epoch 352 Iter 0 subLoss 49453.1 multi -7.96 import weight 0.00
Epoch 352 Iter 1 subLoss 49965.7 multi -4.97 import weight 0.00
Epoch 352 Iter 2 subLoss 49756.5 multi 1.00 import weight 0.00
Epoch 352 Iter 3 subLoss 49718.5 multi 1.00 import weight 0.00
Epoch 352 Iter 4 subLoss 49774.3 multi -4.97 import weight 0.00
Epoch 352 Iter 5 subLoss 49956.9 multi -1.99 import weight 0.00
Epoch 352 Iter 6 subLoss 50123.3 multi -10.94 import weight 0.00
Epoch 352 Iter 7 subLoss 50695.4 multi -1.99 import weight 0.00
Epoch 352 Iter 8 subLoss 50704.9 multi 6.97 import weight 0.00
Epoch 352 Iter 9 subLoss 49992.8 multi 12.94 import weight 0.00
Epoch 352 Iter 10 subLoss 49907.7 multi -10.94 import weight 0.00
Epoch 352 Iter 11 subLoss 50022.8 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1603 / 0.04083 / 1.90
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 352 Acc: 19.07 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 5002 train Loss: 50582.4 test Loss: 8502.5
Epoch 353 Iter 0 subLoss 49604.1 multi -10.94 import weight 0.00
Epoch 353 Iter 1 subLoss 49933.8 multi -1.99 import weight 0.00
Epoch 353 Iter 2 subLoss 49770.8 multi -1.99 import weight 0.00
Epoch 353 Iter 3 subLoss 50241.3 multi 6.97 import weight 0.00
Epoch 353 Iter 4 subLoss 49680.0 multi -4.97 import weight 0.00
Epoch 353 Iter 5 subLoss 50018.4 multi -4.97 import weight 0.00
Epoch 353 Iter 6 subLoss 50795.4 multi 3.99 import weight 0.00
Epoch 353 Iter 7 subLoss 50271.5 multi -1.98 import weight 0.00
Epoch 353 Iter 8 subLoss 50135.4 multi 9.96 import weight 0.00
Epoch 353 Iter 9 subLoss 49924.9 multi 1.00 import weight 0.00
Epoch 353 Iter 10 subLoss 49471.7 multi 3.98 import weight 0.00
Epoch 353 Iter 11 subLoss 49467.8 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1603 / 0.04081 / 1.90
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 353 Acc: 19.07 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4946 train Loss: 50484.3 test Loss: 8486.0
Epoch 354 Iter 0 subLoss 49665.8 multi -16.91 import weight 0.00
Epoch 354 Iter 1 subLoss 50009.7 multi -4.97 import weight 0.00
Epoch 354 Iter 2 subLoss 50210.6 multi 1.00 import weight 0.00
Epoch 354 Iter 3 subLoss 50347.5 multi 1.00 import weight 0.00
Epoch 354 Iter 4 subLoss 50172.7 multi -1.99 import weight 0.00
Epoch 354 Iter 5 subLoss 50600.8 multi 3.99 import weight 0.00
Epoch 354 Iter 6 subLoss 50556.5 multi 3.99 import weight 0.00
Epoch 354 Iter 7 subLoss 50007.1 multi -1.99 import weight 0.00
Epoch 354 Iter 8 subLoss 49893.4 multi 3.99 import weight 0.00
Epoch 354 Iter 9 subLoss 49409.7 multi 9.96 import weight 0.00
Epoch 354 Iter 10 subLoss 49783.1 multi 1.00 import weight 0.00
Epoch 354 Iter 11 subLoss 49568.1 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1602 / 0.04080 / 1.90
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 354 Acc: 19.07 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 4956 train Loss: 50091.5 test Loss: 8419.0
Epoch 355 Iter 0 subLoss 48943.4 multi 15.93 import weight 0.00
Epoch 355 Iter 1 subLoss 48807.6 multi 15.93 import weight 0.00
Epoch 355 Iter 2 subLoss 48647.9 multi 1.00 import weight 0.00
Epoch 355 Iter 3 subLoss 48605.2 multi 12.94 import weight 0.00
Epoch 355 Iter 4 subLoss 48608.7 multi 15.93 import weight 0.00
Epoch 355 Iter 5 subLoss 48499.5 multi -19.90 import weight 0.00
Epoch 355 Iter 6 subLoss 48430.0 multi 6.97 import weight 0.00
Epoch 355 Iter 7 subLoss 48392.7 multi 12.94 import weight 0.00
Epoch 355 Iter 8 subLoss 48409.1 multi -25.87 import weight 0.00
Epoch 355 Iter 9 subLoss 48408.8 multi -22.88 import weight 0.00
Epoch 355 Iter 10 subLoss 48850.6 multi -25.87 import weight 0.00
Epoch 355 Iter 11 subLoss 49068.5 multi -1.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1602 / 0.04079 / 1.90
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 355 Acc: 19.07 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 4906 train Loss: 50108.8 test Loss: 8424.7
Epoch 356 Iter 0 subLoss 48987.2 multi 3.99 import weight 0.00
Epoch 356 Iter 1 subLoss 48924.0 multi 21.90 import weight 0.00
Epoch 356 Iter 2 subLoss 48726.3 multi 18.91 import weight 0.00
Epoch 356 Iter 3 subLoss 48551.5 multi -16.91 import weight 0.00
Epoch 356 Iter 4 subLoss 48842.6 multi 9.96 import weight 0.00
Epoch 356 Iter 5 subLoss 48304.7 multi -52.73 import weight 0.00
Epoch 356 Iter 6 subLoss 48899.8 multi -10.94 import weight 0.00
Epoch 356 Iter 7 subLoss 48857.4 multi -25.87 import weight 0.00
Epoch 356 Iter 8 subLoss 49586.7 multi 3.99 import weight 0.00
Epoch 356 Iter 9 subLoss 49351.0 multi -10.94 import weight 0.00
Epoch 356 Iter 10 subLoss 49488.8 multi 6.97 import weight 0.00
Epoch 356 Iter 11 subLoss 49733.5 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1602 / 0.04077 / 1.90
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 356 Acc: 19.07 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 4973 train Loss: 50530.7 test Loss: 8494.2
Epoch 357 Iter 0 subLoss 49469.0 multi 3.98 import weight 0.00
Epoch 357 Iter 1 subLoss 49395.1 multi -13.93 import weight 0.00
Epoch 357 Iter 2 subLoss 49551.6 multi 1.00 import weight 0.00
Epoch 357 Iter 3 subLoss 49946.8 multi 1.00 import weight 0.00
Epoch 357 Iter 4 subLoss 49697.9 multi 1.00 import weight 0.00
Epoch 357 Iter 5 subLoss 49863.9 multi 15.93 import weight 0.00
Epoch 357 Iter 6 subLoss 49055.8 multi 15.93 import weight 0.00
Epoch 357 Iter 7 subLoss 49163.9 multi -1.99 import weight 0.00
Epoch 357 Iter 8 subLoss 48884.0 multi 21.90 import weight 0.00
Epoch 357 Iter 9 subLoss 48514.3 multi 12.94 import weight 0.00
Epoch 357 Iter 10 subLoss 48544.5 multi 12.94 import weight 0.00
Epoch 357 Iter 11 subLoss 48504.7 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1602 / 0.04077 / 1.90
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 357 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 4850 train Loss: 49389.3 test Loss: 8298.6
Epoch 358 Iter 0 subLoss 48316.9 multi -25.87 import weight 0.00
Epoch 358 Iter 1 subLoss 48479.8 multi -31.84 import weight 0.00
Epoch 358 Iter 2 subLoss 48757.0 multi -13.93 import weight 0.00
Epoch 358 Iter 3 subLoss 49046.8 multi -19.90 import weight 0.00
Epoch 358 Iter 4 subLoss 49643.4 multi -7.96 import weight 0.00
Epoch 358 Iter 5 subLoss 49403.3 multi 9.96 import weight 0.00
Epoch 358 Iter 6 subLoss 49350.4 multi -7.96 import weight 0.00
Epoch 358 Iter 7 subLoss 49977.2 multi 12.94 import weight 0.00
Epoch 358 Iter 8 subLoss 49346.3 multi 18.91 import weight 0.00
Epoch 358 Iter 9 subLoss 48762.7 multi -19.90 import weight 0.00
Epoch 358 Iter 10 subLoss 49064.9 multi -1.99 import weight 0.00
Epoch 358 Iter 11 subLoss 49157.2 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1602 / 0.04076 / 1.90
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 358 Acc: 19.07 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 4915 train Loss: 50009.8 test Loss: 8405.1
Epoch 359 Iter 0 subLoss 48986.4 multi 6.97 import weight 0.00
Epoch 359 Iter 1 subLoss 48932.6 multi -16.91 import weight 0.00
Epoch 359 Iter 2 subLoss 49411.3 multi -7.96 import weight 0.00
Epoch 359 Iter 3 subLoss 49503.1 multi -19.90 import weight 0.00
Epoch 359 Iter 4 subLoss 50105.7 multi 9.96 import weight 0.00
Epoch 359 Iter 5 subLoss 49715.2 multi 3.99 import weight 0.00
Epoch 359 Iter 6 subLoss 49777.0 multi 1.00 import weight 0.00
Epoch 359 Iter 7 subLoss 49539.3 multi 9.96 import weight 0.00
Epoch 359 Iter 8 subLoss 49115.2 multi -22.88 import weight 0.00
Epoch 359 Iter 9 subLoss 49708.3 multi -16.91 import weight 0.00
Epoch 359 Iter 10 subLoss 50636.8 multi 3.99 import weight 0.00
Epoch 359 Iter 11 subLoss 50099.7 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1602 / 0.04074 / 1.90
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 359 Acc: 19.07 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 5009 train Loss: 51605.5 test Loss: 8677.8
Epoch 360 Iter 0 subLoss 50620.5 multi 1.00 import weight 0.00
Epoch 360 Iter 1 subLoss 50925.9 multi 1.00 import weight 0.00
Epoch 360 Iter 2 subLoss 50219.4 multi 3.98 import weight 0.00
Epoch 360 Iter 3 subLoss 49872.8 multi -7.96 import weight 0.00
Epoch 360 Iter 4 subLoss 50871.2 multi 1.00 import weight 0.00
Epoch 360 Iter 5 subLoss 50775.2 multi 1.00 import weight 0.00
Epoch 360 Iter 6 subLoss 50327.1 multi 1.00 import weight 0.00
Epoch 360 Iter 7 subLoss 50638.8 multi 3.98 import weight 0.00
Epoch 360 Iter 8 subLoss 50131.6 multi 12.94 import weight 0.00
Epoch 360 Iter 9 subLoss 49734.3 multi 1.00 import weight 0.00
Epoch 360 Iter 10 subLoss 49618.8 multi 18.91 import weight 0.00
Epoch 360 Iter 11 subLoss 48940.3 multi 15.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1602 / 0.04074 / 1.90
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 360 Acc: 19.07 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 15.93 Pidx 4894 train Loss: 49722.4 test Loss: 8356.1
Epoch 361 Iter 0 subLoss 48589.3 multi 12.94 import weight 0.00
Epoch 361 Iter 1 subLoss 48664.6 multi 9.96 import weight 0.00
Epoch 361 Iter 2 subLoss 48579.0 multi -34.82 import weight 0.00
Epoch 361 Iter 3 subLoss 48844.9 multi 12.94 import weight 0.00
Epoch 361 Iter 4 subLoss 48562.7 multi -1.99 import weight 0.00
Epoch 361 Iter 5 subLoss 48817.8 multi -22.88 import weight 0.00
Epoch 361 Iter 6 subLoss 49068.2 multi 1.00 import weight 0.00
Epoch 361 Iter 7 subLoss 49135.4 multi 9.96 import weight 0.00
Epoch 361 Iter 8 subLoss 48820.2 multi 1.00 import weight 0.00
Epoch 361 Iter 9 subLoss 48754.2 multi -10.94 import weight 0.00
Epoch 361 Iter 10 subLoss 48879.7 multi 1.00 import weight 0.00
Epoch 361 Iter 11 subLoss 49037.0 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1602 / 0.04073 / 1.90
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 361 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 4903 train Loss: 49735.9 test Loss: 8359.5
Epoch 362 Iter 0 subLoss 48862.9 multi 1.00 import weight 0.00
Epoch 362 Iter 1 subLoss 48607.7 multi 18.91 import weight 0.00
Epoch 362 Iter 2 subLoss 48695.0 multi 3.99 import weight 0.00
Epoch 362 Iter 3 subLoss 48456.0 multi -22.88 import weight 0.00
Epoch 362 Iter 4 subLoss 48709.8 multi -13.93 import weight 0.00
Epoch 362 Iter 5 subLoss 48745.1 multi 12.94 import weight 0.00
Epoch 362 Iter 6 subLoss 48799.8 multi -4.97 import weight 0.00
Epoch 362 Iter 7 subLoss 48712.8 multi -1.99 import weight 0.00
Epoch 362 Iter 8 subLoss 48796.7 multi -1.99 import weight 0.00
Epoch 362 Iter 9 subLoss 48693.8 multi 6.97 import weight 0.00
Epoch 362 Iter 10 subLoss 48882.1 multi 21.90 import weight 0.00
Epoch 362 Iter 11 subLoss 48386.8 multi -10.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1602 / 0.04072 / 1.90
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 362 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -10.94 Pidx 4838 train Loss: 49492.9 test Loss: 8316.5
Epoch 363 Iter 0 subLoss 48597.0 multi 1.00 import weight 0.00
Epoch 363 Iter 1 subLoss 48545.8 multi 15.93 import weight 0.00
Epoch 363 Iter 2 subLoss 48370.6 multi 15.93 import weight 0.00
Epoch 363 Iter 3 subLoss 48353.5 multi -25.87 import weight 0.00
Epoch 363 Iter 4 subLoss 48435.0 multi 9.96 import weight 0.00
Epoch 363 Iter 5 subLoss 48371.8 multi 18.91 import weight 0.00
Epoch 363 Iter 6 subLoss 48350.2 multi -22.88 import weight 0.00
Epoch 363 Iter 7 subLoss 48381.9 multi -13.93 import weight 0.00
Epoch 363 Iter 8 subLoss 48401.5 multi -19.90 import weight 0.00
Epoch 363 Iter 9 subLoss 48809.5 multi 12.94 import weight 0.00
Epoch 363 Iter 10 subLoss 48600.9 multi 18.91 import weight 0.00
Epoch 363 Iter 11 subLoss 48392.1 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1602 / 0.04071 / 1.90
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 363 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 4839 train Loss: 49293.8 test Loss: 8281.0
Epoch 364 Iter 0 subLoss 48350.2 multi -19.90 import weight 0.00
Epoch 364 Iter 1 subLoss 48399.2 multi 12.94 import weight 0.00
Epoch 364 Iter 2 subLoss 48357.2 multi -16.91 import weight 0.00
Epoch 364 Iter 3 subLoss 48429.9 multi -22.88 import weight 0.00
Epoch 364 Iter 4 subLoss 48420.0 multi 24.88 import weight 0.00
Epoch 364 Iter 5 subLoss 48329.1 multi 6.97 import weight 0.00
Epoch 364 Iter 6 subLoss 48392.9 multi 15.93 import weight 0.00
Epoch 364 Iter 7 subLoss 48386.5 multi -10.94 import weight 0.00
Epoch 364 Iter 8 subLoss 48368.9 multi -25.87 import weight 0.00
Epoch 364 Iter 9 subLoss 48399.9 multi 15.93 import weight 0.00
Epoch 364 Iter 10 subLoss 48429.0 multi -22.88 import weight 0.00
Epoch 364 Iter 11 subLoss 48384.8 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1602 / 0.04071 / 1.90
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 364 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 4838 train Loss: 49459.7 test Loss: 8311.2
Epoch 365 Iter 0 subLoss 48540.7 multi 18.91 import weight 0.00
Epoch 365 Iter 1 subLoss 48441.0 multi -7.96 import weight 0.00
Epoch 365 Iter 2 subLoss 48409.8 multi -28.85 import weight 0.00
Epoch 365 Iter 3 subLoss 48533.8 multi 27.87 import weight 0.00
Epoch 365 Iter 4 subLoss 48368.0 multi -22.88 import weight 0.00
Epoch 365 Iter 5 subLoss 48542.3 multi 18.91 import weight 0.00
Epoch 365 Iter 6 subLoss 48360.4 multi -19.90 import weight 0.00
Epoch 365 Iter 7 subLoss 48427.7 multi -19.90 import weight 0.00
Epoch 365 Iter 8 subLoss 48568.3 multi 1.00 import weight 0.00
Epoch 365 Iter 9 subLoss 48535.3 multi 30.85 import weight 0.00
Epoch 365 Iter 10 subLoss 48295.9 multi 15.93 import weight 0.00
Epoch 365 Iter 11 subLoss 48348.7 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1602 / 0.04070 / 1.90
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 365 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 4834 train Loss: 49254.4 test Loss: 8275.4
Epoch 366 Iter 0 subLoss 48356.8 multi -16.91 import weight 0.00
Epoch 366 Iter 1 subLoss 48308.0 multi -52.73 import weight 0.00
Epoch 366 Iter 2 subLoss 48393.3 multi 15.93 import weight 0.00
Epoch 366 Iter 3 subLoss 48404.1 multi -28.85 import weight 0.00
Epoch 366 Iter 4 subLoss 48498.2 multi -16.91 import weight 0.00
Epoch 366 Iter 5 subLoss 48723.2 multi 18.91 import weight 0.00
Epoch 366 Iter 6 subLoss 48414.1 multi 21.90 import weight 0.00
Epoch 366 Iter 7 subLoss 48335.4 multi -16.91 import weight 0.00
Epoch 366 Iter 8 subLoss 48461.4 multi 27.87 import weight 0.00
Epoch 366 Iter 9 subLoss 48352.7 multi -13.93 import weight 0.00
Epoch 366 Iter 10 subLoss 48234.4 multi -10.94 import weight 0.00
Epoch 366 Iter 11 subLoss 48481.6 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1602 / 0.04070 / 1.90
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 366 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 4848 train Loss: 49293.6 test Loss: 8281.5
Epoch 367 Iter 0 subLoss 48287.4 multi 21.90 import weight 0.00
Epoch 367 Iter 1 subLoss 48326.6 multi 9.96 import weight 0.00
Epoch 367 Iter 2 subLoss 48358.2 multi -10.94 import weight 0.00
Epoch 367 Iter 3 subLoss 48272.3 multi -52.73 import weight 0.00
Epoch 367 Iter 4 subLoss 48498.5 multi -16.91 import weight 0.00
Epoch 367 Iter 5 subLoss 48476.3 multi -31.84 import weight 0.00
Epoch 367 Iter 6 subLoss 48532.8 multi 33.84 import weight 0.00
Epoch 367 Iter 7 subLoss 48369.5 multi -25.87 import weight 0.00
Epoch 367 Iter 8 subLoss 48443.7 multi -4.97 import weight 0.00
Epoch 367 Iter 9 subLoss 48571.2 multi -37.81 import weight 0.00
Epoch 367 Iter 10 subLoss 49049.6 multi -19.90 import weight 0.00
Epoch 367 Iter 11 subLoss 49394.6 multi -10.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1602 / 0.04069 / 2.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 367 Acc: 19.07 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -10.94 Pidx 4939 train Loss: 50740.1 test Loss: 8529.7
Epoch 368 Iter 0 subLoss 49973.7 multi 15.93 import weight 0.00
Epoch 368 Iter 1 subLoss 48978.9 multi 6.97 import weight 0.00
Epoch 368 Iter 2 subLoss 48955.9 multi -7.96 import weight 0.00
Epoch 368 Iter 3 subLoss 49048.1 multi -16.91 import weight 0.00
Epoch 368 Iter 4 subLoss 49450.9 multi -4.97 import weight 0.00
Epoch 368 Iter 5 subLoss 49684.4 multi 9.96 import weight 0.00
Epoch 368 Iter 6 subLoss 49613.7 multi 21.90 import weight 0.00
Epoch 368 Iter 7 subLoss 49006.6 multi 6.97 import weight 0.00
Epoch 368 Iter 8 subLoss 48612.4 multi -28.85 import weight 0.00
Epoch 368 Iter 9 subLoss 49085.6 multi 9.96 import weight 0.00
Epoch 368 Iter 10 subLoss 48968.5 multi -10.94 import weight 0.00
Epoch 368 Iter 11 subLoss 49305.3 multi 24.88 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1602 / 0.04069 / 2.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 368 Acc: 19.07 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 24.88 Pidx 4930 train Loss: 49575.7 test Loss: 8330.2
Epoch 369 Iter 0 subLoss 48834.5 multi 6.97 import weight 0.00
Epoch 369 Iter 1 subLoss 48595.0 multi 3.99 import weight 0.00
Epoch 369 Iter 2 subLoss 48499.1 multi -13.93 import weight 0.00
Epoch 369 Iter 3 subLoss 48614.4 multi -25.87 import weight 0.00
Epoch 369 Iter 4 subLoss 48810.0 multi 15.93 import weight 0.00
Epoch 369 Iter 5 subLoss 48656.5 multi -4.97 import weight 0.00
Epoch 369 Iter 6 subLoss 48711.2 multi 1.00 import weight 0.00
Epoch 369 Iter 7 subLoss 48501.0 multi -7.96 import weight 0.00
Epoch 369 Iter 8 subLoss 48684.7 multi -10.94 import weight 0.00
Epoch 369 Iter 9 subLoss 49017.2 multi 3.99 import weight 0.00
Epoch 369 Iter 10 subLoss 48997.4 multi -7.96 import weight 0.00
Epoch 369 Iter 11 subLoss 48586.8 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1602 / 0.04068 / 2.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 369 Acc: 19.07 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 4858 train Loss: 49806.6 test Loss: 8370.5
Epoch 370 Iter 0 subLoss 48902.3 multi 18.91 import weight 0.00
Epoch 370 Iter 1 subLoss 48643.7 multi 3.98 import weight 0.00
Epoch 370 Iter 2 subLoss 48380.3 multi -4.97 import weight 0.00
Epoch 370 Iter 3 subLoss 48582.4 multi 12.94 import weight 0.00
Epoch 370 Iter 4 subLoss 48381.7 multi -1.99 import weight 0.00
Epoch 370 Iter 5 subLoss 48518.1 multi 9.96 import weight 0.00
Epoch 370 Iter 6 subLoss 48329.6 multi 12.94 import weight 0.00
Epoch 370 Iter 7 subLoss 48382.3 multi 1.00 import weight 0.00
Epoch 370 Iter 8 subLoss 48361.4 multi -22.88 import weight 0.00
Epoch 370 Iter 9 subLoss 48498.0 multi -10.94 import weight 0.00
Epoch 370 Iter 10 subLoss 48676.4 multi 1.00 import weight 0.00
Epoch 370 Iter 11 subLoss 48710.1 multi 3.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1602 / 0.04068 / 2.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 370 Acc: 19.07 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 4871 train Loss: 49481.2 test Loss: 8314.6
Epoch 371 Iter 0 subLoss 48407.5 multi -25.87 import weight 0.00
Epoch 371 Iter 1 subLoss 48669.4 multi 9.96 import weight 0.00
Epoch 371 Iter 2 subLoss 48593.7 multi 1.00 import weight 0.00
Epoch 371 Iter 3 subLoss 48815.0 multi -25.87 import weight 0.00
Epoch 371 Iter 4 subLoss 48790.1 multi 1.00 import weight 0.00
Epoch 371 Iter 5 subLoss 48998.7 multi -4.97 import weight 0.00
Epoch 371 Iter 6 subLoss 48923.5 multi 24.88 import weight 0.00
Epoch 371 Iter 7 subLoss 48730.2 multi -10.94 import weight 0.00
Epoch 371 Iter 8 subLoss 48681.4 multi -10.94 import weight 0.00
Epoch 371 Iter 9 subLoss 48795.7 multi 3.99 import weight 0.00
Epoch 371 Iter 10 subLoss 48586.5 multi 15.93 import weight 0.00
Epoch 371 Iter 11 subLoss 48581.4 multi 18.91 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04067 / 2.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 371 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 18.91 Pidx 4858 train Loss: 49434.5 test Loss: 8307.5
Epoch 372 Iter 0 subLoss 48336.4 multi -19.90 import weight 0.00
Epoch 372 Iter 1 subLoss 48482.4 multi 12.94 import weight 0.00
Epoch 372 Iter 2 subLoss 48459.1 multi -25.87 import weight 0.00
Epoch 372 Iter 3 subLoss 48574.0 multi -34.82 import weight 0.00
Epoch 372 Iter 4 subLoss 49280.9 multi -4.97 import weight 0.00
Epoch 372 Iter 5 subLoss 49030.4 multi 12.94 import weight 0.00
Epoch 372 Iter 6 subLoss 49112.0 multi -19.90 import weight 0.00
Epoch 372 Iter 7 subLoss 49249.5 multi 6.97 import weight 0.00
Epoch 372 Iter 8 subLoss 49222.3 multi 6.97 import weight 0.00
Epoch 372 Iter 9 subLoss 49027.3 multi -16.91 import weight 0.00
Epoch 372 Iter 10 subLoss 49450.2 multi -1.99 import weight 0.00
Epoch 372 Iter 11 subLoss 49437.8 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04067 / 2.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 372 Acc: 19.07 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4943 train Loss: 50356.5 test Loss: 8467.2
Epoch 373 Iter 0 subLoss 49197.8 multi 6.97 import weight 0.00
Epoch 373 Iter 1 subLoss 49191.3 multi 9.96 import weight 0.00
Epoch 373 Iter 2 subLoss 48958.9 multi -4.97 import weight 0.00
Epoch 373 Iter 3 subLoss 49140.3 multi -1.99 import weight 0.00
Epoch 373 Iter 4 subLoss 49461.2 multi 1.00 import weight 0.00
Epoch 373 Iter 5 subLoss 49097.2 multi -4.97 import weight 0.00
Epoch 373 Iter 6 subLoss 49190.3 multi 12.94 import weight 0.00
Epoch 373 Iter 7 subLoss 49035.5 multi 12.94 import weight 0.00
Epoch 373 Iter 8 subLoss 48756.5 multi -10.94 import weight 0.00
Epoch 373 Iter 9 subLoss 48627.0 multi 15.93 import weight 0.00
Epoch 373 Iter 10 subLoss 48542.9 multi 15.93 import weight 0.00
Epoch 373 Iter 11 subLoss 48523.2 multi -25.87 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04067 / 2.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 373 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -25.87 Pidx 4852 train Loss: 49695.7 test Loss: 8353.5
Epoch 374 Iter 0 subLoss 48640.0 multi -19.90 import weight 0.00
Epoch 374 Iter 1 subLoss 49230.6 multi 1.00 import weight 0.00
Epoch 374 Iter 2 subLoss 48990.7 multi -1.98 import weight 0.00
Epoch 374 Iter 3 subLoss 49020.2 multi -13.93 import weight 0.00
Epoch 374 Iter 4 subLoss 49157.1 multi 3.98 import weight 0.00
Epoch 374 Iter 5 subLoss 49255.8 multi -10.94 import weight 0.00
Epoch 374 Iter 6 subLoss 49187.1 multi -13.93 import weight 0.00
Epoch 374 Iter 7 subLoss 49838.4 multi -4.97 import weight 0.00
Epoch 374 Iter 8 subLoss 50200.4 multi 3.99 import weight 0.00
Epoch 374 Iter 9 subLoss 49944.9 multi 3.98 import weight 0.00
Epoch 374 Iter 10 subLoss 49316.2 multi -25.87 import weight 0.00
Epoch 374 Iter 11 subLoss 51240.9 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04067 / 2.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 374 Acc: 19.07 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 5124 train Loss: 51647.6 test Loss: 8688.7
Epoch 375 Iter 0 subLoss 50776.6 multi 3.98 import weight 0.00
Epoch 375 Iter 1 subLoss 50242.5 multi 9.96 import weight 0.00
Epoch 375 Iter 2 subLoss 49651.4 multi 12.94 import weight 0.00
Epoch 375 Iter 3 subLoss 49423.0 multi 3.98 import weight 0.00
Epoch 375 Iter 4 subLoss 49374.4 multi 15.93 import weight 0.00
Epoch 375 Iter 5 subLoss 48789.6 multi -16.91 import weight 0.00
Epoch 375 Iter 6 subLoss 49223.4 multi 9.96 import weight 0.00
Epoch 375 Iter 7 subLoss 49209.7 multi -10.94 import weight 0.00
Epoch 375 Iter 8 subLoss 49395.2 multi -7.96 import weight 0.00
Epoch 375 Iter 9 subLoss 49401.9 multi 6.97 import weight 0.00
Epoch 375 Iter 10 subLoss 49594.9 multi -4.97 import weight 0.00
Epoch 375 Iter 11 subLoss 49208.4 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04068 / 2.10
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 375 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 4920 train Loss: 50631.6 test Loss: 8516.0
Epoch 376 Iter 0 subLoss 49723.3 multi -1.99 import weight 0.00
Epoch 376 Iter 1 subLoss 49977.5 multi 18.91 import weight 0.00
Epoch 376 Iter 2 subLoss 49012.7 multi 6.97 import weight 0.00
Epoch 376 Iter 3 subLoss 49033.6 multi 12.94 import weight 0.00
Epoch 376 Iter 4 subLoss 48627.9 multi 18.91 import weight 0.00
Epoch 376 Iter 5 subLoss 48555.9 multi -28.85 import weight 0.00
Epoch 376 Iter 6 subLoss 48773.5 multi 24.88 import weight 0.00
Epoch 376 Iter 7 subLoss 48413.2 multi 21.90 import weight 0.00
Epoch 376 Iter 8 subLoss 48370.6 multi 6.97 import weight 0.00
Epoch 376 Iter 9 subLoss 48372.4 multi 9.96 import weight 0.00
Epoch 376 Iter 10 subLoss 48485.3 multi 15.93 import weight 0.00
Epoch 376 Iter 11 subLoss 48215.1 multi 57.72 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04067 / 2.10
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 376 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 57.72 Pidx 4821 train Loss: 49228.1 test Loss: 8269.6
Epoch 377 Iter 0 subLoss 48313.0 multi -25.87 import weight 0.00
Epoch 377 Iter 1 subLoss 48288.0 multi 21.90 import weight 0.00
Epoch 377 Iter 2 subLoss 48285.0 multi 24.88 import weight 0.00
Epoch 377 Iter 3 subLoss 48234.6 multi -7.96 import weight 0.00
Epoch 377 Iter 4 subLoss 48369.5 multi -19.90 import weight 0.00
Epoch 377 Iter 5 subLoss 48287.9 multi 27.87 import weight 0.00
Epoch 377 Iter 6 subLoss 48260.4 multi 3.99 import weight 1.00
Epoch 377 Iter 7 subLoss 48217.3 multi 60.70 import weight 0.00
Epoch 377 Iter 8 subLoss 48294.0 multi 6.97 import weight 0.00
Epoch 377 Iter 9 subLoss 48174.8 multi -1.98 import weight 0.00
Epoch 377 Iter 10 subLoss 48277.0 multi -52.73 import weight 0.00
Epoch 377 Iter 11 subLoss 48255.1 multi 48.76 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04067 / 2.10
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 377 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 48.76 Pidx 4825 train Loss: 49213.1 test Loss: 8267.0
Epoch 378 Iter 0 subLoss 48212.6 multi 63.69 import weight 0.00
Epoch 378 Iter 1 subLoss 48200.0 multi 30.85 import weight 0.00
Epoch 378 Iter 2 subLoss 48256.9 multi 51.75 import weight 1.00
Epoch 378 Iter 3 subLoss 48210.5 multi 66.67 import weight 0.00
Epoch 378 Iter 4 subLoss 48355.8 multi -7.96 import weight 0.00
Epoch 378 Iter 5 subLoss 48320.5 multi 12.94 import weight 0.00
Epoch 378 Iter 6 subLoss 48190.8 multi 33.84 import weight 0.00
Epoch 378 Iter 7 subLoss 48279.8 multi -49.75 import weight 0.00
Epoch 378 Iter 8 subLoss 48335.1 multi -19.90 import weight 0.00
Epoch 378 Iter 9 subLoss 48409.3 multi -22.88 import weight 0.00
Epoch 378 Iter 10 subLoss 48428.5 multi -22.88 import weight 0.00
Epoch 378 Iter 11 subLoss 48450.5 multi -22.88 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04067 / 2.10
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 378 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -22.88 Pidx 4845 train Loss: 49604.6 test Loss: 8339.5
Epoch 379 Iter 0 subLoss 48686.1 multi -7.96 import weight 0.00
Epoch 379 Iter 1 subLoss 48947.8 multi 18.91 import weight 0.00
Epoch 379 Iter 2 subLoss 48561.5 multi 1.00 import weight 0.00
Epoch 379 Iter 3 subLoss 48439.6 multi 1.00 import weight 0.00
Epoch 379 Iter 4 subLoss 48591.1 multi -1.99 import weight 0.00
Epoch 379 Iter 5 subLoss 48534.6 multi 33.84 import weight 0.00
Epoch 379 Iter 6 subLoss 48249.9 multi 33.84 import weight 0.00
Epoch 379 Iter 7 subLoss 48249.2 multi 36.82 import weight 0.00
Epoch 379 Iter 8 subLoss 48334.9 multi -16.91 import weight 0.00
Epoch 379 Iter 9 subLoss 48265.4 multi 1.00 import weight 1.00
Epoch 379 Iter 10 subLoss 48313.8 multi -22.88 import weight 0.00
Epoch 379 Iter 11 subLoss 48155.4 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04067 / 2.10
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 379 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 4815 train Loss: 49280.2 test Loss: 8279.2
Epoch 380 Iter 0 subLoss 48234.0 multi -4.97 import weight 0.00
Epoch 380 Iter 1 subLoss 48245.2 multi 36.82 import weight 0.00
Epoch 380 Iter 2 subLoss 48316.3 multi -19.90 import weight 0.00
Epoch 380 Iter 3 subLoss 48352.3 multi -4.97 import weight 0.00
Epoch 380 Iter 4 subLoss 48244.3 multi 39.81 import weight 0.00
Epoch 380 Iter 5 subLoss 48361.8 multi -22.88 import weight 0.00
Epoch 380 Iter 6 subLoss 48387.4 multi -1.99 import weight 0.00
Epoch 380 Iter 7 subLoss 48277.8 multi -49.75 import weight 0.00
Epoch 380 Iter 8 subLoss 48547.0 multi 15.93 import weight 0.00
Epoch 380 Iter 9 subLoss 48437.9 multi 3.98 import weight 0.00
Epoch 380 Iter 10 subLoss 48317.6 multi -16.91 import weight 0.00
Epoch 380 Iter 11 subLoss 48358.0 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04066 / 2.10
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 380 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 4835 train Loss: 49368.6 test Loss: 8296.9
Epoch 381 Iter 0 subLoss 48479.1 multi -28.85 import weight 0.00
Epoch 381 Iter 1 subLoss 48671.6 multi 1.00 import weight 0.00
Epoch 381 Iter 2 subLoss 48694.7 multi 1.00 import weight 0.00
Epoch 381 Iter 3 subLoss 48772.9 multi 27.87 import weight 0.00
Epoch 381 Iter 4 subLoss 48205.5 multi 9.96 import weight 0.00
Epoch 381 Iter 5 subLoss 48307.6 multi -52.73 import weight 0.00
Epoch 381 Iter 6 subLoss 48365.4 multi -22.88 import weight 0.00
Epoch 381 Iter 7 subLoss 48580.4 multi 18.91 import weight 0.00
Epoch 381 Iter 8 subLoss 48546.5 multi 18.91 import weight 0.00
Epoch 381 Iter 9 subLoss 48443.2 multi -7.96 import weight 0.00
Epoch 381 Iter 10 subLoss 48103.0 multi -7.96 import weight 0.00
Epoch 381 Iter 11 subLoss 48307.3 multi -49.75 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04066 / 2.10
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 381 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -49.75 Pidx 4830 train Loss: 49496.0 test Loss: 8320.6
Epoch 382 Iter 0 subLoss 48346.9 multi 3.99 import weight 0.00
Epoch 382 Iter 1 subLoss 48559.9 multi -31.84 import weight 0.00
Epoch 382 Iter 2 subLoss 48783.9 multi -19.90 import weight 0.00
Epoch 382 Iter 3 subLoss 48841.0 multi 12.94 import weight 0.00
Epoch 382 Iter 4 subLoss 49003.0 multi 1.00 import weight 0.00
Epoch 382 Iter 5 subLoss 48810.1 multi -22.88 import weight 0.00
Epoch 382 Iter 6 subLoss 49214.0 multi -4.97 import weight 0.00
Epoch 382 Iter 7 subLoss 49201.1 multi -4.97 import weight 0.00
Epoch 382 Iter 8 subLoss 49367.2 multi 3.98 import weight 0.00
Epoch 382 Iter 9 subLoss 49696.3 multi 1.00 import weight 0.00
Epoch 382 Iter 10 subLoss 49422.0 multi 6.97 import weight 0.00
Epoch 382 Iter 11 subLoss 49301.7 multi 27.87 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04067 / 2.10
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 382 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 27.87 Pidx 4930 train Loss: 49574.5 test Loss: 8335.1
Epoch 383 Iter 0 subLoss 48481.2 multi 15.93 import weight 0.00
Epoch 383 Iter 1 subLoss 48476.0 multi -25.87 import weight 0.00
Epoch 383 Iter 2 subLoss 48566.0 multi 1.00 import weight 0.00
Epoch 383 Iter 3 subLoss 48511.8 multi 12.94 import weight 0.00
Epoch 383 Iter 4 subLoss 48497.2 multi -16.91 import weight 0.00
Epoch 383 Iter 5 subLoss 48647.6 multi 3.99 import weight 0.00
Epoch 383 Iter 6 subLoss 48454.5 multi -22.88 import weight 0.00
Epoch 383 Iter 7 subLoss 49079.6 multi -10.94 import weight 0.00
Epoch 383 Iter 8 subLoss 49282.0 multi -1.99 import weight 0.00
Epoch 383 Iter 9 subLoss 49158.4 multi 6.97 import weight 0.00
Epoch 383 Iter 10 subLoss 49220.6 multi 9.96 import weight 0.00
Epoch 383 Iter 11 subLoss 48901.0 multi 21.90 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04067 / 2.10
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 383 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 21.90 Pidx 4890 train Loss: 49469.8 test Loss: 8314.4
Epoch 384 Iter 0 subLoss 48503.9 multi -10.94 import weight 0.00
Epoch 384 Iter 1 subLoss 48545.4 multi 21.90 import weight 0.00
Epoch 384 Iter 2 subLoss 48295.4 multi 9.96 import weight 0.00
Epoch 384 Iter 3 subLoss 48615.5 multi -22.88 import weight 0.00
Epoch 384 Iter 4 subLoss 48551.8 multi -31.84 import weight 0.00
Epoch 384 Iter 5 subLoss 49117.5 multi -16.91 import weight 0.00
Epoch 384 Iter 6 subLoss 49083.5 multi 9.96 import weight 0.00
Epoch 384 Iter 7 subLoss 48826.8 multi -1.98 import weight 0.00
Epoch 384 Iter 8 subLoss 49108.6 multi 9.96 import weight 0.00
Epoch 384 Iter 9 subLoss 48696.7 multi 3.99 import weight 0.00
Epoch 384 Iter 10 subLoss 48634.5 multi -19.90 import weight 0.00
Epoch 384 Iter 11 subLoss 49131.2 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04067 / 2.10
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 384 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 4913 train Loss: 49763.1 test Loss: 8365.2
Epoch 385 Iter 0 subLoss 48762.9 multi -22.88 import weight 0.00
Epoch 385 Iter 1 subLoss 49143.8 multi -1.98 import weight 0.00
Epoch 385 Iter 2 subLoss 49093.3 multi -4.97 import weight 0.00
Epoch 385 Iter 3 subLoss 49220.2 multi 12.94 import weight 0.00
Epoch 385 Iter 4 subLoss 48906.3 multi 24.88 import weight 0.00
Epoch 385 Iter 5 subLoss 48576.4 multi -37.81 import weight 0.00
Epoch 385 Iter 6 subLoss 49023.7 multi -13.93 import weight 0.00
Epoch 385 Iter 7 subLoss 49476.0 multi -1.99 import weight 0.00
Epoch 385 Iter 8 subLoss 49231.5 multi -4.97 import weight 0.00
Epoch 385 Iter 9 subLoss 49670.3 multi -4.97 import weight 0.00
Epoch 385 Iter 10 subLoss 49722.2 multi 1.00 import weight 0.00
Epoch 385 Iter 11 subLoss 49828.1 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04068 / 2.20
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 385 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 4982 train Loss: 50378.8 test Loss: 8473.9
Epoch 386 Iter 0 subLoss 49282.0 multi 1.00 import weight 0.00
Epoch 386 Iter 1 subLoss 49614.2 multi 24.88 import weight 0.00
Epoch 386 Iter 2 subLoss 48679.6 multi 3.99 import weight 0.00
Epoch 386 Iter 3 subLoss 48833.6 multi 6.97 import weight 0.00
Epoch 386 Iter 4 subLoss 48563.9 multi 1.00 import weight 0.00
Epoch 386 Iter 5 subLoss 48603.4 multi 12.94 import weight 0.00
Epoch 386 Iter 6 subLoss 48571.9 multi -37.81 import weight 0.00
Epoch 386 Iter 7 subLoss 48911.3 multi -52.73 import weight 0.00
Epoch 386 Iter 8 subLoss 49564.9 multi 12.94 import weight 0.00
Epoch 386 Iter 9 subLoss 49683.3 multi 9.96 import weight 0.00
Epoch 386 Iter 10 subLoss 49030.8 multi 12.94 import weight 0.00
Epoch 386 Iter 11 subLoss 49000.0 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1602 / 0.04069 / 2.20
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 386 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 4900 train Loss: 49845.9 test Loss: 8381.1
Epoch 387 Iter 0 subLoss 48770.9 multi 27.87 import weight 0.00
Epoch 387 Iter 1 subLoss 48445.9 multi -4.97 import weight 0.00
Epoch 387 Iter 2 subLoss 48614.0 multi -22.88 import weight 0.00
Epoch 387 Iter 3 subLoss 48993.3 multi 1.00 import weight 0.00
Epoch 387 Iter 4 subLoss 48752.4 multi -7.96 import weight 0.00
Epoch 387 Iter 5 subLoss 48998.8 multi 3.99 import weight 0.00
Epoch 387 Iter 6 subLoss 48660.9 multi 12.94 import weight 0.00
Epoch 387 Iter 7 subLoss 48656.0 multi -7.96 import weight 0.00
Epoch 387 Iter 8 subLoss 48668.2 multi 12.94 import weight 0.00
Epoch 387 Iter 9 subLoss 48728.1 multi 15.93 import weight 0.00
Epoch 387 Iter 10 subLoss 48429.5 multi -19.90 import weight 0.00
Epoch 387 Iter 11 subLoss 48830.1 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1602 / 0.04069 / 2.20
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 387 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 4883 train Loss: 49475.8 test Loss: 8315.9
Epoch 388 Iter 0 subLoss 48350.9 multi -1.99 import weight 0.00
Epoch 388 Iter 1 subLoss 48448.5 multi -1.99 import weight 0.00
Epoch 388 Iter 2 subLoss 48563.7 multi 3.98 import weight 0.00
Epoch 388 Iter 3 subLoss 48536.3 multi 36.82 import weight 0.00
Epoch 388 Iter 4 subLoss 48275.5 multi -46.76 import weight 0.00
Epoch 388 Iter 5 subLoss 48326.0 multi 6.97 import weight 0.00
Epoch 388 Iter 6 subLoss 48468.1 multi 21.90 import weight 0.00
Epoch 388 Iter 7 subLoss 48423.9 multi -16.91 import weight 0.00
Epoch 388 Iter 8 subLoss 48427.1 multi -13.93 import weight 0.00
Epoch 388 Iter 9 subLoss 48346.6 multi 6.97 import weight 0.00
Epoch 388 Iter 10 subLoss 48416.5 multi 21.90 import weight 0.00
Epoch 388 Iter 11 subLoss 48370.7 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1602 / 0.04069 / 2.20
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 388 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 4837 train Loss: 49269.9 test Loss: 8278.1
Epoch 389 Iter 0 subLoss 48275.4 multi -43.78 import weight 0.00
Epoch 389 Iter 1 subLoss 48334.6 multi -16.91 import weight 0.00
Epoch 389 Iter 2 subLoss 48549.0 multi 21.90 import weight 0.00
Epoch 389 Iter 3 subLoss 48334.0 multi -13.93 import weight 0.00
Epoch 389 Iter 4 subLoss 48388.9 multi -1.99 import weight 0.00
Epoch 389 Iter 5 subLoss 48371.3 multi 6.97 import weight 0.00
Epoch 389 Iter 6 subLoss 48307.3 multi -49.75 import weight 0.00
Epoch 389 Iter 7 subLoss 48575.6 multi -37.81 import weight 0.00
Epoch 389 Iter 8 subLoss 48907.9 multi 27.87 import weight 0.00
Epoch 389 Iter 9 subLoss 48581.1 multi 12.94 import weight 0.00
Epoch 389 Iter 10 subLoss 48458.2 multi -25.87 import weight 0.00
Epoch 389 Iter 11 subLoss 48578.6 multi -34.82 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1602 / 0.04069 / 2.20
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 389 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -34.82 Pidx 4857 train Loss: 49879.7 test Loss: 8387.2
Epoch 390 Iter 0 subLoss 48957.2 multi -4.97 import weight 0.00
Epoch 390 Iter 1 subLoss 48973.6 multi 6.97 import weight 0.00
Epoch 390 Iter 2 subLoss 48846.1 multi 9.96 import weight 0.00
Epoch 390 Iter 3 subLoss 48795.1 multi 1.00 import weight 0.00
Epoch 390 Iter 4 subLoss 48678.3 multi 1.00 import weight 0.00
Epoch 390 Iter 5 subLoss 48666.5 multi 15.93 import weight 0.00
Epoch 390 Iter 6 subLoss 48589.8 multi 12.94 import weight 0.00
Epoch 390 Iter 7 subLoss 48362.3 multi -22.88 import weight 0.00
Epoch 390 Iter 8 subLoss 48746.1 multi 12.94 import weight 0.00
Epoch 390 Iter 9 subLoss 48422.8 multi -13.93 import weight 0.00
Epoch 390 Iter 10 subLoss 48527.1 multi -25.87 import weight 0.00
Epoch 390 Iter 11 subLoss 48811.7 multi -19.90 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1602 / 0.04070 / 2.20
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 390 Acc: 19.65 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -19.90 Pidx 4881 train Loss: 50021.7 test Loss: 8413.5
Epoch 391 Iter 0 subLoss 49261.5 multi -4.97 import weight 0.00
Epoch 391 Iter 1 subLoss 49019.3 multi 3.98 import weight 0.00
Epoch 391 Iter 2 subLoss 49057.2 multi 9.96 import weight 0.00
Epoch 391 Iter 3 subLoss 48936.0 multi -16.91 import weight 0.00
Epoch 391 Iter 4 subLoss 49231.2 multi -1.99 import weight 0.00
Epoch 391 Iter 5 subLoss 49287.2 multi 3.99 import weight 0.00
Epoch 391 Iter 6 subLoss 48886.5 multi 24.88 import weight 0.00
Epoch 391 Iter 7 subLoss 48778.6 multi 30.85 import weight 0.00
Epoch 391 Iter 8 subLoss 48547.4 multi 24.88 import weight 0.00
Epoch 391 Iter 9 subLoss 48325.0 multi 9.96 import weight 0.00
Epoch 391 Iter 10 subLoss 48278.7 multi -40.79 import weight 0.00
Epoch 391 Iter 11 subLoss 48286.0 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1602 / 0.04069 / 2.20
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 391 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 4828 train Loss: 49297.6 test Loss: 8283.8
Epoch 392 Iter 0 subLoss 48296.5 multi 9.96 import weight 0.00
Epoch 392 Iter 1 subLoss 48268.1 multi 3.98 import weight 1.00
Epoch 392 Iter 2 subLoss 48317.9 multi -22.88 import weight 0.00
Epoch 392 Iter 3 subLoss 48302.5 multi -49.75 import weight 0.00
Epoch 392 Iter 4 subLoss 48545.3 multi 27.87 import weight 0.00
Epoch 392 Iter 5 subLoss 48422.0 multi -10.94 import weight 0.00
Epoch 392 Iter 6 subLoss 48291.5 multi 12.94 import weight 0.00
Epoch 392 Iter 7 subLoss 48401.5 multi -19.90 import weight 0.00
Epoch 392 Iter 8 subLoss 48440.1 multi 1.00 import weight 0.00
Epoch 392 Iter 9 subLoss 48352.8 multi -1.98 import weight 0.00
Epoch 392 Iter 10 subLoss 48677.5 multi 1.00 import weight 0.00
Epoch 392 Iter 11 subLoss 48341.0 multi 3.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1602 / 0.04069 / 2.20
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 392 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 4834 train Loss: 49365.3 test Loss: 8297.0
Epoch 393 Iter 0 subLoss 48449.7 multi 3.99 import weight 0.00
Epoch 393 Iter 1 subLoss 48456.1 multi -28.85 import weight 0.00
Epoch 393 Iter 2 subLoss 48357.7 multi -1.99 import weight 0.00
Epoch 393 Iter 3 subLoss 48457.5 multi -25.87 import weight 0.00
Epoch 393 Iter 4 subLoss 48700.5 multi -19.90 import weight 0.00
Epoch 393 Iter 5 subLoss 49147.5 multi 1.00 import weight 0.00
Epoch 393 Iter 6 subLoss 48984.3 multi 3.98 import weight 0.00
Epoch 393 Iter 7 subLoss 49002.5 multi 1.00 import weight 0.00
Epoch 393 Iter 8 subLoss 48999.2 multi 3.99 import weight 0.00
Epoch 393 Iter 9 subLoss 48640.9 multi 3.99 import weight 0.00
Epoch 393 Iter 10 subLoss 48776.7 multi 33.84 import weight 0.00
Epoch 393 Iter 11 subLoss 48375.9 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1602 / 0.04069 / 2.20
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 393 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 4837 train Loss: 49370.0 test Loss: 8298.5
Epoch 394 Iter 0 subLoss 48293.1 multi 15.93 import weight 0.00
Epoch 394 Iter 1 subLoss 48502.9 multi -7.96 import weight 0.00
Epoch 394 Iter 2 subLoss 48437.8 multi -7.96 import weight 0.00
Epoch 394 Iter 3 subLoss 48370.8 multi 9.96 import weight 0.00
Epoch 394 Iter 4 subLoss 48416.1 multi 21.90 import weight 0.00
Epoch 394 Iter 5 subLoss 48375.2 multi 12.94 import weight 0.00
Epoch 394 Iter 6 subLoss 48298.6 multi 18.91 import weight 0.00
Epoch 394 Iter 7 subLoss 48250.3 multi 42.79 import weight 0.00
Epoch 394 Iter 8 subLoss 48235.6 multi -1.99 import weight 0.00
Epoch 394 Iter 9 subLoss 48195.5 multi 36.82 import weight 0.00
Epoch 394 Iter 10 subLoss 48260.3 multi 3.99 import weight 1.00
Epoch 394 Iter 11 subLoss 48300.1 multi -55.72 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1602 / 0.04069 / 2.20
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 394 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -55.72 Pidx 4830 train Loss: 49269.5 test Loss: 8277.3
Epoch 395 Iter 0 subLoss 48473.0 multi -25.87 import weight 0.00
Epoch 395 Iter 1 subLoss 48423.3 multi -10.94 import weight 0.00
Epoch 395 Iter 2 subLoss 48352.7 multi 1.00 import weight 0.00
Epoch 395 Iter 3 subLoss 48637.0 multi -16.91 import weight 0.00
Epoch 395 Iter 4 subLoss 48591.6 multi -7.96 import weight 0.00
Epoch 395 Iter 5 subLoss 48578.9 multi -31.84 import weight 0.00
Epoch 395 Iter 6 subLoss 48984.7 multi 6.97 import weight 0.00
Epoch 395 Iter 7 subLoss 48439.5 multi -7.96 import weight 0.00
Epoch 395 Iter 8 subLoss 49465.2 multi 3.99 import weight 0.00
Epoch 395 Iter 9 subLoss 48927.5 multi 24.88 import weight 0.00
Epoch 395 Iter 10 subLoss 48693.9 multi 6.97 import weight 0.00
Epoch 395 Iter 11 subLoss 48368.0 multi -28.85 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1602 / 0.04069 / 2.30
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 395 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -28.85 Pidx 4836 train Loss: 49659.1 test Loss: 8346.8
Epoch 396 Iter 0 subLoss 48663.7 multi 18.91 import weight 0.00
Epoch 396 Iter 1 subLoss 48617.9 multi -19.90 import weight 0.00
Epoch 396 Iter 2 subLoss 48799.2 multi 3.99 import weight 0.00
Epoch 396 Iter 3 subLoss 48595.9 multi -4.97 import weight 0.00
Epoch 396 Iter 4 subLoss 48562.3 multi 6.97 import weight 0.00
Epoch 396 Iter 5 subLoss 48584.8 multi 12.94 import weight 0.00
Epoch 396 Iter 6 subLoss 48429.6 multi -7.96 import weight 0.00
Epoch 396 Iter 7 subLoss 48507.6 multi -4.97 import weight 0.00
Epoch 396 Iter 8 subLoss 48604.3 multi 9.96 import weight 0.00
Epoch 396 Iter 9 subLoss 48621.6 multi 12.94 import weight 0.00
Epoch 396 Iter 10 subLoss 48333.4 multi -13.93 import weight 0.00
Epoch 396 Iter 11 subLoss 48630.9 multi -16.91 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1602 / 0.04069 / 2.30
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 396 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -16.91 Pidx 4863 train Loss: 49592.4 test Loss: 8336.1
Epoch 397 Iter 0 subLoss 48642.2 multi 1.00 import weight 0.00
Epoch 397 Iter 1 subLoss 48589.1 multi 15.93 import weight 0.00
Epoch 397 Iter 2 subLoss 48456.6 multi -22.88 import weight 0.00
Epoch 397 Iter 3 subLoss 48649.1 multi 3.99 import weight 0.00
Epoch 397 Iter 4 subLoss 48662.8 multi 21.90 import weight 0.00
Epoch 397 Iter 5 subLoss 48575.6 multi -31.84 import weight 0.00
Epoch 397 Iter 6 subLoss 48751.8 multi -7.96 import weight 0.00
Epoch 397 Iter 7 subLoss 48861.7 multi 3.99 import weight 0.00
Epoch 397 Iter 8 subLoss 48640.9 multi 6.97 import weight 0.00
Epoch 397 Iter 9 subLoss 48344.0 multi 3.99 import weight 0.00
Epoch 397 Iter 10 subLoss 48585.1 multi 15.93 import weight 0.00
Epoch 397 Iter 11 subLoss 48382.9 multi -10.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1602 / 0.04070 / 2.30
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 397 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -10.94 Pidx 4838 train Loss: 49493.4 test Loss: 8318.4
Epoch 398 Iter 0 subLoss 48549.8 multi 30.85 import weight 0.00
Epoch 398 Iter 1 subLoss 48231.4 multi 1.00 import weight 0.00
Epoch 398 Iter 2 subLoss 48219.8 multi 66.67 import weight 0.00
Epoch 398 Iter 3 subLoss 48356.0 multi 1.00 import weight 0.00
Epoch 398 Iter 4 subLoss 48313.2 multi -25.87 import weight 0.00
Epoch 398 Iter 5 subLoss 48276.7 multi -43.78 import weight 0.00
Epoch 398 Iter 6 subLoss 48469.7 multi 12.94 import weight 0.00
Epoch 398 Iter 7 subLoss 48283.7 multi 12.94 import weight 0.00
Epoch 398 Iter 8 subLoss 48290.1 multi 18.91 import weight 0.00
Epoch 398 Iter 9 subLoss 48388.1 multi -7.96 import weight 0.00
Epoch 398 Iter 10 subLoss 48329.2 multi 6.97 import weight 0.00
Epoch 398 Iter 11 subLoss 48268.4 multi 6.97 import weight 1.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 398 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 1.000 Grad mul 6.97 Pidx 4826 train Loss: 49250.7 test Loss: 8274.7
Epoch 399 Iter 0 subLoss 48210.1 multi 69.66 import weight 0.00
Epoch 399 Iter 1 subLoss 48264.6 multi 9.96 import weight 1.00
Epoch 399 Iter 2 subLoss 48267.3 multi 12.94 import weight 1.00
Epoch 399 Iter 3 subLoss 48299.6 multi 21.90 import weight 0.00
Epoch 399 Iter 4 subLoss 48286.5 multi 15.93 import weight 0.00
Epoch 399 Iter 5 subLoss 48242.4 multi 36.82 import weight 0.00
Epoch 399 Iter 6 subLoss 48213.9 multi 72.64 import weight 0.00
Epoch 399 Iter 7 subLoss 48301.5 multi -58.70 import weight 0.00
Epoch 399 Iter 8 subLoss 48192.2 multi 39.81 import weight 0.00
Epoch 399 Iter 9 subLoss 48292.0 multi 21.90 import weight 0.00
Epoch 399 Iter 10 subLoss 48243.0 multi 39.81 import weight 0.00
Epoch 399 Iter 11 subLoss 48255.0 multi 39.81 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 399 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 39.81 Pidx 4825 train Loss: 49203.3 test Loss: 8263.8
Epoch 400 Iter 0 subLoss 48247.7 multi 42.79 import weight 0.00
Epoch 400 Iter 1 subLoss 48235.1 multi 3.99 import weight 0.00
Epoch 400 Iter 2 subLoss 48279.1 multi -49.75 import weight 0.00
Epoch 400 Iter 3 subLoss 48278.3 multi -46.76 import weight 0.00
Epoch 400 Iter 4 subLoss 48350.3 multi 3.98 import weight 0.00
Epoch 400 Iter 5 subLoss 48261.7 multi 12.94 import weight 1.00
Epoch 400 Iter 6 subLoss 48357.3 multi 6.97 import weight 0.00
Epoch 400 Iter 7 subLoss 48399.5 multi -1.99 import weight 0.00
Epoch 400 Iter 8 subLoss 48431.4 multi -7.96 import weight 0.00
Epoch 400 Iter 9 subLoss 48419.4 multi 24.88 import weight 0.00
Epoch 400 Iter 10 subLoss 48264.2 multi 15.93 import weight 1.00
Epoch 400 Iter 11 subLoss 48304.9 multi -58.70 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 400 Acc: 20.08 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -58.70 Pidx 4830 train Loss: 49387.7 test Loss: 8288.4
Epoch 401 Iter 0 subLoss 48352.8 multi 9.96 import weight 0.00
Epoch 401 Iter 1 subLoss 48375.3 multi 12.94 import weight 0.00
Epoch 401 Iter 2 subLoss 48312.8 multi -28.85 import weight 0.00
Epoch 401 Iter 3 subLoss 48391.8 multi 1.00 import weight 0.00
Epoch 401 Iter 4 subLoss 48478.3 multi -25.87 import weight 0.00
Epoch 401 Iter 5 subLoss 48588.4 multi 18.91 import weight 0.00
Epoch 401 Iter 6 subLoss 48448.8 multi -1.99 import weight 0.00
Epoch 401 Iter 7 subLoss 48424.2 multi -7.96 import weight 0.00
Epoch 401 Iter 8 subLoss 48562.2 multi 9.96 import weight 0.00
Epoch 401 Iter 9 subLoss 48484.5 multi 9.96 import weight 0.00
Epoch 401 Iter 10 subLoss 48374.3 multi 15.93 import weight 0.00
Epoch 401 Iter 11 subLoss 48283.7 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 401 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 4828 train Loss: 49264.8 test Loss: 8270.3
Epoch 402 Iter 0 subLoss 48364.8 multi -37.81 import weight 0.00
Epoch 402 Iter 1 subLoss 48383.9 multi -10.94 import weight 0.00
Epoch 402 Iter 2 subLoss 48297.4 multi 21.90 import weight 0.00
Epoch 402 Iter 3 subLoss 48366.4 multi -34.82 import weight 0.00
Epoch 402 Iter 4 subLoss 48594.1 multi -13.93 import weight 0.00
Epoch 402 Iter 5 subLoss 48620.6 multi 15.93 import weight 0.00
Epoch 402 Iter 6 subLoss 48557.9 multi -40.79 import weight 0.00
Epoch 402 Iter 7 subLoss 48768.7 multi -25.87 import weight 0.00
Epoch 402 Iter 8 subLoss 48987.2 multi 9.96 import weight 0.00
Epoch 402 Iter 9 subLoss 49001.4 multi 1.00 import weight 0.00
Epoch 402 Iter 10 subLoss 48822.6 multi -1.99 import weight 0.00
Epoch 402 Iter 11 subLoss 48909.3 multi 30.85 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 402 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 30.85 Pidx 4890 train Loss: 49544.8 test Loss: 8314.0
Epoch 403 Iter 0 subLoss 48648.8 multi 9.96 import weight 0.00
Epoch 403 Iter 1 subLoss 48649.4 multi 12.94 import weight 0.00
Epoch 403 Iter 2 subLoss 48422.4 multi -4.97 import weight 0.00
Epoch 403 Iter 3 subLoss 48413.7 multi 27.87 import weight 0.00
Epoch 403 Iter 4 subLoss 48382.3 multi -7.96 import weight 0.00
Epoch 403 Iter 5 subLoss 48339.0 multi -13.93 import weight 0.00
Epoch 403 Iter 6 subLoss 48312.5 multi -25.87 import weight 0.00
Epoch 403 Iter 7 subLoss 48523.5 multi -22.88 import weight 0.00
Epoch 403 Iter 8 subLoss 48484.9 multi 12.94 import weight 0.00
Epoch 403 Iter 9 subLoss 48576.2 multi -31.84 import weight 0.00
Epoch 403 Iter 10 subLoss 48698.0 multi 9.96 import weight 0.00
Epoch 403 Iter 11 subLoss 48799.9 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 403 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 4879 train Loss: 49592.7 test Loss: 8321.4
Epoch 404 Iter 0 subLoss 48680.5 multi -16.91 import weight 0.00
Epoch 404 Iter 1 subLoss 48822.9 multi 1.00 import weight 0.00
Epoch 404 Iter 2 subLoss 48664.3 multi 24.88 import weight 0.00
Epoch 404 Iter 3 subLoss 48578.1 multi -28.85 import weight 0.00
Epoch 404 Iter 4 subLoss 48816.3 multi -16.91 import weight 0.00
Epoch 404 Iter 5 subLoss 49029.2 multi -13.93 import weight 0.00
Epoch 404 Iter 6 subLoss 49227.8 multi 15.93 import weight 0.00
Epoch 404 Iter 7 subLoss 48972.4 multi 9.96 import weight 0.00
Epoch 404 Iter 8 subLoss 48771.1 multi 33.84 import weight 0.00
Epoch 404 Iter 9 subLoss 48521.8 multi -19.90 import weight 0.00
Epoch 404 Iter 10 subLoss 48602.3 multi 9.96 import weight 0.00
Epoch 404 Iter 11 subLoss 48494.0 multi -19.90 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 404 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -19.90 Pidx 4849 train Loss: 49632.5 test Loss: 8328.4
Epoch 405 Iter 0 subLoss 48553.3 multi -37.81 import weight 0.00
Epoch 405 Iter 1 subLoss 48792.1 multi 9.96 import weight 0.00
Epoch 405 Iter 2 subLoss 48893.3 multi -16.91 import weight 0.00
Epoch 405 Iter 3 subLoss 49046.3 multi -25.87 import weight 0.00
Epoch 405 Iter 4 subLoss 49668.8 multi -16.91 import weight 0.00
Epoch 405 Iter 5 subLoss 49656.8 multi 15.93 import weight 0.00
Epoch 405 Iter 6 subLoss 49888.6 multi -1.99 import weight 0.00
Epoch 405 Iter 7 subLoss 49382.1 multi -13.93 import weight 0.00
Epoch 405 Iter 8 subLoss 50136.8 multi 15.93 import weight 0.00
Epoch 405 Iter 9 subLoss 49802.0 multi 1.00 import weight 0.00
Epoch 405 Iter 10 subLoss 49593.0 multi -1.99 import weight 0.00
Epoch 405 Iter 11 subLoss 49641.3 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 405 Acc: 20.08 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 4964 train Loss: 50634.6 test Loss: 8491.0
Epoch 406 Iter 0 subLoss 49579.1 multi -10.94 import weight 0.00
Epoch 406 Iter 1 subLoss 49956.2 multi -4.97 import weight 0.00
Epoch 406 Iter 2 subLoss 50159.0 multi 6.97 import weight 0.00
Epoch 406 Iter 3 subLoss 49853.7 multi -13.93 import weight 0.00
Epoch 406 Iter 4 subLoss 50287.2 multi -4.97 import weight 0.00
Epoch 406 Iter 5 subLoss 50594.6 multi -1.99 import weight 0.00
Epoch 406 Iter 6 subLoss 50346.9 multi 3.98 import weight 0.00
Epoch 406 Iter 7 subLoss 50583.2 multi 1.00 import weight 0.00
Epoch 406 Iter 8 subLoss 50226.2 multi -10.94 import weight 0.00
Epoch 406 Iter 9 subLoss 50946.2 multi 1.00 import weight 0.00
Epoch 406 Iter 10 subLoss 50674.3 multi -4.97 import weight 0.00
Epoch 406 Iter 11 subLoss 50646.0 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 406 Acc: 20.08 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 5064 train Loss: 52134.6 test Loss: 8736.2
Epoch 407 Iter 0 subLoss 51328.6 multi 1.00 import weight 0.00
Epoch 407 Iter 1 subLoss 51282.4 multi 1.00 import weight 0.00
Epoch 407 Iter 2 subLoss 51046.6 multi -1.99 import weight 0.00
Epoch 407 Iter 3 subLoss 51014.6 multi 1.00 import weight 0.00
Epoch 407 Iter 4 subLoss 51142.2 multi 3.99 import weight 0.00
Epoch 407 Iter 5 subLoss 50709.1 multi 9.96 import weight 0.00
Epoch 407 Iter 6 subLoss 50228.6 multi -7.96 import weight 0.00
Epoch 407 Iter 7 subLoss 50698.3 multi 1.00 import weight 0.00
Epoch 407 Iter 8 subLoss 50957.0 multi 3.98 import weight 0.00
Epoch 407 Iter 9 subLoss 50551.1 multi 6.97 import weight 0.00
Epoch 407 Iter 10 subLoss 49915.5 multi 3.99 import weight 0.00
Epoch 407 Iter 11 subLoss 50553.0 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 407 Acc: 20.08 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 5055 train Loss: 50827.5 test Loss: 8522.6
Epoch 408 Iter 0 subLoss 49545.2 multi -7.96 import weight 0.00
Epoch 408 Iter 1 subLoss 50175.5 multi 1.00 import weight 0.00
Epoch 408 Iter 2 subLoss 49910.0 multi 6.97 import weight 0.00
Epoch 408 Iter 3 subLoss 49692.2 multi 1.00 import weight 0.00
Epoch 408 Iter 4 subLoss 49820.4 multi 9.96 import weight 0.00
Epoch 408 Iter 5 subLoss 49599.7 multi 1.00 import weight 0.00
Epoch 408 Iter 6 subLoss 49606.4 multi -16.91 import weight 0.00
Epoch 408 Iter 7 subLoss 49871.8 multi -4.97 import weight 0.00
Epoch 408 Iter 8 subLoss 50254.7 multi -7.96 import weight 0.00
Epoch 408 Iter 9 subLoss 50183.2 multi -4.97 import weight 0.00
Epoch 408 Iter 10 subLoss 50443.3 multi 1.00 import weight 0.00
Epoch 408 Iter 11 subLoss 50615.6 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 408 Acc: 20.08 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 5061 train Loss: 51656.6 test Loss: 8658.6
Epoch 409 Iter 0 subLoss 50908.9 multi -1.99 import weight 0.00
Epoch 409 Iter 1 subLoss 50622.7 multi 1.00 import weight 0.00
Epoch 409 Iter 2 subLoss 50409.8 multi -4.97 import weight 0.00
Epoch 409 Iter 3 subLoss 50877.7 multi 3.99 import weight 0.00
Epoch 409 Iter 4 subLoss 50492.1 multi 3.99 import weight 0.00
Epoch 409 Iter 5 subLoss 50247.1 multi 12.94 import weight 0.00
Epoch 409 Iter 6 subLoss 50710.8 multi -13.93 import weight 0.00
Epoch 409 Iter 7 subLoss 50654.6 multi -1.98 import weight 0.00
Epoch 409 Iter 8 subLoss 50927.5 multi 3.99 import weight 0.00
Epoch 409 Iter 9 subLoss 50596.3 multi -1.98 import weight 0.00
Epoch 409 Iter 10 subLoss 50398.2 multi 1.00 import weight 0.00
Epoch 409 Iter 11 subLoss 50760.8 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 409 Acc: 20.08 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 5076 train Loss: 51598.3 test Loss: 8648.7
Epoch 410 Iter 0 subLoss 50858.5 multi 1.00 import weight 0.00
Epoch 410 Iter 1 subLoss 51342.7 multi 1.00 import weight 0.00
Epoch 410 Iter 2 subLoss 50373.4 multi -4.97 import weight 0.00
Epoch 410 Iter 3 subLoss 50199.7 multi -1.99 import weight 0.00
Epoch 410 Iter 4 subLoss 50719.5 multi -10.94 import weight 0.00
Epoch 410 Iter 5 subLoss 50851.1 multi 3.99 import weight 0.00
Epoch 410 Iter 6 subLoss 50674.4 multi -1.98 import weight 0.00
Epoch 410 Iter 7 subLoss 51614.2 multi 1.00 import weight 0.00
Epoch 410 Iter 8 subLoss 51196.6 multi 1.00 import weight 0.00
Epoch 410 Iter 9 subLoss 50986.1 multi -1.99 import weight 0.00
Epoch 410 Iter 10 subLoss 51054.1 multi -1.99 import weight 0.00
Epoch 410 Iter 11 subLoss 51080.9 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 410 Acc: 20.08 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 5108 train Loss: 52198.2 test Loss: 8746.8
Epoch 411 Iter 0 subLoss 51820.3 multi 1.00 import weight 0.00
Epoch 411 Iter 1 subLoss 51307.9 multi 1.00 import weight 0.00
Epoch 411 Iter 2 subLoss 51199.3 multi 3.99 import weight 0.00
Epoch 411 Iter 3 subLoss 50814.9 multi 3.99 import weight 0.00
Epoch 411 Iter 4 subLoss 50709.8 multi 9.96 import weight 0.00
Epoch 411 Iter 5 subLoss 50110.1 multi 1.00 import weight 0.00
Epoch 411 Iter 6 subLoss 50257.5 multi -7.96 import weight 0.00
Epoch 411 Iter 7 subLoss 50753.7 multi 3.99 import weight 0.00
Epoch 411 Iter 8 subLoss 50266.8 multi -4.97 import weight 0.00
Epoch 411 Iter 9 subLoss 50599.8 multi 1.00 import weight 0.00
Epoch 411 Iter 10 subLoss 50468.0 multi -4.97 import weight 0.00
Epoch 411 Iter 11 subLoss 50543.9 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 411 Acc: 20.08 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 5054 train Loss: 51861.5 test Loss: 8691.4
Epoch 412 Iter 0 subLoss 50851.5 multi 6.97 import weight 0.00
Epoch 412 Iter 1 subLoss 50870.8 multi 6.97 import weight 0.00
Epoch 412 Iter 2 subLoss 50148.4 multi -22.88 import weight 0.00
Epoch 412 Iter 3 subLoss 51056.0 multi 1.00 import weight 0.00
Epoch 412 Iter 4 subLoss 51424.8 multi 1.00 import weight 0.00
Epoch 412 Iter 5 subLoss 50918.5 multi -1.99 import weight 0.00
Epoch 412 Iter 6 subLoss 50808.5 multi -4.97 import weight 0.00
Epoch 412 Iter 7 subLoss 51185.9 multi 1.00 import weight 0.00
Epoch 412 Iter 8 subLoss 51378.0 multi 1.00 import weight 0.00
Epoch 412 Iter 9 subLoss 51443.8 multi 1.00 import weight 0.00
Epoch 412 Iter 10 subLoss 50950.4 multi 6.97 import weight 0.00
Epoch 412 Iter 11 subLoss 50809.7 multi -1.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 412 Acc: 20.08 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 5080 train Loss: 51966.6 test Loss: 8708.1
Epoch 413 Iter 0 subLoss 51032.2 multi 1.00 import weight 0.00
Epoch 413 Iter 1 subLoss 50554.0 multi 9.96 import weight 0.00
Epoch 413 Iter 2 subLoss 50484.4 multi 1.00 import weight 0.00
Epoch 413 Iter 3 subLoss 50609.2 multi -1.99 import weight 0.00
Epoch 413 Iter 4 subLoss 50481.3 multi 3.99 import weight 0.00
Epoch 413 Iter 5 subLoss 50400.1 multi -4.97 import weight 0.00
Epoch 413 Iter 6 subLoss 50723.8 multi -1.98 import weight 0.00
Epoch 413 Iter 7 subLoss 50636.2 multi 3.99 import weight 0.00
Epoch 413 Iter 8 subLoss 50789.3 multi -7.96 import weight 0.00
Epoch 413 Iter 9 subLoss 51038.3 multi 3.98 import weight 0.00
Epoch 413 Iter 10 subLoss 50471.6 multi -1.99 import weight 0.00
Epoch 413 Iter 11 subLoss 50617.7 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 413 Acc: 20.08 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 5061 train Loss: 51955.2 test Loss: 8705.9
Epoch 414 Iter 0 subLoss 50830.1 multi 1.00 import weight 0.00
Epoch 414 Iter 1 subLoss 50889.4 multi -7.96 import weight 0.00
Epoch 414 Iter 2 subLoss 51393.5 multi 1.00 import weight 0.00
Epoch 414 Iter 3 subLoss 51162.1 multi 1.00 import weight 0.00
Epoch 414 Iter 4 subLoss 50867.6 multi -7.96 import weight 0.00
Epoch 414 Iter 5 subLoss 51324.1 multi 3.99 import weight 0.00
Epoch 414 Iter 6 subLoss 51533.4 multi 1.00 import weight 0.00
Epoch 414 Iter 7 subLoss 51262.5 multi 1.00 import weight 0.00
Epoch 414 Iter 8 subLoss 51127.0 multi 1.00 import weight 0.00
Epoch 414 Iter 9 subLoss 50978.2 multi 3.99 import weight 0.00
Epoch 414 Iter 10 subLoss 51525.3 multi 1.00 import weight 0.00
Epoch 414 Iter 11 subLoss 50976.5 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 414 Acc: 20.08 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 5097 train Loss: 51657.8 test Loss: 8657.2
Epoch 415 Iter 0 subLoss 50560.0 multi -10.94 import weight 0.00
Epoch 415 Iter 1 subLoss 51248.6 multi 3.99 import weight 0.00
Epoch 415 Iter 2 subLoss 50553.3 multi 12.94 import weight 0.00
Epoch 415 Iter 3 subLoss 50442.8 multi 3.98 import weight 0.00
Epoch 415 Iter 4 subLoss 50297.0 multi 3.98 import weight 0.00
Epoch 415 Iter 5 subLoss 50078.5 multi 6.97 import weight 0.00
Epoch 415 Iter 6 subLoss 50106.7 multi 9.96 import weight 0.00
Epoch 415 Iter 7 subLoss 49606.3 multi -13.93 import weight 0.00
Epoch 415 Iter 8 subLoss 50064.7 multi -4.97 import weight 0.00
Epoch 415 Iter 9 subLoss 49763.7 multi 3.99 import weight 0.00
Epoch 415 Iter 10 subLoss 50429.8 multi 3.98 import weight 0.00
Epoch 415 Iter 11 subLoss 49934.5 multi -1.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 415 Acc: 20.08 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 4993 train Loss: 50958.3 test Loss: 8543.0
Epoch 416 Iter 0 subLoss 49846.2 multi 15.93 import weight 0.00
Epoch 416 Iter 1 subLoss 49548.2 multi -4.97 import weight 0.00
Epoch 416 Iter 2 subLoss 49572.8 multi -7.96 import weight 0.00
Epoch 416 Iter 3 subLoss 49703.9 multi -19.90 import weight 0.00
Epoch 416 Iter 4 subLoss 50404.8 multi -1.99 import weight 0.00
Epoch 416 Iter 5 subLoss 51016.6 multi 3.99 import weight 0.00
Epoch 416 Iter 6 subLoss 50903.3 multi 1.00 import weight 0.00
Epoch 416 Iter 7 subLoss 50493.8 multi 1.00 import weight 0.00
Epoch 416 Iter 8 subLoss 50050.5 multi -1.99 import weight 0.00
Epoch 416 Iter 9 subLoss 49923.4 multi -1.99 import weight 0.00
Epoch 416 Iter 10 subLoss 50391.7 multi 3.99 import weight 0.00
Epoch 416 Iter 11 subLoss 50052.9 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 416 Acc: 20.08 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 5005 train Loss: 51213.5 test Loss: 8584.3
Epoch 417 Iter 0 subLoss 50397.4 multi 6.97 import weight 0.00
Epoch 417 Iter 1 subLoss 49977.8 multi 21.90 import weight 0.00
Epoch 417 Iter 2 subLoss 49396.4 multi -7.96 import weight 0.00
Epoch 417 Iter 3 subLoss 49374.9 multi 15.93 import weight 0.00
Epoch 417 Iter 4 subLoss 49271.9 multi -7.96 import weight 0.00
Epoch 417 Iter 5 subLoss 49431.2 multi -1.99 import weight 0.00
Epoch 417 Iter 6 subLoss 49343.8 multi 21.90 import weight 0.00
Epoch 417 Iter 7 subLoss 49211.1 multi -4.97 import weight 0.00
Epoch 417 Iter 8 subLoss 49065.4 multi 1.00 import weight 0.00
Epoch 417 Iter 9 subLoss 49197.3 multi 12.94 import weight 0.00
Epoch 417 Iter 10 subLoss 48830.5 multi 6.97 import weight 0.00
Epoch 417 Iter 11 subLoss 48647.8 multi 15.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 417 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 15.93 Pidx 4864 train Loss: 49626.8 test Loss: 8327.8
Epoch 418 Iter 0 subLoss 48429.9 multi -4.97 import weight 0.00
Epoch 418 Iter 1 subLoss 48629.8 multi 18.91 import weight 0.00
Epoch 418 Iter 2 subLoss 48573.6 multi -25.87 import weight 0.00
Epoch 418 Iter 3 subLoss 48670.8 multi -4.97 import weight 0.00
Epoch 418 Iter 4 subLoss 48821.3 multi 1.00 import weight 0.00
Epoch 418 Iter 5 subLoss 48489.6 multi 15.93 import weight 0.00
Epoch 418 Iter 6 subLoss 48652.7 multi -25.87 import weight 0.00
Epoch 418 Iter 7 subLoss 49016.3 multi 1.00 import weight 0.00
Epoch 418 Iter 8 subLoss 49140.2 multi 3.99 import weight 0.00
Epoch 418 Iter 9 subLoss 48950.7 multi -1.99 import weight 0.00
Epoch 418 Iter 10 subLoss 49122.7 multi -10.94 import weight 0.00
Epoch 418 Iter 11 subLoss 48932.8 multi -16.91 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 418 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -16.91 Pidx 4893 train Loss: 50226.7 test Loss: 8424.3
Epoch 419 Iter 0 subLoss 49265.0 multi -1.99 import weight 0.00
Epoch 419 Iter 1 subLoss 49221.9 multi 15.93 import weight 0.00
Epoch 419 Iter 2 subLoss 49035.3 multi 12.94 import weight 0.00
Epoch 419 Iter 3 subLoss 48654.1 multi -22.88 import weight 0.00
Epoch 419 Iter 4 subLoss 49207.6 multi -4.97 import weight 0.00
Epoch 419 Iter 5 subLoss 49238.1 multi -4.97 import weight 0.00
Epoch 419 Iter 6 subLoss 49196.5 multi 15.93 import weight 0.00
Epoch 419 Iter 7 subLoss 48969.7 multi -16.91 import weight 0.00
Epoch 419 Iter 8 subLoss 49302.5 multi 30.85 import weight 0.00
Epoch 419 Iter 9 subLoss 48826.9 multi 3.98 import weight 0.00
Epoch 419 Iter 10 subLoss 48816.7 multi -13.93 import weight 0.00
Epoch 419 Iter 11 subLoss 48754.6 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 419 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 4875 train Loss: 49886.8 test Loss: 8369.4
Epoch 420 Iter 0 subLoss 48602.3 multi 12.94 import weight 0.00
Epoch 420 Iter 1 subLoss 48874.1 multi -1.99 import weight 0.00
Epoch 420 Iter 2 subLoss 48549.7 multi 33.84 import weight 0.00
Epoch 420 Iter 3 subLoss 48636.2 multi -19.90 import weight 0.00
Epoch 420 Iter 4 subLoss 48716.1 multi 3.99 import weight 0.00
Epoch 420 Iter 5 subLoss 48646.8 multi 15.93 import weight 0.00
Epoch 420 Iter 6 subLoss 48768.8 multi -25.87 import weight 0.00
Epoch 420 Iter 7 subLoss 48652.9 multi -22.88 import weight 0.00
Epoch 420 Iter 8 subLoss 49106.2 multi 9.96 import weight 0.00
Epoch 420 Iter 9 subLoss 48996.7 multi 1.00 import weight 0.00
Epoch 420 Iter 10 subLoss 48946.9 multi 15.93 import weight 0.00
Epoch 420 Iter 11 subLoss 48764.5 multi -22.88 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 420 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -22.88 Pidx 4876 train Loss: 49906.2 test Loss: 8370.9
Epoch 421 Iter 0 subLoss 48726.6 multi 15.93 import weight 0.00
Epoch 421 Iter 1 subLoss 48793.5 multi 12.94 import weight 0.00
Epoch 421 Iter 2 subLoss 48579.8 multi -22.88 import weight 0.00
Epoch 421 Iter 3 subLoss 48863.2 multi 6.97 import weight 0.00
Epoch 421 Iter 4 subLoss 48883.0 multi 24.88 import weight 0.00
Epoch 421 Iter 5 subLoss 48410.8 multi 30.85 import weight 0.00
Epoch 421 Iter 6 subLoss 48462.4 multi 15.93 import weight 0.00
Epoch 421 Iter 7 subLoss 48397.3 multi -1.98 import weight 0.00
Epoch 421 Iter 8 subLoss 48317.4 multi -22.88 import weight 0.00
Epoch 421 Iter 9 subLoss 48342.4 multi 3.99 import weight 0.00
Epoch 421 Iter 10 subLoss 48380.2 multi -4.97 import weight 0.00
Epoch 421 Iter 11 subLoss 48377.0 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 421 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 4837 train Loss: 49307.8 test Loss: 8278.4
Epoch 422 Iter 0 subLoss 48338.6 multi -10.94 import weight 0.00
Epoch 422 Iter 1 subLoss 48272.1 multi -49.75 import weight 0.00
Epoch 422 Iter 2 subLoss 48580.9 multi 9.96 import weight 0.00
Epoch 422 Iter 3 subLoss 48344.4 multi 3.98 import weight 0.00
Epoch 422 Iter 4 subLoss 48456.4 multi -22.88 import weight 0.00
Epoch 422 Iter 5 subLoss 48513.0 multi 6.97 import weight 0.00
Epoch 422 Iter 6 subLoss 48408.3 multi -25.87 import weight 0.00
Epoch 422 Iter 7 subLoss 48496.3 multi -19.90 import weight 0.00
Epoch 422 Iter 8 subLoss 48671.3 multi -1.98 import weight 0.00
Epoch 422 Iter 9 subLoss 48901.2 multi 30.85 import weight 0.00
Epoch 422 Iter 10 subLoss 48516.8 multi 9.96 import weight 0.00
Epoch 422 Iter 11 subLoss 48698.3 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 422 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 4869 train Loss: 49344.7 test Loss: 8284.1
Epoch 423 Iter 0 subLoss 48346.3 multi 6.97 import weight 0.00
Epoch 423 Iter 1 subLoss 48431.7 multi -13.93 import weight 0.00
Epoch 423 Iter 2 subLoss 48502.1 multi -7.96 import weight 0.00
Epoch 423 Iter 3 subLoss 48390.0 multi -1.99 import weight 0.00
Epoch 423 Iter 4 subLoss 48394.3 multi 1.00 import weight 0.00
Epoch 423 Iter 5 subLoss 48658.6 multi -19.90 import weight 0.00
Epoch 423 Iter 6 subLoss 48550.9 multi -37.81 import weight 0.00
Epoch 423 Iter 7 subLoss 48641.2 multi 18.91 import weight 0.00
Epoch 423 Iter 8 subLoss 48800.8 multi -1.99 import weight 0.00
Epoch 423 Iter 9 subLoss 48689.7 multi -19.90 import weight 0.00
Epoch 423 Iter 10 subLoss 48915.5 multi -58.70 import weight 0.00
Epoch 423 Iter 11 subLoss 49724.2 multi 3.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 423 Acc: 19.65 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 4972 train Loss: 50719.6 test Loss: 8506.0
Epoch 424 Iter 0 subLoss 49534.8 multi 12.94 import weight 0.00
Epoch 424 Iter 1 subLoss 49258.0 multi -7.96 import weight 0.00
Epoch 424 Iter 2 subLoss 49436.1 multi 1.00 import weight 0.00
Epoch 424 Iter 3 subLoss 49312.3 multi -28.85 import weight 0.00
Epoch 424 Iter 4 subLoss 50469.9 multi -1.98 import weight 0.00
Epoch 424 Iter 5 subLoss 50050.8 multi 3.99 import weight 0.00
Epoch 424 Iter 6 subLoss 50140.8 multi -19.90 import weight 0.00
Epoch 424 Iter 7 subLoss 50748.1 multi 1.00 import weight 0.00
Epoch 424 Iter 8 subLoss 51144.5 multi 6.97 import weight 0.00
Epoch 424 Iter 9 subLoss 50628.7 multi 1.00 import weight 0.00
Epoch 424 Iter 10 subLoss 50887.6 multi -4.97 import weight 0.00
Epoch 424 Iter 11 subLoss 50743.4 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 424 Acc: 19.65 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 5074 train Loss: 51483.3 test Loss: 8630.7
Epoch 425 Iter 0 subLoss 50887.6 multi -1.99 import weight 0.00
Epoch 425 Iter 1 subLoss 50454.2 multi -1.99 import weight 0.00
Epoch 425 Iter 2 subLoss 50464.4 multi -1.99 import weight 0.00
Epoch 425 Iter 3 subLoss 51197.7 multi 3.98 import weight 0.00
Epoch 425 Iter 4 subLoss 50394.5 multi 9.96 import weight 0.00
Epoch 425 Iter 5 subLoss 50425.9 multi 6.97 import weight 0.00
Epoch 425 Iter 6 subLoss 50267.5 multi -1.99 import weight 0.00
Epoch 425 Iter 7 subLoss 49631.7 multi 9.96 import weight 0.00
Epoch 425 Iter 8 subLoss 49842.7 multi 18.91 import weight 0.00
Epoch 425 Iter 9 subLoss 49131.4 multi 12.94 import weight 0.00
Epoch 425 Iter 10 subLoss 49033.1 multi 15.93 import weight 0.00
Epoch 425 Iter 11 subLoss 48856.3 multi -31.84 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 425 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -31.84 Pidx 4885 train Loss: 50295.6 test Loss: 8438.6
Epoch 426 Iter 0 subLoss 49392.0 multi -4.97 import weight 0.00
Epoch 426 Iter 1 subLoss 49122.9 multi -7.96 import weight 0.00
Epoch 426 Iter 2 subLoss 49686.3 multi 12.94 import weight 0.00
Epoch 426 Iter 3 subLoss 49281.9 multi 3.98 import weight 0.00
Epoch 426 Iter 4 subLoss 49115.4 multi -19.90 import weight 0.00
Epoch 426 Iter 5 subLoss 49546.5 multi -4.97 import weight 0.00
Epoch 426 Iter 6 subLoss 50055.4 multi 6.97 import weight 0.00
Epoch 426 Iter 7 subLoss 49158.9 multi 1.00 import weight 0.00
Epoch 426 Iter 8 subLoss 49776.7 multi 1.00 import weight 0.00
Epoch 426 Iter 9 subLoss 49273.4 multi -7.96 import weight 0.00
Epoch 426 Iter 10 subLoss 49502.9 multi -16.91 import weight 0.00
Epoch 426 Iter 11 subLoss 50000.0 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 426 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 5000 train Loss: 50935.6 test Loss: 8542.5
Epoch 427 Iter 0 subLoss 49904.2 multi -10.94 import weight 0.00
Epoch 427 Iter 1 subLoss 50167.5 multi 3.99 import weight 0.00
Epoch 427 Iter 2 subLoss 50182.9 multi -1.98 import weight 0.00
Epoch 427 Iter 3 subLoss 50002.4 multi 3.99 import weight 0.00
Epoch 427 Iter 4 subLoss 50517.8 multi 1.00 import weight 0.00
Epoch 427 Iter 5 subLoss 49718.4 multi 1.00 import weight 0.00
Epoch 427 Iter 6 subLoss 49979.1 multi 24.88 import weight 0.00
Epoch 427 Iter 7 subLoss 49662.4 multi -16.91 import weight 0.00
Epoch 427 Iter 8 subLoss 49386.0 multi -13.93 import weight 0.00
Epoch 427 Iter 9 subLoss 50238.6 multi -7.96 import weight 0.00
Epoch 427 Iter 10 subLoss 50390.1 multi 12.94 import weight 0.00
Epoch 427 Iter 11 subLoss 49933.2 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 427 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 4993 train Loss: 50991.7 test Loss: 8550.5
Epoch 428 Iter 0 subLoss 50008.4 multi 6.97 import weight 0.00
Epoch 428 Iter 1 subLoss 49626.9 multi -13.93 import weight 0.00
Epoch 428 Iter 2 subLoss 50222.7 multi -4.97 import weight 0.00
Epoch 428 Iter 3 subLoss 49791.7 multi -10.94 import weight 0.00
Epoch 428 Iter 4 subLoss 50719.5 multi -10.94 import weight 0.00
Epoch 428 Iter 5 subLoss 51088.9 multi 3.99 import weight 0.00
Epoch 428 Iter 6 subLoss 50723.5 multi -1.99 import weight 0.00
Epoch 428 Iter 7 subLoss 51354.5 multi -1.99 import weight 0.00
Epoch 428 Iter 8 subLoss 51243.2 multi 6.97 import weight 0.00
Epoch 428 Iter 9 subLoss 51004.6 multi 1.00 import weight 0.00
Epoch 428 Iter 10 subLoss 50322.1 multi 3.98 import weight 0.00
Epoch 428 Iter 11 subLoss 50578.1 multi -1.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 428 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 5057 train Loss: 51631.1 test Loss: 8655.0
Epoch 429 Iter 0 subLoss 50557.0 multi 15.93 import weight 0.00
Epoch 429 Iter 1 subLoss 50328.3 multi 6.97 import weight 0.00
Epoch 429 Iter 2 subLoss 49977.5 multi 27.87 import weight 0.00
Epoch 429 Iter 3 subLoss 49292.6 multi -7.96 import weight 0.00
Epoch 429 Iter 4 subLoss 49519.5 multi 9.96 import weight 0.00
Epoch 429 Iter 5 subLoss 49070.8 multi -10.94 import weight 0.00
Epoch 429 Iter 6 subLoss 49059.1 multi 9.96 import weight 0.00
Epoch 429 Iter 7 subLoss 48994.7 multi 3.99 import weight 0.00
Epoch 429 Iter 8 subLoss 49426.2 multi 9.96 import weight 0.00
Epoch 429 Iter 9 subLoss 49052.4 multi 12.94 import weight 0.00
Epoch 429 Iter 10 subLoss 48653.9 multi -19.90 import weight 0.00
Epoch 429 Iter 11 subLoss 49045.4 multi -28.85 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 429 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -28.85 Pidx 4904 train Loss: 50441.2 test Loss: 8460.2
Epoch 430 Iter 0 subLoss 49621.6 multi -10.94 import weight 0.00
Epoch 430 Iter 1 subLoss 49876.7 multi -1.98 import weight 0.00
Epoch 430 Iter 2 subLoss 49624.4 multi -7.96 import weight 0.00
Epoch 430 Iter 3 subLoss 49836.6 multi -7.96 import weight 0.00
Epoch 430 Iter 4 subLoss 50211.0 multi 3.99 import weight 0.00
Epoch 430 Iter 5 subLoss 50002.3 multi 9.96 import weight 0.00
Epoch 430 Iter 6 subLoss 49794.2 multi -7.96 import weight 0.00
Epoch 430 Iter 7 subLoss 49902.9 multi -7.96 import weight 0.00
Epoch 430 Iter 8 subLoss 50296.1 multi 6.97 import weight 0.00
Epoch 430 Iter 9 subLoss 50019.2 multi -19.90 import weight 0.00
Epoch 430 Iter 10 subLoss 50377.0 multi -1.98 import weight 0.00
Epoch 430 Iter 11 subLoss 50922.9 multi 3.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 430 Acc: 19.65 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.98 Pidx 5092 train Loss: 51538.9 test Loss: 8639.3
Epoch 431 Iter 0 subLoss 50857.5 multi 9.96 import weight 0.00
Epoch 431 Iter 1 subLoss 49928.2 multi 1.00 import weight 0.00
Epoch 431 Iter 2 subLoss 50448.3 multi 6.97 import weight 0.00
Epoch 431 Iter 3 subLoss 49876.3 multi 1.00 import weight 0.00
Epoch 431 Iter 4 subLoss 49915.8 multi 3.99 import weight 0.00
Epoch 431 Iter 5 subLoss 50161.7 multi 6.97 import weight 0.00
Epoch 431 Iter 6 subLoss 49785.7 multi -1.99 import weight 0.00
Epoch 431 Iter 7 subLoss 49365.4 multi 6.97 import weight 0.00
Epoch 431 Iter 8 subLoss 49267.2 multi -1.98 import weight 0.00
Epoch 431 Iter 9 subLoss 49425.6 multi 12.94 import weight 0.00
Epoch 431 Iter 10 subLoss 49241.3 multi -1.98 import weight 0.00
Epoch 431 Iter 11 subLoss 49195.6 multi 18.91 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 431 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 18.91 Pidx 4919 train Loss: 49968.0 test Loss: 8384.1
Epoch 432 Iter 0 subLoss 49257.4 multi -7.96 import weight 0.00
Epoch 432 Iter 1 subLoss 49160.2 multi -10.94 import weight 0.00
Epoch 432 Iter 2 subLoss 49135.7 multi 12.94 import weight 0.00
Epoch 432 Iter 3 subLoss 49185.8 multi -10.94 import weight 0.00
Epoch 432 Iter 4 subLoss 49293.0 multi -4.97 import weight 0.00
Epoch 432 Iter 5 subLoss 49327.4 multi 6.97 import weight 0.00
Epoch 432 Iter 6 subLoss 48907.3 multi 33.84 import weight 0.00
Epoch 432 Iter 7 subLoss 48797.2 multi 15.93 import weight 0.00
Epoch 432 Iter 8 subLoss 48728.1 multi 18.91 import weight 0.00
Epoch 432 Iter 9 subLoss 48469.1 multi 15.93 import weight 0.00
Epoch 432 Iter 10 subLoss 48379.8 multi 15.93 import weight 0.00
Epoch 432 Iter 11 subLoss 48434.4 multi -10.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 432 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -10.94 Pidx 4843 train Loss: 49370.9 test Loss: 8288.8
Epoch 433 Iter 0 subLoss 48216.4 multi 75.63 import weight 0.00
Epoch 433 Iter 1 subLoss 48237.9 multi 6.97 import weight 0.00
Epoch 433 Iter 2 subLoss 48290.4 multi 24.88 import weight 0.00
Epoch 433 Iter 3 subLoss 48355.6 multi 3.98 import weight 0.00
Epoch 433 Iter 4 subLoss 48210.2 multi 78.61 import weight 0.00
Epoch 433 Iter 5 subLoss 48295.3 multi 27.87 import weight 0.00
Epoch 433 Iter 6 subLoss 48267.8 multi 18.91 import weight 1.00
Epoch 433 Iter 7 subLoss 48191.9 multi 42.79 import weight 0.00
Epoch 433 Iter 8 subLoss 48259.6 multi 39.81 import weight 0.00
Epoch 433 Iter 9 subLoss 48276.1 multi -49.75 import weight 0.00
Epoch 433 Iter 10 subLoss 48333.1 multi -7.96 import weight 0.00
Epoch 433 Iter 11 subLoss 48259.0 multi 42.79 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 433 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 42.79 Pidx 4825 train Loss: 49215.8 test Loss: 8268.1
Epoch 434 Iter 0 subLoss 48212.2 multi 81.60 import weight 0.00
Epoch 434 Iter 1 subLoss 48178.6 multi 1.00 import weight 0.00
Epoch 434 Iter 2 subLoss 48207.3 multi 3.99 import weight 0.00
Epoch 434 Iter 3 subLoss 48337.2 multi -4.97 import weight 0.00
Epoch 434 Iter 4 subLoss 48262.8 multi 15.93 import weight 1.00
Epoch 434 Iter 5 subLoss 48275.2 multi -49.75 import weight 0.00
Epoch 434 Iter 6 subLoss 48278.5 multi -46.76 import weight 0.00
Epoch 434 Iter 7 subLoss 48401.3 multi -28.85 import weight 0.00
Epoch 434 Iter 8 subLoss 48535.5 multi 30.85 import weight 0.00
Epoch 434 Iter 9 subLoss 48320.3 multi 1.00 import weight 0.00
Epoch 434 Iter 10 subLoss 48344.3 multi 3.99 import weight 0.00
Epoch 434 Iter 11 subLoss 48308.3 multi -64.67 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 434 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -64.67 Pidx 4830 train Loss: 49401.2 test Loss: 8295.1
Epoch 435 Iter 0 subLoss 48549.5 multi 33.84 import weight 0.00
Epoch 435 Iter 1 subLoss 48267.1 multi 18.91 import weight 1.00
Epoch 435 Iter 2 subLoss 48324.1 multi 3.98 import weight 0.00
Epoch 435 Iter 3 subLoss 48253.0 multi 45.78 import weight 0.00
Epoch 435 Iter 4 subLoss 48295.4 multi 30.85 import weight 0.00
Epoch 435 Iter 5 subLoss 48230.8 multi 9.96 import weight 0.00
Epoch 435 Iter 6 subLoss 48210.6 multi 81.60 import weight 0.00
Epoch 435 Iter 7 subLoss 48289.4 multi 3.99 import weight 0.00
Epoch 435 Iter 8 subLoss 48282.3 multi 6.97 import weight 0.00
Epoch 435 Iter 9 subLoss 48230.4 multi 12.94 import weight 0.00
Epoch 435 Iter 10 subLoss 48190.8 multi 45.78 import weight 0.00
Epoch 435 Iter 11 subLoss 48230.5 multi 15.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 435 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 15.93 Pidx 4823 train Loss: 49209.6 test Loss: 8265.9
Epoch 436 Iter 0 subLoss 48254.1 multi 48.76 import weight 0.00
Epoch 436 Iter 1 subLoss 48215.4 multi 84.58 import weight 0.00
Epoch 436 Iter 2 subLoss 48331.1 multi -7.96 import weight 0.00
Epoch 436 Iter 3 subLoss 48270.8 multi -46.76 import weight 0.00
Epoch 436 Iter 4 subLoss 48363.6 multi -34.82 import weight 0.00
Epoch 436 Iter 5 subLoss 48435.5 multi -7.96 import weight 0.00
Epoch 436 Iter 6 subLoss 48395.5 multi 3.99 import weight 0.00
Epoch 436 Iter 7 subLoss 48578.7 multi -19.90 import weight 0.00
Epoch 436 Iter 8 subLoss 48466.1 multi 18.91 import weight 0.00
Epoch 436 Iter 9 subLoss 48576.7 multi -16.91 import weight 0.00
Epoch 436 Iter 10 subLoss 48629.3 multi 21.90 import weight 0.00
Epoch 436 Iter 11 subLoss 48538.1 multi 33.84 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 436 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 33.84 Pidx 4853 train Loss: 49255.5 test Loss: 8272.8
Epoch 437 Iter 0 subLoss 48352.6 multi 3.99 import weight 0.00
Epoch 437 Iter 1 subLoss 48215.2 multi 87.57 import weight 0.00
Epoch 437 Iter 2 subLoss 48367.8 multi -34.82 import weight 0.00
Epoch 437 Iter 3 subLoss 48320.7 multi 6.97 import weight 0.00
Epoch 437 Iter 4 subLoss 48337.6 multi -7.96 import weight 0.00
Epoch 437 Iter 5 subLoss 48364.4 multi -31.84 import weight 0.00
Epoch 437 Iter 6 subLoss 48432.9 multi -4.97 import weight 0.00
Epoch 437 Iter 7 subLoss 48298.7 multi 27.87 import weight 0.00
Epoch 437 Iter 8 subLoss 48371.0 multi 9.96 import weight 0.00
Epoch 437 Iter 9 subLoss 48438.1 multi -1.98 import weight 0.00
Epoch 437 Iter 10 subLoss 48352.6 multi 6.97 import weight 0.00
Epoch 437 Iter 11 subLoss 48257.9 multi 51.75 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 437 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 51.75 Pidx 4825 train Loss: 49222.6 test Loss: 8266.0
Epoch 438 Iter 0 subLoss 48269.7 multi 12.94 import weight 1.00
Epoch 438 Iter 1 subLoss 48206.2 multi 3.99 import weight 0.00
Epoch 438 Iter 2 subLoss 48301.2 multi -67.66 import weight 0.00
Epoch 438 Iter 3 subLoss 48412.9 multi 27.87 import weight 0.00
Epoch 438 Iter 4 subLoss 48234.7 multi 18.91 import weight 0.00
Epoch 438 Iter 5 subLoss 48170.5 multi 3.99 import weight 0.00
Epoch 438 Iter 6 subLoss 48328.7 multi 9.96 import weight 0.00
Epoch 438 Iter 7 subLoss 48234.7 multi 21.90 import weight 0.00
Epoch 438 Iter 8 subLoss 48245.2 multi 24.88 import weight 0.00
Epoch 438 Iter 9 subLoss 48216.3 multi 87.57 import weight 0.00
Epoch 438 Iter 10 subLoss 48303.6 multi -64.67 import weight 0.00
Epoch 438 Iter 11 subLoss 48412.9 multi 30.85 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 438 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 30.85 Pidx 4841 train Loss: 49242.7 test Loss: 8272.3
Epoch 439 Iter 0 subLoss 48327.1 multi 12.94 import weight 0.00
Epoch 439 Iter 1 subLoss 48211.4 multi 90.55 import weight 0.00
Epoch 439 Iter 2 subLoss 48213.1 multi 93.54 import weight 0.00
Epoch 439 Iter 3 subLoss 48223.5 multi -37.81 import weight 0.00
Epoch 439 Iter 4 subLoss 48348.0 multi 1.00 import weight 0.00
Epoch 439 Iter 5 subLoss 48301.6 multi -61.69 import weight 0.00
Epoch 439 Iter 6 subLoss 48382.3 multi -10.94 import weight 0.00
Epoch 439 Iter 7 subLoss 48526.2 multi -22.88 import weight 0.00
Epoch 439 Iter 8 subLoss 48834.9 multi 3.99 import weight 0.00
Epoch 439 Iter 9 subLoss 48676.8 multi 1.00 import weight 0.00
Epoch 439 Iter 10 subLoss 48529.2 multi -19.90 import weight 0.00
Epoch 439 Iter 11 subLoss 48752.7 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 439 Acc: 20.08 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 4875 train Loss: 49777.9 test Loss: 8344.4
Epoch 440 Iter 0 subLoss 48790.2 multi 18.91 import weight 0.00
Epoch 440 Iter 1 subLoss 48503.2 multi -4.97 import weight 0.00
Epoch 440 Iter 2 subLoss 48511.5 multi 6.97 import weight 0.00
Epoch 440 Iter 3 subLoss 48647.5 multi 21.90 import weight 0.00
Epoch 440 Iter 4 subLoss 48384.4 multi -7.96 import weight 0.00
Epoch 440 Iter 5 subLoss 48460.7 multi 21.90 import weight 0.00
Epoch 440 Iter 6 subLoss 48354.5 multi 6.97 import weight 0.00
Epoch 440 Iter 7 subLoss 48380.9 multi -4.97 import weight 0.00
Epoch 440 Iter 8 subLoss 48234.6 multi 21.90 import weight 0.00
Epoch 440 Iter 9 subLoss 48280.5 multi 6.97 import weight 0.00
Epoch 440 Iter 10 subLoss 48352.1 multi 9.96 import weight 0.00
Epoch 440 Iter 11 subLoss 48329.1 multi 15.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 440 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 15.93 Pidx 4832 train Loss: 49219.6 test Loss: 8264.4
Epoch 441 Iter 0 subLoss 48199.6 multi 48.76 import weight 0.00
Epoch 441 Iter 1 subLoss 48327.1 multi 18.91 import weight 0.00
Epoch 441 Iter 2 subLoss 48214.5 multi 96.52 import weight 0.00
Epoch 441 Iter 3 subLoss 48271.2 multi -46.76 import weight 0.00
Epoch 441 Iter 4 subLoss 48309.4 multi -58.70 import weight 0.00
Epoch 441 Iter 5 subLoss 48449.2 multi -13.93 import weight 0.00
Epoch 441 Iter 6 subLoss 48468.1 multi 24.88 import weight 0.00
Epoch 441 Iter 7 subLoss 48172.3 multi 6.97 import weight 0.00
Epoch 441 Iter 8 subLoss 48319.1 multi -34.82 import weight 0.00
Epoch 441 Iter 9 subLoss 48586.6 multi 6.97 import weight 0.00
Epoch 441 Iter 10 subLoss 48336.7 multi -16.91 import weight 0.00
Epoch 441 Iter 11 subLoss 48306.6 multi -55.72 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 441 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -55.72 Pidx 4830 train Loss: 49635.4 test Loss: 8346.4
Epoch 442 Iter 0 subLoss 48492.7 multi -16.91 import weight 0.00
Epoch 442 Iter 1 subLoss 48780.0 multi 30.85 import weight 0.00
Epoch 442 Iter 2 subLoss 48517.8 multi 9.96 import weight 0.00
Epoch 442 Iter 3 subLoss 48552.7 multi -37.81 import weight 0.00
Epoch 442 Iter 4 subLoss 48721.2 multi 21.90 import weight 0.00
Epoch 442 Iter 5 subLoss 48518.8 multi 12.94 import weight 0.00
Epoch 442 Iter 6 subLoss 48247.7 multi 24.88 import weight 0.00
Epoch 442 Iter 7 subLoss 48367.0 multi -37.81 import weight 0.00
Epoch 442 Iter 8 subLoss 48472.2 multi -37.81 import weight 0.00
Epoch 442 Iter 9 subLoss 48864.8 multi 6.97 import weight 0.00
Epoch 442 Iter 10 subLoss 48736.5 multi -19.90 import weight 0.00
Epoch 442 Iter 11 subLoss 48952.1 multi -1.98 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 442 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.98 Pidx 4895 train Loss: 49942.2 test Loss: 8398.9
Epoch 443 Iter 0 subLoss 49132.5 multi 15.93 import weight 0.00
Epoch 443 Iter 1 subLoss 48560.4 multi 1.00 import weight 0.00
Epoch 443 Iter 2 subLoss 48729.7 multi 24.88 import weight 0.00
Epoch 443 Iter 3 subLoss 48504.6 multi -4.97 import weight 0.00
Epoch 443 Iter 4 subLoss 48470.0 multi 27.87 import weight 0.00
Epoch 443 Iter 5 subLoss 48337.6 multi -13.93 import weight 0.00
Epoch 443 Iter 6 subLoss 48323.3 multi 18.91 import weight 0.00
Epoch 443 Iter 7 subLoss 48327.9 multi 21.90 import weight 0.00
Epoch 443 Iter 8 subLoss 48310.7 multi -34.82 import weight 0.00
Epoch 443 Iter 9 subLoss 48386.6 multi -1.99 import weight 0.00
Epoch 443 Iter 10 subLoss 48290.0 multi 6.97 import weight 0.00
Epoch 443 Iter 11 subLoss 48367.5 multi -34.82 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 443 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -34.82 Pidx 4836 train Loss: 49419.6 test Loss: 8306.2
Epoch 444 Iter 0 subLoss 48618.0 multi -25.87 import weight 0.00
Epoch 444 Iter 1 subLoss 48665.9 multi 12.94 import weight 0.00
Epoch 444 Iter 2 subLoss 48528.8 multi -25.87 import weight 0.00
Epoch 444 Iter 3 subLoss 48729.3 multi 27.87 import weight 0.00
Epoch 444 Iter 4 subLoss 48370.5 multi 6.97 import weight 0.00
Epoch 444 Iter 5 subLoss 48479.1 multi -37.81 import weight 0.00
Epoch 444 Iter 6 subLoss 48763.8 multi -22.88 import weight 0.00
Epoch 444 Iter 7 subLoss 49238.2 multi -1.99 import weight 0.00
Epoch 444 Iter 8 subLoss 48768.0 multi -19.90 import weight 0.00
Epoch 444 Iter 9 subLoss 49144.3 multi -1.98 import weight 0.00
Epoch 444 Iter 10 subLoss 49625.6 multi -4.97 import weight 0.00
Epoch 444 Iter 11 subLoss 49516.8 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 444 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 4951 train Loss: 50209.2 test Loss: 8443.8
Epoch 445 Iter 0 subLoss 49320.7 multi 9.96 import weight 0.00
Epoch 445 Iter 1 subLoss 48878.4 multi -4.97 import weight 0.00
Epoch 445 Iter 2 subLoss 49137.0 multi 18.91 import weight 0.00
Epoch 445 Iter 3 subLoss 48360.6 multi -31.84 import weight 0.00
Epoch 445 Iter 4 subLoss 49288.1 multi 3.99 import weight 0.00
Epoch 445 Iter 5 subLoss 49052.1 multi 12.94 import weight 0.00
Epoch 445 Iter 6 subLoss 48780.6 multi -31.84 import weight 0.00
Epoch 445 Iter 7 subLoss 49133.0 multi 21.90 import weight 0.00
Epoch 445 Iter 8 subLoss 48694.8 multi 9.96 import weight 0.00
Epoch 445 Iter 9 subLoss 48612.3 multi -22.88 import weight 0.00
Epoch 445 Iter 10 subLoss 48956.8 multi 1.00 import weight 0.00
Epoch 445 Iter 11 subLoss 48925.4 multi 24.88 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 445 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 24.88 Pidx 4892 train Loss: 49519.5 test Loss: 8323.9
Epoch 446 Iter 0 subLoss 48551.5 multi -34.82 import weight 0.00
Epoch 446 Iter 1 subLoss 48764.9 multi -16.91 import weight 0.00
Epoch 446 Iter 2 subLoss 49153.0 multi 1.00 import weight 0.00
Epoch 446 Iter 3 subLoss 48879.0 multi -1.99 import weight 0.00
Epoch 446 Iter 4 subLoss 49238.1 multi 1.00 import weight 0.00
Epoch 446 Iter 5 subLoss 49054.4 multi 15.93 import weight 0.00
Epoch 446 Iter 6 subLoss 48882.4 multi 21.90 import weight 0.00
Epoch 446 Iter 7 subLoss 48585.8 multi 9.96 import weight 0.00
Epoch 446 Iter 8 subLoss 48541.7 multi 33.84 import weight 0.00
Epoch 446 Iter 9 subLoss 48310.4 multi -31.84 import weight 0.00
Epoch 446 Iter 10 subLoss 48413.1 multi 33.84 import weight 0.00
Epoch 446 Iter 11 subLoss 48287.6 multi 9.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 446 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 9.96 Pidx 4828 train Loss: 49231.9 test Loss: 8271.5
Epoch 447 Iter 0 subLoss 48279.3 multi -43.78 import weight 0.00
Epoch 447 Iter 1 subLoss 48258.0 multi 48.76 import weight 0.00
Epoch 447 Iter 2 subLoss 48332.6 multi -16.91 import weight 0.00
Epoch 447 Iter 3 subLoss 48225.3 multi -37.81 import weight 0.00
Epoch 447 Iter 4 subLoss 48296.1 multi 21.90 import weight 0.00
Epoch 447 Iter 5 subLoss 48259.5 multi 51.75 import weight 0.00
Epoch 447 Iter 6 subLoss 48262.1 multi 9.96 import weight 1.00
Epoch 447 Iter 7 subLoss 48267.6 multi 12.94 import weight 1.00
Epoch 447 Iter 8 subLoss 48226.1 multi -34.82 import weight 0.00
Epoch 447 Iter 9 subLoss 48289.6 multi 9.96 import weight 0.00
Epoch 447 Iter 10 subLoss 48292.7 multi 21.90 import weight 0.00
Epoch 447 Iter 11 subLoss 48249.3 multi 27.87 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 447 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 27.87 Pidx 4824 train Loss: 49203.2 test Loss: 8264.8
Epoch 448 Iter 0 subLoss 48263.2 multi 15.93 import weight 1.00
Epoch 448 Iter 1 subLoss 48272.2 multi -49.75 import weight 0.00
Epoch 448 Iter 2 subLoss 48273.5 multi -46.76 import weight 0.00
Epoch 448 Iter 3 subLoss 48265.0 multi 18.91 import weight 1.00
Epoch 448 Iter 4 subLoss 48311.7 multi -28.85 import weight 0.00
Epoch 448 Iter 5 subLoss 48366.8 multi -28.85 import weight 0.00
Epoch 448 Iter 6 subLoss 48450.5 multi -22.88 import weight 0.00
Epoch 448 Iter 7 subLoss 48500.2 multi -1.98 import weight 0.00
Epoch 448 Iter 8 subLoss 48389.0 multi -1.98 import weight 0.00
Epoch 448 Iter 9 subLoss 48550.6 multi -34.82 import weight 0.00
Epoch 448 Iter 10 subLoss 48881.4 multi 24.88 import weight 0.00
Epoch 448 Iter 11 subLoss 48586.5 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 448 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 4858 train Loss: 49409.7 test Loss: 8300.3
Epoch 449 Iter 0 subLoss 48379.9 multi 3.98 import weight 0.00
Epoch 449 Iter 1 subLoss 48491.7 multi -13.93 import weight 0.00
Epoch 449 Iter 2 subLoss 48560.7 multi -1.99 import weight 0.00
Epoch 449 Iter 3 subLoss 48421.8 multi -13.93 import weight 0.00
Epoch 449 Iter 4 subLoss 48656.0 multi -19.90 import weight 0.00
Epoch 449 Iter 5 subLoss 48874.2 multi 1.00 import weight 0.00
Epoch 449 Iter 6 subLoss 48766.0 multi -13.93 import weight 0.00
Epoch 449 Iter 7 subLoss 49111.9 multi -16.91 import weight 0.00
Epoch 449 Iter 8 subLoss 49386.5 multi -10.94 import weight 0.00
Epoch 449 Iter 9 subLoss 49490.8 multi 9.96 import weight 0.00
Epoch 449 Iter 10 subLoss 49563.1 multi 15.93 import weight 0.00
Epoch 449 Iter 11 subLoss 48806.5 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 449 Acc: 19.07 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 4880 train Loss: 50004.3 test Loss: 8401.7
Epoch 450 Iter 0 subLoss 49088.5 multi 9.96 import weight 0.00
Epoch 450 Iter 1 subLoss 48810.2 multi -16.91 import weight 0.00
Epoch 450 Iter 2 subLoss 49064.7 multi -7.96 import weight 0.00
Epoch 450 Iter 3 subLoss 49234.5 multi 3.99 import weight 0.00
Epoch 450 Iter 4 subLoss 49082.0 multi 12.94 import weight 0.00
Epoch 450 Iter 5 subLoss 48735.4 multi -22.88 import weight 0.00
Epoch 450 Iter 6 subLoss 49398.7 multi -7.96 import weight 0.00
Epoch 450 Iter 7 subLoss 49476.6 multi -1.98 import weight 0.00
Epoch 450 Iter 8 subLoss 49719.2 multi 3.98 import weight 0.00
Epoch 450 Iter 9 subLoss 49683.2 multi 15.93 import weight 0.00
Epoch 450 Iter 10 subLoss 49203.2 multi -7.96 import weight 0.00
Epoch 450 Iter 11 subLoss 49136.7 multi 24.88 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 450 Acc: 19.07 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 24.88 Pidx 4913 train Loss: 49678.7 test Loss: 8344.8
Epoch 451 Iter 0 subLoss 48473.0 multi -34.82 import weight 0.00
Epoch 451 Iter 1 subLoss 48979.0 multi 9.96 import weight 0.00
Epoch 451 Iter 2 subLoss 48927.6 multi 27.87 import weight 0.00
Epoch 451 Iter 3 subLoss 48655.6 multi -16.91 import weight 0.00
Epoch 451 Iter 4 subLoss 48733.9 multi -19.90 import weight 0.00
Epoch 451 Iter 5 subLoss 49045.1 multi -25.87 import weight 0.00
Epoch 451 Iter 6 subLoss 49294.4 multi -4.97 import weight 0.00
Epoch 451 Iter 7 subLoss 49776.3 multi 3.99 import weight 0.00
Epoch 451 Iter 8 subLoss 49761.9 multi 6.97 import weight 0.00
Epoch 451 Iter 9 subLoss 49168.3 multi -10.94 import weight 0.00
Epoch 451 Iter 10 subLoss 49386.4 multi -7.96 import weight 0.00
Epoch 451 Iter 11 subLoss 49882.1 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 451 Acc: 19.07 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 4988 train Loss: 51135.8 test Loss: 8594.8
Epoch 452 Iter 0 subLoss 50039.9 multi -10.94 import weight 0.00
Epoch 452 Iter 1 subLoss 50543.7 multi 1.00 import weight 0.00
Epoch 452 Iter 2 subLoss 50723.3 multi 1.00 import weight 0.00
Epoch 452 Iter 3 subLoss 50595.8 multi 3.99 import weight 0.00
Epoch 452 Iter 4 subLoss 50444.8 multi 9.96 import weight 0.00
Epoch 452 Iter 5 subLoss 49879.2 multi 3.99 import weight 0.00
Epoch 452 Iter 6 subLoss 49808.4 multi -1.99 import weight 0.00
Epoch 452 Iter 7 subLoss 49739.6 multi -4.97 import weight 0.00
Epoch 452 Iter 8 subLoss 50087.6 multi 1.00 import weight 0.00
Epoch 452 Iter 9 subLoss 49608.1 multi -10.94 import weight 0.00
Epoch 452 Iter 10 subLoss 50329.9 multi 9.96 import weight 0.00
Epoch 452 Iter 11 subLoss 49929.5 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 452 Acc: 19.07 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4992 train Loss: 50804.5 test Loss: 8537.9
Epoch 453 Iter 0 subLoss 50127.9 multi -10.94 import weight 0.00
Epoch 453 Iter 1 subLoss 50321.4 multi 12.94 import weight 0.00
Epoch 453 Iter 2 subLoss 49969.8 multi -7.96 import weight 0.00
Epoch 453 Iter 3 subLoss 49728.7 multi 1.00 import weight 0.00
Epoch 453 Iter 4 subLoss 50054.7 multi 9.96 import weight 0.00
Epoch 453 Iter 5 subLoss 49616.8 multi 18.91 import weight 0.00
Epoch 453 Iter 6 subLoss 49093.9 multi -7.96 import weight 0.00
Epoch 453 Iter 7 subLoss 49048.6 multi -22.88 import weight 0.00
Epoch 453 Iter 8 subLoss 49351.8 multi -10.94 import weight 0.00
Epoch 453 Iter 9 subLoss 49926.1 multi 3.98 import weight 0.00
Epoch 453 Iter 10 subLoss 49988.7 multi -31.84 import weight 0.00
Epoch 453 Iter 11 subLoss 51804.1 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 453 Acc: 19.07 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 5180 train Loss: 52610.6 test Loss: 8844.2
Epoch 454 Iter 0 subLoss 51488.6 multi 1.00 import weight 0.00
Epoch 454 Iter 1 subLoss 51346.4 multi 3.99 import weight 0.00
Epoch 454 Iter 2 subLoss 51257.9 multi -7.96 import weight 0.00
Epoch 454 Iter 3 subLoss 51603.4 multi 1.00 import weight 0.00
Epoch 454 Iter 4 subLoss 51741.1 multi 1.00 import weight 0.00
Epoch 454 Iter 5 subLoss 52020.9 multi 1.00 import weight 0.00
Epoch 454 Iter 6 subLoss 52131.3 multi 1.00 import weight 0.00
Epoch 454 Iter 7 subLoss 51666.8 multi 1.00 import weight 0.00
Epoch 454 Iter 8 subLoss 51314.6 multi -1.99 import weight 0.00
Epoch 454 Iter 9 subLoss 51558.9 multi 1.00 import weight 0.00
Epoch 454 Iter 10 subLoss 51165.6 multi 3.99 import weight 0.00
Epoch 454 Iter 11 subLoss 50618.4 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 454 Acc: 19.07 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 5061 train Loss: 52289.9 test Loss: 8789.5
Epoch 455 Iter 0 subLoss 51214.0 multi 1.00 import weight 0.00
Epoch 455 Iter 1 subLoss 51597.4 multi 1.00 import weight 0.00
Epoch 455 Iter 2 subLoss 51409.3 multi -1.99 import weight 0.00
Epoch 455 Iter 3 subLoss 50979.1 multi 9.96 import weight 0.00
Epoch 455 Iter 4 subLoss 50328.7 multi 15.93 import weight 0.00
Epoch 455 Iter 5 subLoss 50112.8 multi 1.00 import weight 0.00
Epoch 455 Iter 6 subLoss 49942.4 multi 1.00 import weight 0.00
Epoch 455 Iter 7 subLoss 49734.3 multi -4.97 import weight 0.00
Epoch 455 Iter 8 subLoss 49794.6 multi -7.96 import weight 0.00
Epoch 455 Iter 9 subLoss 49879.2 multi 6.97 import weight 0.00
Epoch 455 Iter 10 subLoss 49765.5 multi 9.96 import weight 0.00
Epoch 455 Iter 11 subLoss 49431.3 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 455 Acc: 19.07 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 4943 train Loss: 50568.1 test Loss: 8496.1
Epoch 456 Iter 0 subLoss 49234.5 multi 6.97 import weight 0.00
Epoch 456 Iter 1 subLoss 49520.1 multi -28.85 import weight 0.00
Epoch 456 Iter 2 subLoss 50660.3 multi 1.00 import weight 0.00
Epoch 456 Iter 3 subLoss 50059.4 multi 12.94 import weight 0.00
Epoch 456 Iter 4 subLoss 49925.5 multi 6.97 import weight 0.00
Epoch 456 Iter 5 subLoss 49688.5 multi 18.91 import weight 0.00
Epoch 456 Iter 6 subLoss 49036.5 multi 18.91 import weight 0.00
Epoch 456 Iter 7 subLoss 48653.9 multi -13.93 import weight 0.00
Epoch 456 Iter 8 subLoss 48901.0 multi 36.82 import weight 0.00
Epoch 456 Iter 9 subLoss 48282.0 multi 6.97 import weight 0.00
Epoch 456 Iter 10 subLoss 48328.2 multi 15.93 import weight 0.00
Epoch 456 Iter 11 subLoss 48322.0 multi 18.91 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 456 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 18.91 Pidx 4832 train Loss: 49255.4 test Loss: 8273.5
Epoch 457 Iter 0 subLoss 48222.7 multi -31.84 import weight 0.00
Epoch 457 Iter 1 subLoss 48347.3 multi -4.97 import weight 0.00
Epoch 457 Iter 2 subLoss 48268.9 multi 21.90 import weight 1.00
Epoch 457 Iter 3 subLoss 48293.2 multi 21.90 import weight 0.00
Epoch 457 Iter 4 subLoss 48242.7 multi 30.85 import weight 0.00
Epoch 457 Iter 5 subLoss 48344.9 multi -1.98 import weight 0.00
Epoch 457 Iter 6 subLoss 48288.8 multi 9.96 import weight 0.00
Epoch 457 Iter 7 subLoss 48269.6 multi 24.88 import weight 1.00
Epoch 457 Iter 8 subLoss 48288.8 multi 12.94 import weight 0.00
Epoch 457 Iter 9 subLoss 48259.6 multi 48.76 import weight 0.00
Epoch 457 Iter 10 subLoss 48240.4 multi 33.84 import weight 0.00
Epoch 457 Iter 11 subLoss 48226.5 multi -28.85 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 457 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -28.85 Pidx 4822 train Loss: 49208.8 test Loss: 8264.0
Epoch 458 Iter 0 subLoss 48257.0 multi 48.76 import weight 0.00
Epoch 458 Iter 1 subLoss 48259.1 multi 51.75 import weight 0.00
Epoch 458 Iter 2 subLoss 48183.2 multi 18.91 import weight 0.00
Epoch 458 Iter 3 subLoss 48249.8 multi 36.82 import weight 0.00
Epoch 458 Iter 4 subLoss 48180.1 multi 21.90 import weight 0.00
Epoch 458 Iter 5 subLoss 48230.3 multi 12.94 import weight 0.00
Epoch 458 Iter 6 subLoss 48263.0 multi 18.91 import weight 1.00
Epoch 458 Iter 7 subLoss 48272.3 multi -55.72 import weight 0.00
Epoch 458 Iter 8 subLoss 48217.9 multi 99.51 import weight 0.00
Epoch 458 Iter 9 subLoss 48413.2 multi 36.82 import weight 0.00
Epoch 458 Iter 10 subLoss 48317.1 multi -25.87 import weight 0.00
Epoch 458 Iter 11 subLoss 48293.2 multi 18.91 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 458 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 18.91 Pidx 4829 train Loss: 49217.8 test Loss: 8266.5
Epoch 459 Iter 0 subLoss 48297.5 multi 21.90 import weight 0.00
Epoch 459 Iter 1 subLoss 48258.7 multi 51.75 import weight 0.00
Epoch 459 Iter 2 subLoss 48261.2 multi 18.91 import weight 1.00
Epoch 459 Iter 3 subLoss 48274.3 multi -55.72 import weight 0.00
Epoch 459 Iter 4 subLoss 48281.6 multi 9.96 import weight 0.00
Epoch 459 Iter 5 subLoss 48282.6 multi 12.94 import weight 0.00
Epoch 459 Iter 6 subLoss 48262.1 multi 21.90 import weight 1.00
Epoch 459 Iter 7 subLoss 48273.2 multi -55.72 import weight 0.00
Epoch 459 Iter 8 subLoss 48269.6 multi 24.88 import weight 1.00
Epoch 459 Iter 9 subLoss 48286.6 multi 12.94 import weight 0.00
Epoch 459 Iter 10 subLoss 48211.4 multi 102.49 import weight 0.00
Epoch 459 Iter 11 subLoss 48071.9 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 459 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 4807 train Loss: 49238.8 test Loss: 8271.7
Epoch 460 Iter 0 subLoss 48372.2 multi 6.97 import weight 0.00
Epoch 460 Iter 1 subLoss 48221.3 multi -31.84 import weight 0.00
Epoch 460 Iter 2 subLoss 48260.5 multi 27.87 import weight 1.00
Epoch 460 Iter 3 subLoss 48296.1 multi 15.93 import weight 0.00
Epoch 460 Iter 4 subLoss 48208.6 multi 3.98 import weight 0.00
Epoch 460 Iter 5 subLoss 48280.8 multi 15.93 import weight 0.00
Epoch 460 Iter 6 subLoss 48214.6 multi 102.49 import weight 0.00
Epoch 460 Iter 7 subLoss 48230.3 multi 12.94 import weight 0.00
Epoch 460 Iter 8 subLoss 48270.7 multi -58.70 import weight 0.00
Epoch 460 Iter 9 subLoss 48328.9 multi 18.91 import weight 0.00
Epoch 460 Iter 10 subLoss 48295.4 multi 15.93 import weight 0.00
Epoch 460 Iter 11 subLoss 48242.3 multi 33.84 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 460 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 33.84 Pidx 4824 train Loss: 49219.7 test Loss: 8267.5
Epoch 461 Iter 0 subLoss 48230.6 multi 15.93 import weight 0.00
Epoch 461 Iter 1 subLoss 48289.8 multi 15.93 import weight 0.00
Epoch 461 Iter 2 subLoss 48264.4 multi 30.85 import weight 1.00
Epoch 461 Iter 3 subLoss 48277.7 multi -58.70 import weight 0.00
Epoch 461 Iter 4 subLoss 48258.1 multi 51.75 import weight 0.00
Epoch 461 Iter 5 subLoss 48238.2 multi 18.91 import weight 0.00
Epoch 461 Iter 6 subLoss 48181.7 multi 24.88 import weight 0.00
Epoch 461 Iter 7 subLoss 48234.7 multi 21.90 import weight 0.00
Epoch 461 Iter 8 subLoss 48265.2 multi 30.85 import weight 1.00
Epoch 461 Iter 9 subLoss 48240.0 multi 24.88 import weight 0.00
Epoch 461 Iter 10 subLoss 48285.9 multi 15.93 import weight 0.00
Epoch 461 Iter 11 subLoss 48240.6 multi 24.88 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 461 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 24.88 Pidx 4824 train Loss: 49201.2 test Loss: 8263.5
Epoch 462 Iter 0 subLoss 48257.1 multi 51.75 import weight 0.00
Epoch 462 Iter 1 subLoss 48302.2 multi -73.63 import weight 0.00
Epoch 462 Iter 2 subLoss 48238.2 multi 27.87 import weight 0.00
Epoch 462 Iter 3 subLoss 48240.8 multi 24.88 import weight 0.00
Epoch 462 Iter 4 subLoss 48186.4 multi 27.87 import weight 0.00
Epoch 462 Iter 5 subLoss 48275.4 multi -58.70 import weight 0.00
Epoch 462 Iter 6 subLoss 48404.0 multi -28.85 import weight 0.00
Epoch 462 Iter 7 subLoss 48493.7 multi -10.94 import weight 0.00
Epoch 462 Iter 8 subLoss 48596.9 multi -22.88 import weight 0.00
Epoch 462 Iter 9 subLoss 48618.5 multi -19.90 import weight 0.00
Epoch 462 Iter 10 subLoss 48795.7 multi 18.91 import weight 0.00
Epoch 462 Iter 11 subLoss 48733.4 multi -16.91 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 462 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -16.91 Pidx 4873 train Loss: 49790.4 test Loss: 8378.4
Epoch 463 Iter 0 subLoss 48778.6 multi 21.90 import weight 0.00
Epoch 463 Iter 1 subLoss 48876.4 multi 3.99 import weight 0.00
Epoch 463 Iter 2 subLoss 48469.7 multi 27.87 import weight 0.00
Epoch 463 Iter 3 subLoss 48403.5 multi -25.87 import weight 0.00
Epoch 463 Iter 4 subLoss 48637.9 multi -19.90 import weight 0.00
Epoch 463 Iter 5 subLoss 48697.3 multi 12.94 import weight 0.00
Epoch 463 Iter 6 subLoss 48541.6 multi 36.82 import weight 0.00
Epoch 463 Iter 7 subLoss 48335.6 multi -22.88 import weight 0.00
Epoch 463 Iter 8 subLoss 48528.2 multi -22.88 import weight 0.00
Epoch 463 Iter 9 subLoss 48576.6 multi -19.90 import weight 0.00
Epoch 463 Iter 10 subLoss 48648.5 multi 21.90 import weight 0.00
Epoch 463 Iter 11 subLoss 48457.6 multi -19.90 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 463 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -19.90 Pidx 4845 train Loss: 49662.2 test Loss: 8355.5
Epoch 464 Iter 0 subLoss 48689.3 multi -19.90 import weight 0.00
Epoch 464 Iter 1 subLoss 48901.3 multi 39.81 import weight 0.00
Epoch 464 Iter 2 subLoss 48486.9 multi 9.96 import weight 0.00
Epoch 464 Iter 3 subLoss 48492.9 multi -10.94 import weight 0.00
Epoch 464 Iter 4 subLoss 48424.6 multi -13.93 import weight 0.00
Epoch 464 Iter 5 subLoss 48455.3 multi -16.91 import weight 0.00
Epoch 464 Iter 6 subLoss 48592.2 multi -19.90 import weight 0.00
Epoch 464 Iter 7 subLoss 48992.5 multi 6.97 import weight 0.00
Epoch 464 Iter 8 subLoss 48821.7 multi 1.00 import weight 0.00
Epoch 464 Iter 9 subLoss 48578.8 multi -16.91 import weight 0.00
Epoch 464 Iter 10 subLoss 49030.1 multi 21.90 import weight 0.00
Epoch 464 Iter 11 subLoss 48383.6 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 464 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 4838 train Loss: 49570.1 test Loss: 8338.5
Epoch 465 Iter 0 subLoss 48602.3 multi 9.96 import weight 0.00
Epoch 465 Iter 1 subLoss 48547.9 multi 39.81 import weight 0.00
Epoch 465 Iter 2 subLoss 48278.5 multi -55.72 import weight 0.00
Epoch 465 Iter 3 subLoss 48416.3 multi 33.84 import weight 0.00
Epoch 465 Iter 4 subLoss 48293.5 multi 12.94 import weight 0.00
Epoch 465 Iter 5 subLoss 48374.4 multi 9.96 import weight 0.00
Epoch 465 Iter 6 subLoss 48261.3 multi 30.85 import weight 1.00
Epoch 465 Iter 7 subLoss 48233.8 multi 30.85 import weight 0.00
Epoch 465 Iter 8 subLoss 48256.1 multi 51.75 import weight 0.00
Epoch 465 Iter 9 subLoss 48250.9 multi 54.73 import weight 0.00
Epoch 465 Iter 10 subLoss 48245.9 multi 24.88 import weight 0.00
Epoch 465 Iter 11 subLoss 48300.3 multi -73.63 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 465 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -73.63 Pidx 4830 train Loss: 49230.3 test Loss: 8269.0
Epoch 466 Iter 0 subLoss 48243.5 multi 27.87 import weight 0.00
Epoch 466 Iter 1 subLoss 48243.9 multi 30.85 import weight 0.00
Epoch 466 Iter 2 subLoss 48241.5 multi 33.84 import weight 0.00
Epoch 466 Iter 3 subLoss 48293.5 multi 15.93 import weight 0.00
Epoch 466 Iter 4 subLoss 48244.5 multi 36.82 import weight 0.00
Epoch 466 Iter 5 subLoss 48236.4 multi 33.84 import weight 0.00
Epoch 466 Iter 6 subLoss 48244.8 multi 36.82 import weight 0.00
Epoch 466 Iter 7 subLoss 48284.2 multi 12.94 import weight 0.00
Epoch 466 Iter 8 subLoss 48166.4 multi 6.97 import weight 0.00
Epoch 466 Iter 9 subLoss 48272.7 multi -55.72 import weight 0.00
Epoch 466 Iter 10 subLoss 48243.7 multi 39.81 import weight 0.00
Epoch 466 Iter 11 subLoss 48321.6 multi 21.90 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 466 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 21.90 Pidx 4832 train Loss: 49204.5 test Loss: 8265.9
Epoch 467 Iter 0 subLoss 48274.8 multi -52.73 import weight 0.00
Epoch 467 Iter 1 subLoss 48241.4 multi 42.79 import weight 0.00
Epoch 467 Iter 2 subLoss 48241.7 multi 45.78 import weight 0.00
Epoch 467 Iter 3 subLoss 48318.9 multi -28.85 import weight 0.00
Epoch 467 Iter 4 subLoss 48277.9 multi -49.75 import weight 0.00
Epoch 467 Iter 5 subLoss 48283.5 multi 6.97 import weight 0.00
Epoch 467 Iter 6 subLoss 48294.4 multi 12.94 import weight 0.00
Epoch 467 Iter 7 subLoss 48311.7 multi -25.87 import weight 0.00
Epoch 467 Iter 8 subLoss 48163.5 multi 9.96 import weight 0.00
Epoch 467 Iter 9 subLoss 48307.3 multi -76.61 import weight 0.00
Epoch 467 Iter 10 subLoss 48586.0 multi 9.96 import weight 0.00
Epoch 467 Iter 11 subLoss 48396.6 multi -10.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 467 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -10.94 Pidx 4839 train Loss: 49453.8 test Loss: 8314.6
Epoch 468 Iter 0 subLoss 48549.3 multi 42.79 import weight 0.00
Epoch 468 Iter 1 subLoss 48393.6 multi -7.96 import weight 0.00
Epoch 468 Iter 2 subLoss 48265.2 multi 27.87 import weight 1.00
Epoch 468 Iter 3 subLoss 48245.6 multi 48.76 import weight 0.00
Epoch 468 Iter 4 subLoss 48228.1 multi -31.84 import weight 0.00
Epoch 468 Iter 5 subLoss 48240.0 multi 51.75 import weight 0.00
Epoch 468 Iter 6 subLoss 48262.5 multi 30.85 import weight 1.00
Epoch 468 Iter 7 subLoss 48238.1 multi 33.84 import weight 0.00
Epoch 468 Iter 8 subLoss 48229.0 multi -28.85 import weight 0.00
Epoch 468 Iter 9 subLoss 48270.9 multi -52.73 import weight 0.00
Epoch 468 Iter 10 subLoss 48189.4 multi 30.85 import weight 0.00
Epoch 468 Iter 11 subLoss 48288.4 multi 6.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 468 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 6.97 Pidx 4828 train Loss: 49246.5 test Loss: 8268.0
Epoch 469 Iter 0 subLoss 48295.0 multi 12.94 import weight 0.00
Epoch 469 Iter 1 subLoss 48264.9 multi 33.84 import weight 1.00
Epoch 469 Iter 2 subLoss 48261.5 multi 36.82 import weight 1.00
Epoch 469 Iter 3 subLoss 48269.0 multi 39.81 import weight 1.00
Epoch 469 Iter 4 subLoss 48258.7 multi 24.88 import weight 0.00
Epoch 469 Iter 5 subLoss 48223.2 multi -25.87 import weight 0.00
Epoch 469 Iter 6 subLoss 48249.1 multi 51.75 import weight 0.00
Epoch 469 Iter 7 subLoss 48226.2 multi -22.88 import weight 0.00
Epoch 469 Iter 8 subLoss 48283.9 multi 9.96 import weight 0.00
Epoch 469 Iter 9 subLoss 48274.8 multi -58.70 import weight 0.00
Epoch 469 Iter 10 subLoss 48243.1 multi 54.73 import weight 0.00
Epoch 469 Iter 11 subLoss 48293.9 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 469 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 4829 train Loss: 49216.5 test Loss: 8264.9
Epoch 470 Iter 0 subLoss 48276.1 multi -55.72 import weight 0.00
Epoch 470 Iter 1 subLoss 48243.4 multi 57.72 import weight 0.00
Epoch 470 Iter 2 subLoss 48267.7 multi 39.81 import weight 1.00
Epoch 470 Iter 3 subLoss 48324.5 multi 18.91 import weight 0.00
Epoch 470 Iter 4 subLoss 48220.6 multi -19.90 import weight 0.00
Epoch 470 Iter 5 subLoss 48240.2 multi 60.70 import weight 0.00
Epoch 470 Iter 6 subLoss 48232.3 multi 24.88 import weight 0.00
Epoch 470 Iter 7 subLoss 48197.0 multi 36.82 import weight 0.00
Epoch 470 Iter 8 subLoss 48269.8 multi 42.79 import weight 1.00
Epoch 470 Iter 9 subLoss 48297.8 multi 15.93 import weight 0.00
Epoch 470 Iter 10 subLoss 48243.9 multi 60.70 import weight 0.00
Epoch 470 Iter 11 subLoss 48252.1 multi 12.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 470 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 12.94 Pidx 4825 train Loss: 49206.3 test Loss: 8266.1
Epoch 471 Iter 0 subLoss 48237.0 multi 27.87 import weight 0.00
Epoch 471 Iter 1 subLoss 48214.2 multi 105.48 import weight 0.00
Epoch 471 Iter 2 subLoss 48362.4 multi -25.87 import weight 0.00
Epoch 471 Iter 3 subLoss 48270.4 multi -58.70 import weight 0.00
Epoch 471 Iter 4 subLoss 48499.4 multi -7.96 import weight 0.00
Epoch 471 Iter 5 subLoss 48577.5 multi -13.93 import weight 0.00
Epoch 471 Iter 6 subLoss 48762.8 multi -10.94 import weight 0.00
Epoch 471 Iter 7 subLoss 48798.8 multi 21.90 import weight 0.00
Epoch 471 Iter 8 subLoss 48499.4 multi -4.97 import weight 0.00
Epoch 471 Iter 9 subLoss 48460.3 multi 24.88 import weight 0.00
Epoch 471 Iter 10 subLoss 48245.0 multi 60.70 import weight 0.00
Epoch 471 Iter 11 subLoss 48307.2 multi -82.58 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 471 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -82.58 Pidx 4830 train Loss: 49389.3 test Loss: 8299.7
Epoch 472 Iter 0 subLoss 48590.5 multi -19.90 import weight 0.00
Epoch 472 Iter 1 subLoss 48686.8 multi -16.91 import weight 0.00
Epoch 472 Iter 2 subLoss 48889.5 multi 21.90 import weight 0.00
Epoch 472 Iter 3 subLoss 48403.8 multi -28.85 import weight 0.00
Epoch 472 Iter 4 subLoss 48715.9 multi 6.97 import weight 0.00
Epoch 472 Iter 5 subLoss 48298.4 multi 18.91 import weight 0.00
Epoch 472 Iter 6 subLoss 48652.5 multi -13.93 import weight 0.00
Epoch 472 Iter 7 subLoss 48748.5 multi 3.99 import weight 0.00
Epoch 472 Iter 8 subLoss 48580.8 multi 9.96 import weight 0.00
Epoch 472 Iter 9 subLoss 48409.5 multi -25.87 import weight 0.00
Epoch 472 Iter 10 subLoss 48600.2 multi 9.96 import weight 0.00
Epoch 472 Iter 11 subLoss 48290.1 multi 21.90 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 472 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 21.90 Pidx 4829 train Loss: 49412.3 test Loss: 8303.2
Epoch 473 Iter 0 subLoss 48466.5 multi 27.87 import weight 0.00
Epoch 473 Iter 1 subLoss 48367.0 multi -22.88 import weight 0.00
Epoch 473 Iter 2 subLoss 48507.4 multi -13.93 import weight 0.00
Epoch 473 Iter 3 subLoss 48387.6 multi -4.97 import weight 0.00
Epoch 473 Iter 4 subLoss 48523.6 multi -19.90 import weight 0.00
Epoch 473 Iter 5 subLoss 48645.1 multi 24.88 import weight 0.00
Epoch 473 Iter 6 subLoss 48409.9 multi -22.88 import weight 0.00
Epoch 473 Iter 7 subLoss 48553.8 multi -40.79 import weight 0.00
Epoch 473 Iter 8 subLoss 48903.3 multi 42.79 import weight 0.00
Epoch 473 Iter 9 subLoss 48478.6 multi -40.79 import weight 0.00
Epoch 473 Iter 10 subLoss 48529.6 multi -16.91 import weight 0.00
Epoch 473 Iter 11 subLoss 48654.9 multi -13.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 473 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -13.93 Pidx 4865 train Loss: 50006.0 test Loss: 8401.3
Epoch 474 Iter 0 subLoss 49349.7 multi 24.88 import weight 0.00
Epoch 474 Iter 1 subLoss 48707.7 multi -31.84 import weight 0.00
Epoch 474 Iter 2 subLoss 48778.7 multi 21.90 import weight 0.00
Epoch 474 Iter 3 subLoss 48732.7 multi -13.93 import weight 0.00
Epoch 474 Iter 4 subLoss 48693.3 multi 9.96 import weight 0.00
Epoch 474 Iter 5 subLoss 48610.5 multi -22.88 import weight 0.00
Epoch 474 Iter 6 subLoss 48826.4 multi 3.99 import weight 0.00
Epoch 474 Iter 7 subLoss 48811.6 multi -13.93 import weight 0.00
Epoch 474 Iter 8 subLoss 48843.8 multi 6.97 import weight 0.00
Epoch 474 Iter 9 subLoss 48929.6 multi 30.85 import weight 0.00
Epoch 474 Iter 10 subLoss 48580.0 multi -10.94 import weight 0.00
Epoch 474 Iter 11 subLoss 48461.4 multi 30.85 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 474 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 30.85 Pidx 4846 train Loss: 49358.8 test Loss: 8291.3
Epoch 475 Iter 0 subLoss 48526.8 multi -13.93 import weight 0.00
Epoch 475 Iter 1 subLoss 48617.6 multi -19.90 import weight 0.00
Epoch 475 Iter 2 subLoss 48635.8 multi -16.91 import weight 0.00
Epoch 475 Iter 3 subLoss 48512.5 multi 6.97 import weight 0.00
Epoch 475 Iter 4 subLoss 48783.3 multi -34.82 import weight 0.00
Epoch 475 Iter 5 subLoss 49364.0 multi 6.97 import weight 0.00
Epoch 475 Iter 6 subLoss 49138.0 multi 27.87 import weight 0.00
Epoch 475 Iter 7 subLoss 48750.1 multi -1.98 import weight 0.00
Epoch 475 Iter 8 subLoss 48559.0 multi -37.81 import weight 0.00
Epoch 475 Iter 9 subLoss 48903.1 multi 45.78 import weight 0.00
Epoch 475 Iter 10 subLoss 48279.0 multi -55.72 import weight 0.00
Epoch 475 Iter 11 subLoss 48806.9 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 475 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 4880 train Loss: 4823262.8 test Loss: 8360.5
Epoch 476 Iter 0 subLoss 48673.3 multi 1.00 import weight 0.00
Epoch 476 Iter 1 subLoss 48631.7 multi -13.93 import weight 0.00
Epoch 476 Iter 2 subLoss 48815.2 multi -13.93 import weight 0.00
Epoch 476 Iter 3 subLoss 49220.4 multi 18.91 import weight 0.00
Epoch 476 Iter 4 subLoss 48810.1 multi -10.94 import weight 0.00
Epoch 476 Iter 5 subLoss 49136.6 multi 30.85 import weight 0.00
Epoch 476 Iter 6 subLoss 48552.9 multi -34.82 import weight 0.00
Epoch 476 Iter 7 subLoss 48793.3 multi 21.90 import weight 0.00
Epoch 476 Iter 8 subLoss 48399.5 multi -7.96 import weight 0.00
Epoch 476 Iter 9 subLoss 48741.7 multi 3.98 import weight 0.00
Epoch 476 Iter 10 subLoss 48432.3 multi -4.97 import weight 0.00
Epoch 476 Iter 11 subLoss 48508.8 multi -10.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 476 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -10.94 Pidx 4850 train Loss: 49600.3 test Loss: 8338.6
Epoch 477 Iter 0 subLoss 48758.5 multi -1.99 import weight 0.00
Epoch 477 Iter 1 subLoss 48491.1 multi -1.98 import weight 0.00
Epoch 477 Iter 2 subLoss 48511.5 multi 6.97 import weight 0.00
Epoch 477 Iter 3 subLoss 48577.8 multi -7.96 import weight 0.00
Epoch 477 Iter 4 subLoss 48961.0 multi -19.90 import weight 0.00
Epoch 477 Iter 5 subLoss 48815.5 multi -7.96 import weight 0.00
Epoch 477 Iter 6 subLoss 49325.7 multi 12.94 import weight 0.00
Epoch 477 Iter 7 subLoss 48519.4 multi 9.96 import weight 0.00
Epoch 477 Iter 8 subLoss 48610.2 multi -16.91 import weight 0.00
Epoch 477 Iter 9 subLoss 48987.7 multi 6.97 import weight 0.00
Epoch 477 Iter 10 subLoss 48944.0 multi 18.91 import weight 0.00
Epoch 477 Iter 11 subLoss 48768.9 multi -13.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 477 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -13.93 Pidx 4876 train Loss: 49688.6 test Loss: 8354.8
Epoch 478 Iter 0 subLoss 48699.7 multi 12.94 import weight 0.00
Epoch 478 Iter 1 subLoss 48518.2 multi 12.94 import weight 0.00
Epoch 478 Iter 2 subLoss 48431.3 multi -1.99 import weight 0.00
Epoch 478 Iter 3 subLoss 48493.5 multi 1.00 import weight 0.00
Epoch 478 Iter 4 subLoss 48592.4 multi -19.90 import weight 0.00
Epoch 478 Iter 5 subLoss 48731.7 multi -10.94 import weight 0.00
Epoch 478 Iter 6 subLoss 48724.3 multi 27.87 import weight 0.00
Epoch 478 Iter 7 subLoss 48549.0 multi 45.78 import weight 0.00
Epoch 478 Iter 8 subLoss 48212.5 multi 108.46 import weight 0.00
Epoch 478 Iter 9 subLoss 48306.0 multi -85.57 import weight 0.00
Epoch 478 Iter 10 subLoss 48531.6 multi 15.93 import weight 0.00
Epoch 478 Iter 11 subLoss 48340.0 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 478 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 4834 train Loss: 49293.4 test Loss: 8277.7
Epoch 479 Iter 0 subLoss 48349.6 multi 1.00 import weight 0.00
Epoch 479 Iter 1 subLoss 48350.6 multi 1.00 import weight 0.00
Epoch 479 Iter 2 subLoss 48398.9 multi -4.97 import weight 0.00
Epoch 479 Iter 3 subLoss 48359.6 multi 3.98 import weight 0.00
Epoch 479 Iter 4 subLoss 48266.1 multi 42.79 import weight 1.00
Epoch 479 Iter 5 subLoss 48233.5 multi 30.85 import weight 0.00
Epoch 479 Iter 6 subLoss 48276.4 multi -55.72 import weight 0.00
Epoch 479 Iter 7 subLoss 48275.7 multi -52.73 import weight 0.00
Epoch 479 Iter 8 subLoss 48368.9 multi -25.87 import weight 0.00
Epoch 479 Iter 9 subLoss 48681.4 multi -16.91 import weight 0.00
Epoch 479 Iter 10 subLoss 48593.7 multi -16.91 import weight 0.00
Epoch 479 Iter 11 subLoss 48957.4 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 479 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 4895 train Loss: 49945.6 test Loss: 8390.6
Epoch 480 Iter 0 subLoss 49012.0 multi 3.99 import weight 0.00
Epoch 480 Iter 1 subLoss 48886.0 multi 24.88 import weight 0.00
Epoch 480 Iter 2 subLoss 48526.3 multi -22.88 import weight 0.00
Epoch 480 Iter 3 subLoss 48799.3 multi 24.88 import weight 0.00
Epoch 480 Iter 4 subLoss 48454.9 multi -13.93 import weight 0.00
Epoch 480 Iter 5 subLoss 48612.4 multi -13.93 import weight 0.00
Epoch 480 Iter 6 subLoss 48806.0 multi -10.94 import weight 0.00
Epoch 480 Iter 7 subLoss 48874.1 multi 6.97 import weight 0.00
Epoch 480 Iter 8 subLoss 48611.0 multi -10.94 import weight 0.00
Epoch 480 Iter 9 subLoss 48609.6 multi 6.97 import weight 0.00
Epoch 480 Iter 10 subLoss 48627.7 multi 1.00 import weight 0.00
Epoch 480 Iter 11 subLoss 48595.9 multi -13.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 480 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -13.93 Pidx 4859 train Loss: 49875.6 test Loss: 8382.3
Epoch 481 Iter 0 subLoss 48854.9 multi -31.84 import weight 0.00
Epoch 481 Iter 1 subLoss 49589.0 multi 1.00 import weight 0.00
Epoch 481 Iter 2 subLoss 49891.9 multi 1.00 import weight 0.00
Epoch 481 Iter 3 subLoss 49403.7 multi 1.00 import weight 0.00
Epoch 481 Iter 4 subLoss 49386.2 multi -4.97 import weight 0.00
Epoch 481 Iter 5 subLoss 49772.5 multi 1.00 import weight 0.00
Epoch 481 Iter 6 subLoss 49365.6 multi 9.96 import weight 0.00
Epoch 481 Iter 7 subLoss 49430.5 multi 1.00 import weight 0.00
Epoch 481 Iter 8 subLoss 49796.9 multi -4.97 import weight 0.00
Epoch 481 Iter 9 subLoss 49264.5 multi -1.99 import weight 0.00
Epoch 481 Iter 10 subLoss 49612.0 multi 21.90 import weight 0.00
Epoch 481 Iter 11 subLoss 48631.0 multi -13.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 481 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -13.93 Pidx 4863 train Loss: 12860232.9 test Loss: 8403.2
Epoch 482 Iter 0 subLoss 49039.7 multi 24.88 import weight 0.00
Epoch 482 Iter 1 subLoss 48435.7 multi 1.00 import weight 0.00
Epoch 482 Iter 2 subLoss 48519.0 multi 15.93 import weight 0.00
Epoch 482 Iter 3 subLoss 48353.6 multi 6.97 import weight 0.00
Epoch 482 Iter 4 subLoss 48556.4 multi -34.82 import weight 0.00
Epoch 482 Iter 5 subLoss 48532.4 multi 15.93 import weight 0.00
Epoch 482 Iter 6 subLoss 48396.1 multi -1.99 import weight 0.00
Epoch 482 Iter 7 subLoss 48695.1 multi 12.94 import weight 0.00
Epoch 482 Iter 8 subLoss 48470.6 multi -40.79 import weight 0.00
Epoch 482 Iter 9 subLoss 48744.9 multi 3.99 import weight 0.00
Epoch 482 Iter 10 subLoss 48733.2 multi -10.94 import weight 0.00
Epoch 482 Iter 11 subLoss 49004.0 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 482 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 4900 train Loss: 49880.0 test Loss: 8381.2
Epoch 483 Iter 0 subLoss 48816.0 multi -7.96 import weight 0.00
Epoch 483 Iter 1 subLoss 48834.8 multi 1.00 import weight 0.00
Epoch 483 Iter 2 subLoss 49009.5 multi -1.98 import weight 0.00
Epoch 483 Iter 3 subLoss 49132.6 multi 33.84 import weight 0.00
Epoch 483 Iter 4 subLoss 48408.8 multi -28.85 import weight 0.00
Epoch 483 Iter 5 subLoss 48557.9 multi -31.84 import weight 0.00
Epoch 483 Iter 6 subLoss 49144.0 multi -16.91 import weight 0.00
Epoch 483 Iter 7 subLoss 49416.1 multi -10.94 import weight 0.00
Epoch 483 Iter 8 subLoss 50206.8 multi 3.98 import weight 0.00
Epoch 483 Iter 9 subLoss 49819.4 multi -13.93 import weight 0.00
Epoch 483 Iter 10 subLoss 50845.2 multi -1.99 import weight 0.00
Epoch 483 Iter 11 subLoss 50171.6 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 483 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 5017 train Loss: 51609.9 test Loss: 8675.4
Epoch 484 Iter 0 subLoss 50942.8 multi 3.99 import weight 0.00
Epoch 484 Iter 1 subLoss 50245.3 multi 12.94 import weight 0.00
Epoch 484 Iter 2 subLoss 49762.6 multi 12.94 import weight 0.00
Epoch 484 Iter 3 subLoss 49262.0 multi 1.00 import weight 0.00
Epoch 484 Iter 4 subLoss 48946.3 multi 21.90 import weight 0.00
Epoch 484 Iter 5 subLoss 48692.6 multi 15.93 import weight 0.00
Epoch 484 Iter 6 subLoss 48408.3 multi -25.87 import weight 0.00
Epoch 484 Iter 7 subLoss 48753.9 multi -1.99 import weight 0.00
Epoch 484 Iter 8 subLoss 48744.0 multi 3.99 import weight 0.00
Epoch 484 Iter 9 subLoss 48738.8 multi -7.96 import weight 0.00
Epoch 484 Iter 10 subLoss 48673.0 multi 3.99 import weight 0.00
Epoch 484 Iter 11 subLoss 48833.7 multi 3.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 484 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 3.99 Pidx 4883 train Loss: 49673.7 test Loss: 8347.0
Epoch 485 Iter 0 subLoss 48829.5 multi -7.96 import weight 0.00
Epoch 485 Iter 1 subLoss 48601.1 multi 6.97 import weight 0.00
Epoch 485 Iter 2 subLoss 48681.5 multi -16.91 import weight 0.00
Epoch 485 Iter 3 subLoss 48945.8 multi 24.88 import weight 0.00
Epoch 485 Iter 4 subLoss 48584.6 multi 6.97 import weight 0.00
Epoch 485 Iter 5 subLoss 48619.4 multi -13.93 import weight 0.00
Epoch 485 Iter 6 subLoss 48473.4 multi -37.81 import weight 0.00
Epoch 485 Iter 7 subLoss 49115.9 multi -13.93 import weight 0.00
Epoch 485 Iter 8 subLoss 49406.7 multi 3.98 import weight 0.00
Epoch 485 Iter 9 subLoss 49289.7 multi 6.97 import weight 0.00
Epoch 485 Iter 10 subLoss 49053.8 multi 12.94 import weight 0.00
Epoch 485 Iter 11 subLoss 48898.7 multi -28.85 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 485 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -28.85 Pidx 4889 train Loss: 50372.8 test Loss: 8467.2
Epoch 486 Iter 0 subLoss 49279.8 multi -13.93 import weight 0.00
Epoch 486 Iter 1 subLoss 49715.4 multi 6.97 import weight 0.00
Epoch 486 Iter 2 subLoss 49505.4 multi -16.91 import weight 0.00
Epoch 486 Iter 3 subLoss 49874.5 multi 9.96 import weight 0.00
Epoch 486 Iter 4 subLoss 49788.7 multi -4.97 import weight 0.00
Epoch 486 Iter 5 subLoss 49949.8 multi 3.99 import weight 0.00
Epoch 486 Iter 6 subLoss 49671.9 multi -7.96 import weight 0.00
Epoch 486 Iter 7 subLoss 50223.2 multi -4.97 import weight 0.00
Epoch 486 Iter 8 subLoss 50676.8 multi -1.99 import weight 0.00
Epoch 486 Iter 9 subLoss 51201.1 multi -7.96 import weight 0.00
Epoch 486 Iter 10 subLoss 50941.1 multi 6.97 import weight 0.00
Epoch 486 Iter 11 subLoss 50683.5 multi -4.97 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 486 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -4.97 Pidx 5068 train Loss: 51995.4 test Loss: 8742.4
Epoch 487 Iter 0 subLoss 51358.3 multi -1.98 import weight 0.00
Epoch 487 Iter 1 subLoss 51015.9 multi 3.98 import weight 0.00
Epoch 487 Iter 2 subLoss 51025.5 multi -4.97 import weight 0.00
Epoch 487 Iter 3 subLoss 51139.9 multi -1.99 import weight 0.00
Epoch 487 Iter 4 subLoss 51394.6 multi 3.99 import weight 0.00
Epoch 487 Iter 5 subLoss 51012.9 multi 6.97 import weight 0.00
Epoch 487 Iter 6 subLoss 50761.2 multi 1.00 import weight 0.00
Epoch 487 Iter 7 subLoss 50249.3 multi 15.93 import weight 0.00
Epoch 487 Iter 8 subLoss 49730.5 multi -1.99 import weight 0.00
Epoch 487 Iter 9 subLoss 49728.6 multi 1.00 import weight 0.00
Epoch 487 Iter 10 subLoss 49621.7 multi -7.96 import weight 0.00
Epoch 487 Iter 11 subLoss 49448.8 multi -19.90 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 487 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -19.90 Pidx 4944 train Loss: 51907.3 test Loss: 8726.9
Epoch 488 Iter 0 subLoss 50508.3 multi -7.96 import weight 0.00
Epoch 488 Iter 1 subLoss 51084.4 multi 6.97 import weight 0.00
Epoch 488 Iter 2 subLoss 50962.2 multi -10.94 import weight 0.00
Epoch 488 Iter 3 subLoss 51944.6 multi 1.00 import weight 0.00
Epoch 488 Iter 4 subLoss 51994.6 multi 1.00 import weight 0.00
Epoch 488 Iter 5 subLoss 51801.2 multi 3.99 import weight 0.00
Epoch 488 Iter 6 subLoss 51632.9 multi 1.00 import weight 0.00
Epoch 488 Iter 7 subLoss 50994.2 multi -1.99 import weight 0.00
Epoch 488 Iter 8 subLoss 51521.1 multi 3.99 import weight 0.00
Epoch 488 Iter 9 subLoss 50853.4 multi 9.96 import weight 0.00
Epoch 488 Iter 10 subLoss 50011.4 multi -16.91 import weight 0.00
Epoch 488 Iter 11 subLoss 51150.5 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 488 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 5115 train Loss: 52976.0 test Loss: 8907.8
Epoch 489 Iter 0 subLoss 52076.4 multi 1.00 import weight 0.00
Epoch 489 Iter 1 subLoss 52258.4 multi 1.00 import weight 0.00
Epoch 489 Iter 2 subLoss 52049.7 multi 1.00 import weight 0.00
Epoch 489 Iter 3 subLoss 51405.7 multi -1.98 import weight 0.00
Epoch 489 Iter 4 subLoss 51622.5 multi -1.99 import weight 0.00
Epoch 489 Iter 5 subLoss 51378.4 multi 3.99 import weight 0.00
Epoch 489 Iter 6 subLoss 51517.0 multi 1.00 import weight 0.00
Epoch 489 Iter 7 subLoss 51623.0 multi 1.00 import weight 0.00
Epoch 489 Iter 8 subLoss 51508.0 multi 1.00 import weight 0.00
Epoch 489 Iter 9 subLoss 50897.5 multi -4.97 import weight 0.00
Epoch 489 Iter 10 subLoss 52307.6 multi 1.00 import weight 0.00
Epoch 489 Iter 11 subLoss 51727.9 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 489 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 5172 train Loss: 52598.4 test Loss: 8843.8
Epoch 490 Iter 0 subLoss 51938.5 multi 1.00 import weight 0.00
Epoch 490 Iter 1 subLoss 52221.1 multi 1.00 import weight 0.00
Epoch 490 Iter 2 subLoss 51221.4 multi -1.99 import weight 0.00
Epoch 490 Iter 3 subLoss 51894.0 multi 1.00 import weight 0.00
Epoch 490 Iter 4 subLoss 50869.2 multi -10.94 import weight 0.00
Epoch 490 Iter 5 subLoss 51862.0 multi 1.00 import weight 0.00
Epoch 490 Iter 6 subLoss 52730.2 multi 1.00 import weight 0.00
Epoch 490 Iter 7 subLoss 52271.7 multi 1.00 import weight 0.00
Epoch 490 Iter 8 subLoss 51971.8 multi 1.00 import weight 0.00
Epoch 490 Iter 9 subLoss 51824.0 multi 3.99 import weight 0.00
Epoch 490 Iter 10 subLoss 51469.4 multi 1.00 import weight 0.00
Epoch 490 Iter 11 subLoss 51310.6 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 490 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 5131 train Loss: 52413.8 test Loss: 8812.5
Epoch 491 Iter 0 subLoss 51659.1 multi 1.00 import weight 0.00
Epoch 491 Iter 1 subLoss 51038.3 multi 3.99 import weight 0.00
Epoch 491 Iter 2 subLoss 50708.8 multi 12.94 import weight 0.00
Epoch 491 Iter 3 subLoss 49678.3 multi -4.97 import weight 0.00
Epoch 491 Iter 4 subLoss 50349.8 multi 6.97 import weight 0.00
Epoch 491 Iter 5 subLoss 49989.0 multi -28.85 import weight 0.00
Epoch 491 Iter 6 subLoss 51749.7 multi 3.99 import weight 0.00
Epoch 491 Iter 7 subLoss 51055.0 multi 3.98 import weight 0.00
Epoch 491 Iter 8 subLoss 51167.3 multi 3.98 import weight 0.00
Epoch 491 Iter 9 subLoss 51008.0 multi 1.00 import weight 0.00
Epoch 491 Iter 10 subLoss 50317.9 multi 3.99 import weight 0.00
Epoch 491 Iter 11 subLoss 50617.1 multi 1.00 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 491 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 1.00 Pidx 5061 train Loss: 51248.9 test Loss: 8616.5
Epoch 492 Iter 0 subLoss 50166.3 multi 9.96 import weight 0.00
Epoch 492 Iter 1 subLoss 49408.2 multi 6.97 import weight 0.00
Epoch 492 Iter 2 subLoss 49813.0 multi -10.94 import weight 0.00
Epoch 492 Iter 3 subLoss 49664.1 multi -13.93 import weight 0.00
Epoch 492 Iter 4 subLoss 50748.3 multi 6.97 import weight 0.00
Epoch 492 Iter 5 subLoss 50192.7 multi -1.98 import weight 0.00
Epoch 492 Iter 6 subLoss 50315.6 multi 6.97 import weight 0.00
Epoch 492 Iter 7 subLoss 50053.8 multi 15.93 import weight 0.00
Epoch 492 Iter 8 subLoss 49220.7 multi 21.90 import weight 0.00
Epoch 492 Iter 9 subLoss 48760.8 multi -13.93 import weight 0.00
Epoch 492 Iter 10 subLoss 49072.4 multi -10.94 import weight 0.00
Epoch 492 Iter 11 subLoss 49240.3 multi -10.94 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 492 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -10.94 Pidx 4924 train Loss: 50498.1 test Loss: 8490.0
Epoch 493 Iter 0 subLoss 49304.1 multi 24.88 import weight 0.00
Epoch 493 Iter 1 subLoss 49032.9 multi 27.87 import weight 0.00
Epoch 493 Iter 2 subLoss 48407.4 multi -22.88 import weight 0.00
Epoch 493 Iter 3 subLoss 48688.7 multi -13.93 import weight 0.00
Epoch 493 Iter 4 subLoss 48857.3 multi -28.85 import weight 0.00
Epoch 493 Iter 5 subLoss 49461.3 multi 6.97 import weight 0.00
Epoch 493 Iter 6 subLoss 48944.8 multi 27.87 import weight 0.00
Epoch 493 Iter 7 subLoss 48681.8 multi -10.94 import weight 0.00
Epoch 493 Iter 8 subLoss 48887.5 multi 24.88 import weight 0.00
Epoch 493 Iter 9 subLoss 48429.6 multi -13.93 import weight 0.00
Epoch 493 Iter 10 subLoss 48530.8 multi 18.91 import weight 0.00
Epoch 493 Iter 11 subLoss 48277.3 multi -49.75 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 493 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -49.75 Pidx 4827 train Loss: 49601.1 test Loss: 8338.8
Epoch 494 Iter 0 subLoss 48626.1 multi 1.00 import weight 0.00
Epoch 494 Iter 1 subLoss 48485.4 multi 3.98 import weight 0.00
Epoch 494 Iter 2 subLoss 48648.4 multi 18.91 import weight 0.00
Epoch 494 Iter 3 subLoss 48390.0 multi -1.98 import weight 0.00
Epoch 494 Iter 4 subLoss 48523.9 multi -22.88 import weight 0.00
Epoch 494 Iter 5 subLoss 48563.8 multi -13.93 import weight 0.00
Epoch 494 Iter 6 subLoss 48825.8 multi -4.97 import weight 0.00
Epoch 494 Iter 7 subLoss 48704.7 multi -40.79 import weight 0.00
Epoch 494 Iter 8 subLoss 49557.9 multi -4.97 import weight 0.00
Epoch 494 Iter 9 subLoss 49294.5 multi -4.97 import weight 0.00
Epoch 494 Iter 10 subLoss 50082.9 multi 3.99 import weight 0.00
Epoch 494 Iter 11 subLoss 49654.2 multi 15.93 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 494 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 15.93 Pidx 4965 train Loss: 50090.7 test Loss: 8425.0
Epoch 495 Iter 0 subLoss 48969.7 multi -19.90 import weight 0.00
Epoch 495 Iter 1 subLoss 49324.6 multi 15.93 import weight 0.00
Epoch 495 Iter 2 subLoss 49154.4 multi 1.00 import weight 0.00
Epoch 495 Iter 3 subLoss 49060.5 multi -7.96 import weight 0.00
Epoch 495 Iter 4 subLoss 49348.8 multi 27.87 import weight 0.00
Epoch 495 Iter 5 subLoss 48643.4 multi 21.90 import weight 0.00
Epoch 495 Iter 6 subLoss 48618.4 multi -10.94 import weight 0.00
Epoch 495 Iter 7 subLoss 48698.7 multi 9.96 import weight 0.00
Epoch 495 Iter 8 subLoss 48620.7 multi 1.00 import weight 0.00
Epoch 495 Iter 9 subLoss 48588.7 multi 9.96 import weight 0.00
Epoch 495 Iter 10 subLoss 48421.8 multi -10.94 import weight 0.00
Epoch 495 Iter 11 subLoss 48284.0 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 495 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 4828 train Loss: 49473.4 test Loss: 8316.1
Epoch 496 Iter 0 subLoss 48384.6 multi 1.00 import weight 0.00
Epoch 496 Iter 1 subLoss 48462.3 multi 30.85 import weight 0.00
Epoch 496 Iter 2 subLoss 48305.4 multi -82.58 import weight 0.00
Epoch 496 Iter 3 subLoss 48657.0 multi -16.91 import weight 0.00
Epoch 496 Iter 4 subLoss 49033.2 multi 30.85 import weight 0.00
Epoch 496 Iter 5 subLoss 48345.1 multi 3.99 import weight 0.00
Epoch 496 Iter 6 subLoss 48451.3 multi -10.94 import weight 0.00
Epoch 496 Iter 7 subLoss 48488.7 multi 6.97 import weight 0.00
Epoch 496 Iter 8 subLoss 48563.5 multi -10.94 import weight 0.00
Epoch 496 Iter 9 subLoss 48515.6 multi 18.91 import weight 0.00
Epoch 496 Iter 10 subLoss 48486.6 multi 9.96 import weight 0.00
Epoch 496 Iter 11 subLoss 48436.8 multi -1.99 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 496 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -1.99 Pidx 4843 train Loss: 49347.4 test Loss: 8291.4
Epoch 497 Iter 0 subLoss 48363.1 multi -25.87 import weight 0.00
Epoch 497 Iter 1 subLoss 48536.0 multi 18.91 import weight 0.00
Epoch 497 Iter 2 subLoss 48405.0 multi -19.90 import weight 0.00
Epoch 497 Iter 3 subLoss 48531.2 multi 21.90 import weight 0.00
Epoch 497 Iter 4 subLoss 48293.1 multi 21.90 import weight 0.00
Epoch 497 Iter 5 subLoss 48301.2 multi -82.58 import weight 0.00
Epoch 497 Iter 6 subLoss 48719.8 multi 3.98 import weight 0.00
Epoch 497 Iter 7 subLoss 48398.1 multi -4.97 import weight 0.00
Epoch 497 Iter 8 subLoss 48385.6 multi 3.99 import weight 0.00
Epoch 497 Iter 9 subLoss 48456.2 multi -7.96 import weight 0.00
Epoch 497 Iter 10 subLoss 48479.5 multi -37.81 import weight 0.00
Epoch 497 Iter 11 subLoss 48924.2 multi 33.84 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 497 Acc: 19.65 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul 33.84 Pidx 4892 train Loss: 49410.9 test Loss: 8301.8
Epoch 498 Iter 0 subLoss 48398.0 multi -4.97 import weight 0.00
Epoch 498 Iter 1 subLoss 48429.7 multi -7.96 import weight 0.00
Epoch 498 Iter 2 subLoss 48449.3 multi -22.88 import weight 0.00
Epoch 498 Iter 3 subLoss 48539.2 multi 24.88 import weight 0.00
Epoch 498 Iter 4 subLoss 48462.1 multi 27.87 import weight 0.00
Epoch 498 Iter 5 subLoss 48414.5 multi 15.93 import weight 0.00
Epoch 498 Iter 6 subLoss 48240.2 multi 60.70 import weight 0.00
Epoch 498 Iter 7 subLoss 48238.6 multi 33.84 import weight 0.00
Epoch 498 Iter 8 subLoss 48204.5 multi 3.99 import weight 0.00
Epoch 498 Iter 9 subLoss 48330.4 multi -25.87 import weight 0.00
Epoch 498 Iter 10 subLoss 48370.6 multi 1.00 import weight 0.00
Epoch 498 Iter 11 subLoss 48274.8 multi -46.76 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 498 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -46.76 Pidx 4827 train Loss: 49299.2 test Loss: 8281.5
Epoch 499 Iter 0 subLoss 48252.6 multi 9.96 import weight 0.00
Epoch 499 Iter 1 subLoss 48339.2 multi -22.88 import weight 0.00
Epoch 499 Iter 2 subLoss 48330.1 multi -19.90 import weight 0.00
Epoch 499 Iter 3 subLoss 48496.3 multi -4.97 import weight 0.00
Epoch 499 Iter 4 subLoss 48591.6 multi -16.91 import weight 0.00
Epoch 499 Iter 5 subLoss 48486.1 multi 9.96 import weight 0.00
Epoch 499 Iter 6 subLoss 48390.4 multi -1.99 import weight 0.00
Epoch 499 Iter 7 subLoss 48353.5 multi 6.97 import weight 0.00
Epoch 499 Iter 8 subLoss 48512.3 multi 21.90 import weight 0.00
Epoch 499 Iter 9 subLoss 48444.8 multi -19.90 import weight 0.00
Epoch 499 Iter 10 subLoss 48714.8 multi 6.97 import weight 0.00
Epoch 499 Iter 11 subLoss 48427.0 multi -7.96 import weight 0.00

======================================================================================================================================================
vanilla scaling 1 Seen / Unseen / ECE 0.1601 / 0.04037 / 1.00
Entropy seen (from low to high)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0]
Entropy unseen (from high to low)
[0, 0, 0, 0, 4861, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Calibration acc (top: base v.s. mid: proposed v.s. bottom: counts)
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[0, 0, 0, 0, 0, 0, 5139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Epoch 499 Acc: 22.09 BMA: 22.09 lr: 2.00E-06 T: 1.00E-01  Weight 0.000 Grad mul -7.96 Pidx 4842 train Loss: 49422.9 test Loss: 8303.8
Sampling Time used: 15780.9
Grad mul
